Log file created at: 2016/06/21 00:56:31
Running on machine: ubuntu
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0621 00:56:31.488334   388 caffe.cpp:99] Use GPU with device ID 1
I0621 00:56:31.812443   388 caffe.cpp:107] Starting Optimization
I0621 00:56:31.812558   388 solver.cpp:32] Initializing solver from parameters: 
test_iter: 1000
test_interval: 500
base_lr: 0.01
display: 1
max_iter: 15000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 7500
snapshot: 500
snapshot_prefix: "./snapshot/latefusion-"
solver_mode: GPU
net: "./latefusion.prototxt"
iter_size: 16
I0621 00:56:31.812644   388 solver.cpp:70] Creating training net from net file: ./latefusion.prototxt
I0621 00:56:31.815337   388 net.cpp:277] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0621 00:56:31.815429   388 net.cpp:277] The NetState phase (0) differed from the phase (1) specified by a rule in layer seg-accuracy
I0621 00:56:31.816098   388 net.cpp:39] Initializing net from parameters: 
name: "train_seg_Full_anno"
layers {
  top: "data"
  top: "data2"
  top: "seg-label"
  top: "cls-label"
  name: "data"
  type: SELECT_SEG_BINARY_TWO_FRAMES
  image_data_param {
    source: "./dataset/train.txt"
    batch_size: 4
    shuffle: true
    new_height: 350
    new_width: 350
    root_folder: "./dataset"
    label_type: PIXEL
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 320
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
  window_cls_data_param {
    label_dim: 20
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_1p1"
  param: "conv1_1p2"
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_2p1"
  param: "conv1_2p2"
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_1p1"
  param: "conv2_1p2"
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_2p1"
  param: "conv2_2p2"
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_1p1"
  param: "conv3_1p2"
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_2p1"
  param: "conv3_2p2"
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_3p1"
  param: "conv3_3p2"
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_1p1"
  param: "conv4_1p2"
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_2p1"
  param: "conv4_2p2"
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_3p1"
  param: "conv4_3p2"
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_1p1"
  param: "conv5_1p2"
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_2p1"
  param: "conv5_2p2"
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_3p1"
  param: "conv5_3p2"
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "data2"
  top: "conv1_1b"
  name: "conv1_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_1p1"
  param: "conv1_1p2"
}
layers {
  bottom: "conv1_1b"
  top: "conv1_1b"
  name: "relu1_1b"
  type: RELU
}
layers {
  bottom: "conv1_1b"
  top: "conv1_2b"
  name: "conv1_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_2p1"
  param: "conv1_2p2"
}
layers {
  bottom: "conv1_2b"
  top: "conv1_2b"
  name: "relu1_2b"
  type: RELU
}
layers {
  bottom: "conv1_2b"
  top: "pool1b"
  name: "pool1b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1b"
  top: "conv2_1b"
  name: "conv2_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_1p1"
  param: "conv2_1p2"
}
layers {
  bottom: "conv2_1b"
  top: "conv2_1b"
  name: "relu2_1b"
  type: RELU
}
layers {
  bottom: "conv2_1b"
  top: "conv2_2b"
  name: "conv2_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_2p1"
  param: "conv2_2p2"
}
layers {
  bottom: "conv2_2b"
  top: "conv2_2b"
  name: "relu2_2b"
  type: RELU
}
layers {
  bottom: "conv2_2b"
  top: "pool2b"
  name: "pool2b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2b"
  top: "conv3_1b"
  name: "conv3_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_1p1"
  param: "conv3_1p2"
}
layers {
  bottom: "conv3_1b"
  top: "conv3_1b"
  name: "relu3_1b"
  type: RELU
}
layers {
  bottom: "conv3_1b"
  top: "conv3_2b"
  name: "conv3_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_2p1"
  param: "conv3_2p2"
}
layers {
  bottom: "conv3_2b"
  top: "conv3_2b"
  name: "relu3_2b"
  type: RELU
}
layers {
  bottom: "conv3_2b"
  top: "conv3_3b"
  name: "conv3_3b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_3p1"
  param: "conv3_3p2"
}
layers {
  bottom: "conv3_3b"
  top: "conv3_3b"
  name: "relu3_3b"
  type: RELU
}
layers {
  bottom: "conv3_3b"
  top: "pool3b"
  name: "pool3b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3b"
  top: "conv4_1b"
  name: "conv4_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_1p1"
  param: "conv4_1p2"
}
layers {
  bottom: "conv4_1b"
  top: "conv4_1b"
  name: "relu4_1b"
  type: RELU
}
layers {
  bottom: "conv4_1b"
  top: "conv4_2b"
  name: "conv4_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_2p1"
  param: "conv4_2p2"
}
layers {
  bottom: "conv4_2b"
  top: "conv4_2b"
  name: "relu4_2b"
  type: RELU
}
layers {
  bottom: "conv4_2b"
  top: "conv4_3b"
  name: "conv4_3b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_3p1"
  param: "conv4_3p2"
}
layers {
  bottom: "conv4_3b"
  top: "conv4_3b"
  name: "relu4_3b"
  type: RELU
}
layers {
  bottom: "conv4_3b"
  top: "pool4b"
  name: "pool4b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4b"
  top: "conv5_1b"
  name: "conv5_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_1p1"
  param: "conv5_1p2"
}
layers {
  bottom: "conv5_1b"
  top: "conv5_1b"
  name: "relu5_1b"
  type: RELU
}
layers {
  bottom: "conv5_1b"
  top: "conv5_2b"
  name: "conv5_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_2p1"
  param: "conv5_2p2"
}
layers {
  bottom: "conv5_2b"
  top: "conv5_2b"
  name: "relu5_2b"
  type: RELU
}
layers {
  bottom: "conv5_2b"
  top: "conv5_3b"
  name: "conv5_3b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_3p1"
  param: "conv5_3p2"
}
layers {
  bottom: "conv5_3b"
  top: "conv5_3b"
  name: "relu5_3b"
  type: RELU
}
layers {
  bottom: "conv5_3b"
  top: "pool5b"
  name: "pool5b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 7
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  top: "relu6-mask"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  top: "relu7-mask"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "cls-score"
  name: "cls-score-voc"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 20
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "cls-score"
  top: "cls-score-pooled"
  top: "score-pool-mask"
  name: "avg-pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 1
  }
}
layers {
  bottom: "cls-score-pooled"
  top: "cls-score-sigmoid"
  name: "cls-score-sigmoid"
  type: SIGMOID
}
layers {
  bottom: "cls-score-sigmoid"
  bottom: "cls-label"
  top: "cls-score-masked"
  name: "cls-score-mask"
  type: ELTWISE
  eltwise_param {
    operation: PROD
  }
}
layers {
  bottom: "cls-score-masked"
  bottom: "score-pool-mask"
  top: "cls-score-unpooled"
  name: "avg-unpool"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 4
    stride: 1
    unpool_size: 4
  }
}
layers {
  bottom: "cls-score-unpooled"
  top: "fc7-bp"
  name: "cls-score-voc-bp"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7-bp"
  bottom: "relu7-mask"
  top: "fc7-bp"
  name: "relu7-mask"
  type: ELTWISE
  eltwise_param {
    operation: PROD
  }
}
layers {
  bottom: "fc7-bp"
  top: "fc6-bp"
  name: "fc7-bp"
  type: DECONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layers {
  bottom: "fc6-bp"
  bottom: "relu6-mask"
  top: "fc6-bp"
  name: "relu6-mask"
  type: ELTWISE
  eltwise_param {
    operation: PROD
  }
}
layers {
  bottom: "fc6-bp"
  top: "pool5-bp"
  name: "fc6-bp"
  type: DECONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    kernel_size: 7
  }
}
layers {
  bottom: "pool5"
  top: "pool5-bn"
  name: "pool5-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "pool5b"
  top: "pool5b-bn"
  name: "pool5b-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "pool5-bp"
  top: "pool5-bp-bn"
  name: "pool5-bp-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "pool5-bn"
  bottom: "pool5b-bn"
  bottom: "pool5-bp-bn"
  top: "pool5-concat"
  name: "pool5-concat"
  type: CONCAT
}
layers {
  bottom: "pool5-concat"
  top: "fc6-seg"
  name: "fc6-seg"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 2048
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6-seg"
  top: "fc6-seg"
  name: "bnfc6-seg"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "fc6-seg"
  top: "fc6-seg"
  name: "relu6-seg"
  type: RELU
}
layers {
  bottom: "fc6-seg"
  top: "fc7-seg"
  name: "fc7-seg"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 2048
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7-seg"
  top: "fc7-seg"
  name: "bnfc7-seg"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "fc7-seg"
  top: "fc7-seg"
  name: "relu7-seg"
  type: RELU
}
layers {
  bottom: "fc7-seg"
  top: "fc6-deconv"
  name: "fc6-deconv"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6-deconv"
  top: "fc6-deconv"
  name: "fc6-deconv-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "fc6-deconv"
  top: "fc6-deconv"
  name: "fc6-deconv-relu"
  type: RELU
}
layers {
  bottom: "fc6-deconv"
  bottom: "pool5_mask"
  top: "unpool5"
  name: "unpool5"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 20
  }
}
layers {
  bottom: "unpool5"
  top: "deconv5_1"
  name: "deconv5_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv5_1"
  top: "deconv5_1"
  name: "debn5_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv5_1"
  top: "deconv5_1"
  name: "derelu5_1"
  type: RELU
}
layers {
  bottom: "deconv5_1"
  top: "deconv5_2"
  name: "deconv5_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv5_2"
  top: "deconv5_2"
  name: "debn5_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv5_2"
  top: "deconv5_2"
  name: "derelu5_2"
  type: RELU
}
layers {
  bottom: "deconv5_2"
  top: "deconv5_3"
  name: "deconv5_3"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv5_3"
  top: "deconv5_3"
  name: "debn5_3"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv5_3"
  top: "deconv5_3"
  name: "derelu5_3"
  type: RELU
}
layers {
  bottom: "deconv5_3"
  bottom: "pool4_mask"
  top: "unpool4"
  name: "unpool4"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 40
  }
}
layers {
  bottom: "unpool4"
  top: "deconv4_1"
  name: "deconv4_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv4_1"
  top: "deconv4_1"
  name: "debn4_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv4_1"
  top: "deconv4_1"
  name: "derelu4_1"
  type: RELU
}
layers {
  bottom: "deconv4_1"
  top: "deconv4_2"
  name: "deconv4_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv4_2"
  top: "deconv4_2"
  name: "debn4_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv4_2"
  top: "deconv4_2"
  name: "derelu4_2"
  type: RELU
}
layers {
  bottom: "deconv4_2"
  top: "deconv4_3"
  name: "deconv4_3"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv4_3"
  top: "deconv4_3"
  name: "debn4_3"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv4_3"
  top: "deconv4_3"
  name: "derelu4_3"
  type: RELU
}
layers {
  bottom: "deconv4_3"
  bottom: "pool3_mask"
  top: "unpool3"
  name: "unpool3"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 80
  }
}
layers {
  bottom: "unpool3"
  top: "deconv3_1"
  name: "deconv3_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv3_1"
  top: "deconv3_1"
  name: "debn3_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv3_1"
  top: "deconv3_1"
  name: "derelu3_1"
  type: RELU
}
layers {
  bottom: "deconv3_1"
  top: "deconv3_2"
  name: "deconv3_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv3_2"
  top: "deconv3_2"
  name: "debn3_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv3_2"
  top: "deconv3_2"
  name: "derelu3_2"
  type: RELU
}
layers {
  bottom: "deconv3_2"
  top: "deconv3_3"
  name: "deconv3_3"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv3_3"
  top: "deconv3_3"
  name: "debn3_3"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv3_3"
  top: "deconv3_3"
  name: "derelu3_3"
  type: RELU
}
layers {
  bottom: "deconv3_3"
  bottom: "pool2_mask"
  top: "unpool2"
  name: "unpool2"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 160
  }
}
layers {
  bottom: "unpool2"
  top: "deconv2_1"
  name: "deconv2_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv2_1"
  top: "deconv2_1"
  name: "debn2_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv2_1"
  top: "deconv2_1"
  name: "derelu2_1"
  type: RELU
}
layers {
  bottom: "deconv2_1"
  top: "deconv2_2"
  name: "deconv2_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv2_2"
  top: "deconv2_2"
  name: "debn2_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv2_2"
  top: "deconv2_2"
  name: "derelu2_2"
  type: RELU
}
layers {
  bottom: "deconv2_2"
  bottom: "pool1_mask"
  top: "unpool1"
  name: "unpool1"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 320
  }
}
layers {
  bottom: "unpool1"
  top: "deconv1_1"
  name: "deconv1_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv1_1"
  top: "deconv1_1"
  name: "debn1_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv1_1"
  top: "deconv1_1"
  name: "derelu1_1"
  type: RELU
}
layers {
  bottom: "deconv1_1"
  top: "deconv1_2"
  name: "deconv1_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv1_2"
  top: "deconv1_2"
  name: "debn1_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv1_2"
  top: "deconv1_2"
  name: "derelu1_2"
  type: RELU
}
layers {
  bottom: "deconv1_2"
  top: "seg-score"
  name: "seg-score-voc"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 2
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "seg-score"
  bottom: "seg-label"
  top: "seg-loss"
  name: "seg-loss"
  type: SOFTMAX_LOSS
  loss_param {
    ignore_label: 255
  }
}
state {
  phase: TRAIN
}
I0621 00:56:31.821674   388 layer_factory.hpp:78] Creating layer data
I0621 00:56:31.821712   388 net.cpp:69] Creating Layer data
I0621 00:56:31.821723   388 net.cpp:358] data -> data
I0621 00:56:31.821748   388 net.cpp:358] data -> data2
I0621 00:56:31.821763   388 net.cpp:358] data -> seg-label
I0621 00:56:31.821774   388 net.cpp:358] data -> cls-label
I0621 00:56:31.821785   388 net.cpp:98] Setting up data
I0621 00:56:31.821795   388 select_seg_binary_two_frames_layer.cpp:47] Opening file ./dataset/train.txt
I0621 00:56:31.908946   388 select_seg_binary_two_frames_layer.cpp:86] Shuffling data
I0621 00:56:31.919474   388 select_seg_binary_two_frames_layer.cpp:91] A total of 22590 images.
I0621 00:56:32.094297   388 select_seg_binary_two_frames_layer.cpp:146] output data size: 4,3,320,320
I0621 00:56:32.094372   388 select_seg_binary_two_frames_layer.cpp:150] output data2 size: 4,3,320,320
I0621 00:56:32.094383   388 select_seg_binary_two_frames_layer.cpp:154] output label size: 4,1,320,320
I0621 00:56:32.094393   388 select_seg_binary_two_frames_layer.cpp:158] output class label size: 4,20,1,1
I0621 00:56:32.097066   388 net.cpp:105] Top shape: 4 3 320 320 (1228800)
I0621 00:56:32.097090   388 net.cpp:105] Top shape: 4 3 320 320 (1228800)
I0621 00:56:32.097100   388 net.cpp:105] Top shape: 4 1 320 320 (409600)
I0621 00:56:32.097108   388 net.cpp:105] Top shape: 4 20 1 1 (80)
I0621 00:56:32.097118   388 layer_factory.hpp:78] Creating layer conv1_1
I0621 00:56:32.097138   388 net.cpp:69] Creating Layer conv1_1
I0621 00:56:32.097148   388 net.cpp:396] conv1_1 <- data
I0621 00:56:32.097167   388 net.cpp:358] conv1_1 -> conv1_1
I0621 00:56:32.097182   388 net.cpp:98] Setting up conv1_1
I0621 00:56:32.097542   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.097563   388 layer_factory.hpp:78] Creating layer relu1_1
I0621 00:56:32.097581   388 net.cpp:69] Creating Layer relu1_1
I0621 00:56:32.097591   388 net.cpp:396] relu1_1 <- conv1_1
I0621 00:56:32.097604   388 net.cpp:347] relu1_1 -> conv1_1 (in-place)
I0621 00:56:32.097615   388 net.cpp:98] Setting up relu1_1
I0621 00:56:32.097623   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.097632   388 layer_factory.hpp:78] Creating layer conv1_2
I0621 00:56:32.097645   388 net.cpp:69] Creating Layer conv1_2
I0621 00:56:32.097652   388 net.cpp:396] conv1_2 <- conv1_1
I0621 00:56:32.097663   388 net.cpp:358] conv1_2 -> conv1_2
I0621 00:56:32.097674   388 net.cpp:98] Setting up conv1_2
I0621 00:56:32.097970   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.097988   388 layer_factory.hpp:78] Creating layer relu1_2
I0621 00:56:32.098000   388 net.cpp:69] Creating Layer relu1_2
I0621 00:56:32.098007   388 net.cpp:396] relu1_2 <- conv1_2
I0621 00:56:32.098018   388 net.cpp:347] relu1_2 -> conv1_2 (in-place)
I0621 00:56:32.098029   388 net.cpp:98] Setting up relu1_2
I0621 00:56:32.098037   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.098045   388 layer_factory.hpp:78] Creating layer pool1
I0621 00:56:32.098057   388 net.cpp:69] Creating Layer pool1
I0621 00:56:32.098067   388 net.cpp:396] pool1 <- conv1_2
I0621 00:56:32.098076   388 net.cpp:358] pool1 -> pool1
I0621 00:56:32.098088   388 net.cpp:358] pool1 -> pool1_mask
I0621 00:56:32.098099   388 net.cpp:98] Setting up pool1
I0621 00:56:32.098119   388 net.cpp:105] Top shape: 4 64 160 160 (6553600)
I0621 00:56:32.098129   388 net.cpp:105] Top shape: 4 64 160 160 (6553600)
I0621 00:56:32.098137   388 layer_factory.hpp:78] Creating layer conv2_1
I0621 00:56:32.098148   388 net.cpp:69] Creating Layer conv2_1
I0621 00:56:32.098156   388 net.cpp:396] conv2_1 <- pool1
I0621 00:56:32.098167   388 net.cpp:358] conv2_1 -> conv2_1
I0621 00:56:32.098179   388 net.cpp:98] Setting up conv2_1
I0621 00:56:32.098458   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.098475   388 layer_factory.hpp:78] Creating layer relu2_1
I0621 00:56:32.098487   388 net.cpp:69] Creating Layer relu2_1
I0621 00:56:32.098496   388 net.cpp:396] relu2_1 <- conv2_1
I0621 00:56:32.098506   388 net.cpp:347] relu2_1 -> conv2_1 (in-place)
I0621 00:56:32.098516   388 net.cpp:98] Setting up relu2_1
I0621 00:56:32.098525   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.098532   388 layer_factory.hpp:78] Creating layer conv2_2
I0621 00:56:32.098546   388 net.cpp:69] Creating Layer conv2_2
I0621 00:56:32.098554   388 net.cpp:396] conv2_2 <- conv2_1
I0621 00:56:32.098564   388 net.cpp:358] conv2_2 -> conv2_2
I0621 00:56:32.098575   388 net.cpp:98] Setting up conv2_2
I0621 00:56:32.099019   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.099036   388 layer_factory.hpp:78] Creating layer relu2_2
I0621 00:56:32.099047   388 net.cpp:69] Creating Layer relu2_2
I0621 00:56:32.099056   388 net.cpp:396] relu2_2 <- conv2_2
I0621 00:56:32.099076   388 net.cpp:347] relu2_2 -> conv2_2 (in-place)
I0621 00:56:32.099104   388 net.cpp:98] Setting up relu2_2
I0621 00:56:32.099119   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.099128   388 layer_factory.hpp:78] Creating layer pool2
I0621 00:56:32.099138   388 net.cpp:69] Creating Layer pool2
I0621 00:56:32.099145   388 net.cpp:396] pool2 <- conv2_2
I0621 00:56:32.099155   388 net.cpp:358] pool2 -> pool2
I0621 00:56:32.099167   388 net.cpp:358] pool2 -> pool2_mask
I0621 00:56:32.099179   388 net.cpp:98] Setting up pool2
I0621 00:56:32.099189   388 net.cpp:105] Top shape: 4 128 80 80 (3276800)
I0621 00:56:32.099197   388 net.cpp:105] Top shape: 4 128 80 80 (3276800)
I0621 00:56:32.099205   388 layer_factory.hpp:78] Creating layer conv3_1
I0621 00:56:32.099215   388 net.cpp:69] Creating Layer conv3_1
I0621 00:56:32.099223   388 net.cpp:396] conv3_1 <- pool2
I0621 00:56:32.099234   388 net.cpp:358] conv3_1 -> conv3_1
I0621 00:56:32.099244   388 net.cpp:98] Setting up conv3_1
I0621 00:56:32.100122   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.100143   388 layer_factory.hpp:78] Creating layer relu3_1
I0621 00:56:32.100154   388 net.cpp:69] Creating Layer relu3_1
I0621 00:56:32.100163   388 net.cpp:396] relu3_1 <- conv3_1
I0621 00:56:32.100173   388 net.cpp:347] relu3_1 -> conv3_1 (in-place)
I0621 00:56:32.100183   388 net.cpp:98] Setting up relu3_1
I0621 00:56:32.100191   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.100199   388 layer_factory.hpp:78] Creating layer conv3_2
I0621 00:56:32.100209   388 net.cpp:69] Creating Layer conv3_2
I0621 00:56:32.100217   388 net.cpp:396] conv3_2 <- conv3_1
I0621 00:56:32.100227   388 net.cpp:358] conv3_2 -> conv3_2
I0621 00:56:32.100239   388 net.cpp:98] Setting up conv3_2
I0621 00:56:32.101662   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.101682   388 layer_factory.hpp:78] Creating layer relu3_2
I0621 00:56:32.101693   388 net.cpp:69] Creating Layer relu3_2
I0621 00:56:32.101702   388 net.cpp:396] relu3_2 <- conv3_2
I0621 00:56:32.101714   388 net.cpp:347] relu3_2 -> conv3_2 (in-place)
I0621 00:56:32.101724   388 net.cpp:98] Setting up relu3_2
I0621 00:56:32.101732   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.101740   388 layer_factory.hpp:78] Creating layer conv3_3
I0621 00:56:32.101750   388 net.cpp:69] Creating Layer conv3_3
I0621 00:56:32.101759   388 net.cpp:396] conv3_3 <- conv3_2
I0621 00:56:32.101769   388 net.cpp:358] conv3_3 -> conv3_3
I0621 00:56:32.101780   388 net.cpp:98] Setting up conv3_3
I0621 00:56:32.104729   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.104779   388 layer_factory.hpp:78] Creating layer relu3_3
I0621 00:56:32.104797   388 net.cpp:69] Creating Layer relu3_3
I0621 00:56:32.104809   388 net.cpp:396] relu3_3 <- conv3_3
I0621 00:56:32.104821   388 net.cpp:347] relu3_3 -> conv3_3 (in-place)
I0621 00:56:32.104833   388 net.cpp:98] Setting up relu3_3
I0621 00:56:32.104842   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.104851   388 layer_factory.hpp:78] Creating layer pool3
I0621 00:56:32.104862   388 net.cpp:69] Creating Layer pool3
I0621 00:56:32.104871   388 net.cpp:396] pool3 <- conv3_3
I0621 00:56:32.104882   388 net.cpp:358] pool3 -> pool3
I0621 00:56:32.104894   388 net.cpp:358] pool3 -> pool3_mask
I0621 00:56:32.104909   388 net.cpp:98] Setting up pool3
I0621 00:56:32.104921   388 net.cpp:105] Top shape: 4 256 40 40 (1638400)
I0621 00:56:32.104931   388 net.cpp:105] Top shape: 4 256 40 40 (1638400)
I0621 00:56:32.104939   388 layer_factory.hpp:78] Creating layer conv4_1
I0621 00:56:32.104951   388 net.cpp:69] Creating Layer conv4_1
I0621 00:56:32.104960   388 net.cpp:396] conv4_1 <- pool3
I0621 00:56:32.104972   388 net.cpp:358] conv4_1 -> conv4_1
I0621 00:56:32.104985   388 net.cpp:98] Setting up conv4_1
I0621 00:56:32.108927   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.108974   388 layer_factory.hpp:78] Creating layer relu4_1
I0621 00:56:32.108991   388 net.cpp:69] Creating Layer relu4_1
I0621 00:56:32.109035   388 net.cpp:396] relu4_1 <- conv4_1
I0621 00:56:32.109052   388 net.cpp:347] relu4_1 -> conv4_1 (in-place)
I0621 00:56:32.109072   388 net.cpp:98] Setting up relu4_1
I0621 00:56:32.109086   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.109096   388 layer_factory.hpp:78] Creating layer conv4_2
I0621 00:56:32.109112   388 net.cpp:69] Creating Layer conv4_2
I0621 00:56:32.109127   388 net.cpp:396] conv4_2 <- conv4_1
I0621 00:56:32.109144   388 net.cpp:358] conv4_2 -> conv4_2
I0621 00:56:32.109161   388 net.cpp:98] Setting up conv4_2
I0621 00:56:32.113557   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.113600   388 layer_factory.hpp:78] Creating layer relu4_2
I0621 00:56:32.113615   388 net.cpp:69] Creating Layer relu4_2
I0621 00:56:32.113626   388 net.cpp:396] relu4_2 <- conv4_2
I0621 00:56:32.113639   388 net.cpp:347] relu4_2 -> conv4_2 (in-place)
I0621 00:56:32.113651   388 net.cpp:98] Setting up relu4_2
I0621 00:56:32.113661   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.113668   388 layer_factory.hpp:78] Creating layer conv4_3
I0621 00:56:32.113679   388 net.cpp:69] Creating Layer conv4_3
I0621 00:56:32.113688   388 net.cpp:396] conv4_3 <- conv4_2
I0621 00:56:32.113698   388 net.cpp:358] conv4_3 -> conv4_3
I0621 00:56:32.113709   388 net.cpp:98] Setting up conv4_3
I0621 00:56:32.120000   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.120054   388 layer_factory.hpp:78] Creating layer relu4_3
I0621 00:56:32.120069   388 net.cpp:69] Creating Layer relu4_3
I0621 00:56:32.120080   388 net.cpp:396] relu4_3 <- conv4_3
I0621 00:56:32.120093   388 net.cpp:347] relu4_3 -> conv4_3 (in-place)
I0621 00:56:32.120105   388 net.cpp:98] Setting up relu4_3
I0621 00:56:32.120115   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.120123   388 layer_factory.hpp:78] Creating layer pool4
I0621 00:56:32.120134   388 net.cpp:69] Creating Layer pool4
I0621 00:56:32.120142   388 net.cpp:396] pool4 <- conv4_3
I0621 00:56:32.120153   388 net.cpp:358] pool4 -> pool4
I0621 00:56:32.120169   388 net.cpp:358] pool4 -> pool4_mask
I0621 00:56:32.120182   388 net.cpp:98] Setting up pool4
I0621 00:56:32.120193   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.120201   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.120209   388 layer_factory.hpp:78] Creating layer conv5_1
I0621 00:56:32.120220   388 net.cpp:69] Creating Layer conv5_1
I0621 00:56:32.120229   388 net.cpp:396] conv5_1 <- pool4
I0621 00:56:32.120241   388 net.cpp:358] conv5_1 -> conv5_1
I0621 00:56:32.120252   388 net.cpp:98] Setting up conv5_1
I0621 00:56:32.126261   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.126309   388 layer_factory.hpp:78] Creating layer relu5_1
I0621 00:56:32.126323   388 net.cpp:69] Creating Layer relu5_1
I0621 00:56:32.126334   388 net.cpp:396] relu5_1 <- conv5_1
I0621 00:56:32.126349   388 net.cpp:347] relu5_1 -> conv5_1 (in-place)
I0621 00:56:32.126361   388 net.cpp:98] Setting up relu5_1
I0621 00:56:32.126371   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.126379   388 layer_factory.hpp:78] Creating layer conv5_2
I0621 00:56:32.126392   388 net.cpp:69] Creating Layer conv5_2
I0621 00:56:32.126400   388 net.cpp:396] conv5_2 <- conv5_1
I0621 00:56:32.126411   388 net.cpp:358] conv5_2 -> conv5_2
I0621 00:56:32.126423   388 net.cpp:98] Setting up conv5_2
I0621 00:56:32.133908   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.133960   388 layer_factory.hpp:78] Creating layer relu5_2
I0621 00:56:32.133980   388 net.cpp:69] Creating Layer relu5_2
I0621 00:56:32.133991   388 net.cpp:396] relu5_2 <- conv5_2
I0621 00:56:32.134003   388 net.cpp:347] relu5_2 -> conv5_2 (in-place)
I0621 00:56:32.134017   388 net.cpp:98] Setting up relu5_2
I0621 00:56:32.134027   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.134034   388 layer_factory.hpp:78] Creating layer conv5_3
I0621 00:56:32.134047   388 net.cpp:69] Creating Layer conv5_3
I0621 00:56:32.134054   388 net.cpp:396] conv5_3 <- conv5_2
I0621 00:56:32.134093   388 net.cpp:358] conv5_3 -> conv5_3
I0621 00:56:32.134106   388 net.cpp:98] Setting up conv5_3
I0621 00:56:32.138439   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.138469   388 layer_factory.hpp:78] Creating layer relu5_3
I0621 00:56:32.138481   388 net.cpp:69] Creating Layer relu5_3
I0621 00:56:32.138491   388 net.cpp:396] relu5_3 <- conv5_3
I0621 00:56:32.138502   388 net.cpp:347] relu5_3 -> conv5_3 (in-place)
I0621 00:56:32.138514   388 net.cpp:98] Setting up relu5_3
I0621 00:56:32.138522   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.138531   388 layer_factory.hpp:78] Creating layer pool5
I0621 00:56:32.138541   388 net.cpp:69] Creating Layer pool5
I0621 00:56:32.138550   388 net.cpp:396] pool5 <- conv5_3
I0621 00:56:32.138561   388 net.cpp:358] pool5 -> pool5
I0621 00:56:32.138573   388 net.cpp:358] pool5 -> pool5_mask
I0621 00:56:32.138586   388 net.cpp:98] Setting up pool5
I0621 00:56:32.138597   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.138605   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.138613   388 layer_factory.hpp:78] Creating layer pool5_pool5_0_split
I0621 00:56:32.138633   388 net.cpp:69] Creating Layer pool5_pool5_0_split
I0621 00:56:32.138643   388 net.cpp:396] pool5_pool5_0_split <- pool5
I0621 00:56:32.138653   388 net.cpp:358] pool5_pool5_0_split -> pool5_pool5_0_split_0
I0621 00:56:32.138664   388 net.cpp:358] pool5_pool5_0_split -> pool5_pool5_0_split_1
I0621 00:56:32.138675   388 net.cpp:98] Setting up pool5_pool5_0_split
I0621 00:56:32.138685   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.138695   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.138706   388 layer_factory.hpp:78] Creating layer conv1_1b
I0621 00:56:32.138717   388 net.cpp:69] Creating Layer conv1_1b
I0621 00:56:32.138725   388 net.cpp:396] conv1_1b <- data2
I0621 00:56:32.138737   388 net.cpp:358] conv1_1b -> conv1_1b
I0621 00:56:32.138748   388 net.cpp:98] Setting up conv1_1b
I0621 00:56:32.139013   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.139029   388 net.cpp:438] Sharing parameters 'conv1_1p1' owned by layer 'conv1_1', param index 0
I0621 00:56:32.139051   388 net.cpp:438] Sharing parameters 'conv1_1p2' owned by layer 'conv1_1', param index 1
I0621 00:56:32.139072   388 layer_factory.hpp:78] Creating layer relu1_1b
I0621 00:56:32.139084   388 net.cpp:69] Creating Layer relu1_1b
I0621 00:56:32.139094   388 net.cpp:396] relu1_1b <- conv1_1b
I0621 00:56:32.139113   388 net.cpp:347] relu1_1b -> conv1_1b (in-place)
I0621 00:56:32.139124   388 net.cpp:98] Setting up relu1_1b
I0621 00:56:32.139133   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.139142   388 layer_factory.hpp:78] Creating layer conv1_2b
I0621 00:56:32.139153   388 net.cpp:69] Creating Layer conv1_2b
I0621 00:56:32.139160   388 net.cpp:396] conv1_2b <- conv1_1b
I0621 00:56:32.139170   388 net.cpp:358] conv1_2b -> conv1_2b
I0621 00:56:32.139180   388 net.cpp:98] Setting up conv1_2b
I0621 00:56:32.141109   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.141165   388 net.cpp:438] Sharing parameters 'conv1_2p1' owned by layer 'conv1_2', param index 0
I0621 00:56:32.141178   388 net.cpp:438] Sharing parameters 'conv1_2p2' owned by layer 'conv1_2', param index 1
I0621 00:56:32.141190   388 layer_factory.hpp:78] Creating layer relu1_2b
I0621 00:56:32.141206   388 net.cpp:69] Creating Layer relu1_2b
I0621 00:56:32.141217   388 net.cpp:396] relu1_2b <- conv1_2b
I0621 00:56:32.141229   388 net.cpp:347] relu1_2b -> conv1_2b (in-place)
I0621 00:56:32.141242   388 net.cpp:98] Setting up relu1_2b
I0621 00:56:32.141252   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:32.141259   388 layer_factory.hpp:78] Creating layer pool1b
I0621 00:56:32.141270   388 net.cpp:69] Creating Layer pool1b
I0621 00:56:32.141278   388 net.cpp:396] pool1b <- conv1_2b
I0621 00:56:32.141289   388 net.cpp:358] pool1b -> pool1b
I0621 00:56:32.141302   388 net.cpp:98] Setting up pool1b
I0621 00:56:32.141345   388 net.cpp:105] Top shape: 4 64 160 160 (6553600)
I0621 00:56:32.141355   388 layer_factory.hpp:78] Creating layer conv2_1b
I0621 00:56:32.141366   388 net.cpp:69] Creating Layer conv2_1b
I0621 00:56:32.141376   388 net.cpp:396] conv2_1b <- pool1b
I0621 00:56:32.141386   388 net.cpp:358] conv2_1b -> conv2_1b
I0621 00:56:32.141404   388 net.cpp:98] Setting up conv2_1b
I0621 00:56:32.141636   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.141659   388 net.cpp:438] Sharing parameters 'conv2_1p1' owned by layer 'conv2_1', param index 0
I0621 00:56:32.141670   388 net.cpp:438] Sharing parameters 'conv2_1p2' owned by layer 'conv2_1', param index 1
I0621 00:56:32.141680   388 layer_factory.hpp:78] Creating layer relu2_1b
I0621 00:56:32.141690   388 net.cpp:69] Creating Layer relu2_1b
I0621 00:56:32.141700   388 net.cpp:396] relu2_1b <- conv2_1b
I0621 00:56:32.141710   388 net.cpp:347] relu2_1b -> conv2_1b (in-place)
I0621 00:56:32.141721   388 net.cpp:98] Setting up relu2_1b
I0621 00:56:32.141729   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.141738   388 layer_factory.hpp:78] Creating layer conv2_2b
I0621 00:56:32.141752   388 net.cpp:69] Creating Layer conv2_2b
I0621 00:56:32.141760   388 net.cpp:396] conv2_2b <- conv2_1b
I0621 00:56:32.141772   388 net.cpp:358] conv2_2b -> conv2_2b
I0621 00:56:32.141785   388 net.cpp:98] Setting up conv2_2b
I0621 00:56:32.142158   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.142202   388 net.cpp:438] Sharing parameters 'conv2_2p1' owned by layer 'conv2_2', param index 0
I0621 00:56:32.142215   388 net.cpp:438] Sharing parameters 'conv2_2p2' owned by layer 'conv2_2', param index 1
I0621 00:56:32.142225   388 layer_factory.hpp:78] Creating layer relu2_2b
I0621 00:56:32.142240   388 net.cpp:69] Creating Layer relu2_2b
I0621 00:56:32.142248   388 net.cpp:396] relu2_2b <- conv2_2b
I0621 00:56:32.142261   388 net.cpp:347] relu2_2b -> conv2_2b (in-place)
I0621 00:56:32.142272   388 net.cpp:98] Setting up relu2_2b
I0621 00:56:32.142280   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:32.142289   388 layer_factory.hpp:78] Creating layer pool2b
I0621 00:56:32.142299   388 net.cpp:69] Creating Layer pool2b
I0621 00:56:32.142308   388 net.cpp:396] pool2b <- conv2_2b
I0621 00:56:32.142318   388 net.cpp:358] pool2b -> pool2b
I0621 00:56:32.142330   388 net.cpp:98] Setting up pool2b
I0621 00:56:32.142341   388 net.cpp:105] Top shape: 4 128 80 80 (3276800)
I0621 00:56:32.142350   388 layer_factory.hpp:78] Creating layer conv3_1b
I0621 00:56:32.142362   388 net.cpp:69] Creating Layer conv3_1b
I0621 00:56:32.142370   388 net.cpp:396] conv3_1b <- pool2b
I0621 00:56:32.142381   388 net.cpp:358] conv3_1b -> conv3_1b
I0621 00:56:32.142392   388 net.cpp:98] Setting up conv3_1b
I0621 00:56:32.144515   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.144584   388 net.cpp:438] Sharing parameters 'conv3_1p1' owned by layer 'conv3_1', param index 0
I0621 00:56:32.144598   388 net.cpp:438] Sharing parameters 'conv3_1p2' owned by layer 'conv3_1', param index 1
I0621 00:56:32.144611   388 layer_factory.hpp:78] Creating layer relu3_1b
I0621 00:56:32.144624   388 net.cpp:69] Creating Layer relu3_1b
I0621 00:56:32.144635   388 net.cpp:396] relu3_1b <- conv3_1b
I0621 00:56:32.144646   388 net.cpp:347] relu3_1b -> conv3_1b (in-place)
I0621 00:56:32.144659   388 net.cpp:98] Setting up relu3_1b
I0621 00:56:32.144668   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.144676   388 layer_factory.hpp:78] Creating layer conv3_2b
I0621 00:56:32.144688   388 net.cpp:69] Creating Layer conv3_2b
I0621 00:56:32.144697   388 net.cpp:396] conv3_2b <- conv3_1b
I0621 00:56:32.144707   388 net.cpp:358] conv3_2b -> conv3_2b
I0621 00:56:32.144718   388 net.cpp:98] Setting up conv3_2b
I0621 00:56:32.146261   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.146306   388 net.cpp:438] Sharing parameters 'conv3_2p1' owned by layer 'conv3_2', param index 0
I0621 00:56:32.146616   388 net.cpp:438] Sharing parameters 'conv3_2p2' owned by layer 'conv3_2', param index 1
I0621 00:56:32.146661   388 layer_factory.hpp:78] Creating layer relu3_2b
I0621 00:56:32.146682   388 net.cpp:69] Creating Layer relu3_2b
I0621 00:56:32.146716   388 net.cpp:396] relu3_2b <- conv3_2b
I0621 00:56:32.146739   388 net.cpp:347] relu3_2b -> conv3_2b (in-place)
I0621 00:56:32.146752   388 net.cpp:98] Setting up relu3_2b
I0621 00:56:32.146764   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.146772   388 layer_factory.hpp:78] Creating layer conv3_3b
I0621 00:56:32.146787   388 net.cpp:69] Creating Layer conv3_3b
I0621 00:56:32.146795   388 net.cpp:396] conv3_3b <- conv3_2b
I0621 00:56:32.146807   388 net.cpp:358] conv3_3b -> conv3_3b
I0621 00:56:32.146818   388 net.cpp:98] Setting up conv3_3b
I0621 00:56:32.147915   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.147936   388 net.cpp:438] Sharing parameters 'conv3_3p1' owned by layer 'conv3_3', param index 0
I0621 00:56:32.147948   388 net.cpp:438] Sharing parameters 'conv3_3p2' owned by layer 'conv3_3', param index 1
I0621 00:56:32.147958   388 layer_factory.hpp:78] Creating layer relu3_3b
I0621 00:56:32.147969   388 net.cpp:69] Creating Layer relu3_3b
I0621 00:56:32.147977   388 net.cpp:396] relu3_3b <- conv3_3b
I0621 00:56:32.147989   388 net.cpp:347] relu3_3b -> conv3_3b (in-place)
I0621 00:56:32.147999   388 net.cpp:98] Setting up relu3_3b
I0621 00:56:32.148007   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:32.148016   388 layer_factory.hpp:78] Creating layer pool3b
I0621 00:56:32.148028   388 net.cpp:69] Creating Layer pool3b
I0621 00:56:32.148036   388 net.cpp:396] pool3b <- conv3_3b
I0621 00:56:32.148047   388 net.cpp:358] pool3b -> pool3b
I0621 00:56:32.148058   388 net.cpp:98] Setting up pool3b
I0621 00:56:32.148068   388 net.cpp:105] Top shape: 4 256 40 40 (1638400)
I0621 00:56:32.148077   388 layer_factory.hpp:78] Creating layer conv4_1b
I0621 00:56:32.148089   388 net.cpp:69] Creating Layer conv4_1b
I0621 00:56:32.148097   388 net.cpp:396] conv4_1b <- pool3b
I0621 00:56:32.148108   388 net.cpp:358] conv4_1b -> conv4_1b
I0621 00:56:32.148119   388 net.cpp:98] Setting up conv4_1b
I0621 00:56:32.151757   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.151811   388 net.cpp:438] Sharing parameters 'conv4_1p1' owned by layer 'conv4_1', param index 0
I0621 00:56:32.152036   388 net.cpp:438] Sharing parameters 'conv4_1p2' owned by layer 'conv4_1', param index 1
I0621 00:56:32.152057   388 layer_factory.hpp:78] Creating layer relu4_1b
I0621 00:56:32.152076   388 net.cpp:69] Creating Layer relu4_1b
I0621 00:56:32.152092   388 net.cpp:396] relu4_1b <- conv4_1b
I0621 00:56:32.152110   388 net.cpp:347] relu4_1b -> conv4_1b (in-place)
I0621 00:56:32.152139   388 net.cpp:98] Setting up relu4_1b
I0621 00:56:32.152163   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.152179   388 layer_factory.hpp:78] Creating layer conv4_2b
I0621 00:56:32.152199   388 net.cpp:69] Creating Layer conv4_2b
I0621 00:56:32.152216   388 net.cpp:396] conv4_2b <- conv4_1b
I0621 00:56:32.152247   388 net.cpp:358] conv4_2b -> conv4_2b
I0621 00:56:32.152276   388 net.cpp:98] Setting up conv4_2b
I0621 00:56:32.158769   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.158815   388 net.cpp:438] Sharing parameters 'conv4_2p1' owned by layer 'conv4_2', param index 0
I0621 00:56:32.159049   388 net.cpp:438] Sharing parameters 'conv4_2p2' owned by layer 'conv4_2', param index 1
I0621 00:56:32.159076   388 layer_factory.hpp:78] Creating layer relu4_2b
I0621 00:56:32.159091   388 net.cpp:69] Creating Layer relu4_2b
I0621 00:56:32.159103   388 net.cpp:396] relu4_2b <- conv4_2b
I0621 00:56:32.159114   388 net.cpp:347] relu4_2b -> conv4_2b (in-place)
I0621 00:56:32.159127   388 net.cpp:98] Setting up relu4_2b
I0621 00:56:32.159137   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.159147   388 layer_factory.hpp:78] Creating layer conv4_3b
I0621 00:56:32.159159   388 net.cpp:69] Creating Layer conv4_3b
I0621 00:56:32.159193   388 net.cpp:396] conv4_3b <- conv4_2b
I0621 00:56:32.159205   388 net.cpp:358] conv4_3b -> conv4_3b
I0621 00:56:32.159217   388 net.cpp:98] Setting up conv4_3b
I0621 00:56:32.166420   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.166476   388 net.cpp:438] Sharing parameters 'conv4_3p1' owned by layer 'conv4_3', param index 0
I0621 00:56:32.166488   388 net.cpp:438] Sharing parameters 'conv4_3p2' owned by layer 'conv4_3', param index 1
I0621 00:56:32.166499   388 layer_factory.hpp:78] Creating layer relu4_3b
I0621 00:56:32.166514   388 net.cpp:69] Creating Layer relu4_3b
I0621 00:56:32.166524   388 net.cpp:396] relu4_3b <- conv4_3b
I0621 00:56:32.166537   388 net.cpp:347] relu4_3b -> conv4_3b (in-place)
I0621 00:56:32.166548   388 net.cpp:98] Setting up relu4_3b
I0621 00:56:32.166558   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:32.166568   388 layer_factory.hpp:78] Creating layer pool4b
I0621 00:56:32.166577   388 net.cpp:69] Creating Layer pool4b
I0621 00:56:32.166586   388 net.cpp:396] pool4b <- conv4_3b
I0621 00:56:32.166597   388 net.cpp:358] pool4b -> pool4b
I0621 00:56:32.166648   388 net.cpp:98] Setting up pool4b
I0621 00:56:32.166661   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.166671   388 layer_factory.hpp:78] Creating layer conv5_1b
I0621 00:56:32.166683   388 net.cpp:69] Creating Layer conv5_1b
I0621 00:56:32.166692   388 net.cpp:396] conv5_1b <- pool4b
I0621 00:56:32.166704   388 net.cpp:358] conv5_1b -> conv5_1b
I0621 00:56:32.166717   388 net.cpp:98] Setting up conv5_1b
I0621 00:56:32.168567   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.168587   388 net.cpp:438] Sharing parameters 'conv5_1p1' owned by layer 'conv5_1', param index 0
I0621 00:56:32.168597   388 net.cpp:438] Sharing parameters 'conv5_1p2' owned by layer 'conv5_1', param index 1
I0621 00:56:32.168606   388 layer_factory.hpp:78] Creating layer relu5_1b
I0621 00:56:32.168618   388 net.cpp:69] Creating Layer relu5_1b
I0621 00:56:32.168632   388 net.cpp:396] relu5_1b <- conv5_1b
I0621 00:56:32.168642   388 net.cpp:347] relu5_1b -> conv5_1b (in-place)
I0621 00:56:32.168653   388 net.cpp:98] Setting up relu5_1b
I0621 00:56:32.168661   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.168669   388 layer_factory.hpp:78] Creating layer conv5_2b
I0621 00:56:32.168680   388 net.cpp:69] Creating Layer conv5_2b
I0621 00:56:32.168689   388 net.cpp:396] conv5_2b <- conv5_1b
I0621 00:56:32.168699   388 net.cpp:358] conv5_2b -> conv5_2b
I0621 00:56:32.168709   388 net.cpp:98] Setting up conv5_2b
I0621 00:56:32.172184   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.172235   388 net.cpp:438] Sharing parameters 'conv5_2p1' owned by layer 'conv5_2', param index 0
I0621 00:56:32.172246   388 net.cpp:438] Sharing parameters 'conv5_2p2' owned by layer 'conv5_2', param index 1
I0621 00:56:32.172256   388 layer_factory.hpp:78] Creating layer relu5_2b
I0621 00:56:32.172271   388 net.cpp:69] Creating Layer relu5_2b
I0621 00:56:32.173668   388 net.cpp:396] relu5_2b <- conv5_2b
I0621 00:56:32.173743   388 net.cpp:347] relu5_2b -> conv5_2b (in-place)
I0621 00:56:32.173765   388 net.cpp:98] Setting up relu5_2b
I0621 00:56:32.173774   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.173784   388 layer_factory.hpp:78] Creating layer conv5_3b
I0621 00:56:32.173799   388 net.cpp:69] Creating Layer conv5_3b
I0621 00:56:32.173809   388 net.cpp:396] conv5_3b <- conv5_2b
I0621 00:56:32.173821   388 net.cpp:358] conv5_3b -> conv5_3b
I0621 00:56:32.173837   388 net.cpp:98] Setting up conv5_3b
I0621 00:56:32.176364   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.176406   388 net.cpp:438] Sharing parameters 'conv5_3p1' owned by layer 'conv5_3', param index 0
I0621 00:56:32.176419   388 net.cpp:438] Sharing parameters 'conv5_3p2' owned by layer 'conv5_3', param index 1
I0621 00:56:32.176429   388 layer_factory.hpp:78] Creating layer relu5_3b
I0621 00:56:32.176442   388 net.cpp:69] Creating Layer relu5_3b
I0621 00:56:32.176481   388 net.cpp:396] relu5_3b <- conv5_3b
I0621 00:56:32.176492   388 net.cpp:347] relu5_3b -> conv5_3b (in-place)
I0621 00:56:32.176506   388 net.cpp:98] Setting up relu5_3b
I0621 00:56:32.176513   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:32.176522   388 layer_factory.hpp:78] Creating layer pool5b
I0621 00:56:32.176532   388 net.cpp:69] Creating Layer pool5b
I0621 00:56:32.176540   388 net.cpp:396] pool5b <- conv5_3b
I0621 00:56:32.176551   388 net.cpp:358] pool5b -> pool5b
I0621 00:56:32.176563   388 net.cpp:98] Setting up pool5b
I0621 00:56:32.176574   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.176584   388 layer_factory.hpp:78] Creating layer fc6
I0621 00:56:32.176606   388 net.cpp:69] Creating Layer fc6
I0621 00:56:32.176616   388 net.cpp:396] fc6 <- pool5_pool5_0_split_0
I0621 00:56:32.176627   388 net.cpp:358] fc6 -> fc6
I0621 00:56:32.176638   388 net.cpp:98] Setting up fc6
I0621 00:56:32.384042   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.384102   388 layer_factory.hpp:78] Creating layer relu6
I0621 00:56:32.384119   388 net.cpp:69] Creating Layer relu6
I0621 00:56:32.384130   388 net.cpp:396] relu6 <- fc6
I0621 00:56:32.384143   388 net.cpp:347] relu6 -> fc6 (in-place)
I0621 00:56:32.384158   388 net.cpp:358] relu6 -> relu6-mask
I0621 00:56:32.384171   388 net.cpp:98] Setting up relu6
I0621 00:56:32.384181   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.384189   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.384198   388 layer_factory.hpp:78] Creating layer fc7
I0621 00:56:32.384210   388 net.cpp:69] Creating Layer fc7
I0621 00:56:32.384218   388 net.cpp:396] fc7 <- fc6
I0621 00:56:32.384229   388 net.cpp:358] fc7 -> fc7
I0621 00:56:32.384240   388 net.cpp:98] Setting up fc7
I0621 00:56:32.423748   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.423842   388 layer_factory.hpp:78] Creating layer relu7
I0621 00:56:32.423872   388 net.cpp:69] Creating Layer relu7
I0621 00:56:32.423893   388 net.cpp:396] relu7 <- fc7
I0621 00:56:32.423914   388 net.cpp:347] relu7 -> fc7 (in-place)
I0621 00:56:32.423940   388 net.cpp:358] relu7 -> relu7-mask
I0621 00:56:32.423964   388 net.cpp:98] Setting up relu7
I0621 00:56:32.423995   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.424017   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.424028   388 layer_factory.hpp:78] Creating layer cls-score-voc
I0621 00:56:32.424048   388 net.cpp:69] Creating Layer cls-score-voc
I0621 00:56:32.424062   388 net.cpp:396] cls-score-voc <- fc7
I0621 00:56:32.424105   388 net.cpp:358] cls-score-voc -> cls-score
I0621 00:56:32.424162   388 net.cpp:98] Setting up cls-score-voc
I0621 00:56:32.430415   388 net.cpp:105] Top shape: 4 20 4 4 (1280)
I0621 00:56:32.430457   388 layer_factory.hpp:78] Creating layer avg-pool
I0621 00:56:32.430483   388 net.cpp:69] Creating Layer avg-pool
I0621 00:56:32.430502   388 net.cpp:396] avg-pool <- cls-score
I0621 00:56:32.430524   388 net.cpp:358] avg-pool -> cls-score-pooled
I0621 00:56:32.430554   388 net.cpp:358] avg-pool -> score-pool-mask
I0621 00:56:32.430579   388 net.cpp:98] Setting up avg-pool
I0621 00:56:32.430600   388 net.cpp:105] Top shape: 4 20 1 1 (80)
I0621 00:56:32.430618   388 net.cpp:105] Top shape: 4 20 1 1 (80)
I0621 00:56:32.430634   388 layer_factory.hpp:78] Creating layer cls-score-sigmoid
I0621 00:56:32.430654   388 net.cpp:69] Creating Layer cls-score-sigmoid
I0621 00:56:32.430670   388 net.cpp:396] cls-score-sigmoid <- cls-score-pooled
I0621 00:56:32.430703   388 net.cpp:358] cls-score-sigmoid -> cls-score-sigmoid
I0621 00:56:32.430738   388 net.cpp:98] Setting up cls-score-sigmoid
I0621 00:56:32.430752   388 net.cpp:105] Top shape: 4 20 1 1 (80)
I0621 00:56:32.430763   388 layer_factory.hpp:78] Creating layer cls-score-mask
I0621 00:56:32.430780   388 net.cpp:69] Creating Layer cls-score-mask
I0621 00:56:32.430793   388 net.cpp:396] cls-score-mask <- cls-score-sigmoid
I0621 00:56:32.430804   388 net.cpp:396] cls-score-mask <- cls-label
I0621 00:56:32.430861   388 net.cpp:358] cls-score-mask -> cls-score-masked
I0621 00:56:32.430886   388 net.cpp:98] Setting up cls-score-mask
I0621 00:56:32.430899   388 net.cpp:105] Top shape: 4 20 1 1 (80)
I0621 00:56:32.430909   388 layer_factory.hpp:78] Creating layer avg-unpool
I0621 00:56:32.430924   388 net.cpp:69] Creating Layer avg-unpool
I0621 00:56:32.430934   388 net.cpp:396] avg-unpool <- cls-score-masked
I0621 00:56:32.430946   388 net.cpp:396] avg-unpool <- score-pool-mask
I0621 00:56:32.430958   388 net.cpp:358] avg-unpool -> cls-score-unpooled
I0621 00:56:32.430971   388 net.cpp:98] Setting up avg-unpool
I0621 00:56:32.430982   388 net.cpp:105] Top shape: 4 20 4 4 (1280)
I0621 00:56:32.430992   388 layer_factory.hpp:78] Creating layer cls-score-voc-bp
I0621 00:56:32.431007   388 net.cpp:69] Creating Layer cls-score-voc-bp
I0621 00:56:32.431017   388 net.cpp:396] cls-score-voc-bp <- cls-score-unpooled
I0621 00:56:32.431031   388 net.cpp:358] cls-score-voc-bp -> fc7-bp
I0621 00:56:32.431044   388 net.cpp:98] Setting up cls-score-voc-bp
I0621 00:56:32.437077   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.437114   388 layer_factory.hpp:78] Creating layer relu7-mask
I0621 00:56:32.437135   388 net.cpp:69] Creating Layer relu7-mask
I0621 00:56:32.437153   388 net.cpp:396] relu7-mask <- fc7-bp
I0621 00:56:32.437172   388 net.cpp:396] relu7-mask <- relu7-mask
I0621 00:56:32.437191   388 net.cpp:347] relu7-mask -> fc7-bp (in-place)
I0621 00:56:32.437213   388 net.cpp:98] Setting up relu7-mask
I0621 00:56:32.437230   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.437247   388 layer_factory.hpp:78] Creating layer fc7-bp
I0621 00:56:32.437280   388 net.cpp:69] Creating Layer fc7-bp
I0621 00:56:32.437301   388 net.cpp:396] fc7-bp <- fc7-bp
I0621 00:56:32.437321   388 net.cpp:358] fc7-bp -> fc6-bp
I0621 00:56:32.437343   388 net.cpp:98] Setting up fc7-bp
I0621 00:56:32.485285   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.485463   388 layer_factory.hpp:78] Creating layer relu6-mask
I0621 00:56:32.485503   388 net.cpp:69] Creating Layer relu6-mask
I0621 00:56:32.485625   388 net.cpp:396] relu6-mask <- fc6-bp
I0621 00:56:32.485709   388 net.cpp:396] relu6-mask <- relu6-mask
I0621 00:56:32.485739   388 net.cpp:347] relu6-mask -> fc6-bp (in-place)
I0621 00:56:32.485766   388 net.cpp:98] Setting up relu6-mask
I0621 00:56:32.485782   388 net.cpp:105] Top shape: 4 4096 4 4 (262144)
I0621 00:56:32.485795   388 layer_factory.hpp:78] Creating layer fc6-bp
I0621 00:56:32.485822   388 net.cpp:69] Creating Layer fc6-bp
I0621 00:56:32.485836   388 net.cpp:396] fc6-bp <- fc6-bp
I0621 00:56:32.485890   388 net.cpp:358] fc6-bp -> pool5-bp
I0621 00:56:32.485927   388 net.cpp:98] Setting up fc6-bp
I0621 00:56:32.784234   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.784310   388 layer_factory.hpp:78] Creating layer pool5-bn
I0621 00:56:32.784354   388 net.cpp:69] Creating Layer pool5-bn
I0621 00:56:32.784375   388 net.cpp:396] pool5-bn <- pool5_pool5_0_split_1
I0621 00:56:32.784392   388 net.cpp:358] pool5-bn -> pool5-bn
I0621 00:56:32.784415   388 net.cpp:98] Setting up pool5-bn
I0621 00:56:32.784454   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.784813   388 layer_factory.hpp:78] Creating layer pool5b-bn
I0621 00:56:32.784831   388 net.cpp:69] Creating Layer pool5b-bn
I0621 00:56:32.784840   388 net.cpp:396] pool5b-bn <- pool5b
I0621 00:56:32.784855   388 net.cpp:358] pool5b-bn -> pool5b-bn
I0621 00:56:32.784868   388 net.cpp:98] Setting up pool5b-bn
I0621 00:56:32.784900   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.784912   388 layer_factory.hpp:78] Creating layer pool5-bp-bn
I0621 00:56:32.784924   388 net.cpp:69] Creating Layer pool5-bp-bn
I0621 00:56:32.784932   388 net.cpp:396] pool5-bp-bn <- pool5-bp
I0621 00:56:32.784943   388 net.cpp:358] pool5-bp-bn -> pool5-bp-bn
I0621 00:56:32.784955   388 net.cpp:98] Setting up pool5-bp-bn
I0621 00:56:32.784970   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:32.784981   388 layer_factory.hpp:78] Creating layer pool5-concat
I0621 00:56:32.785038   388 net.cpp:69] Creating Layer pool5-concat
I0621 00:56:32.785055   388 net.cpp:396] pool5-concat <- pool5-bn
I0621 00:56:32.785068   388 net.cpp:396] pool5-concat <- pool5b-bn
I0621 00:56:32.785078   388 net.cpp:396] pool5-concat <- pool5-bp-bn
I0621 00:56:32.785099   388 net.cpp:358] pool5-concat -> pool5-concat
I0621 00:56:32.785111   388 net.cpp:98] Setting up pool5-concat
I0621 00:56:32.785121   388 net.cpp:105] Top shape: 4 1536 10 10 (614400)
I0621 00:56:32.785130   388 layer_factory.hpp:78] Creating layer fc6-seg
I0621 00:56:32.785152   388 net.cpp:69] Creating Layer fc6-seg
I0621 00:56:32.785162   388 net.cpp:396] fc6-seg <- pool5-concat
I0621 00:56:32.785173   388 net.cpp:358] fc6-seg -> fc6-seg
I0621 00:56:32.785342   388 net.cpp:98] Setting up fc6-seg
I0621 00:56:38.705054   388 net.cpp:105] Top shape: 4 2048 4 4 (131072)
I0621 00:56:38.705132   388 layer_factory.hpp:78] Creating layer bnfc6-seg
I0621 00:56:38.705155   388 net.cpp:69] Creating Layer bnfc6-seg
I0621 00:56:38.705175   388 net.cpp:396] bnfc6-seg <- fc6-seg
I0621 00:56:38.705188   388 net.cpp:347] bnfc6-seg -> fc6-seg (in-place)
I0621 00:56:38.705200   388 net.cpp:98] Setting up bnfc6-seg
I0621 00:56:38.705220   388 net.cpp:105] Top shape: 4 2048 4 4 (131072)
I0621 00:56:38.705229   388 layer_factory.hpp:78] Creating layer relu6-seg
I0621 00:56:38.705240   388 net.cpp:69] Creating Layer relu6-seg
I0621 00:56:38.705246   388 net.cpp:396] relu6-seg <- fc6-seg
I0621 00:56:38.705255   388 net.cpp:347] relu6-seg -> fc6-seg (in-place)
I0621 00:56:38.705261   388 net.cpp:98] Setting up relu6-seg
I0621 00:56:38.705268   388 net.cpp:105] Top shape: 4 2048 4 4 (131072)
I0621 00:56:38.705274   388 layer_factory.hpp:78] Creating layer fc7-seg
I0621 00:56:38.705286   388 net.cpp:69] Creating Layer fc7-seg
I0621 00:56:38.705292   388 net.cpp:396] fc7-seg <- fc6-seg
I0621 00:56:38.705307   388 net.cpp:358] fc7-seg -> fc7-seg
I0621 00:56:38.705317   388 net.cpp:98] Setting up fc7-seg
I0621 00:56:38.911926   388 net.cpp:105] Top shape: 4 2048 4 4 (131072)
I0621 00:56:38.912036   388 layer_factory.hpp:78] Creating layer bnfc7-seg
I0621 00:56:38.912086   388 net.cpp:69] Creating Layer bnfc7-seg
I0621 00:56:38.912163   388 net.cpp:396] bnfc7-seg <- fc7-seg
I0621 00:56:38.912194   388 net.cpp:347] bnfc7-seg -> fc7-seg (in-place)
I0621 00:56:38.912220   388 net.cpp:98] Setting up bnfc7-seg
I0621 00:56:38.912252   388 net.cpp:105] Top shape: 4 2048 4 4 (131072)
I0621 00:56:38.912268   388 layer_factory.hpp:78] Creating layer relu7-seg
I0621 00:56:38.912286   388 net.cpp:69] Creating Layer relu7-seg
I0621 00:56:38.912294   388 net.cpp:396] relu7-seg <- fc7-seg
I0621 00:56:38.912307   388 net.cpp:347] relu7-seg -> fc7-seg (in-place)
I0621 00:56:38.912322   388 net.cpp:98] Setting up relu7-seg
I0621 00:56:38.912331   388 net.cpp:105] Top shape: 4 2048 4 4 (131072)
I0621 00:56:38.912340   388 layer_factory.hpp:78] Creating layer fc6-deconv
I0621 00:56:38.912354   388 net.cpp:69] Creating Layer fc6-deconv
I0621 00:56:38.912364   388 net.cpp:396] fc6-deconv <- fc7-seg
I0621 00:56:38.912391   388 net.cpp:358] fc6-deconv -> fc6-deconv
I0621 00:56:38.912417   388 net.cpp:98] Setting up fc6-deconv
I0621 00:56:40.588368   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:40.588424   388 layer_factory.hpp:78] Creating layer fc6-deconv-bn
I0621 00:56:40.588443   388 net.cpp:69] Creating Layer fc6-deconv-bn
I0621 00:56:40.588461   388 net.cpp:396] fc6-deconv-bn <- fc6-deconv
I0621 00:56:40.588474   388 net.cpp:347] fc6-deconv-bn -> fc6-deconv (in-place)
I0621 00:56:40.588485   388 net.cpp:98] Setting up fc6-deconv-bn
I0621 00:56:40.588500   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:40.588507   388 layer_factory.hpp:78] Creating layer fc6-deconv-relu
I0621 00:56:40.588518   388 net.cpp:69] Creating Layer fc6-deconv-relu
I0621 00:56:40.588526   388 net.cpp:396] fc6-deconv-relu <- fc6-deconv
I0621 00:56:40.588532   388 net.cpp:347] fc6-deconv-relu -> fc6-deconv (in-place)
I0621 00:56:40.588579   388 net.cpp:98] Setting up fc6-deconv-relu
I0621 00:56:40.588587   388 net.cpp:105] Top shape: 4 512 10 10 (204800)
I0621 00:56:40.588594   388 layer_factory.hpp:78] Creating layer unpool5
I0621 00:56:40.588604   388 net.cpp:69] Creating Layer unpool5
I0621 00:56:40.588610   388 net.cpp:396] unpool5 <- fc6-deconv
I0621 00:56:40.588629   388 net.cpp:396] unpool5 <- pool5_mask
I0621 00:56:40.588645   388 net.cpp:358] unpool5 -> unpool5
I0621 00:56:40.588655   388 net.cpp:98] Setting up unpool5
I0621 00:56:40.588663   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.588670   388 layer_factory.hpp:78] Creating layer deconv5_1
I0621 00:56:40.588680   388 net.cpp:69] Creating Layer deconv5_1
I0621 00:56:40.588685   388 net.cpp:396] deconv5_1 <- unpool5
I0621 00:56:40.588699   388 net.cpp:358] deconv5_1 -> deconv5_1
I0621 00:56:40.588709   388 net.cpp:98] Setting up deconv5_1
I0621 00:56:40.660301   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.660348   388 layer_factory.hpp:78] Creating layer debn5_1
I0621 00:56:40.660367   388 net.cpp:69] Creating Layer debn5_1
I0621 00:56:40.660389   388 net.cpp:396] debn5_1 <- deconv5_1
I0621 00:56:40.660401   388 net.cpp:347] debn5_1 -> deconv5_1 (in-place)
I0621 00:56:40.660413   388 net.cpp:98] Setting up debn5_1
I0621 00:56:40.660431   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.660444   388 layer_factory.hpp:78] Creating layer derelu5_1
I0621 00:56:40.660454   388 net.cpp:69] Creating Layer derelu5_1
I0621 00:56:40.660461   388 net.cpp:396] derelu5_1 <- deconv5_1
I0621 00:56:40.660470   388 net.cpp:347] derelu5_1 -> deconv5_1 (in-place)
I0621 00:56:40.660478   388 net.cpp:98] Setting up derelu5_1
I0621 00:56:40.660485   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.660495   388 layer_factory.hpp:78] Creating layer deconv5_2
I0621 00:56:40.660506   388 net.cpp:69] Creating Layer deconv5_2
I0621 00:56:40.660526   388 net.cpp:396] deconv5_2 <- deconv5_1
I0621 00:56:40.660534   388 net.cpp:358] deconv5_2 -> deconv5_2
I0621 00:56:40.660545   388 net.cpp:98] Setting up deconv5_2
I0621 00:56:40.732003   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.732039   388 layer_factory.hpp:78] Creating layer debn5_2
I0621 00:56:40.732053   388 net.cpp:69] Creating Layer debn5_2
I0621 00:56:40.732062   388 net.cpp:396] debn5_2 <- deconv5_2
I0621 00:56:40.732074   388 net.cpp:347] debn5_2 -> deconv5_2 (in-place)
I0621 00:56:40.732084   388 net.cpp:98] Setting up debn5_2
I0621 00:56:40.732102   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.732111   388 layer_factory.hpp:78] Creating layer derelu5_2
I0621 00:56:40.732121   388 net.cpp:69] Creating Layer derelu5_2
I0621 00:56:40.732128   388 net.cpp:396] derelu5_2 <- deconv5_2
I0621 00:56:40.732138   388 net.cpp:347] derelu5_2 -> deconv5_2 (in-place)
I0621 00:56:40.732147   388 net.cpp:98] Setting up derelu5_2
I0621 00:56:40.732154   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.732162   388 layer_factory.hpp:78] Creating layer deconv5_3
I0621 00:56:40.732172   388 net.cpp:69] Creating Layer deconv5_3
I0621 00:56:40.732179   388 net.cpp:396] deconv5_3 <- deconv5_2
I0621 00:56:40.732187   388 net.cpp:358] deconv5_3 -> deconv5_3
I0621 00:56:40.732197   388 net.cpp:98] Setting up deconv5_3
I0621 00:56:40.803474   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.803510   388 layer_factory.hpp:78] Creating layer debn5_3
I0621 00:56:40.803525   388 net.cpp:69] Creating Layer debn5_3
I0621 00:56:40.803534   388 net.cpp:396] debn5_3 <- deconv5_3
I0621 00:56:40.803545   388 net.cpp:347] debn5_3 -> deconv5_3 (in-place)
I0621 00:56:40.803555   388 net.cpp:98] Setting up debn5_3
I0621 00:56:40.803571   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.803580   388 layer_factory.hpp:78] Creating layer derelu5_3
I0621 00:56:40.803587   388 net.cpp:69] Creating Layer derelu5_3
I0621 00:56:40.803593   388 net.cpp:396] derelu5_3 <- deconv5_3
I0621 00:56:40.803602   388 net.cpp:347] derelu5_3 -> deconv5_3 (in-place)
I0621 00:56:40.803633   388 net.cpp:98] Setting up derelu5_3
I0621 00:56:40.803642   388 net.cpp:105] Top shape: 4 512 20 20 (819200)
I0621 00:56:40.803647   388 layer_factory.hpp:78] Creating layer unpool4
I0621 00:56:40.803656   388 net.cpp:69] Creating Layer unpool4
I0621 00:56:40.803663   388 net.cpp:396] unpool4 <- deconv5_3
I0621 00:56:40.803680   388 net.cpp:396] unpool4 <- pool4_mask
I0621 00:56:40.803715   388 net.cpp:358] unpool4 -> unpool4
I0621 00:56:40.803726   388 net.cpp:98] Setting up unpool4
I0621 00:56:40.803733   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:40.803740   388 layer_factory.hpp:78] Creating layer deconv4_1
I0621 00:56:40.803751   388 net.cpp:69] Creating Layer deconv4_1
I0621 00:56:40.803757   388 net.cpp:396] deconv4_1 <- unpool4
I0621 00:56:40.803766   388 net.cpp:358] deconv4_1 -> deconv4_1
I0621 00:56:40.803773   388 net.cpp:98] Setting up deconv4_1
I0621 00:56:40.872397   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:40.872428   388 layer_factory.hpp:78] Creating layer debn4_1
I0621 00:56:40.872453   388 net.cpp:69] Creating Layer debn4_1
I0621 00:56:40.872463   388 net.cpp:396] debn4_1 <- deconv4_1
I0621 00:56:40.872473   388 net.cpp:347] debn4_1 -> deconv4_1 (in-place)
I0621 00:56:40.872483   388 net.cpp:98] Setting up debn4_1
I0621 00:56:40.872505   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:40.872514   388 layer_factory.hpp:78] Creating layer derelu4_1
I0621 00:56:40.872522   388 net.cpp:69] Creating Layer derelu4_1
I0621 00:56:40.872529   388 net.cpp:396] derelu4_1 <- deconv4_1
I0621 00:56:40.872539   388 net.cpp:347] derelu4_1 -> deconv4_1 (in-place)
I0621 00:56:40.872546   388 net.cpp:98] Setting up derelu4_1
I0621 00:56:40.872553   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:40.872560   388 layer_factory.hpp:78] Creating layer deconv4_2
I0621 00:56:40.872570   388 net.cpp:69] Creating Layer deconv4_2
I0621 00:56:40.872576   388 net.cpp:396] deconv4_2 <- deconv4_1
I0621 00:56:40.872586   388 net.cpp:358] deconv4_2 -> deconv4_2
I0621 00:56:40.872594   388 net.cpp:98] Setting up deconv4_2
I0621 00:56:40.941112   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:40.941138   388 layer_factory.hpp:78] Creating layer debn4_2
I0621 00:56:40.941149   388 net.cpp:69] Creating Layer debn4_2
I0621 00:56:40.941157   388 net.cpp:396] debn4_2 <- deconv4_2
I0621 00:56:40.941166   388 net.cpp:347] debn4_2 -> deconv4_2 (in-place)
I0621 00:56:40.941176   388 net.cpp:98] Setting up debn4_2
I0621 00:56:40.941200   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:40.941210   388 layer_factory.hpp:78] Creating layer derelu4_2
I0621 00:56:40.941218   388 net.cpp:69] Creating Layer derelu4_2
I0621 00:56:40.941226   388 net.cpp:396] derelu4_2 <- deconv4_2
I0621 00:56:40.941233   388 net.cpp:347] derelu4_2 -> deconv4_2 (in-place)
I0621 00:56:40.941241   388 net.cpp:98] Setting up derelu4_2
I0621 00:56:40.941249   388 net.cpp:105] Top shape: 4 512 40 40 (3276800)
I0621 00:56:40.941257   388 layer_factory.hpp:78] Creating layer deconv4_3
I0621 00:56:40.941268   388 net.cpp:69] Creating Layer deconv4_3
I0621 00:56:40.941274   388 net.cpp:396] deconv4_3 <- deconv4_2
I0621 00:56:40.941284   388 net.cpp:358] deconv4_3 -> deconv4_3
I0621 00:56:40.941294   388 net.cpp:98] Setting up deconv4_3
I0621 00:56:40.975478   388 net.cpp:105] Top shape: 4 256 40 40 (1638400)
I0621 00:56:40.975495   388 layer_factory.hpp:78] Creating layer debn4_3
I0621 00:56:40.975504   388 net.cpp:69] Creating Layer debn4_3
I0621 00:56:40.975512   388 net.cpp:396] debn4_3 <- deconv4_3
I0621 00:56:40.975518   388 net.cpp:347] debn4_3 -> deconv4_3 (in-place)
I0621 00:56:40.975527   388 net.cpp:98] Setting up debn4_3
I0621 00:56:40.975543   388 net.cpp:105] Top shape: 4 256 40 40 (1638400)
I0621 00:56:40.975550   388 layer_factory.hpp:78] Creating layer derelu4_3
I0621 00:56:40.975558   388 net.cpp:69] Creating Layer derelu4_3
I0621 00:56:40.975564   388 net.cpp:396] derelu4_3 <- deconv4_3
I0621 00:56:40.975571   388 net.cpp:347] derelu4_3 -> deconv4_3 (in-place)
I0621 00:56:40.975599   388 net.cpp:98] Setting up derelu4_3
I0621 00:56:40.975605   388 net.cpp:105] Top shape: 4 256 40 40 (1638400)
I0621 00:56:40.975611   388 layer_factory.hpp:78] Creating layer unpool3
I0621 00:56:40.975621   388 net.cpp:69] Creating Layer unpool3
I0621 00:56:40.975628   388 net.cpp:396] unpool3 <- deconv4_3
I0621 00:56:40.975637   388 net.cpp:396] unpool3 <- pool3_mask
I0621 00:56:40.975646   388 net.cpp:358] unpool3 -> unpool3
I0621 00:56:40.975663   388 net.cpp:98] Setting up unpool3
I0621 00:56:40.975672   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:40.975677   388 layer_factory.hpp:78] Creating layer deconv3_1
I0621 00:56:40.975687   388 net.cpp:69] Creating Layer deconv3_1
I0621 00:56:40.975693   388 net.cpp:396] deconv3_1 <- unpool3
I0621 00:56:40.975700   388 net.cpp:358] deconv3_1 -> deconv3_1
I0621 00:56:40.975708   388 net.cpp:98] Setting up deconv3_1
I0621 00:56:40.993155   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:40.993172   388 layer_factory.hpp:78] Creating layer debn3_1
I0621 00:56:40.993181   388 net.cpp:69] Creating Layer debn3_1
I0621 00:56:40.993188   388 net.cpp:396] debn3_1 <- deconv3_1
I0621 00:56:40.993197   388 net.cpp:347] debn3_1 -> deconv3_1 (in-place)
I0621 00:56:40.993206   388 net.cpp:98] Setting up debn3_1
I0621 00:56:40.993238   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:40.993248   388 layer_factory.hpp:78] Creating layer derelu3_1
I0621 00:56:40.993255   388 net.cpp:69] Creating Layer derelu3_1
I0621 00:56:40.993262   388 net.cpp:396] derelu3_1 <- deconv3_1
I0621 00:56:40.993268   388 net.cpp:347] derelu3_1 -> deconv3_1 (in-place)
I0621 00:56:40.993275   388 net.cpp:98] Setting up derelu3_1
I0621 00:56:40.993281   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:40.993288   388 layer_factory.hpp:78] Creating layer deconv3_2
I0621 00:56:40.993296   388 net.cpp:69] Creating Layer deconv3_2
I0621 00:56:40.993302   388 net.cpp:396] deconv3_2 <- deconv3_1
I0621 00:56:40.993310   388 net.cpp:358] deconv3_2 -> deconv3_2
I0621 00:56:40.993319   388 net.cpp:98] Setting up deconv3_2
I0621 00:56:41.010701   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:41.010717   388 layer_factory.hpp:78] Creating layer debn3_2
I0621 00:56:41.010728   388 net.cpp:69] Creating Layer debn3_2
I0621 00:56:41.010735   388 net.cpp:396] debn3_2 <- deconv3_2
I0621 00:56:41.010745   388 net.cpp:347] debn3_2 -> deconv3_2 (in-place)
I0621 00:56:41.010752   388 net.cpp:98] Setting up debn3_2
I0621 00:56:41.010787   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:41.010795   388 layer_factory.hpp:78] Creating layer derelu3_2
I0621 00:56:41.010804   388 net.cpp:69] Creating Layer derelu3_2
I0621 00:56:41.010810   388 net.cpp:396] derelu3_2 <- deconv3_2
I0621 00:56:41.010818   388 net.cpp:347] derelu3_2 -> deconv3_2 (in-place)
I0621 00:56:41.010824   388 net.cpp:98] Setting up derelu3_2
I0621 00:56:41.010829   388 net.cpp:105] Top shape: 4 256 80 80 (6553600)
I0621 00:56:41.010836   388 layer_factory.hpp:78] Creating layer deconv3_3
I0621 00:56:41.010844   388 net.cpp:69] Creating Layer deconv3_3
I0621 00:56:41.010851   388 net.cpp:396] deconv3_3 <- deconv3_2
I0621 00:56:41.010862   388 net.cpp:358] deconv3_3 -> deconv3_3
I0621 00:56:41.010871   388 net.cpp:98] Setting up deconv3_3
I0621 00:56:41.019475   388 net.cpp:105] Top shape: 4 128 80 80 (3276800)
I0621 00:56:41.019490   388 layer_factory.hpp:78] Creating layer debn3_3
I0621 00:56:41.019500   388 net.cpp:69] Creating Layer debn3_3
I0621 00:56:41.019507   388 net.cpp:396] debn3_3 <- deconv3_3
I0621 00:56:41.019515   388 net.cpp:347] debn3_3 -> deconv3_3 (in-place)
I0621 00:56:41.019522   388 net.cpp:98] Setting up debn3_3
I0621 00:56:41.019554   388 net.cpp:105] Top shape: 4 128 80 80 (3276800)
I0621 00:56:41.019563   388 layer_factory.hpp:78] Creating layer derelu3_3
I0621 00:56:41.019575   388 net.cpp:69] Creating Layer derelu3_3
I0621 00:56:41.019582   388 net.cpp:396] derelu3_3 <- deconv3_3
I0621 00:56:41.019588   388 net.cpp:347] derelu3_3 -> deconv3_3 (in-place)
I0621 00:56:41.019605   388 net.cpp:98] Setting up derelu3_3
I0621 00:56:41.019613   388 net.cpp:105] Top shape: 4 128 80 80 (3276800)
I0621 00:56:41.019618   388 layer_factory.hpp:78] Creating layer unpool2
I0621 00:56:41.019625   388 net.cpp:69] Creating Layer unpool2
I0621 00:56:41.019632   388 net.cpp:396] unpool2 <- deconv3_3
I0621 00:56:41.019639   388 net.cpp:396] unpool2 <- pool2_mask
I0621 00:56:41.019649   388 net.cpp:358] unpool2 -> unpool2
I0621 00:56:41.019659   388 net.cpp:98] Setting up unpool2
I0621 00:56:41.019665   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:41.019671   388 layer_factory.hpp:78] Creating layer deconv2_1
I0621 00:56:41.019680   388 net.cpp:69] Creating Layer deconv2_1
I0621 00:56:41.019686   388 net.cpp:396] deconv2_1 <- unpool2
I0621 00:56:41.019695   388 net.cpp:358] deconv2_1 -> deconv2_1
I0621 00:56:41.019702   388 net.cpp:98] Setting up deconv2_1
I0621 00:56:41.024039   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:41.024057   388 layer_factory.hpp:78] Creating layer debn2_1
I0621 00:56:41.024066   388 net.cpp:69] Creating Layer debn2_1
I0621 00:56:41.024073   388 net.cpp:396] debn2_1 <- deconv2_1
I0621 00:56:41.024080   388 net.cpp:347] debn2_1 -> deconv2_1 (in-place)
I0621 00:56:41.024088   388 net.cpp:98] Setting up debn2_1
I0621 00:56:41.024189   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:41.024201   388 layer_factory.hpp:78] Creating layer derelu2_1
I0621 00:56:41.024209   388 net.cpp:69] Creating Layer derelu2_1
I0621 00:56:41.024214   388 net.cpp:396] derelu2_1 <- deconv2_1
I0621 00:56:41.024221   388 net.cpp:347] derelu2_1 -> deconv2_1 (in-place)
I0621 00:56:41.024229   388 net.cpp:98] Setting up derelu2_1
I0621 00:56:41.024235   388 net.cpp:105] Top shape: 4 128 160 160 (13107200)
I0621 00:56:41.024243   388 layer_factory.hpp:78] Creating layer deconv2_2
I0621 00:56:41.024253   388 net.cpp:69] Creating Layer deconv2_2
I0621 00:56:41.024260   388 net.cpp:396] deconv2_2 <- deconv2_1
I0621 00:56:41.024267   388 net.cpp:358] deconv2_2 -> deconv2_2
I0621 00:56:41.024276   388 net.cpp:98] Setting up deconv2_2
I0621 00:56:41.026629   388 net.cpp:105] Top shape: 4 64 160 160 (6553600)
I0621 00:56:41.026643   388 layer_factory.hpp:78] Creating layer debn2_2
I0621 00:56:41.026650   388 net.cpp:69] Creating Layer debn2_2
I0621 00:56:41.026657   388 net.cpp:396] debn2_2 <- deconv2_2
I0621 00:56:41.026665   388 net.cpp:347] debn2_2 -> deconv2_2 (in-place)
I0621 00:56:41.026674   388 net.cpp:98] Setting up debn2_2
I0621 00:56:41.026782   388 net.cpp:105] Top shape: 4 64 160 160 (6553600)
I0621 00:56:41.026793   388 layer_factory.hpp:78] Creating layer derelu2_2
I0621 00:56:41.026801   388 net.cpp:69] Creating Layer derelu2_2
I0621 00:56:41.026808   388 net.cpp:396] derelu2_2 <- deconv2_2
I0621 00:56:41.026816   388 net.cpp:347] derelu2_2 -> deconv2_2 (in-place)
I0621 00:56:41.026823   388 net.cpp:98] Setting up derelu2_2
I0621 00:56:41.026829   388 net.cpp:105] Top shape: 4 64 160 160 (6553600)
I0621 00:56:41.026835   388 layer_factory.hpp:78] Creating layer unpool1
I0621 00:56:41.026919   388 net.cpp:69] Creating Layer unpool1
I0621 00:56:41.026928   388 net.cpp:396] unpool1 <- deconv2_2
I0621 00:56:41.026938   388 net.cpp:396] unpool1 <- pool1_mask
I0621 00:56:41.026949   388 net.cpp:358] unpool1 -> unpool1
I0621 00:56:41.026957   388 net.cpp:98] Setting up unpool1
I0621 00:56:41.026964   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:41.026971   388 layer_factory.hpp:78] Creating layer deconv1_1
I0621 00:56:41.026981   388 net.cpp:69] Creating Layer deconv1_1
I0621 00:56:41.026988   388 net.cpp:396] deconv1_1 <- unpool1
I0621 00:56:41.026996   388 net.cpp:358] deconv1_1 -> deconv1_1
I0621 00:56:41.027004   388 net.cpp:98] Setting up deconv1_1
I0621 00:56:41.028278   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:41.028293   388 layer_factory.hpp:78] Creating layer debn1_1
I0621 00:56:41.028303   388 net.cpp:69] Creating Layer debn1_1
I0621 00:56:41.028311   388 net.cpp:396] debn1_1 <- deconv1_1
I0621 00:56:41.028331   388 net.cpp:347] debn1_1 -> deconv1_1 (in-place)
I0621 00:56:41.028339   388 net.cpp:98] Setting up debn1_1
I0621 00:56:41.028702   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:41.028761   388 layer_factory.hpp:78] Creating layer derelu1_1
I0621 00:56:41.028771   388 net.cpp:69] Creating Layer derelu1_1
I0621 00:56:41.028779   388 net.cpp:396] derelu1_1 <- deconv1_1
I0621 00:56:41.028787   388 net.cpp:347] derelu1_1 -> deconv1_1 (in-place)
I0621 00:56:41.028795   388 net.cpp:98] Setting up derelu1_1
I0621 00:56:41.028800   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:41.028806   388 layer_factory.hpp:78] Creating layer deconv1_2
I0621 00:56:41.028815   388 net.cpp:69] Creating Layer deconv1_2
I0621 00:56:41.028822   388 net.cpp:396] deconv1_2 <- deconv1_1
I0621 00:56:41.028831   388 net.cpp:358] deconv1_2 -> deconv1_2
I0621 00:56:41.028838   388 net.cpp:98] Setting up deconv1_2
I0621 00:56:41.030114   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:41.030128   388 layer_factory.hpp:78] Creating layer debn1_2
I0621 00:56:41.030136   388 net.cpp:69] Creating Layer debn1_2
I0621 00:56:41.030144   388 net.cpp:396] debn1_2 <- deconv1_2
I0621 00:56:41.030151   388 net.cpp:347] debn1_2 -> deconv1_2 (in-place)
I0621 00:56:41.030159   388 net.cpp:98] Setting up debn1_2
I0621 00:56:41.030524   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:41.030536   388 layer_factory.hpp:78] Creating layer derelu1_2
I0621 00:56:41.030544   388 net.cpp:69] Creating Layer derelu1_2
I0621 00:56:41.030550   388 net.cpp:396] derelu1_2 <- deconv1_2
I0621 00:56:41.030558   388 net.cpp:347] derelu1_2 -> deconv1_2 (in-place)
I0621 00:56:41.030565   388 net.cpp:98] Setting up derelu1_2
I0621 00:56:41.030572   388 net.cpp:105] Top shape: 4 64 320 320 (26214400)
I0621 00:56:41.030578   388 layer_factory.hpp:78] Creating layer seg-score-voc
I0621 00:56:41.030592   388 net.cpp:69] Creating Layer seg-score-voc
I0621 00:56:41.030599   388 net.cpp:396] seg-score-voc <- deconv1_2
I0621 00:56:41.030607   388 net.cpp:358] seg-score-voc -> seg-score
I0621 00:56:41.030616   388 net.cpp:98] Setting up seg-score-voc
I0621 00:56:41.030815   388 net.cpp:105] Top shape: 4 2 320 320 (819200)
I0621 00:56:41.030830   388 layer_factory.hpp:78] Creating layer seg-loss
I0621 00:56:41.030841   388 net.cpp:69] Creating Layer seg-loss
I0621 00:56:41.030848   388 net.cpp:396] seg-loss <- seg-score
I0621 00:56:41.030856   388 net.cpp:396] seg-loss <- seg-label
I0621 00:56:41.030864   388 net.cpp:358] seg-loss -> seg-loss
I0621 00:56:41.030872   388 net.cpp:98] Setting up seg-loss
I0621 00:56:41.030881   388 net.cpp:105] Top shape: 1 1 1 1 (1)
I0621 00:56:41.030887   388 net.cpp:111]     with loss weight 1
I0621 00:56:41.031008   388 net.cpp:172] seg-loss needs backward computation.
I0621 00:56:41.031019   388 net.cpp:172] seg-score-voc needs backward computation.
I0621 00:56:41.031026   388 net.cpp:172] derelu1_2 needs backward computation.
I0621 00:56:41.031033   388 net.cpp:172] debn1_2 needs backward computation.
I0621 00:56:41.031038   388 net.cpp:172] deconv1_2 needs backward computation.
I0621 00:56:41.031044   388 net.cpp:172] derelu1_1 needs backward computation.
I0621 00:56:41.031050   388 net.cpp:172] debn1_1 needs backward computation.
I0621 00:56:41.031055   388 net.cpp:172] deconv1_1 needs backward computation.
I0621 00:56:41.031065   388 net.cpp:172] unpool1 needs backward computation.
I0621 00:56:41.031072   388 net.cpp:172] derelu2_2 needs backward computation.
I0621 00:56:41.031078   388 net.cpp:172] debn2_2 needs backward computation.
I0621 00:56:41.031083   388 net.cpp:172] deconv2_2 needs backward computation.
I0621 00:56:41.031090   388 net.cpp:172] derelu2_1 needs backward computation.
I0621 00:56:41.031096   388 net.cpp:172] debn2_1 needs backward computation.
I0621 00:56:41.031101   388 net.cpp:172] deconv2_1 needs backward computation.
I0621 00:56:41.031107   388 net.cpp:172] unpool2 needs backward computation.
I0621 00:56:41.031122   388 net.cpp:172] derelu3_3 needs backward computation.
I0621 00:56:41.031129   388 net.cpp:172] debn3_3 needs backward computation.
I0621 00:56:41.031134   388 net.cpp:172] deconv3_3 needs backward computation.
I0621 00:56:41.031141   388 net.cpp:172] derelu3_2 needs backward computation.
I0621 00:56:41.031146   388 net.cpp:172] debn3_2 needs backward computation.
I0621 00:56:41.031152   388 net.cpp:172] deconv3_2 needs backward computation.
I0621 00:56:41.031157   388 net.cpp:172] derelu3_1 needs backward computation.
I0621 00:56:41.031162   388 net.cpp:172] debn3_1 needs backward computation.
I0621 00:56:41.031168   388 net.cpp:172] deconv3_1 needs backward computation.
I0621 00:56:41.031174   388 net.cpp:172] unpool3 needs backward computation.
I0621 00:56:41.031180   388 net.cpp:172] derelu4_3 needs backward computation.
I0621 00:56:41.031185   388 net.cpp:172] debn4_3 needs backward computation.
I0621 00:56:41.031191   388 net.cpp:172] deconv4_3 needs backward computation.
I0621 00:56:41.031198   388 net.cpp:172] derelu4_2 needs backward computation.
I0621 00:56:41.031203   388 net.cpp:172] debn4_2 needs backward computation.
I0621 00:56:41.031209   388 net.cpp:172] deconv4_2 needs backward computation.
I0621 00:56:41.031214   388 net.cpp:172] derelu4_1 needs backward computation.
I0621 00:56:41.031221   388 net.cpp:172] debn4_1 needs backward computation.
I0621 00:56:41.031227   388 net.cpp:172] deconv4_1 needs backward computation.
I0621 00:56:41.031234   388 net.cpp:172] unpool4 needs backward computation.
I0621 00:56:41.031240   388 net.cpp:172] derelu5_3 needs backward computation.
I0621 00:56:41.031246   388 net.cpp:172] debn5_3 needs backward computation.
I0621 00:56:41.031252   388 net.cpp:172] deconv5_3 needs backward computation.
I0621 00:56:41.031258   388 net.cpp:172] derelu5_2 needs backward computation.
I0621 00:56:41.031263   388 net.cpp:172] debn5_2 needs backward computation.
I0621 00:56:41.031270   388 net.cpp:172] deconv5_2 needs backward computation.
I0621 00:56:41.031275   388 net.cpp:172] derelu5_1 needs backward computation.
I0621 00:56:41.031281   388 net.cpp:172] debn5_1 needs backward computation.
I0621 00:56:41.031287   388 net.cpp:172] deconv5_1 needs backward computation.
I0621 00:56:41.031293   388 net.cpp:172] unpool5 needs backward computation.
I0621 00:56:41.031299   388 net.cpp:172] fc6-deconv-relu needs backward computation.
I0621 00:56:41.031306   388 net.cpp:172] fc6-deconv-bn needs backward computation.
I0621 00:56:41.031311   388 net.cpp:172] fc6-deconv needs backward computation.
I0621 00:56:41.031317   388 net.cpp:172] relu7-seg needs backward computation.
I0621 00:56:41.031324   388 net.cpp:172] bnfc7-seg needs backward computation.
I0621 00:56:41.031330   388 net.cpp:172] fc7-seg needs backward computation.
I0621 00:56:41.031337   388 net.cpp:172] relu6-seg needs backward computation.
I0621 00:56:41.031342   388 net.cpp:172] bnfc6-seg needs backward computation.
I0621 00:56:41.031347   388 net.cpp:172] fc6-seg needs backward computation.
I0621 00:56:41.031353   388 net.cpp:172] pool5-concat needs backward computation.
I0621 00:56:41.031360   388 net.cpp:172] pool5-bp-bn needs backward computation.
I0621 00:56:41.031368   388 net.cpp:172] pool5b-bn needs backward computation.
I0621 00:56:41.031373   388 net.cpp:172] pool5-bn needs backward computation.
I0621 00:56:41.031380   388 net.cpp:174] fc6-bp does not need backward computation.
I0621 00:56:41.031388   388 net.cpp:174] relu6-mask does not need backward computation.
I0621 00:56:41.031395   388 net.cpp:174] fc7-bp does not need backward computation.
I0621 00:56:41.031401   388 net.cpp:174] relu7-mask does not need backward computation.
I0621 00:56:41.031409   388 net.cpp:174] cls-score-voc-bp does not need backward computation.
I0621 00:56:41.031414   388 net.cpp:174] avg-unpool does not need backward computation.
I0621 00:56:41.031421   388 net.cpp:174] cls-score-mask does not need backward computation.
I0621 00:56:41.031429   388 net.cpp:174] cls-score-sigmoid does not need backward computation.
I0621 00:56:41.031441   388 net.cpp:174] avg-pool does not need backward computation.
I0621 00:56:41.031448   388 net.cpp:174] cls-score-voc does not need backward computation.
I0621 00:56:41.031455   388 net.cpp:174] relu7 does not need backward computation.
I0621 00:56:41.031461   388 net.cpp:174] fc7 does not need backward computation.
I0621 00:56:41.031466   388 net.cpp:174] relu6 does not need backward computation.
I0621 00:56:41.031472   388 net.cpp:174] fc6 does not need backward computation.
I0621 00:56:41.031478   388 net.cpp:174] pool5b does not need backward computation.
I0621 00:56:41.031486   388 net.cpp:174] relu5_3b does not need backward computation.
I0621 00:56:41.031491   388 net.cpp:174] conv5_3b does not need backward computation.
I0621 00:56:41.031497   388 net.cpp:174] relu5_2b does not need backward computation.
I0621 00:56:41.031503   388 net.cpp:174] conv5_2b does not need backward computation.
I0621 00:56:41.031509   388 net.cpp:174] relu5_1b does not need backward computation.
I0621 00:56:41.031515   388 net.cpp:174] conv5_1b does not need backward computation.
I0621 00:56:41.031522   388 net.cpp:174] pool4b does not need backward computation.
I0621 00:56:41.031527   388 net.cpp:174] relu4_3b does not need backward computation.
I0621 00:56:41.031534   388 net.cpp:174] conv4_3b does not need backward computation.
I0621 00:56:41.031541   388 net.cpp:174] relu4_2b does not need backward computation.
I0621 00:56:41.031546   388 net.cpp:174] conv4_2b does not need backward computation.
I0621 00:56:41.031553   388 net.cpp:174] relu4_1b does not need backward computation.
I0621 00:56:41.031558   388 net.cpp:174] conv4_1b does not need backward computation.
I0621 00:56:41.031564   388 net.cpp:174] pool3b does not need backward computation.
I0621 00:56:41.031570   388 net.cpp:174] relu3_3b does not need backward computation.
I0621 00:56:41.031579   388 net.cpp:174] conv3_3b does not need backward computation.
I0621 00:56:41.031581   388 net.cpp:174] relu3_2b does not need backward computation.
I0621 00:56:41.031585   388 net.cpp:174] conv3_2b does not need backward computation.
I0621 00:56:41.031589   388 net.cpp:174] relu3_1b does not need backward computation.
I0621 00:56:41.031592   388 net.cpp:174] conv3_1b does not need backward computation.
I0621 00:56:41.031595   388 net.cpp:174] pool2b does not need backward computation.
I0621 00:56:41.031599   388 net.cpp:174] relu2_2b does not need backward computation.
I0621 00:56:41.031602   388 net.cpp:174] conv2_2b does not need backward computation.
I0621 00:56:41.031606   388 net.cpp:174] relu2_1b does not need backward computation.
I0621 00:56:41.031616   388 net.cpp:174] conv2_1b does not need backward computation.
I0621 00:56:41.031622   388 net.cpp:174] pool1b does not need backward computation.
I0621 00:56:41.031631   388 net.cpp:174] relu1_2b does not need backward computation.
I0621 00:56:41.031638   388 net.cpp:174] conv1_2b does not need backward computation.
I0621 00:56:41.031646   388 net.cpp:174] relu1_1b does not need backward computation.
I0621 00:56:41.031652   388 net.cpp:174] conv1_1b does not need backward computation.
I0621 00:56:41.031659   388 net.cpp:174] pool5_pool5_0_split does not need backward computation.
I0621 00:56:41.031667   388 net.cpp:174] pool5 does not need backward computation.
I0621 00:56:41.031675   388 net.cpp:174] relu5_3 does not need backward computation.
I0621 00:56:41.031683   388 net.cpp:174] conv5_3 does not need backward computation.
I0621 00:56:41.031690   388 net.cpp:174] relu5_2 does not need backward computation.
I0621 00:56:41.031697   388 net.cpp:174] conv5_2 does not need backward computation.
I0621 00:56:41.031704   388 net.cpp:174] relu5_1 does not need backward computation.
I0621 00:56:41.031711   388 net.cpp:174] conv5_1 does not need backward computation.
I0621 00:56:41.031718   388 net.cpp:174] pool4 does not need backward computation.
I0621 00:56:41.031725   388 net.cpp:174] relu4_3 does not need backward computation.
I0621 00:56:41.031733   388 net.cpp:174] conv4_3 does not need backward computation.
I0621 00:56:41.031745   388 net.cpp:174] relu4_2 does not need backward computation.
I0621 00:56:41.031754   388 net.cpp:174] conv4_2 does not need backward computation.
I0621 00:56:41.031760   388 net.cpp:174] relu4_1 does not need backward computation.
I0621 00:56:41.031766   388 net.cpp:174] conv4_1 does not need backward computation.
I0621 00:56:41.031772   388 net.cpp:174] pool3 does not need backward computation.
I0621 00:56:41.031780   388 net.cpp:174] relu3_3 does not need backward computation.
I0621 00:56:41.031787   388 net.cpp:174] conv3_3 does not need backward computation.
I0621 00:56:41.031795   388 net.cpp:174] relu3_2 does not need backward computation.
I0621 00:56:41.031802   388 net.cpp:174] conv3_2 does not need backward computation.
I0621 00:56:41.031808   388 net.cpp:174] relu3_1 does not need backward computation.
I0621 00:56:41.031816   388 net.cpp:174] conv3_1 does not need backward computation.
I0621 00:56:41.031821   388 net.cpp:174] pool2 does not need backward computation.
I0621 00:56:41.031828   388 net.cpp:174] relu2_2 does not need backward computation.
I0621 00:56:41.031836   388 net.cpp:174] conv2_2 does not need backward computation.
I0621 00:56:41.031841   388 net.cpp:174] relu2_1 does not need backward computation.
I0621 00:56:41.031848   388 net.cpp:174] conv2_1 does not need backward computation.
I0621 00:56:41.031854   388 net.cpp:174] pool1 does not need backward computation.
I0621 00:56:41.031862   388 net.cpp:174] relu1_2 does not need backward computation.
I0621 00:56:41.031868   388 net.cpp:174] conv1_2 does not need backward computation.
I0621 00:56:41.031875   388 net.cpp:174] relu1_1 does not need backward computation.
I0621 00:56:41.031882   388 net.cpp:174] conv1_1 does not need backward computation.
I0621 00:56:41.031889   388 net.cpp:174] data does not need backward computation.
I0621 00:56:41.031894   388 net.cpp:210] This network produces output seg-loss
I0621 00:56:41.031961   388 net.cpp:469] Collecting Learning Rate and Weight Decay.
I0621 00:56:41.031982   388 net.cpp:221] Network initialization done.
I0621 00:56:41.031988   388 net.cpp:222] Memory required for data: 3346968132
I0621 00:56:41.034365   388 solver.cpp:154] Creating test net (#0) specified by net file: ./latefusion.prototxt
I0621 00:56:41.034482   388 net.cpp:277] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0621 00:56:41.035025   388 net.cpp:39] Initializing net from parameters: 
name: "train_seg_Full_anno"
layers {
  top: "data"
  top: "data2"
  top: "seg-label"
  top: "cls-label"
  name: "data"
  type: SELECT_SEG_BINARY_TWO_FRAMES
  image_data_param {
    source: "./dataset/val.txt"
    batch_size: 2
    shuffle: true
    new_height: 350
    new_width: 350
    root_folder: "./dataset"
    label_type: PIXEL
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 320
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
  window_cls_data_param {
    label_dim: 20
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_1p1"
  param: "conv1_1p2"
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_2p1"
  param: "conv1_2p2"
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_1p1"
  param: "conv2_1p2"
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_2p1"
  param: "conv2_2p2"
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_1p1"
  param: "conv3_1p2"
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_2p1"
  param: "conv3_2p2"
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_3p1"
  param: "conv3_3p2"
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_1p1"
  param: "conv4_1p2"
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_2p1"
  param: "conv4_2p2"
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_3p1"
  param: "conv4_3p2"
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_1p1"
  param: "conv5_1p2"
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_2p1"
  param: "conv5_2p2"
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_3p1"
  param: "conv5_3p2"
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "data2"
  top: "conv1_1b"
  name: "conv1_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_1p1"
  param: "conv1_1p2"
}
layers {
  bottom: "conv1_1b"
  top: "conv1_1b"
  name: "relu1_1b"
  type: RELU
}
layers {
  bottom: "conv1_1b"
  top: "conv1_2b"
  name: "conv1_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param: "conv1_2p1"
  param: "conv1_2p2"
}
layers {
  bottom: "conv1_2b"
  top: "conv1_2b"
  name: "relu1_2b"
  type: RELU
}
layers {
  bottom: "conv1_2b"
  top: "pool1b"
  name: "pool1b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1b"
  top: "conv2_1b"
  name: "conv2_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_1p1"
  param: "conv2_1p2"
}
layers {
  bottom: "conv2_1b"
  top: "conv2_1b"
  name: "relu2_1b"
  type: RELU
}
layers {
  bottom: "conv2_1b"
  top: "conv2_2b"
  name: "conv2_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param: "conv2_2p1"
  param: "conv2_2p2"
}
layers {
  bottom: "conv2_2b"
  top: "conv2_2b"
  name: "relu2_2b"
  type: RELU
}
layers {
  bottom: "conv2_2b"
  top: "pool2b"
  name: "pool2b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2b"
  top: "conv3_1b"
  name: "conv3_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_1p1"
  param: "conv3_1p2"
}
layers {
  bottom: "conv3_1b"
  top: "conv3_1b"
  name: "relu3_1b"
  type: RELU
}
layers {
  bottom: "conv3_1b"
  top: "conv3_2b"
  name: "conv3_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_2p1"
  param: "conv3_2p2"
}
layers {
  bottom: "conv3_2b"
  top: "conv3_2b"
  name: "relu3_2b"
  type: RELU
}
layers {
  bottom: "conv3_2b"
  top: "conv3_3b"
  name: "conv3_3b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param: "conv3_3p1"
  param: "conv3_3p2"
}
layers {
  bottom: "conv3_3b"
  top: "conv3_3b"
  name: "relu3_3b"
  type: RELU
}
layers {
  bottom: "conv3_3b"
  top: "pool3b"
  name: "pool3b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3b"
  top: "conv4_1b"
  name: "conv4_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_1p1"
  param: "conv4_1p2"
}
layers {
  bottom: "conv4_1b"
  top: "conv4_1b"
  name: "relu4_1b"
  type: RELU
}
layers {
  bottom: "conv4_1b"
  top: "conv4_2b"
  name: "conv4_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_2p1"
  param: "conv4_2p2"
}
layers {
  bottom: "conv4_2b"
  top: "conv4_2b"
  name: "relu4_2b"
  type: RELU
}
layers {
  bottom: "conv4_2b"
  top: "conv4_3b"
  name: "conv4_3b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv4_3p1"
  param: "conv4_3p2"
}
layers {
  bottom: "conv4_3b"
  top: "conv4_3b"
  name: "relu4_3b"
  type: RELU
}
layers {
  bottom: "conv4_3b"
  top: "pool4b"
  name: "pool4b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4b"
  top: "conv5_1b"
  name: "conv5_1b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_1p1"
  param: "conv5_1p2"
}
layers {
  bottom: "conv5_1b"
  top: "conv5_1b"
  name: "relu5_1b"
  type: RELU
}
layers {
  bottom: "conv5_1b"
  top: "conv5_2b"
  name: "conv5_2b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_2p1"
  param: "conv5_2p2"
}
layers {
  bottom: "conv5_2b"
  top: "conv5_2b"
  name: "relu5_2b"
  type: RELU
}
layers {
  bottom: "conv5_2b"
  top: "conv5_3b"
  name: "conv5_3b"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param: "conv5_3p1"
  param: "conv5_3p2"
}
layers {
  bottom: "conv5_3b"
  top: "conv5_3b"
  name: "relu5_3b"
  type: RELU
}
layers {
  bottom: "conv5_3b"
  top: "pool5b"
  name: "pool5b"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 7
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  top: "relu6-mask"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  top: "relu7-mask"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "cls-score"
  name: "cls-score-voc"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 20
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "cls-score"
  top: "cls-score-pooled"
  top: "score-pool-mask"
  name: "avg-pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 1
  }
}
layers {
  bottom: "cls-score-pooled"
  top: "cls-score-sigmoid"
  name: "cls-score-sigmoid"
  type: SIGMOID
}
layers {
  bottom: "cls-score-sigmoid"
  bottom: "cls-label"
  top: "cls-score-masked"
  name: "cls-score-mask"
  type: ELTWISE
  eltwise_param {
    operation: PROD
  }
}
layers {
  bottom: "cls-score-masked"
  bottom: "score-pool-mask"
  top: "cls-score-unpooled"
  name: "avg-unpool"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 4
    stride: 1
    unpool_size: 4
  }
}
layers {
  bottom: "cls-score-unpooled"
  top: "fc7-bp"
  name: "cls-score-voc-bp"
  type: CONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7-bp"
  bottom: "relu7-mask"
  top: "fc7-bp"
  name: "relu7-mask"
  type: ELTWISE
  eltwise_param {
    operation: PROD
  }
}
layers {
  bottom: "fc7-bp"
  top: "fc6-bp"
  name: "fc7-bp"
  type: DECONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layers {
  bottom: "fc6-bp"
  bottom: "relu6-mask"
  top: "fc6-bp"
  name: "relu6-mask"
  type: ELTWISE
  eltwise_param {
    operation: PROD
  }
}
layers {
  bottom: "fc6-bp"
  top: "pool5-bp"
  name: "fc6-bp"
  type: DECONVOLUTION
  blobs_lr: 0
  blobs_lr: 0
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    kernel_size: 7
  }
}
layers {
  bottom: "pool5"
  top: "pool5-bn"
  name: "pool5-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "pool5b"
  top: "pool5b-bn"
  name: "pool5b-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "pool5-bp"
  top: "pool5-bp-bn"
  name: "pool5-bp-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "pool5-bn"
  bottom: "pool5b-bn"
  bottom: "pool5-bp-bn"
  top: "pool5-concat"
  name: "pool5-concat"
  type: CONCAT
}
layers {
  bottom: "pool5-concat"
  top: "fc6-seg"
  name: "fc6-seg"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 2048
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6-seg"
  top: "fc6-seg"
  name: "bnfc6-seg"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "fc6-seg"
  top: "fc6-seg"
  name: "relu6-seg"
  type: RELU
}
layers {
  bottom: "fc6-seg"
  top: "fc7-seg"
  name: "fc7-seg"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 2048
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7-seg"
  top: "fc7-seg"
  name: "bnfc7-seg"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "fc7-seg"
  top: "fc7-seg"
  name: "relu7-seg"
  type: RELU
}
layers {
  bottom: "fc7-seg"
  top: "fc6-deconv"
  name: "fc6-deconv"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    kernel_size: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6-deconv"
  top: "fc6-deconv"
  name: "fc6-deconv-bn"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "fc6-deconv"
  top: "fc6-deconv"
  name: "fc6-deconv-relu"
  type: RELU
}
layers {
  bottom: "fc6-deconv"
  bottom: "pool5_mask"
  top: "unpool5"
  name: "unpool5"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 20
  }
}
layers {
  bottom: "unpool5"
  top: "deconv5_1"
  name: "deconv5_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv5_1"
  top: "deconv5_1"
  name: "debn5_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv5_1"
  top: "deconv5_1"
  name: "derelu5_1"
  type: RELU
}
layers {
  bottom: "deconv5_1"
  top: "deconv5_2"
  name: "deconv5_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv5_2"
  top: "deconv5_2"
  name: "debn5_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv5_2"
  top: "deconv5_2"
  name: "derelu5_2"
  type: RELU
}
layers {
  bottom: "deconv5_2"
  top: "deconv5_3"
  name: "deconv5_3"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv5_3"
  top: "deconv5_3"
  name: "debn5_3"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv5_3"
  top: "deconv5_3"
  name: "derelu5_3"
  type: RELU
}
layers {
  bottom: "deconv5_3"
  bottom: "pool4_mask"
  top: "unpool4"
  name: "unpool4"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 40
  }
}
layers {
  bottom: "unpool4"
  top: "deconv4_1"
  name: "deconv4_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv4_1"
  top: "deconv4_1"
  name: "debn4_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv4_1"
  top: "deconv4_1"
  name: "derelu4_1"
  type: RELU
}
layers {
  bottom: "deconv4_1"
  top: "deconv4_2"
  name: "deconv4_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv4_2"
  top: "deconv4_2"
  name: "debn4_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv4_2"
  top: "deconv4_2"
  name: "derelu4_2"
  type: RELU
}
layers {
  bottom: "deconv4_2"
  top: "deconv4_3"
  name: "deconv4_3"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv4_3"
  top: "deconv4_3"
  name: "debn4_3"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv4_3"
  top: "deconv4_3"
  name: "derelu4_3"
  type: RELU
}
layers {
  bottom: "deconv4_3"
  bottom: "pool3_mask"
  top: "unpool3"
  name: "unpool3"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 80
  }
}
layers {
  bottom: "unpool3"
  top: "deconv3_1"
  name: "deconv3_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv3_1"
  top: "deconv3_1"
  name: "debn3_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv3_1"
  top: "deconv3_1"
  name: "derelu3_1"
  type: RELU
}
layers {
  bottom: "deconv3_1"
  top: "deconv3_2"
  name: "deconv3_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv3_2"
  top: "deconv3_2"
  name: "debn3_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv3_2"
  top: "deconv3_2"
  name: "derelu3_2"
  type: RELU
}
layers {
  bottom: "deconv3_2"
  top: "deconv3_3"
  name: "deconv3_3"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv3_3"
  top: "deconv3_3"
  name: "debn3_3"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv3_3"
  top: "deconv3_3"
  name: "derelu3_3"
  type: RELU
}
layers {
  bottom: "deconv3_3"
  bottom: "pool2_mask"
  top: "unpool2"
  name: "unpool2"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 160
  }
}
layers {
  bottom: "unpool2"
  top: "deconv2_1"
  name: "deconv2_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv2_1"
  top: "deconv2_1"
  name: "debn2_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv2_1"
  top: "deconv2_1"
  name: "derelu2_1"
  type: RELU
}
layers {
  bottom: "deconv2_1"
  top: "deconv2_2"
  name: "deconv2_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv2_2"
  top: "deconv2_2"
  name: "debn2_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv2_2"
  top: "deconv2_2"
  name: "derelu2_2"
  type: RELU
}
layers {
  bottom: "deconv2_2"
  bottom: "pool1_mask"
  top: "unpool1"
  name: "unpool1"
  type: UNPOOLING
  unpooling_param {
    unpool: MAX
    kernel_size: 2
    stride: 2
    unpool_size: 320
  }
}
layers {
  bottom: "unpool1"
  top: "deconv1_1"
  name: "deconv1_1"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv1_1"
  top: "deconv1_1"
  name: "debn1_1"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv1_1"
  top: "deconv1_1"
  name: "derelu1_1"
  type: RELU
}
layers {
  bottom: "deconv1_1"
  top: "deconv1_2"
  name: "deconv1_2"
  type: DECONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "deconv1_2"
  top: "deconv1_2"
  name: "debn1_2"
  type: BN
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0.001
    }
  }
}
layers {
  bottom: "deconv1_2"
  top: "deconv1_2"
  name: "derelu1_2"
  type: RELU
}
layers {
  bottom: "deconv1_2"
  top: "seg-score"
  name: "seg-score-voc"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 2
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "seg-score"
  bottom: "seg-label"
  top: "seg-accuracy"
  name: "seg-accuracy"
  type: ELTWISE_ACCURACY
  include {
    phase: TEST
  }
  eltwise_accuracy_param {
    ignore_label: 255
  }
}
layers {
  bottom: "seg-score"
  bottom: "seg-label"
  top: "seg-loss"
  name: "seg-loss"
  type: SOFTMAX_LOSS
  loss_param {
    ignore_label: 255
  }
}
state {
  phase: TEST
}
I0621 00:56:41.039336   388 layer_factory.hpp:78] Creating layer data
I0621 00:56:41.039357   388 net.cpp:69] Creating Layer data
I0621 00:56:41.039366   388 net.cpp:358] data -> data
I0621 00:56:41.039377   388 net.cpp:358] data -> data2
I0621 00:56:41.039388   388 net.cpp:358] data -> seg-label
I0621 00:56:41.039398   388 net.cpp:358] data -> cls-label
I0621 00:56:41.039407   388 net.cpp:98] Setting up data
I0621 00:56:41.039425   388 select_seg_binary_two_frames_layer.cpp:47] Opening file ./dataset/val.txt
I0621 00:56:41.050000   388 select_seg_binary_two_frames_layer.cpp:86] Shuffling data
I0621 00:56:41.050851   388 select_seg_binary_two_frames_layer.cpp:91] A total of 3677 images.
I0621 00:56:41.055181   388 select_seg_binary_two_frames_layer.cpp:146] output data size: 2,3,320,320
I0621 00:56:41.055202   388 select_seg_binary_two_frames_layer.cpp:150] output data2 size: 2,3,320,320
I0621 00:56:41.055209   388 select_seg_binary_two_frames_layer.cpp:154] output label size: 2,1,320,320
I0621 00:56:41.055217   388 select_seg_binary_two_frames_layer.cpp:158] output class label size: 2,20,1,1
I0621 00:56:41.056279   388 net.cpp:105] Top shape: 2 3 320 320 (614400)
I0621 00:56:41.056293   388 net.cpp:105] Top shape: 2 3 320 320 (614400)
I0621 00:56:41.056300   388 net.cpp:105] Top shape: 2 1 320 320 (204800)
I0621 00:56:41.056308   388 net.cpp:105] Top shape: 2 20 1 1 (40)
I0621 00:56:41.056314   388 layer_factory.hpp:78] Creating layer seg-label_data_2_split
I0621 00:56:41.056325   388 net.cpp:69] Creating Layer seg-label_data_2_split
I0621 00:56:41.056334   388 net.cpp:396] seg-label_data_2_split <- seg-label
I0621 00:56:41.056341   388 net.cpp:358] seg-label_data_2_split -> seg-label_data_2_split_0
I0621 00:56:41.056351   388 net.cpp:358] seg-label_data_2_split -> seg-label_data_2_split_1
I0621 00:56:41.056360   388 net.cpp:98] Setting up seg-label_data_2_split
I0621 00:56:41.056367   388 net.cpp:105] Top shape: 2 1 320 320 (204800)
I0621 00:56:41.056373   388 net.cpp:105] Top shape: 2 1 320 320 (204800)
I0621 00:56:41.056380   388 layer_factory.hpp:78] Creating layer conv1_1
I0621 00:56:41.056387   388 net.cpp:69] Creating Layer conv1_1
I0621 00:56:41.056394   388 net.cpp:396] conv1_1 <- data
I0621 00:56:41.056429   388 net.cpp:358] conv1_1 -> conv1_1
I0621 00:56:41.056438   388 net.cpp:98] Setting up conv1_1
I0621 00:56:41.056676   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.056690   388 layer_factory.hpp:78] Creating layer relu1_1
I0621 00:56:41.056699   388 net.cpp:69] Creating Layer relu1_1
I0621 00:56:41.056705   388 net.cpp:396] relu1_1 <- conv1_1
I0621 00:56:41.056712   388 net.cpp:347] relu1_1 -> conv1_1 (in-place)
I0621 00:56:41.056720   388 net.cpp:98] Setting up relu1_1
I0621 00:56:41.056726   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.056733   388 layer_factory.hpp:78] Creating layer conv1_2
I0621 00:56:41.056741   388 net.cpp:69] Creating Layer conv1_2
I0621 00:56:41.056747   388 net.cpp:396] conv1_2 <- conv1_1
I0621 00:56:41.056757   388 net.cpp:358] conv1_2 -> conv1_2
I0621 00:56:41.056779   388 net.cpp:98] Setting up conv1_2
I0621 00:56:41.057085   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.057096   388 layer_factory.hpp:78] Creating layer relu1_2
I0621 00:56:41.057106   388 net.cpp:69] Creating Layer relu1_2
I0621 00:56:41.057113   388 net.cpp:396] relu1_2 <- conv1_2
I0621 00:56:41.057121   388 net.cpp:347] relu1_2 -> conv1_2 (in-place)
I0621 00:56:41.057128   388 net.cpp:98] Setting up relu1_2
I0621 00:56:41.057134   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.057140   388 layer_factory.hpp:78] Creating layer pool1
I0621 00:56:41.057147   388 net.cpp:69] Creating Layer pool1
I0621 00:56:41.057154   388 net.cpp:396] pool1 <- conv1_2
I0621 00:56:41.057162   388 net.cpp:358] pool1 -> pool1
I0621 00:56:41.057170   388 net.cpp:358] pool1 -> pool1_mask
I0621 00:56:41.057179   388 net.cpp:98] Setting up pool1
I0621 00:56:41.057190   388 net.cpp:105] Top shape: 2 64 160 160 (3276800)
I0621 00:56:41.057196   388 net.cpp:105] Top shape: 2 64 160 160 (3276800)
I0621 00:56:41.057204   388 layer_factory.hpp:78] Creating layer conv2_1
I0621 00:56:41.057210   388 net.cpp:69] Creating Layer conv2_1
I0621 00:56:41.057217   388 net.cpp:396] conv2_1 <- pool1
I0621 00:56:41.057227   388 net.cpp:358] conv2_1 -> conv2_1
I0621 00:56:41.057235   388 net.cpp:98] Setting up conv2_1
I0621 00:56:41.057471   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.057484   388 layer_factory.hpp:78] Creating layer relu2_1
I0621 00:56:41.057493   388 net.cpp:69] Creating Layer relu2_1
I0621 00:56:41.057500   388 net.cpp:396] relu2_1 <- conv2_1
I0621 00:56:41.057509   388 net.cpp:347] relu2_1 -> conv2_1 (in-place)
I0621 00:56:41.057518   388 net.cpp:98] Setting up relu2_1
I0621 00:56:41.057523   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.057530   388 layer_factory.hpp:78] Creating layer conv2_2
I0621 00:56:41.057538   388 net.cpp:69] Creating Layer conv2_2
I0621 00:56:41.057544   388 net.cpp:396] conv2_2 <- conv2_1
I0621 00:56:41.057552   388 net.cpp:358] conv2_2 -> conv2_2
I0621 00:56:41.057560   388 net.cpp:98] Setting up conv2_2
I0621 00:56:41.057952   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.057965   388 layer_factory.hpp:78] Creating layer relu2_2
I0621 00:56:41.057973   388 net.cpp:69] Creating Layer relu2_2
I0621 00:56:41.057992   388 net.cpp:396] relu2_2 <- conv2_2
I0621 00:56:41.058023   388 net.cpp:347] relu2_2 -> conv2_2 (in-place)
I0621 00:56:41.058032   388 net.cpp:98] Setting up relu2_2
I0621 00:56:41.058039   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.058046   388 layer_factory.hpp:78] Creating layer pool2
I0621 00:56:41.058053   388 net.cpp:69] Creating Layer pool2
I0621 00:56:41.058059   388 net.cpp:396] pool2 <- conv2_2
I0621 00:56:41.058066   388 net.cpp:358] pool2 -> pool2
I0621 00:56:41.058075   388 net.cpp:358] pool2 -> pool2_mask
I0621 00:56:41.058084   388 net.cpp:98] Setting up pool2
I0621 00:56:41.058090   388 net.cpp:105] Top shape: 2 128 80 80 (1638400)
I0621 00:56:41.058097   388 net.cpp:105] Top shape: 2 128 80 80 (1638400)
I0621 00:56:41.058104   388 layer_factory.hpp:78] Creating layer conv3_1
I0621 00:56:41.058114   388 net.cpp:69] Creating Layer conv3_1
I0621 00:56:41.058120   388 net.cpp:396] conv3_1 <- pool2
I0621 00:56:41.058128   388 net.cpp:358] conv3_1 -> conv3_1
I0621 00:56:41.058136   388 net.cpp:98] Setting up conv3_1
I0621 00:56:41.058739   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.058756   388 layer_factory.hpp:78] Creating layer relu3_1
I0621 00:56:41.058766   388 net.cpp:69] Creating Layer relu3_1
I0621 00:56:41.058773   388 net.cpp:396] relu3_1 <- conv3_1
I0621 00:56:41.058780   388 net.cpp:347] relu3_1 -> conv3_1 (in-place)
I0621 00:56:41.058787   388 net.cpp:98] Setting up relu3_1
I0621 00:56:41.058794   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.058799   388 layer_factory.hpp:78] Creating layer conv3_2
I0621 00:56:41.058806   388 net.cpp:69] Creating Layer conv3_2
I0621 00:56:41.058822   388 net.cpp:396] conv3_2 <- conv3_1
I0621 00:56:41.058831   388 net.cpp:358] conv3_2 -> conv3_2
I0621 00:56:41.058840   388 net.cpp:98] Setting up conv3_2
I0621 00:56:41.059949   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.059963   388 layer_factory.hpp:78] Creating layer relu3_2
I0621 00:56:41.059973   388 net.cpp:69] Creating Layer relu3_2
I0621 00:56:41.059979   388 net.cpp:396] relu3_2 <- conv3_2
I0621 00:56:41.059986   388 net.cpp:347] relu3_2 -> conv3_2 (in-place)
I0621 00:56:41.059993   388 net.cpp:98] Setting up relu3_2
I0621 00:56:41.059999   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.060005   388 layer_factory.hpp:78] Creating layer conv3_3
I0621 00:56:41.060015   388 net.cpp:69] Creating Layer conv3_3
I0621 00:56:41.060021   388 net.cpp:396] conv3_3 <- conv3_2
I0621 00:56:41.060029   388 net.cpp:358] conv3_3 -> conv3_3
I0621 00:56:41.060037   388 net.cpp:98] Setting up conv3_3
I0621 00:56:41.061136   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.061151   388 layer_factory.hpp:78] Creating layer relu3_3
I0621 00:56:41.061158   388 net.cpp:69] Creating Layer relu3_3
I0621 00:56:41.061166   388 net.cpp:396] relu3_3 <- conv3_3
I0621 00:56:41.061172   388 net.cpp:347] relu3_3 -> conv3_3 (in-place)
I0621 00:56:41.061182   388 net.cpp:98] Setting up relu3_3
I0621 00:56:41.061187   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.061193   388 layer_factory.hpp:78] Creating layer pool3
I0621 00:56:41.061200   388 net.cpp:69] Creating Layer pool3
I0621 00:56:41.061206   388 net.cpp:396] pool3 <- conv3_3
I0621 00:56:41.061214   388 net.cpp:358] pool3 -> pool3
I0621 00:56:41.061223   388 net.cpp:358] pool3 -> pool3_mask
I0621 00:56:41.061231   388 net.cpp:98] Setting up pool3
I0621 00:56:41.061239   388 net.cpp:105] Top shape: 2 256 40 40 (819200)
I0621 00:56:41.061244   388 net.cpp:105] Top shape: 2 256 40 40 (819200)
I0621 00:56:41.061250   388 layer_factory.hpp:78] Creating layer conv4_1
I0621 00:56:41.061257   388 net.cpp:69] Creating Layer conv4_1
I0621 00:56:41.061264   388 net.cpp:396] conv4_1 <- pool3
I0621 00:56:41.061271   388 net.cpp:358] conv4_1 -> conv4_1
I0621 00:56:41.061278   388 net.cpp:98] Setting up conv4_1
I0621 00:56:41.063155   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.063169   388 layer_factory.hpp:78] Creating layer relu4_1
I0621 00:56:41.063177   388 net.cpp:69] Creating Layer relu4_1
I0621 00:56:41.063185   388 net.cpp:396] relu4_1 <- conv4_1
I0621 00:56:41.063194   388 net.cpp:347] relu4_1 -> conv4_1 (in-place)
I0621 00:56:41.063202   388 net.cpp:98] Setting up relu4_1
I0621 00:56:41.063208   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.063215   388 layer_factory.hpp:78] Creating layer conv4_2
I0621 00:56:41.063222   388 net.cpp:69] Creating Layer conv4_2
I0621 00:56:41.063228   388 net.cpp:396] conv4_2 <- conv4_1
I0621 00:56:41.063235   388 net.cpp:358] conv4_2 -> conv4_2
I0621 00:56:41.063243   388 net.cpp:98] Setting up conv4_2
I0621 00:56:41.066313   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.066334   388 layer_factory.hpp:78] Creating layer relu4_2
I0621 00:56:41.066341   388 net.cpp:69] Creating Layer relu4_2
I0621 00:56:41.066349   388 net.cpp:396] relu4_2 <- conv4_2
I0621 00:56:41.066355   388 net.cpp:347] relu4_2 -> conv4_2 (in-place)
I0621 00:56:41.066362   388 net.cpp:98] Setting up relu4_2
I0621 00:56:41.066368   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.066375   388 layer_factory.hpp:78] Creating layer conv4_3
I0621 00:56:41.066383   388 net.cpp:69] Creating Layer conv4_3
I0621 00:56:41.066390   388 net.cpp:396] conv4_3 <- conv4_2
I0621 00:56:41.066397   388 net.cpp:358] conv4_3 -> conv4_3
I0621 00:56:41.066406   388 net.cpp:98] Setting up conv4_3
I0621 00:56:41.069876   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.069898   388 layer_factory.hpp:78] Creating layer relu4_3
I0621 00:56:41.069910   388 net.cpp:69] Creating Layer relu4_3
I0621 00:56:41.069917   388 net.cpp:396] relu4_3 <- conv4_3
I0621 00:56:41.069947   388 net.cpp:347] relu4_3 -> conv4_3 (in-place)
I0621 00:56:41.069955   388 net.cpp:98] Setting up relu4_3
I0621 00:56:41.069962   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.069967   388 layer_factory.hpp:78] Creating layer pool4
I0621 00:56:41.069975   388 net.cpp:69] Creating Layer pool4
I0621 00:56:41.069980   388 net.cpp:396] pool4 <- conv4_3
I0621 00:56:41.069990   388 net.cpp:358] pool4 -> pool4
I0621 00:56:41.069999   388 net.cpp:358] pool4 -> pool4_mask
I0621 00:56:41.070008   388 net.cpp:98] Setting up pool4
I0621 00:56:41.070016   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.070022   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.070030   388 layer_factory.hpp:78] Creating layer conv5_1
I0621 00:56:41.070039   388 net.cpp:69] Creating Layer conv5_1
I0621 00:56:41.070044   388 net.cpp:396] conv5_1 <- pool4
I0621 00:56:41.070052   388 net.cpp:358] conv5_1 -> conv5_1
I0621 00:56:41.070060   388 net.cpp:98] Setting up conv5_1
I0621 00:56:41.073153   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.073173   388 layer_factory.hpp:78] Creating layer relu5_1
I0621 00:56:41.073181   388 net.cpp:69] Creating Layer relu5_1
I0621 00:56:41.073189   388 net.cpp:396] relu5_1 <- conv5_1
I0621 00:56:41.073195   388 net.cpp:347] relu5_1 -> conv5_1 (in-place)
I0621 00:56:41.073202   388 net.cpp:98] Setting up relu5_1
I0621 00:56:41.073209   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.073215   388 layer_factory.hpp:78] Creating layer conv5_2
I0621 00:56:41.073223   388 net.cpp:69] Creating Layer conv5_2
I0621 00:56:41.073228   388 net.cpp:396] conv5_2 <- conv5_1
I0621 00:56:41.073236   388 net.cpp:358] conv5_2 -> conv5_2
I0621 00:56:41.073245   388 net.cpp:98] Setting up conv5_2
I0621 00:56:41.076750   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.076784   388 layer_factory.hpp:78] Creating layer relu5_2
I0621 00:56:41.076794   388 net.cpp:69] Creating Layer relu5_2
I0621 00:56:41.076814   388 net.cpp:396] relu5_2 <- conv5_2
I0621 00:56:41.076843   388 net.cpp:347] relu5_2 -> conv5_2 (in-place)
I0621 00:56:41.076859   388 net.cpp:98] Setting up relu5_2
I0621 00:56:41.076871   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.076884   388 layer_factory.hpp:78] Creating layer conv5_3
I0621 00:56:41.076900   388 net.cpp:69] Creating Layer conv5_3
I0621 00:56:41.076911   388 net.cpp:396] conv5_3 <- conv5_2
I0621 00:56:41.076926   388 net.cpp:358] conv5_3 -> conv5_3
I0621 00:56:41.076942   388 net.cpp:98] Setting up conv5_3
I0621 00:56:41.081079   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.081121   388 layer_factory.hpp:78] Creating layer relu5_3
I0621 00:56:41.081142   388 net.cpp:69] Creating Layer relu5_3
I0621 00:56:41.081161   388 net.cpp:396] relu5_3 <- conv5_3
I0621 00:56:41.081183   388 net.cpp:347] relu5_3 -> conv5_3 (in-place)
I0621 00:56:41.081209   388 net.cpp:98] Setting up relu5_3
I0621 00:56:41.081230   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.081249   388 layer_factory.hpp:78] Creating layer pool5
I0621 00:56:41.081286   388 net.cpp:69] Creating Layer pool5
I0621 00:56:41.081302   388 net.cpp:396] pool5 <- conv5_3
I0621 00:56:41.081326   388 net.cpp:358] pool5 -> pool5
I0621 00:56:41.081351   388 net.cpp:358] pool5 -> pool5_mask
I0621 00:56:41.081378   388 net.cpp:98] Setting up pool5
I0621 00:56:41.081403   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:41.081420   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:41.081441   388 layer_factory.hpp:78] Creating layer pool5_pool5_0_split
I0621 00:56:41.081460   388 net.cpp:69] Creating Layer pool5_pool5_0_split
I0621 00:56:41.081478   388 net.cpp:396] pool5_pool5_0_split <- pool5
I0621 00:56:41.081502   388 net.cpp:358] pool5_pool5_0_split -> pool5_pool5_0_split_0
I0621 00:56:41.081527   388 net.cpp:358] pool5_pool5_0_split -> pool5_pool5_0_split_1
I0621 00:56:41.081552   388 net.cpp:98] Setting up pool5_pool5_0_split
I0621 00:56:41.081604   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:41.081624   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:41.081640   388 layer_factory.hpp:78] Creating layer conv1_1b
I0621 00:56:41.081665   388 net.cpp:69] Creating Layer conv1_1b
I0621 00:56:41.081686   388 net.cpp:396] conv1_1b <- data2
I0621 00:56:41.081710   388 net.cpp:358] conv1_1b -> conv1_1b
I0621 00:56:41.081737   388 net.cpp:98] Setting up conv1_1b
I0621 00:56:41.082082   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.082108   388 net.cpp:438] Sharing parameters 'conv1_1p1' owned by layer 'conv1_1', param index 0
I0621 00:56:41.082129   388 net.cpp:438] Sharing parameters 'conv1_1p2' owned by layer 'conv1_1', param index 1
I0621 00:56:41.082145   388 layer_factory.hpp:78] Creating layer relu1_1b
I0621 00:56:41.082170   388 net.cpp:69] Creating Layer relu1_1b
I0621 00:56:41.082187   388 net.cpp:396] relu1_1b <- conv1_1b
I0621 00:56:41.082206   388 net.cpp:347] relu1_1b -> conv1_1b (in-place)
I0621 00:56:41.082228   388 net.cpp:98] Setting up relu1_1b
I0621 00:56:41.082248   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.082267   388 layer_factory.hpp:78] Creating layer conv1_2b
I0621 00:56:41.082289   388 net.cpp:69] Creating Layer conv1_2b
I0621 00:56:41.082309   388 net.cpp:396] conv1_2b <- conv1_1b
I0621 00:56:41.082332   388 net.cpp:358] conv1_2b -> conv1_2b
I0621 00:56:41.082367   388 net.cpp:98] Setting up conv1_2b
I0621 00:56:41.082900   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.082927   388 net.cpp:438] Sharing parameters 'conv1_2p1' owned by layer 'conv1_2', param index 0
I0621 00:56:41.082947   388 net.cpp:438] Sharing parameters 'conv1_2p2' owned by layer 'conv1_2', param index 1
I0621 00:56:41.082963   388 layer_factory.hpp:78] Creating layer relu1_2b
I0621 00:56:41.082989   388 net.cpp:69] Creating Layer relu1_2b
I0621 00:56:41.083009   388 net.cpp:396] relu1_2b <- conv1_2b
I0621 00:56:41.083034   388 net.cpp:347] relu1_2b -> conv1_2b (in-place)
I0621 00:56:41.083067   388 net.cpp:98] Setting up relu1_2b
I0621 00:56:41.083091   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:41.083111   388 layer_factory.hpp:78] Creating layer pool1b
I0621 00:56:41.083130   388 net.cpp:69] Creating Layer pool1b
I0621 00:56:41.083148   388 net.cpp:396] pool1b <- conv1_2b
I0621 00:56:41.083171   388 net.cpp:358] pool1b -> pool1b
I0621 00:56:41.083199   388 net.cpp:98] Setting up pool1b
I0621 00:56:41.083221   388 net.cpp:105] Top shape: 2 64 160 160 (3276800)
I0621 00:56:41.083242   388 layer_factory.hpp:78] Creating layer conv2_1b
I0621 00:56:41.083266   388 net.cpp:69] Creating Layer conv2_1b
I0621 00:56:41.083283   388 net.cpp:396] conv2_1b <- pool1b
I0621 00:56:41.083307   388 net.cpp:358] conv2_1b -> conv2_1b
I0621 00:56:41.083333   388 net.cpp:98] Setting up conv2_1b
I0621 00:56:41.083621   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.083652   388 net.cpp:438] Sharing parameters 'conv2_1p1' owned by layer 'conv2_1', param index 0
I0621 00:56:41.083676   388 net.cpp:438] Sharing parameters 'conv2_1p2' owned by layer 'conv2_1', param index 1
I0621 00:56:41.083700   388 layer_factory.hpp:78] Creating layer relu2_1b
I0621 00:56:41.083721   388 net.cpp:69] Creating Layer relu2_1b
I0621 00:56:41.083744   388 net.cpp:396] relu2_1b <- conv2_1b
I0621 00:56:41.083765   388 net.cpp:347] relu2_1b -> conv2_1b (in-place)
I0621 00:56:41.083788   388 net.cpp:98] Setting up relu2_1b
I0621 00:56:41.083806   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.083827   388 layer_factory.hpp:78] Creating layer conv2_2b
I0621 00:56:41.083848   388 net.cpp:69] Creating Layer conv2_2b
I0621 00:56:41.083868   388 net.cpp:396] conv2_2b <- conv2_1b
I0621 00:56:41.083892   388 net.cpp:358] conv2_2b -> conv2_2b
I0621 00:56:41.083920   388 net.cpp:98] Setting up conv2_2b
I0621 00:56:41.084327   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.084369   388 net.cpp:438] Sharing parameters 'conv2_2p1' owned by layer 'conv2_2', param index 0
I0621 00:56:41.084427   388 net.cpp:438] Sharing parameters 'conv2_2p2' owned by layer 'conv2_2', param index 1
I0621 00:56:41.084450   388 layer_factory.hpp:78] Creating layer relu2_2b
I0621 00:56:41.084475   388 net.cpp:69] Creating Layer relu2_2b
I0621 00:56:41.084489   388 net.cpp:396] relu2_2b <- conv2_2b
I0621 00:56:41.084513   388 net.cpp:347] relu2_2b -> conv2_2b (in-place)
I0621 00:56:41.084537   388 net.cpp:98] Setting up relu2_2b
I0621 00:56:41.084555   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:41.084574   388 layer_factory.hpp:78] Creating layer pool2b
I0621 00:56:41.084599   388 net.cpp:69] Creating Layer pool2b
I0621 00:56:41.084619   388 net.cpp:396] pool2b <- conv2_2b
I0621 00:56:41.084645   388 net.cpp:358] pool2b -> pool2b
I0621 00:56:41.084673   388 net.cpp:98] Setting up pool2b
I0621 00:56:41.084695   388 net.cpp:105] Top shape: 2 128 80 80 (1638400)
I0621 00:56:41.084717   388 layer_factory.hpp:78] Creating layer conv3_1b
I0621 00:56:41.084741   388 net.cpp:69] Creating Layer conv3_1b
I0621 00:56:41.084759   388 net.cpp:396] conv3_1b <- pool2b
I0621 00:56:41.084785   388 net.cpp:358] conv3_1b -> conv3_1b
I0621 00:56:41.084813   388 net.cpp:98] Setting up conv3_1b
I0621 00:56:41.085764   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.085790   388 net.cpp:438] Sharing parameters 'conv3_1p1' owned by layer 'conv3_1', param index 0
I0621 00:56:41.085811   388 net.cpp:438] Sharing parameters 'conv3_1p2' owned by layer 'conv3_1', param index 1
I0621 00:56:41.085834   388 layer_factory.hpp:78] Creating layer relu3_1b
I0621 00:56:41.085852   388 net.cpp:69] Creating Layer relu3_1b
I0621 00:56:41.085871   388 net.cpp:396] relu3_1b <- conv3_1b
I0621 00:56:41.085894   388 net.cpp:347] relu3_1b -> conv3_1b (in-place)
I0621 00:56:41.085913   388 net.cpp:98] Setting up relu3_1b
I0621 00:56:41.085929   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.085947   388 layer_factory.hpp:78] Creating layer conv3_2b
I0621 00:56:41.085966   388 net.cpp:69] Creating Layer conv3_2b
I0621 00:56:41.085983   388 net.cpp:396] conv3_2b <- conv3_1b
I0621 00:56:41.086004   388 net.cpp:358] conv3_2b -> conv3_2b
I0621 00:56:41.086024   388 net.cpp:98] Setting up conv3_2b
I0621 00:56:41.087013   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.087028   388 net.cpp:438] Sharing parameters 'conv3_2p1' owned by layer 'conv3_2', param index 0
I0621 00:56:41.087038   388 net.cpp:438] Sharing parameters 'conv3_2p2' owned by layer 'conv3_2', param index 1
I0621 00:56:41.087044   388 layer_factory.hpp:78] Creating layer relu3_2b
I0621 00:56:41.087051   388 net.cpp:69] Creating Layer relu3_2b
I0621 00:56:41.087059   388 net.cpp:396] relu3_2b <- conv3_2b
I0621 00:56:41.087074   388 net.cpp:347] relu3_2b -> conv3_2b (in-place)
I0621 00:56:41.087082   388 net.cpp:98] Setting up relu3_2b
I0621 00:56:41.087088   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.087095   388 layer_factory.hpp:78] Creating layer conv3_3b
I0621 00:56:41.087102   388 net.cpp:69] Creating Layer conv3_3b
I0621 00:56:41.087108   388 net.cpp:396] conv3_3b <- conv3_2b
I0621 00:56:41.087117   388 net.cpp:358] conv3_3b -> conv3_3b
I0621 00:56:41.087127   388 net.cpp:98] Setting up conv3_3b
I0621 00:56:41.087455   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.087468   388 net.cpp:438] Sharing parameters 'conv3_3p1' owned by layer 'conv3_3', param index 0
I0621 00:56:41.087476   388 net.cpp:438] Sharing parameters 'conv3_3p2' owned by layer 'conv3_3', param index 1
I0621 00:56:41.087483   388 layer_factory.hpp:78] Creating layer relu3_3b
I0621 00:56:41.087491   388 net.cpp:69] Creating Layer relu3_3b
I0621 00:56:41.087496   388 net.cpp:396] relu3_3b <- conv3_3b
I0621 00:56:41.087503   388 net.cpp:347] relu3_3b -> conv3_3b (in-place)
I0621 00:56:41.087510   388 net.cpp:98] Setting up relu3_3b
I0621 00:56:41.087517   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:41.087522   388 layer_factory.hpp:78] Creating layer pool3b
I0621 00:56:41.087539   388 net.cpp:69] Creating Layer pool3b
I0621 00:56:41.087548   388 net.cpp:396] pool3b <- conv3_3b
I0621 00:56:41.087554   388 net.cpp:358] pool3b -> pool3b
I0621 00:56:41.087563   388 net.cpp:98] Setting up pool3b
I0621 00:56:41.087569   388 net.cpp:105] Top shape: 2 256 40 40 (819200)
I0621 00:56:41.087576   388 layer_factory.hpp:78] Creating layer conv4_1b
I0621 00:56:41.087584   388 net.cpp:69] Creating Layer conv4_1b
I0621 00:56:41.087589   388 net.cpp:396] conv4_1b <- pool3b
I0621 00:56:41.087596   388 net.cpp:358] conv4_1b -> conv4_1b
I0621 00:56:41.087604   388 net.cpp:98] Setting up conv4_1b
I0621 00:56:41.089016   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.089030   388 net.cpp:438] Sharing parameters 'conv4_1p1' owned by layer 'conv4_1', param index 0
I0621 00:56:41.089038   388 net.cpp:438] Sharing parameters 'conv4_1p2' owned by layer 'conv4_1', param index 1
I0621 00:56:41.089046   388 layer_factory.hpp:78] Creating layer relu4_1b
I0621 00:56:41.089052   388 net.cpp:69] Creating Layer relu4_1b
I0621 00:56:41.089058   388 net.cpp:396] relu4_1b <- conv4_1b
I0621 00:56:41.089066   388 net.cpp:347] relu4_1b -> conv4_1b (in-place)
I0621 00:56:41.089072   388 net.cpp:98] Setting up relu4_1b
I0621 00:56:41.089078   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.089084   388 layer_factory.hpp:78] Creating layer conv4_2b
I0621 00:56:41.089092   388 net.cpp:69] Creating Layer conv4_2b
I0621 00:56:41.089097   388 net.cpp:396] conv4_2b <- conv4_1b
I0621 00:56:41.089105   388 net.cpp:358] conv4_2b -> conv4_2b
I0621 00:56:41.089114   388 net.cpp:98] Setting up conv4_2b
I0621 00:56:41.091714   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.091730   388 net.cpp:438] Sharing parameters 'conv4_2p1' owned by layer 'conv4_2', param index 0
I0621 00:56:41.091738   388 net.cpp:438] Sharing parameters 'conv4_2p2' owned by layer 'conv4_2', param index 1
I0621 00:56:41.091745   388 layer_factory.hpp:78] Creating layer relu4_2b
I0621 00:56:41.091753   388 net.cpp:69] Creating Layer relu4_2b
I0621 00:56:41.091759   388 net.cpp:396] relu4_2b <- conv4_2b
I0621 00:56:41.091766   388 net.cpp:347] relu4_2b -> conv4_2b (in-place)
I0621 00:56:41.091774   388 net.cpp:98] Setting up relu4_2b
I0621 00:56:41.091780   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.091785   388 layer_factory.hpp:78] Creating layer conv4_3b
I0621 00:56:41.091794   388 net.cpp:69] Creating Layer conv4_3b
I0621 00:56:41.091799   388 net.cpp:396] conv4_3b <- conv4_2b
I0621 00:56:41.091807   388 net.cpp:358] conv4_3b -> conv4_3b
I0621 00:56:41.091816   388 net.cpp:98] Setting up conv4_3b
I0621 00:56:41.093161   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.093174   388 net.cpp:438] Sharing parameters 'conv4_3p1' owned by layer 'conv4_3', param index 0
I0621 00:56:41.093183   388 net.cpp:438] Sharing parameters 'conv4_3p2' owned by layer 'conv4_3', param index 1
I0621 00:56:41.093190   388 layer_factory.hpp:78] Creating layer relu4_3b
I0621 00:56:41.093197   388 net.cpp:69] Creating Layer relu4_3b
I0621 00:56:41.093204   388 net.cpp:396] relu4_3b <- conv4_3b
I0621 00:56:41.093210   388 net.cpp:347] relu4_3b -> conv4_3b (in-place)
I0621 00:56:41.093217   388 net.cpp:98] Setting up relu4_3b
I0621 00:56:41.093224   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:41.093230   388 layer_factory.hpp:78] Creating layer pool4b
I0621 00:56:41.093236   388 net.cpp:69] Creating Layer pool4b
I0621 00:56:41.093241   388 net.cpp:396] pool4b <- conv4_3b
I0621 00:56:41.093250   388 net.cpp:358] pool4b -> pool4b
I0621 00:56:41.093260   388 net.cpp:98] Setting up pool4b
I0621 00:56:41.093266   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.093273   388 layer_factory.hpp:78] Creating layer conv5_1b
I0621 00:56:41.093281   388 net.cpp:69] Creating Layer conv5_1b
I0621 00:56:41.093286   388 net.cpp:396] conv5_1b <- pool4b
I0621 00:56:41.093294   388 net.cpp:358] conv5_1b -> conv5_1b
I0621 00:56:41.093303   388 net.cpp:98] Setting up conv5_1b
I0621 00:56:41.094614   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.094627   388 net.cpp:438] Sharing parameters 'conv5_1p1' owned by layer 'conv5_1', param index 0
I0621 00:56:41.094635   388 net.cpp:438] Sharing parameters 'conv5_1p2' owned by layer 'conv5_1', param index 1
I0621 00:56:41.094642   388 layer_factory.hpp:78] Creating layer relu5_1b
I0621 00:56:41.094650   388 net.cpp:69] Creating Layer relu5_1b
I0621 00:56:41.094655   388 net.cpp:396] relu5_1b <- conv5_1b
I0621 00:56:41.094662   388 net.cpp:347] relu5_1b -> conv5_1b (in-place)
I0621 00:56:41.094669   388 net.cpp:98] Setting up relu5_1b
I0621 00:56:41.094676   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.094681   388 layer_factory.hpp:78] Creating layer conv5_2b
I0621 00:56:41.094688   388 net.cpp:69] Creating Layer conv5_2b
I0621 00:56:41.094694   388 net.cpp:396] conv5_2b <- conv5_1b
I0621 00:56:41.094702   388 net.cpp:358] conv5_2b -> conv5_2b
I0621 00:56:41.094710   388 net.cpp:98] Setting up conv5_2b
I0621 00:56:41.096016   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.096030   388 net.cpp:438] Sharing parameters 'conv5_2p1' owned by layer 'conv5_2', param index 0
I0621 00:56:41.096038   388 net.cpp:438] Sharing parameters 'conv5_2p2' owned by layer 'conv5_2', param index 1
I0621 00:56:41.096046   388 layer_factory.hpp:78] Creating layer relu5_2b
I0621 00:56:41.096053   388 net.cpp:69] Creating Layer relu5_2b
I0621 00:56:41.096060   388 net.cpp:396] relu5_2b <- conv5_2b
I0621 00:56:41.096066   388 net.cpp:347] relu5_2b -> conv5_2b (in-place)
I0621 00:56:41.096073   388 net.cpp:98] Setting up relu5_2b
I0621 00:56:41.096079   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.096086   388 layer_factory.hpp:78] Creating layer conv5_3b
I0621 00:56:41.096092   388 net.cpp:69] Creating Layer conv5_3b
I0621 00:56:41.096098   388 net.cpp:396] conv5_3b <- conv5_2b
I0621 00:56:41.096107   388 net.cpp:358] conv5_3b -> conv5_3b
I0621 00:56:41.096117   388 net.cpp:98] Setting up conv5_3b
I0621 00:56:41.097415   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.097429   388 net.cpp:438] Sharing parameters 'conv5_3p1' owned by layer 'conv5_3', param index 0
I0621 00:56:41.097437   388 net.cpp:438] Sharing parameters 'conv5_3p2' owned by layer 'conv5_3', param index 1
I0621 00:56:41.097445   388 layer_factory.hpp:78] Creating layer relu5_3b
I0621 00:56:41.097451   388 net.cpp:69] Creating Layer relu5_3b
I0621 00:56:41.097457   388 net.cpp:396] relu5_3b <- conv5_3b
I0621 00:56:41.097465   388 net.cpp:347] relu5_3b -> conv5_3b (in-place)
I0621 00:56:41.097471   388 net.cpp:98] Setting up relu5_3b
I0621 00:56:41.097476   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:41.097482   388 layer_factory.hpp:78] Creating layer pool5b
I0621 00:56:41.097496   388 net.cpp:69] Creating Layer pool5b
I0621 00:56:41.097501   388 net.cpp:396] pool5b <- conv5_3b
I0621 00:56:41.097509   388 net.cpp:358] pool5b -> pool5b
I0621 00:56:41.097517   388 net.cpp:98] Setting up pool5b
I0621 00:56:41.097524   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:41.097532   388 layer_factory.hpp:78] Creating layer fc6
I0621 00:56:41.097538   388 net.cpp:69] Creating Layer fc6
I0621 00:56:41.097545   388 net.cpp:396] fc6 <- pool5_pool5_0_split_0
I0621 00:56:41.097553   388 net.cpp:358] fc6 -> fc6
I0621 00:56:41.097560   388 net.cpp:98] Setting up fc6
I0621 00:56:41.234817   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.234869   388 layer_factory.hpp:78] Creating layer relu6
I0621 00:56:41.234881   388 net.cpp:69] Creating Layer relu6
I0621 00:56:41.234890   388 net.cpp:396] relu6 <- fc6
I0621 00:56:41.234900   388 net.cpp:347] relu6 -> fc6 (in-place)
I0621 00:56:41.234910   388 net.cpp:358] relu6 -> relu6-mask
I0621 00:56:41.234921   388 net.cpp:98] Setting up relu6
I0621 00:56:41.234928   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.234935   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.234941   388 layer_factory.hpp:78] Creating layer fc7
I0621 00:56:41.234951   388 net.cpp:69] Creating Layer fc7
I0621 00:56:41.234982   388 net.cpp:396] fc7 <- fc6
I0621 00:56:41.234990   388 net.cpp:358] fc7 -> fc7
I0621 00:56:41.234999   388 net.cpp:98] Setting up fc7
I0621 00:56:41.257612   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.257659   388 layer_factory.hpp:78] Creating layer relu7
I0621 00:56:41.257670   388 net.cpp:69] Creating Layer relu7
I0621 00:56:41.257679   388 net.cpp:396] relu7 <- fc7
I0621 00:56:41.257688   388 net.cpp:347] relu7 -> fc7 (in-place)
I0621 00:56:41.257711   388 net.cpp:358] relu7 -> relu7-mask
I0621 00:56:41.257722   388 net.cpp:98] Setting up relu7
I0621 00:56:41.257730   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.257737   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.257745   388 layer_factory.hpp:78] Creating layer cls-score-voc
I0621 00:56:41.257755   388 net.cpp:69] Creating Layer cls-score-voc
I0621 00:56:41.257761   388 net.cpp:396] cls-score-voc <- fc7
I0621 00:56:41.257771   388 net.cpp:358] cls-score-voc -> cls-score
I0621 00:56:41.257781   388 net.cpp:98] Setting up cls-score-voc
I0621 00:56:41.260098   388 net.cpp:105] Top shape: 2 20 4 4 (640)
I0621 00:56:41.260113   388 layer_factory.hpp:78] Creating layer avg-pool
I0621 00:56:41.260123   388 net.cpp:69] Creating Layer avg-pool
I0621 00:56:41.260128   388 net.cpp:396] avg-pool <- cls-score
I0621 00:56:41.260138   388 net.cpp:358] avg-pool -> cls-score-pooled
I0621 00:56:41.260148   388 net.cpp:358] avg-pool -> score-pool-mask
I0621 00:56:41.260156   388 net.cpp:98] Setting up avg-pool
I0621 00:56:41.260164   388 net.cpp:105] Top shape: 2 20 1 1 (40)
I0621 00:56:41.260170   388 net.cpp:105] Top shape: 2 20 1 1 (40)
I0621 00:56:41.260176   388 layer_factory.hpp:78] Creating layer cls-score-sigmoid
I0621 00:56:41.260185   388 net.cpp:69] Creating Layer cls-score-sigmoid
I0621 00:56:41.260190   388 net.cpp:396] cls-score-sigmoid <- cls-score-pooled
I0621 00:56:41.260198   388 net.cpp:358] cls-score-sigmoid -> cls-score-sigmoid
I0621 00:56:41.260206   388 net.cpp:98] Setting up cls-score-sigmoid
I0621 00:56:41.260213   388 net.cpp:105] Top shape: 2 20 1 1 (40)
I0621 00:56:41.260220   388 layer_factory.hpp:78] Creating layer cls-score-mask
I0621 00:56:41.260227   388 net.cpp:69] Creating Layer cls-score-mask
I0621 00:56:41.260234   388 net.cpp:396] cls-score-mask <- cls-score-sigmoid
I0621 00:56:41.260241   388 net.cpp:396] cls-score-mask <- cls-label
I0621 00:56:41.260248   388 net.cpp:358] cls-score-mask -> cls-score-masked
I0621 00:56:41.260257   388 net.cpp:98] Setting up cls-score-mask
I0621 00:56:41.260264   388 net.cpp:105] Top shape: 2 20 1 1 (40)
I0621 00:56:41.260270   388 layer_factory.hpp:78] Creating layer avg-unpool
I0621 00:56:41.260278   388 net.cpp:69] Creating Layer avg-unpool
I0621 00:56:41.260285   388 net.cpp:396] avg-unpool <- cls-score-masked
I0621 00:56:41.260291   388 net.cpp:396] avg-unpool <- score-pool-mask
I0621 00:56:41.260299   388 net.cpp:358] avg-unpool -> cls-score-unpooled
I0621 00:56:41.260308   388 net.cpp:98] Setting up avg-unpool
I0621 00:56:41.260315   388 net.cpp:105] Top shape: 2 20 4 4 (640)
I0621 00:56:41.260321   388 layer_factory.hpp:78] Creating layer cls-score-voc-bp
I0621 00:56:41.260334   388 net.cpp:69] Creating Layer cls-score-voc-bp
I0621 00:56:41.260340   388 net.cpp:396] cls-score-voc-bp <- cls-score-unpooled
I0621 00:56:41.260349   388 net.cpp:358] cls-score-voc-bp -> fc7-bp
I0621 00:56:41.260357   388 net.cpp:98] Setting up cls-score-voc-bp
I0621 00:56:41.262578   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.262591   388 layer_factory.hpp:78] Creating layer relu7-mask
I0621 00:56:41.262600   388 net.cpp:69] Creating Layer relu7-mask
I0621 00:56:41.262606   388 net.cpp:396] relu7-mask <- fc7-bp
I0621 00:56:41.262614   388 net.cpp:396] relu7-mask <- relu7-mask
I0621 00:56:41.262624   388 net.cpp:347] relu7-mask -> fc7-bp (in-place)
I0621 00:56:41.262631   388 net.cpp:98] Setting up relu7-mask
I0621 00:56:41.262639   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.262665   388 layer_factory.hpp:78] Creating layer fc7-bp
I0621 00:56:41.262675   388 net.cpp:69] Creating Layer fc7-bp
I0621 00:56:41.262681   388 net.cpp:396] fc7-bp <- fc7-bp
I0621 00:56:41.262689   388 net.cpp:358] fc7-bp -> fc6-bp
I0621 00:56:41.262699   388 net.cpp:98] Setting up fc7-bp
I0621 00:56:41.285351   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.285399   388 layer_factory.hpp:78] Creating layer relu6-mask
I0621 00:56:41.285411   388 net.cpp:69] Creating Layer relu6-mask
I0621 00:56:41.285420   388 net.cpp:396] relu6-mask <- fc6-bp
I0621 00:56:41.285430   388 net.cpp:396] relu6-mask <- relu6-mask
I0621 00:56:41.285439   388 net.cpp:347] relu6-mask -> fc6-bp (in-place)
I0621 00:56:41.285449   388 net.cpp:98] Setting up relu6-mask
I0621 00:56:41.285456   388 net.cpp:105] Top shape: 2 4096 4 4 (131072)
I0621 00:56:41.285464   388 layer_factory.hpp:78] Creating layer fc6-bp
I0621 00:56:41.285471   388 net.cpp:69] Creating Layer fc6-bp
I0621 00:56:41.285477   388 net.cpp:396] fc6-bp <- fc6-bp
I0621 00:56:41.285485   388 net.cpp:358] fc6-bp -> pool5-bp
I0621 00:56:41.285495   388 net.cpp:98] Setting up fc6-bp
I0621 00:56:42.010483   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:42.010535   388 layer_factory.hpp:78] Creating layer pool5-bn
I0621 00:56:42.010550   388 net.cpp:69] Creating Layer pool5-bn
I0621 00:56:42.010562   388 net.cpp:396] pool5-bn <- pool5_pool5_0_split_1
I0621 00:56:42.010574   388 net.cpp:358] pool5-bn -> pool5-bn
I0621 00:56:42.010586   388 net.cpp:98] Setting up pool5-bn
I0621 00:56:42.010601   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:42.010622   388 layer_factory.hpp:78] Creating layer pool5b-bn
I0621 00:56:42.010632   388 net.cpp:69] Creating Layer pool5b-bn
I0621 00:56:42.010638   388 net.cpp:396] pool5b-bn <- pool5b
I0621 00:56:42.010648   388 net.cpp:358] pool5b-bn -> pool5b-bn
I0621 00:56:42.010656   388 net.cpp:98] Setting up pool5b-bn
I0621 00:56:42.010673   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:42.010684   388 layer_factory.hpp:78] Creating layer pool5-bp-bn
I0621 00:56:42.010691   388 net.cpp:69] Creating Layer pool5-bp-bn
I0621 00:56:42.010699   388 net.cpp:396] pool5-bp-bn <- pool5-bp
I0621 00:56:42.010706   388 net.cpp:358] pool5-bp-bn -> pool5-bp-bn
I0621 00:56:42.010722   388 net.cpp:98] Setting up pool5-bp-bn
I0621 00:56:42.010740   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:42.010748   388 layer_factory.hpp:78] Creating layer pool5-concat
I0621 00:56:42.010756   388 net.cpp:69] Creating Layer pool5-concat
I0621 00:56:42.010762   388 net.cpp:396] pool5-concat <- pool5-bn
I0621 00:56:42.010771   388 net.cpp:396] pool5-concat <- pool5b-bn
I0621 00:56:42.010777   388 net.cpp:396] pool5-concat <- pool5-bp-bn
I0621 00:56:42.010785   388 net.cpp:358] pool5-concat -> pool5-concat
I0621 00:56:42.010794   388 net.cpp:98] Setting up pool5-concat
I0621 00:56:42.010802   388 net.cpp:105] Top shape: 2 1536 10 10 (307200)
I0621 00:56:42.010818   388 layer_factory.hpp:78] Creating layer fc6-seg
I0621 00:56:42.010829   388 net.cpp:69] Creating Layer fc6-seg
I0621 00:56:42.010838   388 net.cpp:396] fc6-seg <- pool5-concat
I0621 00:56:42.010846   388 net.cpp:358] fc6-seg -> fc6-seg
I0621 00:56:42.010856   388 net.cpp:98] Setting up fc6-seg
I0621 00:56:49.030704   388 net.cpp:105] Top shape: 2 2048 4 4 (65536)
I0621 00:56:49.030768   388 layer_factory.hpp:78] Creating layer bnfc6-seg
I0621 00:56:49.030793   388 net.cpp:69] Creating Layer bnfc6-seg
I0621 00:56:49.030815   388 net.cpp:396] bnfc6-seg <- fc6-seg
I0621 00:56:49.030829   388 net.cpp:347] bnfc6-seg -> fc6-seg (in-place)
I0621 00:56:49.030841   388 net.cpp:98] Setting up bnfc6-seg
I0621 00:56:49.030869   388 net.cpp:105] Top shape: 2 2048 4 4 (65536)
I0621 00:56:49.030879   388 layer_factory.hpp:78] Creating layer relu6-seg
I0621 00:56:49.030890   388 net.cpp:69] Creating Layer relu6-seg
I0621 00:56:49.030897   388 net.cpp:396] relu6-seg <- fc6-seg
I0621 00:56:49.030906   388 net.cpp:347] relu6-seg -> fc6-seg (in-place)
I0621 00:56:49.030948   388 net.cpp:98] Setting up relu6-seg
I0621 00:56:49.030957   388 net.cpp:105] Top shape: 2 2048 4 4 (65536)
I0621 00:56:49.030964   388 layer_factory.hpp:78] Creating layer fc7-seg
I0621 00:56:49.030982   388 net.cpp:69] Creating Layer fc7-seg
I0621 00:56:49.030988   388 net.cpp:396] fc7-seg <- fc6-seg
I0621 00:56:49.030999   388 net.cpp:358] fc7-seg -> fc7-seg
I0621 00:56:49.031014   388 net.cpp:98] Setting up fc7-seg
I0621 00:56:49.206914   388 net.cpp:105] Top shape: 2 2048 4 4 (65536)
I0621 00:56:49.206959   388 layer_factory.hpp:78] Creating layer bnfc7-seg
I0621 00:56:49.206976   388 net.cpp:69] Creating Layer bnfc7-seg
I0621 00:56:49.206986   388 net.cpp:396] bnfc7-seg <- fc7-seg
I0621 00:56:49.206997   388 net.cpp:347] bnfc7-seg -> fc7-seg (in-place)
I0621 00:56:49.207010   388 net.cpp:98] Setting up bnfc7-seg
I0621 00:56:49.207039   388 net.cpp:105] Top shape: 2 2048 4 4 (65536)
I0621 00:56:49.207051   388 layer_factory.hpp:78] Creating layer relu7-seg
I0621 00:56:49.207072   388 net.cpp:69] Creating Layer relu7-seg
I0621 00:56:49.207079   388 net.cpp:396] relu7-seg <- fc7-seg
I0621 00:56:49.207090   388 net.cpp:347] relu7-seg -> fc7-seg (in-place)
I0621 00:56:49.207099   388 net.cpp:98] Setting up relu7-seg
I0621 00:56:49.207106   388 net.cpp:105] Top shape: 2 2048 4 4 (65536)
I0621 00:56:49.207113   388 layer_factory.hpp:78] Creating layer fc6-deconv
I0621 00:56:49.207123   388 net.cpp:69] Creating Layer fc6-deconv
I0621 00:56:49.207129   388 net.cpp:396] fc6-deconv <- fc7-seg
I0621 00:56:49.207139   388 net.cpp:358] fc6-deconv -> fc6-deconv
I0621 00:56:49.207151   388 net.cpp:98] Setting up fc6-deconv
I0621 00:56:51.736253   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:51.736316   388 layer_factory.hpp:78] Creating layer fc6-deconv-bn
I0621 00:56:51.736340   388 net.cpp:69] Creating Layer fc6-deconv-bn
I0621 00:56:51.736358   388 net.cpp:396] fc6-deconv-bn <- fc6-deconv
I0621 00:56:51.736371   388 net.cpp:347] fc6-deconv-bn -> fc6-deconv (in-place)
I0621 00:56:51.736382   388 net.cpp:98] Setting up fc6-deconv-bn
I0621 00:56:51.736397   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:51.736405   388 layer_factory.hpp:78] Creating layer fc6-deconv-relu
I0621 00:56:51.736418   388 net.cpp:69] Creating Layer fc6-deconv-relu
I0621 00:56:51.736423   388 net.cpp:396] fc6-deconv-relu <- fc6-deconv
I0621 00:56:51.736433   388 net.cpp:347] fc6-deconv-relu -> fc6-deconv (in-place)
I0621 00:56:51.736440   388 net.cpp:98] Setting up fc6-deconv-relu
I0621 00:56:51.736448   388 net.cpp:105] Top shape: 2 512 10 10 (102400)
I0621 00:56:51.736454   388 layer_factory.hpp:78] Creating layer unpool5
I0621 00:56:51.736464   388 net.cpp:69] Creating Layer unpool5
I0621 00:56:51.736469   388 net.cpp:396] unpool5 <- fc6-deconv
I0621 00:56:51.736488   388 net.cpp:396] unpool5 <- pool5_mask
I0621 00:56:51.736501   388 net.cpp:358] unpool5 -> unpool5
I0621 00:56:51.736511   388 net.cpp:98] Setting up unpool5
I0621 00:56:51.736518   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.736524   388 layer_factory.hpp:78] Creating layer deconv5_1
I0621 00:56:51.736536   388 net.cpp:69] Creating Layer deconv5_1
I0621 00:56:51.736541   388 net.cpp:396] deconv5_1 <- unpool5
I0621 00:56:51.736552   388 net.cpp:358] deconv5_1 -> deconv5_1
I0621 00:56:51.736559   388 net.cpp:98] Setting up deconv5_1
I0621 00:56:51.809643   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.809685   388 layer_factory.hpp:78] Creating layer debn5_1
I0621 00:56:51.809700   388 net.cpp:69] Creating Layer debn5_1
I0621 00:56:51.809707   388 net.cpp:396] debn5_1 <- deconv5_1
I0621 00:56:51.809718   388 net.cpp:347] debn5_1 -> deconv5_1 (in-place)
I0621 00:56:51.809728   388 net.cpp:98] Setting up debn5_1
I0621 00:56:51.809746   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.809753   388 layer_factory.hpp:78] Creating layer derelu5_1
I0621 00:56:51.809763   388 net.cpp:69] Creating Layer derelu5_1
I0621 00:56:51.809769   388 net.cpp:396] derelu5_1 <- deconv5_1
I0621 00:56:51.809779   388 net.cpp:347] derelu5_1 -> deconv5_1 (in-place)
I0621 00:56:51.809810   388 net.cpp:98] Setting up derelu5_1
I0621 00:56:51.809818   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.809825   388 layer_factory.hpp:78] Creating layer deconv5_2
I0621 00:56:51.809836   388 net.cpp:69] Creating Layer deconv5_2
I0621 00:56:51.809842   388 net.cpp:396] deconv5_2 <- deconv5_1
I0621 00:56:51.809852   388 net.cpp:358] deconv5_2 -> deconv5_2
I0621 00:56:51.809861   388 net.cpp:98] Setting up deconv5_2
I0621 00:56:51.903750   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.903798   388 layer_factory.hpp:78] Creating layer debn5_2
I0621 00:56:51.903815   388 net.cpp:69] Creating Layer debn5_2
I0621 00:56:51.903823   388 net.cpp:396] debn5_2 <- deconv5_2
I0621 00:56:51.903833   388 net.cpp:347] debn5_2 -> deconv5_2 (in-place)
I0621 00:56:51.903843   388 net.cpp:98] Setting up debn5_2
I0621 00:56:51.903859   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.903869   388 layer_factory.hpp:78] Creating layer derelu5_2
I0621 00:56:51.903879   388 net.cpp:69] Creating Layer derelu5_2
I0621 00:56:51.903885   388 net.cpp:396] derelu5_2 <- deconv5_2
I0621 00:56:51.903892   388 net.cpp:347] derelu5_2 -> deconv5_2 (in-place)
I0621 00:56:51.903900   388 net.cpp:98] Setting up derelu5_2
I0621 00:56:51.903908   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.903916   388 layer_factory.hpp:78] Creating layer deconv5_3
I0621 00:56:51.903926   388 net.cpp:69] Creating Layer deconv5_3
I0621 00:56:51.903933   388 net.cpp:396] deconv5_3 <- deconv5_2
I0621 00:56:51.903941   388 net.cpp:358] deconv5_3 -> deconv5_3
I0621 00:56:51.903951   388 net.cpp:98] Setting up deconv5_3
I0621 00:56:51.994698   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.994747   388 layer_factory.hpp:78] Creating layer debn5_3
I0621 00:56:51.994767   388 net.cpp:69] Creating Layer debn5_3
I0621 00:56:51.994786   388 net.cpp:396] debn5_3 <- deconv5_3
I0621 00:56:51.994797   388 net.cpp:347] debn5_3 -> deconv5_3 (in-place)
I0621 00:56:51.994808   388 net.cpp:98] Setting up debn5_3
I0621 00:56:51.994828   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.994837   388 layer_factory.hpp:78] Creating layer derelu5_3
I0621 00:56:51.994850   388 net.cpp:69] Creating Layer derelu5_3
I0621 00:56:51.994858   388 net.cpp:396] derelu5_3 <- deconv5_3
I0621 00:56:51.994865   388 net.cpp:347] derelu5_3 -> deconv5_3 (in-place)
I0621 00:56:51.994874   388 net.cpp:98] Setting up derelu5_3
I0621 00:56:51.994881   388 net.cpp:105] Top shape: 2 512 20 20 (409600)
I0621 00:56:51.994889   388 layer_factory.hpp:78] Creating layer unpool4
I0621 00:56:51.994901   388 net.cpp:69] Creating Layer unpool4
I0621 00:56:51.994909   388 net.cpp:396] unpool4 <- deconv5_3
I0621 00:56:51.994918   388 net.cpp:396] unpool4 <- pool4_mask
I0621 00:56:51.994932   388 net.cpp:358] unpool4 -> unpool4
I0621 00:56:51.994942   388 net.cpp:98] Setting up unpool4
I0621 00:56:51.994951   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:51.994957   388 layer_factory.hpp:78] Creating layer deconv4_1
I0621 00:56:51.994967   388 net.cpp:69] Creating Layer deconv4_1
I0621 00:56:51.994974   388 net.cpp:396] deconv4_1 <- unpool4
I0621 00:56:51.994985   388 net.cpp:358] deconv4_1 -> deconv4_1
I0621 00:56:51.994995   388 net.cpp:98] Setting up deconv4_1
I0621 00:56:52.092298   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:52.092342   388 layer_factory.hpp:78] Creating layer debn4_1
I0621 00:56:52.092356   388 net.cpp:69] Creating Layer debn4_1
I0621 00:56:52.092365   388 net.cpp:396] debn4_1 <- deconv4_1
I0621 00:56:52.092375   388 net.cpp:347] debn4_1 -> deconv4_1 (in-place)
I0621 00:56:52.092386   388 net.cpp:98] Setting up debn4_1
I0621 00:56:52.092408   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:52.092419   388 layer_factory.hpp:78] Creating layer derelu4_1
I0621 00:56:52.092427   388 net.cpp:69] Creating Layer derelu4_1
I0621 00:56:52.092433   388 net.cpp:396] derelu4_1 <- deconv4_1
I0621 00:56:52.092442   388 net.cpp:347] derelu4_1 -> deconv4_1 (in-place)
I0621 00:56:52.092473   388 net.cpp:98] Setting up derelu4_1
I0621 00:56:52.092483   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:52.092489   388 layer_factory.hpp:78] Creating layer deconv4_2
I0621 00:56:52.092500   388 net.cpp:69] Creating Layer deconv4_2
I0621 00:56:52.092506   388 net.cpp:396] deconv4_2 <- deconv4_1
I0621 00:56:52.092514   388 net.cpp:358] deconv4_2 -> deconv4_2
I0621 00:56:52.092524   388 net.cpp:98] Setting up deconv4_2
I0621 00:56:52.182309   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:52.182350   388 layer_factory.hpp:78] Creating layer debn4_2
I0621 00:56:52.182364   388 net.cpp:69] Creating Layer debn4_2
I0621 00:56:52.182374   388 net.cpp:396] debn4_2 <- deconv4_2
I0621 00:56:52.182385   388 net.cpp:347] debn4_2 -> deconv4_2 (in-place)
I0621 00:56:52.182395   388 net.cpp:98] Setting up debn4_2
I0621 00:56:52.182418   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:52.182426   388 layer_factory.hpp:78] Creating layer derelu4_2
I0621 00:56:52.182436   388 net.cpp:69] Creating Layer derelu4_2
I0621 00:56:52.182442   388 net.cpp:396] derelu4_2 <- deconv4_2
I0621 00:56:52.182449   388 net.cpp:347] derelu4_2 -> deconv4_2 (in-place)
I0621 00:56:52.182456   388 net.cpp:98] Setting up derelu4_2
I0621 00:56:52.182463   388 net.cpp:105] Top shape: 2 512 40 40 (1638400)
I0621 00:56:52.182471   388 layer_factory.hpp:78] Creating layer deconv4_3
I0621 00:56:52.182482   388 net.cpp:69] Creating Layer deconv4_3
I0621 00:56:52.182488   388 net.cpp:396] deconv4_3 <- deconv4_2
I0621 00:56:52.182497   388 net.cpp:358] deconv4_3 -> deconv4_3
I0621 00:56:52.182507   388 net.cpp:98] Setting up deconv4_3
I0621 00:56:52.222854   388 net.cpp:105] Top shape: 2 256 40 40 (819200)
I0621 00:56:52.222877   388 layer_factory.hpp:78] Creating layer debn4_3
I0621 00:56:52.222887   388 net.cpp:69] Creating Layer debn4_3
I0621 00:56:52.222895   388 net.cpp:396] debn4_3 <- deconv4_3
I0621 00:56:52.222903   388 net.cpp:347] debn4_3 -> deconv4_3 (in-place)
I0621 00:56:52.222911   388 net.cpp:98] Setting up debn4_3
I0621 00:56:52.222930   388 net.cpp:105] Top shape: 2 256 40 40 (819200)
I0621 00:56:52.222939   388 layer_factory.hpp:78] Creating layer derelu4_3
I0621 00:56:52.222949   388 net.cpp:69] Creating Layer derelu4_3
I0621 00:56:52.222955   388 net.cpp:396] derelu4_3 <- deconv4_3
I0621 00:56:52.222962   388 net.cpp:347] derelu4_3 -> deconv4_3 (in-place)
I0621 00:56:52.222970   388 net.cpp:98] Setting up derelu4_3
I0621 00:56:52.222982   388 net.cpp:105] Top shape: 2 256 40 40 (819200)
I0621 00:56:52.222988   388 layer_factory.hpp:78] Creating layer unpool3
I0621 00:56:52.222997   388 net.cpp:69] Creating Layer unpool3
I0621 00:56:52.223006   388 net.cpp:396] unpool3 <- deconv4_3
I0621 00:56:52.223014   388 net.cpp:396] unpool3 <- pool3_mask
I0621 00:56:52.223026   388 net.cpp:358] unpool3 -> unpool3
I0621 00:56:52.223036   388 net.cpp:98] Setting up unpool3
I0621 00:56:52.223042   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:52.223049   388 layer_factory.hpp:78] Creating layer deconv3_1
I0621 00:56:52.223058   388 net.cpp:69] Creating Layer deconv3_1
I0621 00:56:52.223069   388 net.cpp:396] deconv3_1 <- unpool3
I0621 00:56:52.223093   388 net.cpp:358] deconv3_1 -> deconv3_1
I0621 00:56:52.223103   388 net.cpp:98] Setting up deconv3_1
I0621 00:56:52.245807   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:52.245829   388 layer_factory.hpp:78] Creating layer debn3_1
I0621 00:56:52.245839   388 net.cpp:69] Creating Layer debn3_1
I0621 00:56:52.245847   388 net.cpp:396] debn3_1 <- deconv3_1
I0621 00:56:52.245856   388 net.cpp:347] debn3_1 -> deconv3_1 (in-place)
I0621 00:56:52.245863   388 net.cpp:98] Setting up debn3_1
I0621 00:56:52.245898   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:52.245908   388 layer_factory.hpp:78] Creating layer derelu3_1
I0621 00:56:52.245918   388 net.cpp:69] Creating Layer derelu3_1
I0621 00:56:52.245923   388 net.cpp:396] derelu3_1 <- deconv3_1
I0621 00:56:52.245954   388 net.cpp:347] derelu3_1 -> deconv3_1 (in-place)
I0621 00:56:52.245962   388 net.cpp:98] Setting up derelu3_1
I0621 00:56:52.245970   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:52.245975   388 layer_factory.hpp:78] Creating layer deconv3_2
I0621 00:56:52.245985   388 net.cpp:69] Creating Layer deconv3_2
I0621 00:56:52.245990   388 net.cpp:396] deconv3_2 <- deconv3_1
I0621 00:56:52.246000   388 net.cpp:358] deconv3_2 -> deconv3_2
I0621 00:56:52.246007   388 net.cpp:98] Setting up deconv3_2
I0621 00:56:52.262578   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:52.262595   388 layer_factory.hpp:78] Creating layer debn3_2
I0621 00:56:52.262606   388 net.cpp:69] Creating Layer debn3_2
I0621 00:56:52.262612   388 net.cpp:396] debn3_2 <- deconv3_2
I0621 00:56:52.262620   388 net.cpp:347] debn3_2 -> deconv3_2 (in-place)
I0621 00:56:52.262629   388 net.cpp:98] Setting up debn3_2
I0621 00:56:52.262662   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:52.262672   388 layer_factory.hpp:78] Creating layer derelu3_2
I0621 00:56:52.262679   388 net.cpp:69] Creating Layer derelu3_2
I0621 00:56:52.262686   388 net.cpp:396] derelu3_2 <- deconv3_2
I0621 00:56:52.262693   388 net.cpp:347] derelu3_2 -> deconv3_2 (in-place)
I0621 00:56:52.262701   388 net.cpp:98] Setting up derelu3_2
I0621 00:56:52.262707   388 net.cpp:105] Top shape: 2 256 80 80 (3276800)
I0621 00:56:52.262713   388 layer_factory.hpp:78] Creating layer deconv3_3
I0621 00:56:52.262722   388 net.cpp:69] Creating Layer deconv3_3
I0621 00:56:52.262727   388 net.cpp:396] deconv3_3 <- deconv3_2
I0621 00:56:52.262737   388 net.cpp:358] deconv3_3 -> deconv3_3
I0621 00:56:52.262748   388 net.cpp:98] Setting up deconv3_3
I0621 00:56:52.271365   388 net.cpp:105] Top shape: 2 128 80 80 (1638400)
I0621 00:56:52.271389   388 layer_factory.hpp:78] Creating layer debn3_3
I0621 00:56:52.271412   388 net.cpp:69] Creating Layer debn3_3
I0621 00:56:52.271420   388 net.cpp:396] debn3_3 <- deconv3_3
I0621 00:56:52.271430   388 net.cpp:347] debn3_3 -> deconv3_3 (in-place)
I0621 00:56:52.271437   388 net.cpp:98] Setting up debn3_3
I0621 00:56:52.271469   388 net.cpp:105] Top shape: 2 128 80 80 (1638400)
I0621 00:56:52.271478   388 layer_factory.hpp:78] Creating layer derelu3_3
I0621 00:56:52.271488   388 net.cpp:69] Creating Layer derelu3_3
I0621 00:56:52.271494   388 net.cpp:396] derelu3_3 <- deconv3_3
I0621 00:56:52.271502   388 net.cpp:347] derelu3_3 -> deconv3_3 (in-place)
I0621 00:56:52.271508   388 net.cpp:98] Setting up derelu3_3
I0621 00:56:52.271514   388 net.cpp:105] Top shape: 2 128 80 80 (1638400)
I0621 00:56:52.271522   388 layer_factory.hpp:78] Creating layer unpool2
I0621 00:56:52.271530   388 net.cpp:69] Creating Layer unpool2
I0621 00:56:52.271536   388 net.cpp:396] unpool2 <- deconv3_3
I0621 00:56:52.271544   388 net.cpp:396] unpool2 <- pool2_mask
I0621 00:56:52.271553   388 net.cpp:358] unpool2 -> unpool2
I0621 00:56:52.271561   388 net.cpp:98] Setting up unpool2
I0621 00:56:52.271569   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:52.271574   388 layer_factory.hpp:78] Creating layer deconv2_1
I0621 00:56:52.271584   388 net.cpp:69] Creating Layer deconv2_1
I0621 00:56:52.271589   388 net.cpp:396] deconv2_1 <- unpool2
I0621 00:56:52.271598   388 net.cpp:358] deconv2_1 -> deconv2_1
I0621 00:56:52.271608   388 net.cpp:98] Setting up deconv2_1
I0621 00:56:52.275869   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:52.275883   388 layer_factory.hpp:78] Creating layer debn2_1
I0621 00:56:52.275894   388 net.cpp:69] Creating Layer debn2_1
I0621 00:56:52.275902   388 net.cpp:396] debn2_1 <- deconv2_1
I0621 00:56:52.275909   388 net.cpp:347] debn2_1 -> deconv2_1 (in-place)
I0621 00:56:52.275918   388 net.cpp:98] Setting up debn2_1
I0621 00:56:52.276013   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:52.276024   388 layer_factory.hpp:78] Creating layer derelu2_1
I0621 00:56:52.276036   388 net.cpp:69] Creating Layer derelu2_1
I0621 00:56:52.276042   388 net.cpp:396] derelu2_1 <- deconv2_1
I0621 00:56:52.276063   388 net.cpp:347] derelu2_1 -> deconv2_1 (in-place)
I0621 00:56:52.276072   388 net.cpp:98] Setting up derelu2_1
I0621 00:56:52.276077   388 net.cpp:105] Top shape: 2 128 160 160 (6553600)
I0621 00:56:52.276084   388 layer_factory.hpp:78] Creating layer deconv2_2
I0621 00:56:52.276093   388 net.cpp:69] Creating Layer deconv2_2
I0621 00:56:52.276101   388 net.cpp:396] deconv2_2 <- deconv2_1
I0621 00:56:52.276108   388 net.cpp:358] deconv2_2 -> deconv2_2
I0621 00:56:52.276116   388 net.cpp:98] Setting up deconv2_2
I0621 00:56:52.278234   388 net.cpp:105] Top shape: 2 64 160 160 (3276800)
I0621 00:56:52.278247   388 layer_factory.hpp:78] Creating layer debn2_2
I0621 00:56:52.278259   388 net.cpp:69] Creating Layer debn2_2
I0621 00:56:52.278265   388 net.cpp:396] debn2_2 <- deconv2_2
I0621 00:56:52.278276   388 net.cpp:347] debn2_2 -> deconv2_2 (in-place)
I0621 00:56:52.278285   388 net.cpp:98] Setting up debn2_2
I0621 00:56:52.278378   388 net.cpp:105] Top shape: 2 64 160 160 (3276800)
I0621 00:56:52.278388   388 layer_factory.hpp:78] Creating layer derelu2_2
I0621 00:56:52.278471   388 net.cpp:69] Creating Layer derelu2_2
I0621 00:56:52.278482   388 net.cpp:396] derelu2_2 <- deconv2_2
I0621 00:56:52.278491   388 net.cpp:347] derelu2_2 -> deconv2_2 (in-place)
I0621 00:56:52.278501   388 net.cpp:98] Setting up derelu2_2
I0621 00:56:52.278506   388 net.cpp:105] Top shape: 2 64 160 160 (3276800)
I0621 00:56:52.278513   388 layer_factory.hpp:78] Creating layer unpool1
I0621 00:56:52.278520   388 net.cpp:69] Creating Layer unpool1
I0621 00:56:52.278530   388 net.cpp:396] unpool1 <- deconv2_2
I0621 00:56:52.278538   388 net.cpp:396] unpool1 <- pool1_mask
I0621 00:56:52.278548   388 net.cpp:358] unpool1 -> unpool1
I0621 00:56:52.278556   388 net.cpp:98] Setting up unpool1
I0621 00:56:52.278563   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:52.278569   388 layer_factory.hpp:78] Creating layer deconv1_1
I0621 00:56:52.278578   388 net.cpp:69] Creating Layer deconv1_1
I0621 00:56:52.278584   388 net.cpp:396] deconv1_1 <- unpool1
I0621 00:56:52.278592   388 net.cpp:358] deconv1_1 -> deconv1_1
I0621 00:56:52.278600   388 net.cpp:98] Setting up deconv1_1
I0621 00:56:52.279829   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:52.279842   388 layer_factory.hpp:78] Creating layer debn1_1
I0621 00:56:52.279853   388 net.cpp:69] Creating Layer debn1_1
I0621 00:56:52.279860   388 net.cpp:396] debn1_1 <- deconv1_1
I0621 00:56:52.279867   388 net.cpp:347] debn1_1 -> deconv1_1 (in-place)
I0621 00:56:52.279875   388 net.cpp:98] Setting up debn1_1
I0621 00:56:52.280232   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:52.280302   388 layer_factory.hpp:78] Creating layer derelu1_1
I0621 00:56:52.280310   388 net.cpp:69] Creating Layer derelu1_1
I0621 00:56:52.280316   388 net.cpp:396] derelu1_1 <- deconv1_1
I0621 00:56:52.280323   388 net.cpp:347] derelu1_1 -> deconv1_1 (in-place)
I0621 00:56:52.280331   388 net.cpp:98] Setting up derelu1_1
I0621 00:56:52.280338   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:52.280344   388 layer_factory.hpp:78] Creating layer deconv1_2
I0621 00:56:52.280352   388 net.cpp:69] Creating Layer deconv1_2
I0621 00:56:52.280359   388 net.cpp:396] deconv1_2 <- deconv1_1
I0621 00:56:52.280367   388 net.cpp:358] deconv1_2 -> deconv1_2
I0621 00:56:52.280376   388 net.cpp:98] Setting up deconv1_2
I0621 00:56:52.281599   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:52.281615   388 layer_factory.hpp:78] Creating layer debn1_2
I0621 00:56:52.281623   388 net.cpp:69] Creating Layer debn1_2
I0621 00:56:52.281630   388 net.cpp:396] debn1_2 <- deconv1_2
I0621 00:56:52.281638   388 net.cpp:347] debn1_2 -> deconv1_2 (in-place)
I0621 00:56:52.281646   388 net.cpp:98] Setting up debn1_2
I0621 00:56:52.282001   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:52.282016   388 layer_factory.hpp:78] Creating layer derelu1_2
I0621 00:56:52.282023   388 net.cpp:69] Creating Layer derelu1_2
I0621 00:56:52.282040   388 net.cpp:396] derelu1_2 <- deconv1_2
I0621 00:56:52.282048   388 net.cpp:347] derelu1_2 -> deconv1_2 (in-place)
I0621 00:56:52.282057   388 net.cpp:98] Setting up derelu1_2
I0621 00:56:52.282063   388 net.cpp:105] Top shape: 2 64 320 320 (13107200)
I0621 00:56:52.282068   388 layer_factory.hpp:78] Creating layer seg-score-voc
I0621 00:56:52.282079   388 net.cpp:69] Creating Layer seg-score-voc
I0621 00:56:52.282085   388 net.cpp:396] seg-score-voc <- deconv1_2
I0621 00:56:52.282094   388 net.cpp:358] seg-score-voc -> seg-score
I0621 00:56:52.282101   388 net.cpp:98] Setting up seg-score-voc
I0621 00:56:52.282299   388 net.cpp:105] Top shape: 2 2 320 320 (409600)
I0621 00:56:52.282312   388 layer_factory.hpp:78] Creating layer seg-score_seg-score-voc_0_split
I0621 00:56:52.282323   388 net.cpp:69] Creating Layer seg-score_seg-score-voc_0_split
I0621 00:56:52.282330   388 net.cpp:396] seg-score_seg-score-voc_0_split <- seg-score
I0621 00:56:52.282337   388 net.cpp:358] seg-score_seg-score-voc_0_split -> seg-score_seg-score-voc_0_split_0
I0621 00:56:52.282351   388 net.cpp:358] seg-score_seg-score-voc_0_split -> seg-score_seg-score-voc_0_split_1
I0621 00:56:52.282359   388 net.cpp:98] Setting up seg-score_seg-score-voc_0_split
I0621 00:56:52.282367   388 net.cpp:105] Top shape: 2 2 320 320 (409600)
I0621 00:56:52.282373   388 net.cpp:105] Top shape: 2 2 320 320 (409600)
I0621 00:56:52.282379   388 layer_factory.hpp:78] Creating layer seg-accuracy
I0621 00:56:52.282388   388 net.cpp:69] Creating Layer seg-accuracy
I0621 00:56:52.282394   388 net.cpp:396] seg-accuracy <- seg-score_seg-score-voc_0_split_0
I0621 00:56:52.282402   388 net.cpp:396] seg-accuracy <- seg-label_data_2_split_0
I0621 00:56:52.282412   388 net.cpp:358] seg-accuracy -> seg-accuracy
I0621 00:56:52.282420   388 net.cpp:98] Setting up seg-accuracy
I0621 00:56:52.282428   388 net.cpp:105] Top shape: 1 1 1 1 (1)
I0621 00:56:52.282434   388 layer_factory.hpp:78] Creating layer seg-loss
I0621 00:56:52.282449   388 net.cpp:69] Creating Layer seg-loss
I0621 00:56:52.282455   388 net.cpp:396] seg-loss <- seg-score_seg-score-voc_0_split_1
I0621 00:56:52.282462   388 net.cpp:396] seg-loss <- seg-label_data_2_split_1
I0621 00:56:52.282472   388 net.cpp:358] seg-loss -> seg-loss
I0621 00:56:52.282481   388 net.cpp:98] Setting up seg-loss
I0621 00:56:52.282490   388 net.cpp:105] Top shape: 1 1 1 1 (1)
I0621 00:56:52.282495   388 net.cpp:111]     with loss weight 1
I0621 00:56:52.282512   388 net.cpp:172] seg-loss needs backward computation.
I0621 00:56:52.282518   388 net.cpp:174] seg-accuracy does not need backward computation.
I0621 00:56:52.282524   388 net.cpp:172] seg-score_seg-score-voc_0_split needs backward computation.
I0621 00:56:52.282531   388 net.cpp:172] seg-score-voc needs backward computation.
I0621 00:56:52.282536   388 net.cpp:172] derelu1_2 needs backward computation.
I0621 00:56:52.282542   388 net.cpp:172] debn1_2 needs backward computation.
I0621 00:56:52.282548   388 net.cpp:172] deconv1_2 needs backward computation.
I0621 00:56:52.282554   388 net.cpp:172] derelu1_1 needs backward computation.
I0621 00:56:52.282559   388 net.cpp:172] debn1_1 needs backward computation.
I0621 00:56:52.282565   388 net.cpp:172] deconv1_1 needs backward computation.
I0621 00:56:52.282572   388 net.cpp:172] unpool1 needs backward computation.
I0621 00:56:52.282577   388 net.cpp:172] derelu2_2 needs backward computation.
I0621 00:56:52.282583   388 net.cpp:172] debn2_2 needs backward computation.
I0621 00:56:52.282589   388 net.cpp:172] deconv2_2 needs backward computation.
I0621 00:56:52.282595   388 net.cpp:172] derelu2_1 needs backward computation.
I0621 00:56:52.282603   388 net.cpp:172] debn2_1 needs backward computation.
I0621 00:56:52.282608   388 net.cpp:172] deconv2_1 needs backward computation.
I0621 00:56:52.282614   388 net.cpp:172] unpool2 needs backward computation.
I0621 00:56:52.282620   388 net.cpp:172] derelu3_3 needs backward computation.
I0621 00:56:52.282626   388 net.cpp:172] debn3_3 needs backward computation.
I0621 00:56:52.282639   388 net.cpp:172] deconv3_3 needs backward computation.
I0621 00:56:52.282646   388 net.cpp:172] derelu3_2 needs backward computation.
I0621 00:56:52.282651   388 net.cpp:172] debn3_2 needs backward computation.
I0621 00:56:52.282657   388 net.cpp:172] deconv3_2 needs backward computation.
I0621 00:56:52.282663   388 net.cpp:172] derelu3_1 needs backward computation.
I0621 00:56:52.282668   388 net.cpp:172] debn3_1 needs backward computation.
I0621 00:56:52.282675   388 net.cpp:172] deconv3_1 needs backward computation.
I0621 00:56:52.282680   388 net.cpp:172] unpool3 needs backward computation.
I0621 00:56:52.282686   388 net.cpp:172] derelu4_3 needs backward computation.
I0621 00:56:52.282691   388 net.cpp:172] debn4_3 needs backward computation.
I0621 00:56:52.282697   388 net.cpp:172] deconv4_3 needs backward computation.
I0621 00:56:52.282703   388 net.cpp:172] derelu4_2 needs backward computation.
I0621 00:56:52.282709   388 net.cpp:172] debn4_2 needs backward computation.
I0621 00:56:52.282714   388 net.cpp:172] deconv4_2 needs backward computation.
I0621 00:56:52.282721   388 net.cpp:172] derelu4_1 needs backward computation.
I0621 00:56:52.282727   388 net.cpp:172] debn4_1 needs backward computation.
I0621 00:56:52.282732   388 net.cpp:172] deconv4_1 needs backward computation.
I0621 00:56:52.282738   388 net.cpp:172] unpool4 needs backward computation.
I0621 00:56:52.282744   388 net.cpp:172] derelu5_3 needs backward computation.
I0621 00:56:52.282753   388 net.cpp:172] debn5_3 needs backward computation.
I0621 00:56:52.282759   388 net.cpp:172] deconv5_3 needs backward computation.
I0621 00:56:52.282765   388 net.cpp:172] derelu5_2 needs backward computation.
I0621 00:56:52.282770   388 net.cpp:172] debn5_2 needs backward computation.
I0621 00:56:52.282776   388 net.cpp:172] deconv5_2 needs backward computation.
I0621 00:56:52.282783   388 net.cpp:172] derelu5_1 needs backward computation.
I0621 00:56:52.282788   388 net.cpp:172] debn5_1 needs backward computation.
I0621 00:56:52.282794   388 net.cpp:172] deconv5_1 needs backward computation.
I0621 00:56:52.282800   388 net.cpp:172] unpool5 needs backward computation.
I0621 00:56:52.282807   388 net.cpp:172] fc6-deconv-relu needs backward computation.
I0621 00:56:52.282814   388 net.cpp:172] fc6-deconv-bn needs backward computation.
I0621 00:56:52.282819   388 net.cpp:172] fc6-deconv needs backward computation.
I0621 00:56:52.282826   388 net.cpp:172] relu7-seg needs backward computation.
I0621 00:56:52.282832   388 net.cpp:172] bnfc7-seg needs backward computation.
I0621 00:56:52.282838   388 net.cpp:172] fc7-seg needs backward computation.
I0621 00:56:52.282845   388 net.cpp:172] relu6-seg needs backward computation.
I0621 00:56:52.282851   388 net.cpp:172] bnfc6-seg needs backward computation.
I0621 00:56:52.282857   388 net.cpp:172] fc6-seg needs backward computation.
I0621 00:56:52.282865   388 net.cpp:172] pool5-concat needs backward computation.
I0621 00:56:52.282872   388 net.cpp:172] pool5-bp-bn needs backward computation.
I0621 00:56:52.282879   388 net.cpp:172] pool5b-bn needs backward computation.
I0621 00:56:52.282886   388 net.cpp:172] pool5-bn needs backward computation.
I0621 00:56:52.282893   388 net.cpp:174] fc6-bp does not need backward computation.
I0621 00:56:52.282902   388 net.cpp:174] relu6-mask does not need backward computation.
I0621 00:56:52.282907   388 net.cpp:174] fc7-bp does not need backward computation.
I0621 00:56:52.282914   388 net.cpp:174] relu7-mask does not need backward computation.
I0621 00:56:52.282920   388 net.cpp:174] cls-score-voc-bp does not need backward computation.
I0621 00:56:52.282927   388 net.cpp:174] avg-unpool does not need backward computation.
I0621 00:56:52.282935   388 net.cpp:174] cls-score-mask does not need backward computation.
I0621 00:56:52.282943   388 net.cpp:174] cls-score-sigmoid does not need backward computation.
I0621 00:56:52.282955   388 net.cpp:174] avg-pool does not need backward computation.
I0621 00:56:52.282960   388 net.cpp:174] cls-score-voc does not need backward computation.
I0621 00:56:52.282968   388 net.cpp:174] relu7 does not need backward computation.
I0621 00:56:52.282973   388 net.cpp:174] fc7 does not need backward computation.
I0621 00:56:52.282976   388 net.cpp:174] relu6 does not need backward computation.
I0621 00:56:52.282979   388 net.cpp:174] fc6 does not need backward computation.
I0621 00:56:52.282989   388 net.cpp:174] pool5b does not need backward computation.
I0621 00:56:52.282995   388 net.cpp:174] relu5_3b does not need backward computation.
I0621 00:56:52.283001   388 net.cpp:174] conv5_3b does not need backward computation.
I0621 00:56:52.283009   388 net.cpp:174] relu5_2b does not need backward computation.
I0621 00:56:52.283015   388 net.cpp:174] conv5_2b does not need backward computation.
I0621 00:56:52.283021   388 net.cpp:174] relu5_1b does not need backward computation.
I0621 00:56:52.283027   388 net.cpp:174] conv5_1b does not need backward computation.
I0621 00:56:52.283035   388 net.cpp:174] pool4b does not need backward computation.
I0621 00:56:52.283041   388 net.cpp:174] relu4_3b does not need backward computation.
I0621 00:56:52.283047   388 net.cpp:174] conv4_3b does not need backward computation.
I0621 00:56:52.283053   388 net.cpp:174] relu4_2b does not need backward computation.
I0621 00:56:52.283059   388 net.cpp:174] conv4_2b does not need backward computation.
I0621 00:56:52.283071   388 net.cpp:174] relu4_1b does not need backward computation.
I0621 00:56:52.283077   388 net.cpp:174] conv4_1b does not need backward computation.
I0621 00:56:52.283085   388 net.cpp:174] pool3b does not need backward computation.
I0621 00:56:52.283092   388 net.cpp:174] relu3_3b does not need backward computation.
I0621 00:56:52.283097   388 net.cpp:174] conv3_3b does not need backward computation.
I0621 00:56:52.283103   388 net.cpp:174] relu3_2b does not need backward computation.
I0621 00:56:52.283110   388 net.cpp:174] conv3_2b does not need backward computation.
I0621 00:56:52.283118   388 net.cpp:174] relu3_1b does not need backward computation.
I0621 00:56:52.283123   388 net.cpp:174] conv3_1b does not need backward computation.
I0621 00:56:52.283129   388 net.cpp:174] pool2b does not need backward computation.
I0621 00:56:52.283136   388 net.cpp:174] relu2_2b does not need backward computation.
I0621 00:56:52.283143   388 net.cpp:174] conv2_2b does not need backward computation.
I0621 00:56:52.283149   388 net.cpp:174] relu2_1b does not need backward computation.
I0621 00:56:52.283154   388 net.cpp:174] conv2_1b does not need backward computation.
I0621 00:56:52.283160   388 net.cpp:174] pool1b does not need backward computation.
I0621 00:56:52.283166   388 net.cpp:174] relu1_2b does not need backward computation.
I0621 00:56:52.283172   388 net.cpp:174] conv1_2b does not need backward computation.
I0621 00:56:52.283179   388 net.cpp:174] relu1_1b does not need backward computation.
I0621 00:56:52.283185   388 net.cpp:174] conv1_1b does not need backward computation.
I0621 00:56:52.283190   388 net.cpp:174] pool5_pool5_0_split does not need backward computation.
I0621 00:56:52.283197   388 net.cpp:174] pool5 does not need backward computation.
I0621 00:56:52.283205   388 net.cpp:174] relu5_3 does not need backward computation.
I0621 00:56:52.283211   388 net.cpp:174] conv5_3 does not need backward computation.
I0621 00:56:52.283218   388 net.cpp:174] relu5_2 does not need backward computation.
I0621 00:56:52.283226   388 net.cpp:174] conv5_2 does not need backward computation.
I0621 00:56:52.283231   388 net.cpp:174] relu5_1 does not need backward computation.
I0621 00:56:52.283237   388 net.cpp:174] conv5_1 does not need backward computation.
I0621 00:56:52.283244   388 net.cpp:174] pool4 does not need backward computation.
I0621 00:56:52.283251   388 net.cpp:174] relu4_3 does not need backward computation.
I0621 00:56:52.283257   388 net.cpp:174] conv4_3 does not need backward computation.
I0621 00:56:52.283263   388 net.cpp:174] relu4_2 does not need backward computation.
I0621 00:56:52.283269   388 net.cpp:174] conv4_2 does not need backward computation.
I0621 00:56:52.283282   388 net.cpp:174] relu4_1 does not need backward computation.
I0621 00:56:52.283288   388 net.cpp:174] conv4_1 does not need backward computation.
I0621 00:56:52.283294   388 net.cpp:174] pool3 does not need backward computation.
I0621 00:56:52.283301   388 net.cpp:174] relu3_3 does not need backward computation.
I0621 00:56:52.283308   388 net.cpp:174] conv3_3 does not need backward computation.
I0621 00:56:52.283314   388 net.cpp:174] relu3_2 does not need backward computation.
I0621 00:56:52.283321   388 net.cpp:174] conv3_2 does not need backward computation.
I0621 00:56:52.283329   388 net.cpp:174] relu3_1 does not need backward computation.
I0621 00:56:52.283335   388 net.cpp:174] conv3_1 does not need backward computation.
I0621 00:56:52.283342   388 net.cpp:174] pool2 does not need backward computation.
I0621 00:56:52.283349   388 net.cpp:174] relu2_2 does not need backward computation.
I0621 00:56:52.283356   388 net.cpp:174] conv2_2 does not need backward computation.
I0621 00:56:52.283365   388 net.cpp:174] relu2_1 does not need backward computation.
I0621 00:56:52.283370   388 net.cpp:174] conv2_1 does not need backward computation.
I0621 00:56:52.283376   388 net.cpp:174] pool1 does not need backward computation.
I0621 00:56:52.283385   388 net.cpp:174] relu1_2 does not need backward computation.
I0621 00:56:52.283390   388 net.cpp:174] conv1_2 does not need backward computation.
I0621 00:56:52.283397   388 net.cpp:174] relu1_1 does not need backward computation.
I0621 00:56:52.283403   388 net.cpp:174] conv1_1 does not need backward computation.
I0621 00:56:52.283411   388 net.cpp:174] seg-label_data_2_split does not need backward computation.
I0621 00:56:52.283417   388 net.cpp:174] data does not need backward computation.
I0621 00:56:52.283422   388 net.cpp:210] This network produces output seg-accuracy
I0621 00:56:52.283428   388 net.cpp:210] This network produces output seg-loss
I0621 00:56:52.283499   388 net.cpp:469] Collecting Learning Rate and Weight Decay.
I0621 00:56:52.283517   388 net.cpp:221] Network initialization done.
I0621 00:56:52.283524   388 net.cpp:222] Memory required for data: 1678399272
I0621 00:56:52.284015   388 solver.cpp:42] Solver scaffolding done.
I0621 00:56:52.284209   388 caffe.cpp:115] Finetuning from initialization.caffemodel
I0621 00:56:58.931414   388 net.cpp:707] Copying source layer conv1_1
I0621 00:56:58.931463   388 net.cpp:713] Layer#0 | Blob#0:
I0621 00:56:58.931473   388 net.cpp:714] - num 64 | 64
I0621 00:56:58.931478   388 net.cpp:715] - cha 3 | 3
I0621 00:56:58.931484   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.931490   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.931502   388 net.cpp:713] Layer#0 | Blob#1:
I0621 00:56:58.931509   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.931515   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.931520   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.931526   388 net.cpp:717] - wid 64 | 64
I0621 00:56:58.931535   388 net.cpp:707] Copying source layer relu1_1
I0621 00:56:58.931541   388 net.cpp:707] Copying source layer conv1_2
I0621 00:56:58.931546   388 net.cpp:713] Layer#2 | Blob#0:
I0621 00:56:58.931553   388 net.cpp:714] - num 64 | 64
I0621 00:56:58.931560   388 net.cpp:715] - cha 64 | 64
I0621 00:56:58.931565   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.931571   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.931639   388 net.cpp:713] Layer#2 | Blob#1:
I0621 00:56:58.931648   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.931653   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.931659   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.931664   388 net.cpp:717] - wid 64 | 64
I0621 00:56:58.931681   388 net.cpp:707] Copying source layer relu1_2
I0621 00:56:58.931691   388 net.cpp:707] Copying source layer pool1
I0621 00:56:58.931699   388 net.cpp:707] Copying source layer conv2_1
I0621 00:56:58.931704   388 net.cpp:713] Layer#5 | Blob#0:
I0621 00:56:58.931710   388 net.cpp:714] - num 128 | 128
I0621 00:56:58.931716   388 net.cpp:715] - cha 64 | 64
I0621 00:56:58.931721   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.931754   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.931891   388 net.cpp:713] Layer#5 | Blob#1:
I0621 00:56:58.931900   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.931906   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.931912   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.931917   388 net.cpp:717] - wid 128 | 128
I0621 00:56:58.931927   388 net.cpp:707] Copying source layer relu2_1
I0621 00:56:58.931934   388 net.cpp:707] Copying source layer conv2_2
I0621 00:56:58.931941   388 net.cpp:713] Layer#7 | Blob#0:
I0621 00:56:58.931947   388 net.cpp:714] - num 128 | 128
I0621 00:56:58.931952   388 net.cpp:715] - cha 128 | 128
I0621 00:56:58.931957   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.931963   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.932222   388 net.cpp:713] Layer#7 | Blob#1:
I0621 00:56:58.932235   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.932241   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.932247   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.932253   388 net.cpp:717] - wid 128 | 128
I0621 00:56:58.932260   388 net.cpp:707] Copying source layer relu2_2
I0621 00:56:58.932265   388 net.cpp:707] Copying source layer pool2
I0621 00:56:58.932271   388 net.cpp:707] Copying source layer conv3_1
I0621 00:56:58.932277   388 net.cpp:713] Layer#10 | Blob#0:
I0621 00:56:58.932283   388 net.cpp:714] - num 256 | 256
I0621 00:56:58.932289   388 net.cpp:715] - cha 128 | 128
I0621 00:56:58.932294   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.932299   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.932808   388 net.cpp:713] Layer#10 | Blob#1:
I0621 00:56:58.932821   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.932826   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.932832   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.932837   388 net.cpp:717] - wid 256 | 256
I0621 00:56:58.932844   388 net.cpp:707] Copying source layer relu3_1
I0621 00:56:58.932852   388 net.cpp:707] Copying source layer conv3_2
I0621 00:56:58.932857   388 net.cpp:713] Layer#12 | Blob#0:
I0621 00:56:58.932865   388 net.cpp:714] - num 256 | 256
I0621 00:56:58.932871   388 net.cpp:715] - cha 256 | 256
I0621 00:56:58.932876   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.932881   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.933861   388 net.cpp:713] Layer#12 | Blob#1:
I0621 00:56:58.933873   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.933879   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.933884   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.933890   388 net.cpp:717] - wid 256 | 256
I0621 00:56:58.933897   388 net.cpp:707] Copying source layer relu3_2
I0621 00:56:58.933904   388 net.cpp:707] Copying source layer conv3_3
I0621 00:56:58.933912   388 net.cpp:713] Layer#14 | Blob#0:
I0621 00:56:58.933919   388 net.cpp:714] - num 256 | 256
I0621 00:56:58.933925   388 net.cpp:715] - cha 256 | 256
I0621 00:56:58.933930   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.933936   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.934916   388 net.cpp:713] Layer#14 | Blob#1:
I0621 00:56:58.934928   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.934934   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.934940   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.934945   388 net.cpp:717] - wid 256 | 256
I0621 00:56:58.934955   388 net.cpp:707] Copying source layer relu3_3
I0621 00:56:58.934962   388 net.cpp:707] Copying source layer pool3
I0621 00:56:58.934970   388 net.cpp:707] Copying source layer conv4_1
I0621 00:56:58.934978   388 net.cpp:713] Layer#17 | Blob#0:
I0621 00:56:58.934983   388 net.cpp:714] - num 512 | 512
I0621 00:56:58.934988   388 net.cpp:715] - cha 256 | 256
I0621 00:56:58.934993   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.934999   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.936696   388 net.cpp:713] Layer#17 | Blob#1:
I0621 00:56:58.936710   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.936717   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.936722   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.936728   388 net.cpp:717] - wid 512 | 512
I0621 00:56:58.936734   388 net.cpp:707] Copying source layer relu4_1
I0621 00:56:58.936741   388 net.cpp:707] Copying source layer conv4_2
I0621 00:56:58.936755   388 net.cpp:713] Layer#19 | Blob#0:
I0621 00:56:58.936780   388 net.cpp:714] - num 512 | 512
I0621 00:56:58.936786   388 net.cpp:715] - cha 512 | 512
I0621 00:56:58.936791   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.936797   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.939653   388 net.cpp:713] Layer#19 | Blob#1:
I0621 00:56:58.939682   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.939687   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.939693   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.939699   388 net.cpp:717] - wid 512 | 512
I0621 00:56:58.939709   388 net.cpp:707] Copying source layer relu4_2
I0621 00:56:58.939718   388 net.cpp:707] Copying source layer conv4_3
I0621 00:56:58.939724   388 net.cpp:713] Layer#21 | Blob#0:
I0621 00:56:58.939731   388 net.cpp:714] - num 512 | 512
I0621 00:56:58.939736   388 net.cpp:715] - cha 512 | 512
I0621 00:56:58.939743   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.939748   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.942952   388 net.cpp:713] Layer#21 | Blob#1:
I0621 00:56:58.942981   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.942987   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.942993   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.942999   388 net.cpp:717] - wid 512 | 512
I0621 00:56:58.943009   388 net.cpp:707] Copying source layer relu4_3
I0621 00:56:58.943017   388 net.cpp:707] Copying source layer pool4
I0621 00:56:58.943023   388 net.cpp:707] Copying source layer conv5_1
I0621 00:56:58.943029   388 net.cpp:713] Layer#24 | Blob#0:
I0621 00:56:58.943035   388 net.cpp:714] - num 512 | 512
I0621 00:56:58.943042   388 net.cpp:715] - cha 512 | 512
I0621 00:56:58.943047   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.943053   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.945924   388 net.cpp:713] Layer#24 | Blob#1:
I0621 00:56:58.945961   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.945967   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.945973   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.945979   388 net.cpp:717] - wid 512 | 512
I0621 00:56:58.945988   388 net.cpp:707] Copying source layer relu5_1
I0621 00:56:58.945996   388 net.cpp:707] Copying source layer conv5_2
I0621 00:56:58.946002   388 net.cpp:713] Layer#26 | Blob#0:
I0621 00:56:58.946009   388 net.cpp:714] - num 512 | 512
I0621 00:56:58.946014   388 net.cpp:715] - cha 512 | 512
I0621 00:56:58.946020   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.946025   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.948863   388 net.cpp:713] Layer#26 | Blob#1:
I0621 00:56:58.948892   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.948899   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.948904   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.948909   388 net.cpp:717] - wid 512 | 512
I0621 00:56:58.948920   388 net.cpp:707] Copying source layer relu5_2
I0621 00:56:58.948928   388 net.cpp:707] Copying source layer conv5_3
I0621 00:56:58.948936   388 net.cpp:713] Layer#28 | Blob#0:
I0621 00:56:58.948943   388 net.cpp:714] - num 512 | 512
I0621 00:56:58.948950   388 net.cpp:715] - cha 512 | 512
I0621 00:56:58.948954   388 net.cpp:716] - hei 3 | 3
I0621 00:56:58.948959   388 net.cpp:717] - wid 3 | 3
I0621 00:56:58.951838   388 net.cpp:713] Layer#28 | Blob#1:
I0621 00:56:58.951872   388 net.cpp:714] - num 1 | 1
I0621 00:56:58.951879   388 net.cpp:715] - cha 1 | 1
I0621 00:56:58.951884   388 net.cpp:716] - hei 1 | 1
I0621 00:56:58.951890   388 net.cpp:717] - wid 512 | 512
I0621 00:56:58.951900   388 net.cpp:707] Copying source layer relu5_3
I0621 00:56:58.951907   388 net.cpp:707] Copying source layer pool5
I0621 00:56:58.951918   388 net.cpp:707] Copying source layer fc6
I0621 00:56:58.951925   388 net.cpp:713] Layer#31 | Blob#0:
I0621 00:56:58.951930   388 net.cpp:714] - num 4096 | 4096
I0621 00:56:58.951936   388 net.cpp:715] - cha 512 | 512
I0621 00:56:58.951941   388 net.cpp:716] - hei 7 | 7
I0621 00:56:58.951947   388 net.cpp:717] - wid 7 | 7
I0621 00:56:59.070528   388 net.cpp:713] Layer#31 | Blob#1:
I0621 00:56:59.070574   388 net.cpp:714] - num 1 | 1
I0621 00:56:59.070581   388 net.cpp:715] - cha 1 | 1
I0621 00:56:59.070586   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.070617   388 net.cpp:717] - wid 4096 | 4096
I0621 00:56:59.070637   388 net.cpp:707] Copying source layer relu6
I0621 00:56:59.070646   388 net.cpp:707] Copying source layer fc7
I0621 00:56:59.070652   388 net.cpp:713] Layer#33 | Blob#0:
I0621 00:56:59.070657   388 net.cpp:714] - num 4096 | 4096
I0621 00:56:59.070662   388 net.cpp:715] - cha 4096 | 4096
I0621 00:56:59.070668   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.070674   388 net.cpp:717] - wid 1 | 1
I0621 00:56:59.095958   388 net.cpp:713] Layer#33 | Blob#1:
I0621 00:56:59.096006   388 net.cpp:714] - num 1 | 1
I0621 00:56:59.096014   388 net.cpp:715] - cha 1 | 1
I0621 00:56:59.096019   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.096024   388 net.cpp:717] - wid 4096 | 4096
I0621 00:56:59.096043   388 net.cpp:707] Copying source layer relu7
I0621 00:56:59.096050   388 net.cpp:707] Copying source layer cls-score-voc
I0621 00:56:59.096056   388 net.cpp:713] Layer#35 | Blob#0:
I0621 00:56:59.096062   388 net.cpp:714] - num 20 | 20
I0621 00:56:59.096068   388 net.cpp:715] - cha 4096 | 4096
I0621 00:56:59.096073   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.096079   388 net.cpp:717] - wid 1 | 1
I0621 00:56:59.096222   388 net.cpp:713] Layer#35 | Blob#1:
I0621 00:56:59.096235   388 net.cpp:714] - num 1 | 1
I0621 00:56:59.096240   388 net.cpp:715] - cha 1 | 1
I0621 00:56:59.096246   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.096252   388 net.cpp:717] - wid 20 | 20
I0621 00:56:59.096258   388 net.cpp:707] Copying source layer avg-pool
I0621 00:56:59.096266   388 net.cpp:707] Copying source layer avg-unpool
I0621 00:56:59.096274   388 net.cpp:707] Copying source layer cls-score-voc-bp
I0621 00:56:59.096281   388 net.cpp:713] Layer#38 | Blob#0:
I0621 00:56:59.096287   388 net.cpp:714] - num 4096 | 4096
I0621 00:56:59.096292   388 net.cpp:715] - cha 20 | 20
I0621 00:56:59.096297   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.096302   388 net.cpp:717] - wid 1 | 1
I0621 00:56:59.096462   388 net.cpp:713] Layer#38 | Blob#1:
I0621 00:56:59.096472   388 net.cpp:714] - num 1 | 1
I0621 00:56:59.096479   388 net.cpp:715] - cha 1 | 1
I0621 00:56:59.096485   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.096490   388 net.cpp:717] - wid 4096 | 4096
I0621 00:56:59.096508   388 net.cpp:707] Copying source layer fc7-bp
I0621 00:56:59.096516   388 net.cpp:713] Layer#40 | Blob#0:
I0621 00:56:59.096523   388 net.cpp:714] - num 4096 | 4096
I0621 00:56:59.096527   388 net.cpp:715] - cha 4096 | 4096
I0621 00:56:59.096534   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.096539   388 net.cpp:717] - wid 1 | 1
I0621 00:56:59.119194   388 net.cpp:713] Layer#40 | Blob#1:
I0621 00:56:59.119238   388 net.cpp:714] - num 1 | 1
I0621 00:56:59.119245   388 net.cpp:715] - cha 1 | 1
I0621 00:56:59.119251   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.119256   388 net.cpp:717] - wid 4096 | 4096
I0621 00:56:59.119284   388 net.cpp:707] Copying source layer fc6-bp
I0621 00:56:59.119293   388 net.cpp:713] Layer#42 | Blob#0:
I0621 00:56:59.119299   388 net.cpp:714] - num 4096 | 4096
I0621 00:56:59.119305   388 net.cpp:715] - cha 512 | 512
I0621 00:56:59.119310   388 net.cpp:716] - hei 7 | 7
I0621 00:56:59.119316   388 net.cpp:717] - wid 7 | 7
I0621 00:56:59.233276   388 net.cpp:713] Layer#42 | Blob#1:
I0621 00:56:59.233325   388 net.cpp:714] - num 1 | 1
I0621 00:56:59.233332   388 net.cpp:715] - cha 1 | 1
I0621 00:56:59.233337   388 net.cpp:716] - hei 1 | 1
I0621 00:56:59.233343   388 net.cpp:717] - wid 512 | 512
I0621 00:56:59.276715   388 solver.cpp:247] Solving train_seg_Full_anno
I0621 00:56:59.276754   388 solver.cpp:248] Learning Rate Policy: step
I0621 00:56:59.296232   388 solver.cpp:291] Iteration 0, Testing net (#0)
I0621 01:00:49.400990   388 solver.cpp:342]     Test net output #0: seg-accuracy = 0.634412
I0621 01:00:49.401118   388 solver.cpp:342]     Test net output #1: seg-loss = 0.68569 (* 1 = 0.68569 loss)
I0621 01:01:01.307783   388 solver.cpp:213] Iteration 0, loss = 0.685816
I0621 01:01:01.307873   388 solver.cpp:228]     Train net output #0: seg-loss = 0.685765 (* 1 = 0.685765 loss)
I0621 01:01:01.307919   388 solver.cpp:473] Iteration 0, lr = 0.01
I0621 01:01:13.614751   388 solver.cpp:213] Iteration 1, loss = 0.634922
I0621 01:01:13.614838   388 solver.cpp:228]     Train net output #0: seg-loss = 0.63499 (* 1 = 0.63499 loss)
I0621 01:01:13.614886   388 solver.cpp:473] Iteration 1, lr = 0.01
I0621 01:01:25.939995   388 solver.cpp:213] Iteration 2, loss = 0.550168
I0621 01:01:25.940207   388 solver.cpp:228]     Train net output #0: seg-loss = 0.551162 (* 1 = 0.551162 loss)
I0621 01:01:25.940233   388 solver.cpp:473] Iteration 2, lr = 0.01
I0621 01:01:38.251664   388 solver.cpp:213] Iteration 3, loss = 0.450221
I0621 01:01:38.251746   388 solver.cpp:228]     Train net output #0: seg-loss = 0.44958 (* 1 = 0.44958 loss)
I0621 01:01:38.251771   388 solver.cpp:473] Iteration 3, lr = 0.01
I0621 01:01:50.583312   388 solver.cpp:213] Iteration 4, loss = 0.350228
I0621 01:01:50.583398   388 solver.cpp:228]     Train net output #0: seg-loss = 0.342211 (* 1 = 0.342211 loss)
I0621 01:01:50.583423   388 solver.cpp:473] Iteration 4, lr = 0.01
I0621 01:02:02.943347   388 solver.cpp:213] Iteration 5, loss = 0.261857
I0621 01:02:02.943529   388 solver.cpp:228]     Train net output #0: seg-loss = 0.268157 (* 1 = 0.268157 loss)
I0621 01:02:02.943557   388 solver.cpp:473] Iteration 5, lr = 0.01
I0621 01:02:15.255939   388 solver.cpp:213] Iteration 6, loss = 0.189289
I0621 01:02:15.256024   388 solver.cpp:228]     Train net output #0: seg-loss = 0.19202 (* 1 = 0.19202 loss)
I0621 01:02:15.256048   388 solver.cpp:473] Iteration 6, lr = 0.01
I0621 01:02:27.565798   388 solver.cpp:213] Iteration 7, loss = 0.133295
I0621 01:02:27.565886   388 solver.cpp:228]     Train net output #0: seg-loss = 0.133992 (* 1 = 0.133992 loss)
I0621 01:02:27.565909   388 solver.cpp:473] Iteration 7, lr = 0.01
I0621 01:02:39.894920   388 solver.cpp:213] Iteration 8, loss = 0.094004
I0621 01:02:39.895164   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0934754 (* 1 = 0.0934754 loss)
I0621 01:02:39.895220   388 solver.cpp:473] Iteration 8, lr = 0.01
I0621 01:02:52.228392   388 solver.cpp:213] Iteration 9, loss = 0.0677299
I0621 01:02:52.228477   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0672937 (* 1 = 0.0672937 loss)
I0621 01:02:52.228500   388 solver.cpp:473] Iteration 9, lr = 0.01
I0621 01:03:04.561601   388 solver.cpp:213] Iteration 10, loss = 0.0497195
I0621 01:03:04.561691   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0498716 (* 1 = 0.0498716 loss)
I0621 01:03:04.561715   388 solver.cpp:473] Iteration 10, lr = 0.01
I0621 01:03:16.858386   388 solver.cpp:213] Iteration 11, loss = 0.0373394
I0621 01:03:16.858562   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0373052 (* 1 = 0.0373052 loss)
I0621 01:03:16.858589   388 solver.cpp:473] Iteration 11, lr = 0.01
I0621 01:03:29.116331   388 solver.cpp:213] Iteration 12, loss = 0.0286853
I0621 01:03:29.116420   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0287205 (* 1 = 0.0287205 loss)
I0621 01:03:29.116444   388 solver.cpp:473] Iteration 12, lr = 0.01
I0621 01:03:41.411672   388 solver.cpp:213] Iteration 13, loss = 0.0225219
I0621 01:03:41.411764   388 solver.cpp:228]     Train net output #0: seg-loss = 0.022528 (* 1 = 0.022528 loss)
I0621 01:03:41.411790   388 solver.cpp:473] Iteration 13, lr = 0.01
I0621 01:03:53.641243   388 solver.cpp:213] Iteration 14, loss = 0.0180319
I0621 01:03:53.647145   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0180313 (* 1 = 0.0180313 loss)
I0621 01:03:53.647173   388 solver.cpp:473] Iteration 14, lr = 0.01
I0621 01:04:05.897698   388 solver.cpp:213] Iteration 15, loss = 0.0147176
I0621 01:04:05.897783   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0147144 (* 1 = 0.0147144 loss)
I0621 01:04:05.897809   388 solver.cpp:473] Iteration 15, lr = 0.01
I0621 01:04:18.142793   388 solver.cpp:213] Iteration 16, loss = 0.0122138
I0621 01:04:18.142880   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0122072 (* 1 = 0.0122072 loss)
I0621 01:04:18.142904   388 solver.cpp:473] Iteration 16, lr = 0.01
I0621 01:04:30.366920   388 solver.cpp:213] Iteration 17, loss = 0.0103024
I0621 01:04:30.367146   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0102881 (* 1 = 0.0102881 loss)
I0621 01:04:30.367173   388 solver.cpp:473] Iteration 17, lr = 0.01
I0621 01:04:42.594355   388 solver.cpp:213] Iteration 18, loss = 0.00881945
I0621 01:04:42.594436   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00881326 (* 1 = 0.00881326 loss)
I0621 01:04:42.594460   388 solver.cpp:473] Iteration 18, lr = 0.01
I0621 01:04:54.805260   388 solver.cpp:213] Iteration 19, loss = 0.00765472
I0621 01:04:54.805342   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00765943 (* 1 = 0.00765943 loss)
I0621 01:04:54.805366   388 solver.cpp:473] Iteration 19, lr = 0.01
I0621 01:05:07.019659   388 solver.cpp:213] Iteration 20, loss = 0.00672921
I0621 01:05:07.019852   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00671554 (* 1 = 0.00671554 loss)
I0621 01:05:07.019878   388 solver.cpp:473] Iteration 20, lr = 0.01
I0621 01:05:19.231590   388 solver.cpp:213] Iteration 21, loss = 0.00598248
I0621 01:05:19.231676   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00598188 (* 1 = 0.00598188 loss)
I0621 01:05:19.231701   388 solver.cpp:473] Iteration 21, lr = 0.01
I0621 01:05:31.446169   388 solver.cpp:213] Iteration 22, loss = 0.00537644
I0621 01:05:31.446297   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00537314 (* 1 = 0.00537314 loss)
I0621 01:05:31.446322   388 solver.cpp:473] Iteration 22, lr = 0.01
I0621 01:05:43.679167   388 solver.cpp:213] Iteration 23, loss = 0.00487823
I0621 01:05:43.679340   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00488154 (* 1 = 0.00488154 loss)
I0621 01:05:43.679365   388 solver.cpp:473] Iteration 23, lr = 0.01
I0621 01:05:55.894258   388 solver.cpp:213] Iteration 24, loss = 0.00446058
I0621 01:05:55.894328   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0044587 (* 1 = 0.0044587 loss)
I0621 01:05:55.894345   388 solver.cpp:473] Iteration 24, lr = 0.01
I0621 01:06:08.106789   388 solver.cpp:213] Iteration 25, loss = 0.00411582
I0621 01:06:08.106869   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00412109 (* 1 = 0.00412109 loss)
I0621 01:06:08.106892   388 solver.cpp:473] Iteration 25, lr = 0.01
I0621 01:06:20.321331   388 solver.cpp:213] Iteration 26, loss = 0.00382226
I0621 01:06:20.321491   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00382455 (* 1 = 0.00382455 loss)
I0621 01:06:20.321516   388 solver.cpp:473] Iteration 26, lr = 0.01
I0621 01:06:32.555591   388 solver.cpp:213] Iteration 27, loss = 0.00357325
I0621 01:06:32.555675   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00356529 (* 1 = 0.00356529 loss)
I0621 01:06:32.555697   388 solver.cpp:473] Iteration 27, lr = 0.01
I0621 01:06:44.773777   388 solver.cpp:213] Iteration 28, loss = 0.00336225
I0621 01:06:44.773864   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00335517 (* 1 = 0.00335517 loss)
I0621 01:06:44.773893   388 solver.cpp:473] Iteration 28, lr = 0.01
I0621 01:06:56.973347   388 solver.cpp:213] Iteration 29, loss = 0.00317841
I0621 01:06:56.973521   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0031712 (* 1 = 0.0031712 loss)
I0621 01:06:56.973549   388 solver.cpp:473] Iteration 29, lr = 0.01
I0621 01:07:09.168022   388 solver.cpp:213] Iteration 30, loss = 0.00302062
I0621 01:07:09.168107   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00302283 (* 1 = 0.00302283 loss)
I0621 01:07:09.168133   388 solver.cpp:473] Iteration 30, lr = 0.01
I0621 01:07:21.394822   388 solver.cpp:213] Iteration 31, loss = 0.00288262
I0621 01:07:21.394907   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00288397 (* 1 = 0.00288397 loss)
I0621 01:07:21.394932   388 solver.cpp:473] Iteration 31, lr = 0.01
I0621 01:07:33.641682   388 solver.cpp:213] Iteration 32, loss = 0.00276306
I0621 01:07:33.647140   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00276862 (* 1 = 0.00276862 loss)
I0621 01:07:33.647169   388 solver.cpp:473] Iteration 32, lr = 0.01
I0621 01:07:45.860980   388 solver.cpp:213] Iteration 33, loss = 0.00265549
I0621 01:07:45.861069   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0026543 (* 1 = 0.0026543 loss)
I0621 01:07:45.861096   388 solver.cpp:473] Iteration 33, lr = 0.01
I0621 01:07:58.059883   388 solver.cpp:213] Iteration 34, loss = 0.00256445
I0621 01:07:58.059953   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00256765 (* 1 = 0.00256765 loss)
I0621 01:07:58.059973   388 solver.cpp:473] Iteration 34, lr = 0.01
I0621 01:08:10.300145   388 solver.cpp:213] Iteration 35, loss = 0.00247864
I0621 01:08:10.300387   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00247645 (* 1 = 0.00247645 loss)
I0621 01:08:10.300451   388 solver.cpp:473] Iteration 35, lr = 0.01
I0621 01:08:22.506402   388 solver.cpp:213] Iteration 36, loss = 0.00240601
I0621 01:08:22.506486   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00240719 (* 1 = 0.00240719 loss)
I0621 01:08:22.506511   388 solver.cpp:473] Iteration 36, lr = 0.01
I0621 01:08:34.728031   388 solver.cpp:213] Iteration 37, loss = 0.00234039
I0621 01:08:34.728116   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0023376 (* 1 = 0.0023376 loss)
I0621 01:08:34.728139   388 solver.cpp:473] Iteration 37, lr = 0.01
I0621 01:08:46.928414   388 solver.cpp:213] Iteration 38, loss = 0.00227994
I0621 01:08:46.928586   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0022835 (* 1 = 0.0022835 loss)
I0621 01:08:46.928612   388 solver.cpp:473] Iteration 38, lr = 0.01
I0621 01:08:59.156823   388 solver.cpp:213] Iteration 39, loss = 0.00222928
I0621 01:08:59.156898   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00223427 (* 1 = 0.00223427 loss)
I0621 01:08:59.156924   388 solver.cpp:473] Iteration 39, lr = 0.01
I0621 01:09:11.357925   388 solver.cpp:213] Iteration 40, loss = 0.002181
I0621 01:09:11.357997   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00218262 (* 1 = 0.00218262 loss)
I0621 01:09:11.358018   388 solver.cpp:473] Iteration 40, lr = 0.01
I0621 01:09:23.571171   388 solver.cpp:213] Iteration 41, loss = 0.0021364
I0621 01:09:23.571343   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00213448 (* 1 = 0.00213448 loss)
I0621 01:09:23.571368   388 solver.cpp:473] Iteration 41, lr = 0.01
I0621 01:09:35.769778   388 solver.cpp:213] Iteration 42, loss = 0.00209777
I0621 01:09:35.769852   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00209808 (* 1 = 0.00209808 loss)
I0621 01:09:35.769872   388 solver.cpp:473] Iteration 42, lr = 0.01
I0621 01:09:47.974014   388 solver.cpp:213] Iteration 43, loss = 0.00206214
I0621 01:09:47.974098   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0020614 (* 1 = 0.0020614 loss)
I0621 01:09:47.974123   388 solver.cpp:473] Iteration 43, lr = 0.01
I0621 01:10:00.188292   388 solver.cpp:213] Iteration 44, loss = 0.00202965
I0621 01:10:00.188446   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00202743 (* 1 = 0.00202743 loss)
I0621 01:10:00.188469   388 solver.cpp:473] Iteration 44, lr = 0.01
I0621 01:10:12.409025   388 solver.cpp:213] Iteration 45, loss = 0.0019994
I0621 01:10:12.409106   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00200076 (* 1 = 0.00200076 loss)
I0621 01:10:12.409127   388 solver.cpp:473] Iteration 45, lr = 0.01
I0621 01:10:24.623886   388 solver.cpp:213] Iteration 46, loss = 0.0019711
I0621 01:10:24.623963   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00197069 (* 1 = 0.00197069 loss)
I0621 01:10:24.623987   388 solver.cpp:473] Iteration 46, lr = 0.01
I0621 01:10:36.831120   388 solver.cpp:213] Iteration 47, loss = 0.00194609
I0621 01:10:36.831280   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00194506 (* 1 = 0.00194506 loss)
I0621 01:10:36.831306   388 solver.cpp:473] Iteration 47, lr = 0.01
I0621 01:10:49.040843   388 solver.cpp:213] Iteration 48, loss = 0.00192217
I0621 01:10:49.040933   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00192034 (* 1 = 0.00192034 loss)
I0621 01:10:49.040957   388 solver.cpp:473] Iteration 48, lr = 0.01
I0621 01:11:01.252735   388 solver.cpp:213] Iteration 49, loss = 0.00190102
I0621 01:11:01.252810   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00189887 (* 1 = 0.00189887 loss)
I0621 01:11:01.252831   388 solver.cpp:473] Iteration 49, lr = 0.01
I0621 01:11:13.458607   388 solver.cpp:213] Iteration 50, loss = 0.00188102
I0621 01:11:13.458773   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00188043 (* 1 = 0.00188043 loss)
I0621 01:11:13.458793   388 solver.cpp:473] Iteration 50, lr = 0.01
I0621 01:11:25.678688   388 solver.cpp:213] Iteration 51, loss = 0.00186112
I0621 01:11:25.678763   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00185817 (* 1 = 0.00185817 loss)
I0621 01:11:25.678783   388 solver.cpp:473] Iteration 51, lr = 0.01
I0621 01:11:37.910887   388 solver.cpp:213] Iteration 52, loss = 0.00184283
I0621 01:11:37.910965   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00184175 (* 1 = 0.00184175 loss)
I0621 01:11:37.910987   388 solver.cpp:473] Iteration 52, lr = 0.01
I0621 01:11:50.115360   388 solver.cpp:213] Iteration 53, loss = 0.00182752
I0621 01:11:50.115530   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00183224 (* 1 = 0.00183224 loss)
I0621 01:11:50.115556   388 solver.cpp:473] Iteration 53, lr = 0.01
I0621 01:12:02.319684   388 solver.cpp:213] Iteration 54, loss = 0.0018102
I0621 01:12:02.319754   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00180733 (* 1 = 0.00180733 loss)
I0621 01:12:02.319775   388 solver.cpp:473] Iteration 54, lr = 0.01
I0621 01:12:14.550741   388 solver.cpp:213] Iteration 55, loss = 0.00179544
I0621 01:12:14.550827   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00179153 (* 1 = 0.00179153 loss)
I0621 01:12:14.550849   388 solver.cpp:473] Iteration 55, lr = 0.01
I0621 01:12:26.760110   388 solver.cpp:213] Iteration 56, loss = 0.00178302
I0621 01:12:26.760254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00178613 (* 1 = 0.00178613 loss)
I0621 01:12:26.760272   388 solver.cpp:473] Iteration 56, lr = 0.01
I0621 01:12:38.962234   388 solver.cpp:213] Iteration 57, loss = 0.0017679
I0621 01:12:38.962318   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00176954 (* 1 = 0.00176954 loss)
I0621 01:12:38.962340   388 solver.cpp:473] Iteration 57, lr = 0.01
I0621 01:12:51.193437   388 solver.cpp:213] Iteration 58, loss = 0.00175723
I0621 01:12:51.193524   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00176251 (* 1 = 0.00176251 loss)
I0621 01:12:51.193548   388 solver.cpp:473] Iteration 58, lr = 0.01
I0621 01:13:03.432227   388 solver.cpp:213] Iteration 59, loss = 0.00174405
I0621 01:13:03.432392   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00174136 (* 1 = 0.00174136 loss)
I0621 01:13:03.432418   388 solver.cpp:473] Iteration 59, lr = 0.01
I0621 01:13:15.646371   388 solver.cpp:213] Iteration 60, loss = 0.00173255
I0621 01:13:15.646457   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00173551 (* 1 = 0.00173551 loss)
I0621 01:13:15.646481   388 solver.cpp:473] Iteration 60, lr = 0.01
I0621 01:13:27.865834   388 solver.cpp:213] Iteration 61, loss = 0.00172154
I0621 01:13:27.865919   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00172218 (* 1 = 0.00172218 loss)
I0621 01:13:27.865944   388 solver.cpp:473] Iteration 61, lr = 0.01
I0621 01:13:40.095692   388 solver.cpp:213] Iteration 62, loss = 0.00171143
I0621 01:13:40.095893   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00171201 (* 1 = 0.00171201 loss)
I0621 01:13:40.095921   388 solver.cpp:473] Iteration 62, lr = 0.01
I0621 01:13:52.350294   388 solver.cpp:213] Iteration 63, loss = 0.00170173
I0621 01:13:52.350375   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00170271 (* 1 = 0.00170271 loss)
I0621 01:13:52.350400   388 solver.cpp:473] Iteration 63, lr = 0.01
I0621 01:14:04.575057   388 solver.cpp:213] Iteration 64, loss = 0.00169146
I0621 01:14:04.575150   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00169134 (* 1 = 0.00169134 loss)
I0621 01:14:04.575175   388 solver.cpp:473] Iteration 64, lr = 0.01
I0621 01:14:16.779773   388 solver.cpp:213] Iteration 65, loss = 0.00168163
I0621 01:14:16.779935   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00168173 (* 1 = 0.00168173 loss)
I0621 01:14:16.779955   388 solver.cpp:473] Iteration 65, lr = 0.01
I0621 01:14:29.002265   388 solver.cpp:213] Iteration 66, loss = 0.00167278
I0621 01:14:29.002351   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00167111 (* 1 = 0.00167111 loss)
I0621 01:14:29.002374   388 solver.cpp:473] Iteration 66, lr = 0.01
I0621 01:14:41.240492   388 solver.cpp:213] Iteration 67, loss = 0.0016645
I0621 01:14:41.240578   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00166734 (* 1 = 0.00166734 loss)
I0621 01:14:41.240603   388 solver.cpp:473] Iteration 67, lr = 0.01
I0621 01:14:53.485713   388 solver.cpp:213] Iteration 68, loss = 0.00165512
I0621 01:14:53.485887   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00165537 (* 1 = 0.00165537 loss)
I0621 01:14:53.485913   388 solver.cpp:473] Iteration 68, lr = 0.01
I0621 01:15:05.747707   388 solver.cpp:213] Iteration 69, loss = 0.0016466
I0621 01:15:05.747792   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00164507 (* 1 = 0.00164507 loss)
I0621 01:15:05.747817   388 solver.cpp:473] Iteration 69, lr = 0.01
I0621 01:15:18.016641   388 solver.cpp:213] Iteration 70, loss = 0.0016391
I0621 01:15:18.016721   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00164044 (* 1 = 0.00164044 loss)
I0621 01:15:18.016744   388 solver.cpp:473] Iteration 70, lr = 0.01
I0621 01:15:30.291824   388 solver.cpp:213] Iteration 71, loss = 0.00163215
I0621 01:15:30.292037   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00162978 (* 1 = 0.00162978 loss)
I0621 01:15:30.292068   388 solver.cpp:473] Iteration 71, lr = 0.01
I0621 01:15:42.567278   388 solver.cpp:213] Iteration 72, loss = 0.00162403
I0621 01:15:42.567370   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00162405 (* 1 = 0.00162405 loss)
I0621 01:15:42.567395   388 solver.cpp:473] Iteration 72, lr = 0.01
I0621 01:15:54.871948   388 solver.cpp:213] Iteration 73, loss = 0.00161403
I0621 01:15:54.872038   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00161719 (* 1 = 0.00161719 loss)
I0621 01:15:54.872064   388 solver.cpp:473] Iteration 73, lr = 0.01
I0621 01:16:07.112824   388 solver.cpp:213] Iteration 74, loss = 0.00160835
I0621 01:16:07.113003   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00160801 (* 1 = 0.00160801 loss)
I0621 01:16:07.113030   388 solver.cpp:473] Iteration 74, lr = 0.01
I0621 01:16:19.388954   388 solver.cpp:213] Iteration 75, loss = 0.00160127
I0621 01:16:19.389041   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00160275 (* 1 = 0.00160275 loss)
I0621 01:16:19.389066   388 solver.cpp:473] Iteration 75, lr = 0.01
I0621 01:16:31.660882   388 solver.cpp:213] Iteration 76, loss = 0.00159316
I0621 01:16:31.660969   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00159533 (* 1 = 0.00159533 loss)
I0621 01:16:31.660995   388 solver.cpp:473] Iteration 76, lr = 0.01
I0621 01:16:43.945427   388 solver.cpp:213] Iteration 77, loss = 0.00158645
I0621 01:16:43.945624   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00158505 (* 1 = 0.00158505 loss)
I0621 01:16:43.945657   388 solver.cpp:473] Iteration 77, lr = 0.01
I0621 01:16:56.211872   388 solver.cpp:213] Iteration 78, loss = 0.00158012
I0621 01:16:56.211968   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00158256 (* 1 = 0.00158256 loss)
I0621 01:16:56.211997   388 solver.cpp:473] Iteration 78, lr = 0.01
I0621 01:17:08.471807   388 solver.cpp:213] Iteration 79, loss = 0.00157245
I0621 01:17:08.471894   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0015716 (* 1 = 0.0015716 loss)
I0621 01:17:08.471918   388 solver.cpp:473] Iteration 79, lr = 0.01
I0621 01:17:20.737390   388 solver.cpp:213] Iteration 80, loss = 0.00156596
I0621 01:17:20.737640   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00156997 (* 1 = 0.00156997 loss)
I0621 01:17:20.737699   388 solver.cpp:473] Iteration 80, lr = 0.01
I0621 01:17:32.972074   388 solver.cpp:213] Iteration 81, loss = 0.00156076
I0621 01:17:32.972163   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0015587 (* 1 = 0.0015587 loss)
I0621 01:17:32.972189   388 solver.cpp:473] Iteration 81, lr = 0.01
I0621 01:17:45.222455   388 solver.cpp:213] Iteration 82, loss = 0.00155326
I0621 01:17:45.222543   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00155078 (* 1 = 0.00155078 loss)
I0621 01:17:45.222570   388 solver.cpp:473] Iteration 82, lr = 0.01
I0621 01:17:57.459910   388 solver.cpp:213] Iteration 83, loss = 0.00154673
I0621 01:17:57.460227   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00154704 (* 1 = 0.00154704 loss)
I0621 01:17:57.460253   388 solver.cpp:473] Iteration 83, lr = 0.01
I0621 01:18:09.735671   388 solver.cpp:213] Iteration 84, loss = 0.0015416
I0621 01:18:09.735756   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00153787 (* 1 = 0.00153787 loss)
I0621 01:18:09.735781   388 solver.cpp:473] Iteration 84, lr = 0.01
I0621 01:18:22.007726   388 solver.cpp:213] Iteration 85, loss = 0.00153428
I0621 01:18:22.007813   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00153772 (* 1 = 0.00153772 loss)
I0621 01:18:22.007839   388 solver.cpp:473] Iteration 85, lr = 0.01
I0621 01:18:34.261814   388 solver.cpp:213] Iteration 86, loss = 0.0015284
I0621 01:18:34.261998   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00152807 (* 1 = 0.00152807 loss)
I0621 01:18:34.262025   388 solver.cpp:473] Iteration 86, lr = 0.01
I0621 01:18:46.483981   388 solver.cpp:213] Iteration 87, loss = 0.00152344
I0621 01:18:46.484076   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00152286 (* 1 = 0.00152286 loss)
I0621 01:18:46.484102   388 solver.cpp:473] Iteration 87, lr = 0.01
I0621 01:18:58.747828   388 solver.cpp:213] Iteration 88, loss = 0.00151634
I0621 01:18:58.747927   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00151727 (* 1 = 0.00151727 loss)
I0621 01:18:58.747954   388 solver.cpp:473] Iteration 88, lr = 0.01
I0621 01:19:11.051369   388 solver.cpp:213] Iteration 89, loss = 0.00151153
I0621 01:19:11.051555   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00151018 (* 1 = 0.00151018 loss)
I0621 01:19:11.051581   388 solver.cpp:473] Iteration 89, lr = 0.01
I0621 01:19:23.280122   388 solver.cpp:213] Iteration 90, loss = 0.00150518
I0621 01:19:23.280206   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00150666 (* 1 = 0.00150666 loss)
I0621 01:19:23.280231   388 solver.cpp:473] Iteration 90, lr = 0.01
I0621 01:19:35.509562   388 solver.cpp:213] Iteration 91, loss = 0.00149947
I0621 01:19:35.509717   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00150058 (* 1 = 0.00150058 loss)
I0621 01:19:35.509743   388 solver.cpp:473] Iteration 91, lr = 0.01
I0621 01:19:47.718042   388 solver.cpp:213] Iteration 92, loss = 0.00149238
I0621 01:19:47.718231   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00149092 (* 1 = 0.00149092 loss)
I0621 01:19:47.718258   388 solver.cpp:473] Iteration 92, lr = 0.01
I0621 01:19:59.982713   388 solver.cpp:213] Iteration 93, loss = 0.00148854
I0621 01:19:59.982802   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00149042 (* 1 = 0.00149042 loss)
I0621 01:19:59.982825   388 solver.cpp:473] Iteration 93, lr = 0.01
I0621 01:20:12.215669   388 solver.cpp:213] Iteration 94, loss = 0.00148227
I0621 01:20:12.215770   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00148423 (* 1 = 0.00148423 loss)
I0621 01:20:12.215795   388 solver.cpp:473] Iteration 94, lr = 0.01
I0621 01:20:24.433915   388 solver.cpp:213] Iteration 95, loss = 0.00147644
I0621 01:20:24.434156   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00147845 (* 1 = 0.00147845 loss)
I0621 01:20:24.434211   388 solver.cpp:473] Iteration 95, lr = 0.01
I0621 01:20:36.685698   388 solver.cpp:213] Iteration 96, loss = 0.00147156
I0621 01:20:36.685784   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00147342 (* 1 = 0.00147342 loss)
I0621 01:20:36.685806   388 solver.cpp:473] Iteration 96, lr = 0.01
I0621 01:20:48.924785   388 solver.cpp:213] Iteration 97, loss = 0.00146562
I0621 01:20:48.924870   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00146465 (* 1 = 0.00146465 loss)
I0621 01:20:48.924892   388 solver.cpp:473] Iteration 97, lr = 0.01
I0621 01:21:01.160800   388 solver.cpp:213] Iteration 98, loss = 0.00146045
I0621 01:21:01.160982   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00146244 (* 1 = 0.00146244 loss)
I0621 01:21:01.161006   388 solver.cpp:473] Iteration 98, lr = 0.01
I0621 01:21:13.442886   388 solver.cpp:213] Iteration 99, loss = 0.00145578
I0621 01:21:13.443042   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00145448 (* 1 = 0.00145448 loss)
I0621 01:21:13.443079   388 solver.cpp:473] Iteration 99, lr = 0.01
I0621 01:21:25.662011   388 solver.cpp:213] Iteration 100, loss = 0.00145015
I0621 01:21:25.662096   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00144983 (* 1 = 0.00144983 loss)
I0621 01:21:25.662117   388 solver.cpp:473] Iteration 100, lr = 0.01
I0621 01:21:37.870867   388 solver.cpp:213] Iteration 101, loss = 0.00144524
I0621 01:21:37.871042   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00144679 (* 1 = 0.00144679 loss)
I0621 01:21:37.871073   388 solver.cpp:473] Iteration 101, lr = 0.01
I0621 01:21:50.082590   388 solver.cpp:213] Iteration 102, loss = 0.00143895
I0621 01:21:50.082676   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00143798 (* 1 = 0.00143798 loss)
I0621 01:21:50.082698   388 solver.cpp:473] Iteration 102, lr = 0.01
I0621 01:22:02.360831   388 solver.cpp:213] Iteration 103, loss = 0.00143394
I0621 01:22:02.360916   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00143586 (* 1 = 0.00143586 loss)
I0621 01:22:02.360939   388 solver.cpp:473] Iteration 103, lr = 0.01
I0621 01:22:14.649557   388 solver.cpp:213] Iteration 104, loss = 0.00142927
I0621 01:22:14.650213   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0014313 (* 1 = 0.0014313 loss)
I0621 01:22:14.650239   388 solver.cpp:473] Iteration 104, lr = 0.01
I0621 01:22:26.888936   388 solver.cpp:213] Iteration 105, loss = 0.00142444
I0621 01:22:26.889024   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00142043 (* 1 = 0.00142043 loss)
I0621 01:22:26.889047   388 solver.cpp:473] Iteration 105, lr = 0.01
I0621 01:22:39.150262   388 solver.cpp:213] Iteration 106, loss = 0.00141871
I0621 01:22:39.150352   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00141708 (* 1 = 0.00141708 loss)
I0621 01:22:39.150373   388 solver.cpp:473] Iteration 106, lr = 0.01
I0621 01:22:51.453292   388 solver.cpp:213] Iteration 107, loss = 0.00141431
I0621 01:22:51.453470   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00141666 (* 1 = 0.00141666 loss)
I0621 01:22:51.453495   388 solver.cpp:473] Iteration 107, lr = 0.01
I0621 01:23:03.661092   388 solver.cpp:213] Iteration 108, loss = 0.00140883
I0621 01:23:03.661177   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0014078 (* 1 = 0.0014078 loss)
I0621 01:23:03.661201   388 solver.cpp:473] Iteration 108, lr = 0.01
I0621 01:23:15.865358   388 solver.cpp:213] Iteration 109, loss = 0.00140381
I0621 01:23:15.865447   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00139926 (* 1 = 0.00139926 loss)
I0621 01:23:15.865468   388 solver.cpp:473] Iteration 109, lr = 0.01
I0621 01:23:28.061002   388 solver.cpp:213] Iteration 110, loss = 0.00139945
I0621 01:23:28.061187   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00139918 (* 1 = 0.00139918 loss)
I0621 01:23:28.061213   388 solver.cpp:473] Iteration 110, lr = 0.01
I0621 01:23:40.351526   388 solver.cpp:213] Iteration 111, loss = 0.00139432
I0621 01:23:40.351610   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00139894 (* 1 = 0.00139894 loss)
I0621 01:23:40.351632   388 solver.cpp:473] Iteration 111, lr = 0.01
I0621 01:23:52.644824   388 solver.cpp:213] Iteration 112, loss = 0.00139042
I0621 01:23:52.644909   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00138896 (* 1 = 0.00138896 loss)
I0621 01:23:52.644932   388 solver.cpp:473] Iteration 112, lr = 0.01
I0621 01:24:04.939115   388 solver.cpp:213] Iteration 113, loss = 0.00138559
I0621 01:24:04.939352   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00138705 (* 1 = 0.00138705 loss)
I0621 01:24:04.939405   388 solver.cpp:473] Iteration 113, lr = 0.01
I0621 01:24:17.171983   388 solver.cpp:213] Iteration 114, loss = 0.00138044
I0621 01:24:17.172067   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00137834 (* 1 = 0.00137834 loss)
I0621 01:24:17.172091   388 solver.cpp:473] Iteration 114, lr = 0.01
I0621 01:24:29.398615   388 solver.cpp:213] Iteration 115, loss = 0.00137567
I0621 01:24:29.398699   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00137668 (* 1 = 0.00137668 loss)
I0621 01:24:29.398722   388 solver.cpp:473] Iteration 115, lr = 0.01
I0621 01:24:41.610241   388 solver.cpp:213] Iteration 116, loss = 0.00137185
I0621 01:24:41.610491   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00137133 (* 1 = 0.00137133 loss)
I0621 01:24:41.610558   388 solver.cpp:473] Iteration 116, lr = 0.01
I0621 01:24:53.828865   388 solver.cpp:213] Iteration 117, loss = 0.00136706
I0621 01:24:53.828949   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00136697 (* 1 = 0.00136697 loss)
I0621 01:24:53.828971   388 solver.cpp:473] Iteration 117, lr = 0.01
I0621 01:25:06.042647   388 solver.cpp:213] Iteration 118, loss = 0.00136196
I0621 01:25:06.042735   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00136191 (* 1 = 0.00136191 loss)
I0621 01:25:06.042757   388 solver.cpp:473] Iteration 118, lr = 0.01
I0621 01:25:18.320657   388 solver.cpp:213] Iteration 119, loss = 0.00135727
I0621 01:25:18.320863   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00135986 (* 1 = 0.00135986 loss)
I0621 01:25:18.320894   388 solver.cpp:473] Iteration 119, lr = 0.01
I0621 01:25:30.597441   388 solver.cpp:213] Iteration 120, loss = 0.00135271
I0621 01:25:30.597527   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0013511 (* 1 = 0.0013511 loss)
I0621 01:25:30.597549   388 solver.cpp:473] Iteration 120, lr = 0.01
I0621 01:25:42.798945   388 solver.cpp:213] Iteration 121, loss = 0.00134818
I0621 01:25:42.799031   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00134775 (* 1 = 0.00134775 loss)
I0621 01:25:42.799052   388 solver.cpp:473] Iteration 121, lr = 0.01
I0621 01:25:55.032028   388 solver.cpp:213] Iteration 122, loss = 0.0013425
I0621 01:25:55.032207   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00133997 (* 1 = 0.00133997 loss)
I0621 01:25:55.032233   388 solver.cpp:473] Iteration 122, lr = 0.01
I0621 01:26:07.331964   388 solver.cpp:213] Iteration 123, loss = 0.00133865
I0621 01:26:07.332051   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00133892 (* 1 = 0.00133892 loss)
I0621 01:26:07.332072   388 solver.cpp:473] Iteration 123, lr = 0.01
I0621 01:26:19.543165   388 solver.cpp:213] Iteration 124, loss = 0.00133594
I0621 01:26:19.543246   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0013372 (* 1 = 0.0013372 loss)
I0621 01:26:19.543268   388 solver.cpp:473] Iteration 124, lr = 0.01
I0621 01:26:31.818372   388 solver.cpp:213] Iteration 125, loss = 0.00133179
I0621 01:26:31.818555   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00133115 (* 1 = 0.00133115 loss)
I0621 01:26:31.818579   388 solver.cpp:473] Iteration 125, lr = 0.01
I0621 01:26:44.052410   388 solver.cpp:213] Iteration 126, loss = 0.00132676
I0621 01:26:44.052494   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00133069 (* 1 = 0.00133069 loss)
I0621 01:26:44.052515   388 solver.cpp:473] Iteration 126, lr = 0.01
I0621 01:26:56.299384   388 solver.cpp:213] Iteration 127, loss = 0.00132209
I0621 01:26:56.299471   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00132424 (* 1 = 0.00132424 loss)
I0621 01:26:56.299494   388 solver.cpp:473] Iteration 127, lr = 0.01
I0621 01:27:08.543145   388 solver.cpp:213] Iteration 128, loss = 0.00131757
I0621 01:27:08.543339   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00131705 (* 1 = 0.00131705 loss)
I0621 01:27:08.543362   388 solver.cpp:473] Iteration 128, lr = 0.01
I0621 01:27:20.766670   388 solver.cpp:213] Iteration 129, loss = 0.00131326
I0621 01:27:20.766757   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00131205 (* 1 = 0.00131205 loss)
I0621 01:27:20.766779   388 solver.cpp:473] Iteration 129, lr = 0.01
I0621 01:27:32.975389   388 solver.cpp:213] Iteration 130, loss = 0.00131013
I0621 01:27:32.975476   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00130943 (* 1 = 0.00130943 loss)
I0621 01:27:32.975497   388 solver.cpp:473] Iteration 130, lr = 0.01
I0621 01:27:45.254766   388 solver.cpp:213] Iteration 131, loss = 0.00130602
I0621 01:27:45.254951   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00130766 (* 1 = 0.00130766 loss)
I0621 01:27:45.254976   388 solver.cpp:473] Iteration 131, lr = 0.01
I0621 01:27:57.484841   388 solver.cpp:213] Iteration 132, loss = 0.00130193
I0621 01:27:57.484923   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00130626 (* 1 = 0.00130626 loss)
I0621 01:27:57.484946   388 solver.cpp:473] Iteration 132, lr = 0.01
I0621 01:28:09.719104   388 solver.cpp:213] Iteration 133, loss = 0.00129651
I0621 01:28:09.719183   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00129506 (* 1 = 0.00129506 loss)
I0621 01:28:09.719208   388 solver.cpp:473] Iteration 133, lr = 0.01
I0621 01:28:21.947458   388 solver.cpp:213] Iteration 134, loss = 0.00129322
I0621 01:28:21.947655   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00129417 (* 1 = 0.00129417 loss)
I0621 01:28:21.947680   388 solver.cpp:473] Iteration 134, lr = 0.01
I0621 01:28:34.160985   388 solver.cpp:213] Iteration 135, loss = 0.00128982
I0621 01:28:34.161067   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00128782 (* 1 = 0.00128782 loss)
I0621 01:28:34.161089   388 solver.cpp:473] Iteration 135, lr = 0.01
I0621 01:28:46.385885   388 solver.cpp:213] Iteration 136, loss = 0.00128612
I0621 01:28:46.385967   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00128729 (* 1 = 0.00128729 loss)
I0621 01:28:46.385989   388 solver.cpp:473] Iteration 136, lr = 0.01
I0621 01:28:58.602010   388 solver.cpp:213] Iteration 137, loss = 0.00128111
I0621 01:28:58.602187   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00128009 (* 1 = 0.00128009 loss)
I0621 01:28:58.602211   388 solver.cpp:473] Iteration 137, lr = 0.01
I0621 01:29:10.816296   388 solver.cpp:213] Iteration 138, loss = 0.00127781
I0621 01:29:10.816380   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00127758 (* 1 = 0.00127758 loss)
I0621 01:29:10.816402   388 solver.cpp:473] Iteration 138, lr = 0.01
I0621 01:29:23.020048   388 solver.cpp:213] Iteration 139, loss = 0.001273
I0621 01:29:23.020134   388 solver.cpp:228]     Train net output #0: seg-loss = 0.001273 (* 1 = 0.001273 loss)
I0621 01:29:23.020156   388 solver.cpp:473] Iteration 139, lr = 0.01
I0621 01:29:35.225502   388 solver.cpp:213] Iteration 140, loss = 0.0012699
I0621 01:29:35.225672   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00126992 (* 1 = 0.00126992 loss)
I0621 01:29:35.225695   388 solver.cpp:473] Iteration 140, lr = 0.01
I0621 01:29:47.461236   388 solver.cpp:213] Iteration 141, loss = 0.00126546
I0621 01:29:47.461323   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00127072 (* 1 = 0.00127072 loss)
I0621 01:29:47.461346   388 solver.cpp:473] Iteration 141, lr = 0.01
I0621 01:29:59.662530   388 solver.cpp:213] Iteration 142, loss = 0.00126167
I0621 01:29:59.662616   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00125911 (* 1 = 0.00125911 loss)
I0621 01:29:59.662638   388 solver.cpp:473] Iteration 142, lr = 0.01
I0621 01:30:11.869240   388 solver.cpp:213] Iteration 143, loss = 0.00125714
I0621 01:30:11.869426   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00125626 (* 1 = 0.00125626 loss)
I0621 01:30:11.869449   388 solver.cpp:473] Iteration 143, lr = 0.01
I0621 01:30:24.082752   388 solver.cpp:213] Iteration 144, loss = 0.00125399
I0621 01:30:24.082828   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00125584 (* 1 = 0.00125584 loss)
I0621 01:30:24.082847   388 solver.cpp:473] Iteration 144, lr = 0.01
I0621 01:30:36.288050   388 solver.cpp:213] Iteration 145, loss = 0.00125038
I0621 01:30:36.288123   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0012489 (* 1 = 0.0012489 loss)
I0621 01:30:36.288144   388 solver.cpp:473] Iteration 145, lr = 0.01
I0621 01:30:48.532099   388 solver.cpp:213] Iteration 146, loss = 0.00124628
I0621 01:30:48.532292   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00124473 (* 1 = 0.00124473 loss)
I0621 01:30:48.532320   388 solver.cpp:473] Iteration 146, lr = 0.01
I0621 01:31:00.759775   388 solver.cpp:213] Iteration 147, loss = 0.00124268
I0621 01:31:00.759870   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00124485 (* 1 = 0.00124485 loss)
I0621 01:31:00.759894   388 solver.cpp:473] Iteration 147, lr = 0.01
I0621 01:31:12.972950   388 solver.cpp:213] Iteration 148, loss = 0.00123935
I0621 01:31:12.973024   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00124007 (* 1 = 0.00124007 loss)
I0621 01:31:12.973045   388 solver.cpp:473] Iteration 148, lr = 0.01
I0621 01:31:25.177122   388 solver.cpp:213] Iteration 149, loss = 0.00123549
I0621 01:31:25.177302   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00123466 (* 1 = 0.00123466 loss)
I0621 01:31:25.177327   388 solver.cpp:473] Iteration 149, lr = 0.01
I0621 01:31:37.398284   388 solver.cpp:213] Iteration 150, loss = 0.00123095
I0621 01:31:37.398365   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0012325 (* 1 = 0.0012325 loss)
I0621 01:31:37.398387   388 solver.cpp:473] Iteration 150, lr = 0.01
I0621 01:31:49.612097   388 solver.cpp:213] Iteration 151, loss = 0.00122735
I0621 01:31:49.612182   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00122437 (* 1 = 0.00122437 loss)
I0621 01:31:49.612203   388 solver.cpp:473] Iteration 151, lr = 0.01
I0621 01:32:01.816341   388 solver.cpp:213] Iteration 152, loss = 0.00122415
I0621 01:32:01.816514   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00122535 (* 1 = 0.00122535 loss)
I0621 01:32:01.816536   388 solver.cpp:473] Iteration 152, lr = 0.01
I0621 01:32:14.025168   388 solver.cpp:213] Iteration 153, loss = 0.0012209
I0621 01:32:14.025254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00122234 (* 1 = 0.00122234 loss)
I0621 01:32:14.025275   388 solver.cpp:473] Iteration 153, lr = 0.01
I0621 01:32:26.233362   388 solver.cpp:213] Iteration 154, loss = 0.00121657
I0621 01:32:26.233438   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00121429 (* 1 = 0.00121429 loss)
I0621 01:32:26.233458   388 solver.cpp:473] Iteration 154, lr = 0.01
I0621 01:32:38.442353   388 solver.cpp:213] Iteration 155, loss = 0.00121273
I0621 01:32:38.442553   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0012084 (* 1 = 0.0012084 loss)
I0621 01:32:38.442582   388 solver.cpp:473] Iteration 155, lr = 0.01
I0621 01:32:50.681495   388 solver.cpp:213] Iteration 156, loss = 0.00120921
I0621 01:32:50.681583   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00121194 (* 1 = 0.00121194 loss)
I0621 01:32:50.681605   388 solver.cpp:473] Iteration 156, lr = 0.01
I0621 01:33:02.928705   388 solver.cpp:213] Iteration 157, loss = 0.0012059
I0621 01:33:02.928791   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00120498 (* 1 = 0.00120498 loss)
I0621 01:33:02.928813   388 solver.cpp:473] Iteration 157, lr = 0.01
I0621 01:33:15.143090   388 solver.cpp:213] Iteration 158, loss = 0.00120223
I0621 01:33:15.143282   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00120297 (* 1 = 0.00120297 loss)
I0621 01:33:15.143307   388 solver.cpp:473] Iteration 158, lr = 0.01
I0621 01:33:27.384809   388 solver.cpp:213] Iteration 159, loss = 0.00119957
I0621 01:33:27.384891   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00120001 (* 1 = 0.00120001 loss)
I0621 01:33:27.384917   388 solver.cpp:473] Iteration 159, lr = 0.01
I0621 01:33:39.586941   388 solver.cpp:213] Iteration 160, loss = 0.00119524
I0621 01:33:39.587025   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00119521 (* 1 = 0.00119521 loss)
I0621 01:33:39.587047   388 solver.cpp:473] Iteration 160, lr = 0.01
I0621 01:33:51.807389   388 solver.cpp:213] Iteration 161, loss = 0.00119247
I0621 01:33:51.807564   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0011933 (* 1 = 0.0011933 loss)
I0621 01:33:51.807593   388 solver.cpp:473] Iteration 161, lr = 0.01
I0621 01:34:04.018811   388 solver.cpp:213] Iteration 162, loss = 0.00118891
I0621 01:34:04.018893   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00119222 (* 1 = 0.00119222 loss)
I0621 01:34:04.018914   388 solver.cpp:473] Iteration 162, lr = 0.01
I0621 01:34:16.231218   388 solver.cpp:213] Iteration 163, loss = 0.00118615
I0621 01:34:16.231302   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00118508 (* 1 = 0.00118508 loss)
I0621 01:34:16.231323   388 solver.cpp:473] Iteration 163, lr = 0.01
I0621 01:34:28.443342   388 solver.cpp:213] Iteration 164, loss = 0.0011821
I0621 01:34:28.443922   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00118265 (* 1 = 0.00118265 loss)
I0621 01:34:28.443948   388 solver.cpp:473] Iteration 164, lr = 0.01
I0621 01:34:40.645179   388 solver.cpp:213] Iteration 165, loss = 0.0011785
I0621 01:34:40.645254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00118157 (* 1 = 0.00118157 loss)
I0621 01:34:40.645275   388 solver.cpp:473] Iteration 165, lr = 0.01
I0621 01:34:52.895380   388 solver.cpp:213] Iteration 166, loss = 0.00117569
I0621 01:34:52.895464   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00117456 (* 1 = 0.00117456 loss)
I0621 01:34:52.895488   388 solver.cpp:473] Iteration 166, lr = 0.01
I0621 01:35:05.095512   388 solver.cpp:213] Iteration 167, loss = 0.0011721
I0621 01:35:05.095666   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00117225 (* 1 = 0.00117225 loss)
I0621 01:35:05.095690   388 solver.cpp:473] Iteration 167, lr = 0.01
I0621 01:35:17.306262   388 solver.cpp:213] Iteration 168, loss = 0.00116886
I0621 01:35:17.306344   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00117079 (* 1 = 0.00117079 loss)
I0621 01:35:17.306365   388 solver.cpp:473] Iteration 168, lr = 0.01
I0621 01:35:29.511847   388 solver.cpp:213] Iteration 169, loss = 0.00116546
I0621 01:35:29.511919   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00116649 (* 1 = 0.00116649 loss)
I0621 01:35:29.511940   388 solver.cpp:473] Iteration 169, lr = 0.01
I0621 01:35:41.718310   388 solver.cpp:213] Iteration 170, loss = 0.00116201
I0621 01:35:41.718485   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00116106 (* 1 = 0.00116106 loss)
I0621 01:35:41.718510   388 solver.cpp:473] Iteration 170, lr = 0.01
I0621 01:35:53.929999   388 solver.cpp:213] Iteration 171, loss = 0.00115903
I0621 01:35:53.930083   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00115981 (* 1 = 0.00115981 loss)
I0621 01:35:53.930102   388 solver.cpp:473] Iteration 171, lr = 0.01
I0621 01:36:06.162009   388 solver.cpp:213] Iteration 172, loss = 0.00115504
I0621 01:36:06.162091   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00115876 (* 1 = 0.00115876 loss)
I0621 01:36:06.162113   388 solver.cpp:473] Iteration 172, lr = 0.01
I0621 01:36:18.395037   388 solver.cpp:213] Iteration 173, loss = 0.00115301
I0621 01:36:18.395226   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00115326 (* 1 = 0.00115326 loss)
I0621 01:36:18.395251   388 solver.cpp:473] Iteration 173, lr = 0.01
I0621 01:36:30.613667   388 solver.cpp:213] Iteration 174, loss = 0.00114954
I0621 01:36:30.613752   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00114931 (* 1 = 0.00114931 loss)
I0621 01:36:30.613775   388 solver.cpp:473] Iteration 174, lr = 0.01
I0621 01:36:42.865681   388 solver.cpp:213] Iteration 175, loss = 0.00114643
I0621 01:36:42.865767   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00114455 (* 1 = 0.00114455 loss)
I0621 01:36:42.865788   388 solver.cpp:473] Iteration 175, lr = 0.01
I0621 01:36:55.090781   388 solver.cpp:213] Iteration 176, loss = 0.0011433
I0621 01:36:55.091342   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00114283 (* 1 = 0.00114283 loss)
I0621 01:36:55.091368   388 solver.cpp:473] Iteration 176, lr = 0.01
I0621 01:37:07.295259   388 solver.cpp:213] Iteration 177, loss = 0.00113979
I0621 01:37:07.295346   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00114005 (* 1 = 0.00114005 loss)
I0621 01:37:07.295369   388 solver.cpp:473] Iteration 177, lr = 0.01
I0621 01:37:19.519393   388 solver.cpp:213] Iteration 178, loss = 0.00113687
I0621 01:37:19.519475   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00113681 (* 1 = 0.00113681 loss)
I0621 01:37:19.519498   388 solver.cpp:473] Iteration 178, lr = 0.01
I0621 01:37:31.730013   388 solver.cpp:213] Iteration 179, loss = 0.00113392
I0621 01:37:31.730278   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00113432 (* 1 = 0.00113432 loss)
I0621 01:37:31.730345   388 solver.cpp:473] Iteration 179, lr = 0.01
I0621 01:37:43.934669   388 solver.cpp:213] Iteration 180, loss = 0.00113088
I0621 01:37:43.934753   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0011295 (* 1 = 0.0011295 loss)
I0621 01:37:43.934777   388 solver.cpp:473] Iteration 180, lr = 0.01
I0621 01:37:56.218874   388 solver.cpp:213] Iteration 181, loss = 0.00112829
I0621 01:37:56.218962   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00112782 (* 1 = 0.00112782 loss)
I0621 01:37:56.218986   388 solver.cpp:473] Iteration 181, lr = 0.01
I0621 01:38:08.444129   388 solver.cpp:213] Iteration 182, loss = 0.00112488
I0621 01:38:08.444301   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00112688 (* 1 = 0.00112688 loss)
I0621 01:38:08.444326   388 solver.cpp:473] Iteration 182, lr = 0.01
I0621 01:38:20.659044   388 solver.cpp:213] Iteration 183, loss = 0.00112157
I0621 01:38:20.659133   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00112309 (* 1 = 0.00112309 loss)
I0621 01:38:20.659157   388 solver.cpp:473] Iteration 183, lr = 0.01
I0621 01:38:32.902786   388 solver.cpp:213] Iteration 184, loss = 0.00111887
I0621 01:38:32.902881   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00111943 (* 1 = 0.00111943 loss)
I0621 01:38:32.902907   388 solver.cpp:473] Iteration 184, lr = 0.01
I0621 01:38:45.252780   388 solver.cpp:213] Iteration 185, loss = 0.0011158
I0621 01:38:45.252967   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00111534 (* 1 = 0.00111534 loss)
I0621 01:38:45.252991   388 solver.cpp:473] Iteration 185, lr = 0.01
I0621 01:38:57.459704   388 solver.cpp:213] Iteration 186, loss = 0.00111272
I0621 01:38:57.459786   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00111401 (* 1 = 0.00111401 loss)
I0621 01:38:57.459808   388 solver.cpp:473] Iteration 186, lr = 0.01
I0621 01:39:09.676393   388 solver.cpp:213] Iteration 187, loss = 0.00110959
I0621 01:39:09.676475   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00111032 (* 1 = 0.00111032 loss)
I0621 01:39:09.676497   388 solver.cpp:473] Iteration 187, lr = 0.01
I0621 01:39:21.898129   388 solver.cpp:213] Iteration 188, loss = 0.0011066
I0621 01:39:21.898298   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00110626 (* 1 = 0.00110626 loss)
I0621 01:39:21.898322   388 solver.cpp:473] Iteration 188, lr = 0.01
I0621 01:39:34.181427   388 solver.cpp:213] Iteration 189, loss = 0.00110401
I0621 01:39:34.181515   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00110367 (* 1 = 0.00110367 loss)
I0621 01:39:34.181537   388 solver.cpp:473] Iteration 189, lr = 0.01
I0621 01:39:46.419435   388 solver.cpp:213] Iteration 190, loss = 0.0011011
I0621 01:39:46.419520   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00110092 (* 1 = 0.00110092 loss)
I0621 01:39:46.419543   388 solver.cpp:473] Iteration 190, lr = 0.01
I0621 01:39:58.695858   388 solver.cpp:213] Iteration 191, loss = 0.00109806
I0621 01:39:58.696058   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00109648 (* 1 = 0.00109648 loss)
I0621 01:39:58.696082   388 solver.cpp:473] Iteration 191, lr = 0.01
I0621 01:40:10.913319   388 solver.cpp:213] Iteration 192, loss = 0.00109537
I0621 01:40:10.913398   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00109738 (* 1 = 0.00109738 loss)
I0621 01:40:10.913420   388 solver.cpp:473] Iteration 192, lr = 0.01
I0621 01:40:23.134501   388 solver.cpp:213] Iteration 193, loss = 0.0010921
I0621 01:40:23.134582   388 solver.cpp:228]     Train net output #0: seg-loss = 0.001092 (* 1 = 0.001092 loss)
I0621 01:40:23.134604   388 solver.cpp:473] Iteration 193, lr = 0.01
I0621 01:40:35.356149   388 solver.cpp:213] Iteration 194, loss = 0.00108938
I0621 01:40:35.357321   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00108787 (* 1 = 0.00108787 loss)
I0621 01:40:35.357345   388 solver.cpp:473] Iteration 194, lr = 0.01
I0621 01:40:47.625427   388 solver.cpp:213] Iteration 195, loss = 0.00108706
I0621 01:40:47.625515   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00108717 (* 1 = 0.00108717 loss)
I0621 01:40:47.625537   388 solver.cpp:473] Iteration 195, lr = 0.01
I0621 01:40:59.857321   388 solver.cpp:213] Iteration 196, loss = 0.00108422
I0621 01:40:59.857406   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00108457 (* 1 = 0.00108457 loss)
I0621 01:40:59.857429   388 solver.cpp:473] Iteration 196, lr = 0.01
I0621 01:41:12.098616   388 solver.cpp:213] Iteration 197, loss = 0.00108183
I0621 01:41:12.098844   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0010832 (* 1 = 0.0010832 loss)
I0621 01:41:12.098873   388 solver.cpp:473] Iteration 197, lr = 0.01
I0621 01:41:24.385776   388 solver.cpp:213] Iteration 198, loss = 0.00107821
I0621 01:41:24.385862   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00107925 (* 1 = 0.00107925 loss)
I0621 01:41:24.385885   388 solver.cpp:473] Iteration 198, lr = 0.01
I0621 01:41:36.604457   388 solver.cpp:213] Iteration 199, loss = 0.00107551
I0621 01:41:36.604539   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00107555 (* 1 = 0.00107555 loss)
I0621 01:41:36.604562   388 solver.cpp:473] Iteration 199, lr = 0.01
I0621 01:41:48.889380   388 solver.cpp:213] Iteration 200, loss = 0.00107315
I0621 01:41:48.889605   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00107379 (* 1 = 0.00107379 loss)
I0621 01:41:48.889647   388 solver.cpp:473] Iteration 200, lr = 0.01
I0621 01:42:01.168095   388 solver.cpp:213] Iteration 201, loss = 0.00107026
I0621 01:42:01.168184   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00107015 (* 1 = 0.00107015 loss)
I0621 01:42:01.168205   388 solver.cpp:473] Iteration 201, lr = 0.01
I0621 01:42:13.388216   388 solver.cpp:213] Iteration 202, loss = 0.00106739
I0621 01:42:13.388303   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00106919 (* 1 = 0.00106919 loss)
I0621 01:42:13.388324   388 solver.cpp:473] Iteration 202, lr = 0.01
I0621 01:42:25.605681   388 solver.cpp:213] Iteration 203, loss = 0.00106511
I0621 01:42:25.605872   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00106411 (* 1 = 0.00106411 loss)
I0621 01:42:25.605898   388 solver.cpp:473] Iteration 203, lr = 0.01
I0621 01:42:37.841032   388 solver.cpp:213] Iteration 204, loss = 0.00106205
I0621 01:42:37.841120   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00106066 (* 1 = 0.00106066 loss)
I0621 01:42:37.841142   388 solver.cpp:473] Iteration 204, lr = 0.01
I0621 01:42:50.050187   388 solver.cpp:213] Iteration 205, loss = 0.00105903
I0621 01:42:50.050257   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00105828 (* 1 = 0.00105828 loss)
I0621 01:42:50.050273   388 solver.cpp:473] Iteration 205, lr = 0.01
I0621 01:43:02.318718   388 solver.cpp:213] Iteration 206, loss = 0.00105708
I0621 01:43:02.318925   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00105615 (* 1 = 0.00105615 loss)
I0621 01:43:02.318950   388 solver.cpp:473] Iteration 206, lr = 0.01
I0621 01:43:14.541304   388 solver.cpp:213] Iteration 207, loss = 0.00105386
I0621 01:43:14.541390   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00105443 (* 1 = 0.00105443 loss)
I0621 01:43:14.541412   388 solver.cpp:473] Iteration 207, lr = 0.01
I0621 01:43:26.806073   388 solver.cpp:213] Iteration 208, loss = 0.0010517
I0621 01:43:26.806162   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00105156 (* 1 = 0.00105156 loss)
I0621 01:43:26.806185   388 solver.cpp:473] Iteration 208, lr = 0.01
I0621 01:43:39.045882   388 solver.cpp:213] Iteration 209, loss = 0.00104876
I0621 01:43:39.046080   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00105071 (* 1 = 0.00105071 loss)
I0621 01:43:39.046106   388 solver.cpp:473] Iteration 209, lr = 0.01
I0621 01:43:51.295519   388 solver.cpp:213] Iteration 210, loss = 0.00104634
I0621 01:43:51.295605   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00104694 (* 1 = 0.00104694 loss)
I0621 01:43:51.295626   388 solver.cpp:473] Iteration 210, lr = 0.01
I0621 01:44:03.524139   388 solver.cpp:213] Iteration 211, loss = 0.00104322
I0621 01:44:03.524225   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00104171 (* 1 = 0.00104171 loss)
I0621 01:44:03.524248   388 solver.cpp:473] Iteration 211, lr = 0.01
I0621 01:44:15.749378   388 solver.cpp:213] Iteration 212, loss = 0.0010411
I0621 01:44:15.749615   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00104113 (* 1 = 0.00104113 loss)
I0621 01:44:15.749662   388 solver.cpp:473] Iteration 212, lr = 0.01
I0621 01:44:27.980166   388 solver.cpp:213] Iteration 213, loss = 0.00103837
I0621 01:44:27.980254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.001039 (* 1 = 0.001039 loss)
I0621 01:44:27.980275   388 solver.cpp:473] Iteration 213, lr = 0.01
I0621 01:44:40.205426   388 solver.cpp:213] Iteration 214, loss = 0.00103552
I0621 01:44:40.205514   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00103832 (* 1 = 0.00103832 loss)
I0621 01:44:40.205538   388 solver.cpp:473] Iteration 214, lr = 0.01
I0621 01:44:52.423447   388 solver.cpp:213] Iteration 215, loss = 0.00103362
I0621 01:44:52.423621   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00103273 (* 1 = 0.00103273 loss)
I0621 01:44:52.423648   388 solver.cpp:473] Iteration 215, lr = 0.01
I0621 01:45:04.650667   388 solver.cpp:213] Iteration 216, loss = 0.0010307
I0621 01:45:04.650764   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00103267 (* 1 = 0.00103267 loss)
I0621 01:45:04.650790   388 solver.cpp:473] Iteration 216, lr = 0.01
I0621 01:45:16.871651   388 solver.cpp:213] Iteration 217, loss = 0.0010285
I0621 01:45:16.871733   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00102952 (* 1 = 0.00102952 loss)
I0621 01:45:16.871755   388 solver.cpp:473] Iteration 217, lr = 0.01
I0621 01:45:29.093189   388 solver.cpp:213] Iteration 218, loss = 0.00102571
I0621 01:45:29.093364   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00102559 (* 1 = 0.00102559 loss)
I0621 01:45:29.093387   388 solver.cpp:473] Iteration 218, lr = 0.01
I0621 01:45:41.305392   388 solver.cpp:213] Iteration 219, loss = 0.00102328
I0621 01:45:41.305476   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00102279 (* 1 = 0.00102279 loss)
I0621 01:45:41.305498   388 solver.cpp:473] Iteration 219, lr = 0.01
I0621 01:45:53.523372   388 solver.cpp:213] Iteration 220, loss = 0.00102081
I0621 01:45:53.523458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00101978 (* 1 = 0.00101978 loss)
I0621 01:45:53.523480   388 solver.cpp:473] Iteration 220, lr = 0.01
I0621 01:46:05.741055   388 solver.cpp:213] Iteration 221, loss = 0.00101891
I0621 01:46:05.747131   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00101885 (* 1 = 0.00101885 loss)
I0621 01:46:05.747159   388 solver.cpp:473] Iteration 221, lr = 0.01
I0621 01:46:17.947338   388 solver.cpp:213] Iteration 222, loss = 0.00101628
I0621 01:46:17.947424   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00101555 (* 1 = 0.00101555 loss)
I0621 01:46:17.947446   388 solver.cpp:473] Iteration 222, lr = 0.01
I0621 01:46:30.212165   388 solver.cpp:213] Iteration 223, loss = 0.00101366
I0621 01:46:30.212254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00101225 (* 1 = 0.00101225 loss)
I0621 01:46:30.212276   388 solver.cpp:473] Iteration 223, lr = 0.01
I0621 01:46:42.463698   388 solver.cpp:213] Iteration 224, loss = 0.00101087
I0621 01:46:42.463892   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00101216 (* 1 = 0.00101216 loss)
I0621 01:46:42.463918   388 solver.cpp:473] Iteration 224, lr = 0.01
I0621 01:46:54.679865   388 solver.cpp:213] Iteration 225, loss = 0.00100831
I0621 01:46:54.679949   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00100675 (* 1 = 0.00100675 loss)
I0621 01:46:54.679972   388 solver.cpp:473] Iteration 225, lr = 0.01
I0621 01:47:06.931958   388 solver.cpp:213] Iteration 226, loss = 0.00100648
I0621 01:47:06.932047   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00100752 (* 1 = 0.00100752 loss)
I0621 01:47:06.932070   388 solver.cpp:473] Iteration 226, lr = 0.01
I0621 01:47:19.151715   388 solver.cpp:213] Iteration 227, loss = 0.00100367
I0621 01:47:19.151890   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00100244 (* 1 = 0.00100244 loss)
I0621 01:47:19.151916   388 solver.cpp:473] Iteration 227, lr = 0.01
I0621 01:47:31.400647   388 solver.cpp:213] Iteration 228, loss = 0.00100194
I0621 01:47:31.400730   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00100112 (* 1 = 0.00100112 loss)
I0621 01:47:31.400751   388 solver.cpp:473] Iteration 228, lr = 0.01
I0621 01:47:43.628214   388 solver.cpp:213] Iteration 229, loss = 0.000999065
I0621 01:47:43.628300   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000997345 (* 1 = 0.000997345 loss)
I0621 01:47:43.628324   388 solver.cpp:473] Iteration 229, lr = 0.01
I0621 01:47:55.885527   388 solver.cpp:213] Iteration 230, loss = 0.000996929
I0621 01:47:55.885757   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000995097 (* 1 = 0.000995097 loss)
I0621 01:47:55.885790   388 solver.cpp:473] Iteration 230, lr = 0.01
I0621 01:48:08.160411   388 solver.cpp:213] Iteration 231, loss = 0.000994199
I0621 01:48:08.160495   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000994305 (* 1 = 0.000994305 loss)
I0621 01:48:08.160517   388 solver.cpp:473] Iteration 231, lr = 0.01
I0621 01:48:20.371651   388 solver.cpp:213] Iteration 232, loss = 0.000992351
I0621 01:48:20.371732   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000992114 (* 1 = 0.000992114 loss)
I0621 01:48:20.371754   388 solver.cpp:473] Iteration 232, lr = 0.01
I0621 01:48:32.593402   388 solver.cpp:213] Iteration 233, loss = 0.000989572
I0621 01:48:32.593739   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000990498 (* 1 = 0.000990498 loss)
I0621 01:48:32.593765   388 solver.cpp:473] Iteration 233, lr = 0.01
I0621 01:48:44.868954   388 solver.cpp:213] Iteration 234, loss = 0.000987651
I0621 01:48:44.869041   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000988382 (* 1 = 0.000988382 loss)
I0621 01:48:44.869063   388 solver.cpp:473] Iteration 234, lr = 0.01
I0621 01:48:57.102352   388 solver.cpp:213] Iteration 235, loss = 0.000985967
I0621 01:48:57.102440   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000985509 (* 1 = 0.000985509 loss)
I0621 01:48:57.102463   388 solver.cpp:473] Iteration 235, lr = 0.01
I0621 01:49:09.310077   388 solver.cpp:213] Iteration 236, loss = 0.000983146
I0621 01:49:09.310303   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000983672 (* 1 = 0.000983672 loss)
I0621 01:49:09.310334   388 solver.cpp:473] Iteration 236, lr = 0.01
I0621 01:49:21.568853   388 solver.cpp:213] Iteration 237, loss = 0.000980858
I0621 01:49:21.568939   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000978793 (* 1 = 0.000978793 loss)
I0621 01:49:21.568963   388 solver.cpp:473] Iteration 237, lr = 0.01
I0621 01:49:33.784373   388 solver.cpp:213] Iteration 238, loss = 0.000978179
I0621 01:49:33.784458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000978219 (* 1 = 0.000978219 loss)
I0621 01:49:33.784482   388 solver.cpp:473] Iteration 238, lr = 0.01
I0621 01:49:46.091156   388 solver.cpp:213] Iteration 239, loss = 0.000975992
I0621 01:49:46.091356   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000976166 (* 1 = 0.000976166 loss)
I0621 01:49:46.091382   388 solver.cpp:473] Iteration 239, lr = 0.01
I0621 01:49:58.362305   388 solver.cpp:213] Iteration 240, loss = 0.000973491
I0621 01:49:58.362427   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00097397 (* 1 = 0.00097397 loss)
I0621 01:49:58.362467   388 solver.cpp:473] Iteration 240, lr = 0.01
I0621 01:50:10.619767   388 solver.cpp:213] Iteration 241, loss = 0.000971528
I0621 01:50:10.619849   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000969565 (* 1 = 0.000969565 loss)
I0621 01:50:10.619871   388 solver.cpp:473] Iteration 241, lr = 0.01
I0621 01:50:22.878156   388 solver.cpp:213] Iteration 242, loss = 0.000969645
I0621 01:50:22.878437   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000968657 (* 1 = 0.000968657 loss)
I0621 01:50:22.878461   388 solver.cpp:473] Iteration 242, lr = 0.01
I0621 01:50:35.100744   388 solver.cpp:213] Iteration 243, loss = 0.000967136
I0621 01:50:35.100827   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000966788 (* 1 = 0.000966788 loss)
I0621 01:50:35.100849   388 solver.cpp:473] Iteration 243, lr = 0.01
I0621 01:50:47.347591   388 solver.cpp:213] Iteration 244, loss = 0.000965284
I0621 01:50:47.347671   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000966806 (* 1 = 0.000966806 loss)
I0621 01:50:47.347694   388 solver.cpp:473] Iteration 244, lr = 0.01
I0621 01:50:59.658856   388 solver.cpp:213] Iteration 245, loss = 0.000962694
I0621 01:50:59.665951   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000962488 (* 1 = 0.000962488 loss)
I0621 01:50:59.666008   388 solver.cpp:473] Iteration 245, lr = 0.01
I0621 01:51:12.019021   388 solver.cpp:213] Iteration 246, loss = 0.000960749
I0621 01:51:12.019114   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000960379 (* 1 = 0.000960379 loss)
I0621 01:51:12.019136   388 solver.cpp:473] Iteration 246, lr = 0.01
I0621 01:51:24.284801   388 solver.cpp:213] Iteration 247, loss = 0.000957838
I0621 01:51:24.284881   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000956281 (* 1 = 0.000956281 loss)
I0621 01:51:24.284905   388 solver.cpp:473] Iteration 247, lr = 0.01
I0621 01:51:36.551779   388 solver.cpp:213] Iteration 248, loss = 0.000956192
I0621 01:51:36.551990   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000955276 (* 1 = 0.000955276 loss)
I0621 01:51:36.552026   388 solver.cpp:473] Iteration 248, lr = 0.01
I0621 01:51:48.792140   388 solver.cpp:213] Iteration 249, loss = 0.000954061
I0621 01:51:48.792227   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000953014 (* 1 = 0.000953014 loss)
I0621 01:51:48.792250   388 solver.cpp:473] Iteration 249, lr = 0.01
I0621 01:52:01.036932   388 solver.cpp:213] Iteration 250, loss = 0.000952013
I0621 01:52:01.037017   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000951794 (* 1 = 0.000951794 loss)
I0621 01:52:01.037041   388 solver.cpp:473] Iteration 250, lr = 0.01
I0621 01:52:13.245802   388 solver.cpp:213] Iteration 251, loss = 0.000949454
I0621 01:52:13.245982   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000947899 (* 1 = 0.000947899 loss)
I0621 01:52:13.246007   388 solver.cpp:473] Iteration 251, lr = 0.01
I0621 01:52:25.535392   388 solver.cpp:213] Iteration 252, loss = 0.000947902
I0621 01:52:25.535467   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00094862 (* 1 = 0.00094862 loss)
I0621 01:52:25.535483   388 solver.cpp:473] Iteration 252, lr = 0.01
I0621 01:52:37.754803   388 solver.cpp:213] Iteration 253, loss = 0.000945846
I0621 01:52:37.754885   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000946065 (* 1 = 0.000946065 loss)
I0621 01:52:37.754909   388 solver.cpp:473] Iteration 253, lr = 0.01
I0621 01:52:50.067412   388 solver.cpp:213] Iteration 254, loss = 0.000943121
I0621 01:52:50.067670   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000943075 (* 1 = 0.000943075 loss)
I0621 01:52:50.067729   388 solver.cpp:473] Iteration 254, lr = 0.01
I0621 01:53:02.298499   388 solver.cpp:213] Iteration 255, loss = 0.000941709
I0621 01:53:02.298588   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000941815 (* 1 = 0.000941815 loss)
I0621 01:53:02.298610   388 solver.cpp:473] Iteration 255, lr = 0.01
I0621 01:53:14.651958   388 solver.cpp:213] Iteration 256, loss = 0.000940004
I0621 01:53:14.652043   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000939189 (* 1 = 0.000939189 loss)
I0621 01:53:14.652066   388 solver.cpp:473] Iteration 256, lr = 0.01
I0621 01:53:26.988631   388 solver.cpp:213] Iteration 257, loss = 0.000937286
I0621 01:53:26.988883   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000937708 (* 1 = 0.000937708 loss)
I0621 01:53:26.988930   388 solver.cpp:473] Iteration 257, lr = 0.01
I0621 01:53:39.281458   388 solver.cpp:213] Iteration 258, loss = 0.000935089
I0621 01:53:39.281539   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000935663 (* 1 = 0.000935663 loss)
I0621 01:53:39.281563   388 solver.cpp:473] Iteration 258, lr = 0.01
I0621 01:53:51.534165   388 solver.cpp:213] Iteration 259, loss = 0.000933111
I0621 01:53:51.534246   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000934407 (* 1 = 0.000934407 loss)
I0621 01:53:51.534271   388 solver.cpp:473] Iteration 259, lr = 0.01
I0621 01:54:03.763494   388 solver.cpp:213] Iteration 260, loss = 0.000931436
I0621 01:54:03.763731   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000931021 (* 1 = 0.000931021 loss)
I0621 01:54:03.763767   388 solver.cpp:473] Iteration 260, lr = 0.01
I0621 01:54:16.122846   388 solver.cpp:213] Iteration 261, loss = 0.000929497
I0621 01:54:16.122936   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000929525 (* 1 = 0.000929525 loss)
I0621 01:54:16.122957   388 solver.cpp:473] Iteration 261, lr = 0.01
I0621 01:54:28.363979   388 solver.cpp:213] Iteration 262, loss = 0.00092735
I0621 01:54:28.364063   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000926533 (* 1 = 0.000926533 loss)
I0621 01:54:28.364086   388 solver.cpp:473] Iteration 262, lr = 0.01
I0621 01:54:40.586627   388 solver.cpp:213] Iteration 263, loss = 0.000924946
I0621 01:54:40.586799   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000926418 (* 1 = 0.000926418 loss)
I0621 01:54:40.586824   388 solver.cpp:473] Iteration 263, lr = 0.01
I0621 01:54:52.813920   388 solver.cpp:213] Iteration 264, loss = 0.000923014
I0621 01:54:52.814002   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000923895 (* 1 = 0.000923895 loss)
I0621 01:54:52.814023   388 solver.cpp:473] Iteration 264, lr = 0.01
I0621 01:55:05.112906   388 solver.cpp:213] Iteration 265, loss = 0.000920761
I0621 01:55:05.112988   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000922613 (* 1 = 0.000922613 loss)
I0621 01:55:05.113011   388 solver.cpp:473] Iteration 265, lr = 0.01
I0621 01:55:17.354954   388 solver.cpp:213] Iteration 266, loss = 0.000919347
I0621 01:55:17.355129   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000919227 (* 1 = 0.000919227 loss)
I0621 01:55:17.355154   388 solver.cpp:473] Iteration 266, lr = 0.01
I0621 01:55:29.596230   388 solver.cpp:213] Iteration 267, loss = 0.000916706
I0621 01:55:29.596312   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000914288 (* 1 = 0.000914288 loss)
I0621 01:55:29.596334   388 solver.cpp:473] Iteration 267, lr = 0.01
I0621 01:55:41.823472   388 solver.cpp:213] Iteration 268, loss = 0.000914983
I0621 01:55:41.823554   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000915577 (* 1 = 0.000915577 loss)
I0621 01:55:41.823575   388 solver.cpp:473] Iteration 268, lr = 0.01
I0621 01:55:54.045351   388 solver.cpp:213] Iteration 269, loss = 0.000913198
I0621 01:55:54.045538   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00091477 (* 1 = 0.00091477 loss)
I0621 01:55:54.045564   388 solver.cpp:473] Iteration 269, lr = 0.01
I0621 01:56:06.262200   388 solver.cpp:213] Iteration 270, loss = 0.000911334
I0621 01:56:06.262287   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000912094 (* 1 = 0.000912094 loss)
I0621 01:56:06.262308   388 solver.cpp:473] Iteration 270, lr = 0.01
I0621 01:56:18.611305   388 solver.cpp:213] Iteration 271, loss = 0.000909649
I0621 01:56:18.611390   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000909971 (* 1 = 0.000909971 loss)
I0621 01:56:18.611413   388 solver.cpp:473] Iteration 271, lr = 0.01
I0621 01:56:30.925941   388 solver.cpp:213] Iteration 272, loss = 0.000907334
I0621 01:56:30.926126   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000906674 (* 1 = 0.000906674 loss)
I0621 01:56:30.926152   388 solver.cpp:473] Iteration 272, lr = 0.01
I0621 01:56:43.202617   388 solver.cpp:213] Iteration 273, loss = 0.000905207
I0621 01:56:43.202698   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000904051 (* 1 = 0.000904051 loss)
I0621 01:56:43.202721   388 solver.cpp:473] Iteration 273, lr = 0.01
I0621 01:56:55.600118   388 solver.cpp:213] Iteration 274, loss = 0.000903478
I0621 01:56:55.600205   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000903844 (* 1 = 0.000903844 loss)
I0621 01:56:55.600229   388 solver.cpp:473] Iteration 274, lr = 0.01
I0621 01:57:07.927255   388 solver.cpp:213] Iteration 275, loss = 0.000901919
I0621 01:57:07.927500   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000902385 (* 1 = 0.000902385 loss)
I0621 01:57:07.927543   388 solver.cpp:473] Iteration 275, lr = 0.01
I0621 01:57:20.228919   388 solver.cpp:213] Iteration 276, loss = 0.000899979
I0621 01:57:20.229006   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000899906 (* 1 = 0.000899906 loss)
I0621 01:57:20.229028   388 solver.cpp:473] Iteration 276, lr = 0.01
I0621 01:57:32.462086   388 solver.cpp:213] Iteration 277, loss = 0.000897762
I0621 01:57:32.462169   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000896441 (* 1 = 0.000896441 loss)
I0621 01:57:32.462191   388 solver.cpp:473] Iteration 277, lr = 0.01
I0621 01:57:44.744019   388 solver.cpp:213] Iteration 278, loss = 0.000896018
I0621 01:57:44.744478   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000897132 (* 1 = 0.000897132 loss)
I0621 01:57:44.744505   388 solver.cpp:473] Iteration 278, lr = 0.01
I0621 01:57:56.978276   388 solver.cpp:213] Iteration 279, loss = 0.000893969
I0621 01:57:56.978363   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000893587 (* 1 = 0.000893587 loss)
I0621 01:57:56.978386   388 solver.cpp:473] Iteration 279, lr = 0.01
I0621 01:58:09.204347   388 solver.cpp:213] Iteration 280, loss = 0.000892273
I0621 01:58:09.204432   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000893144 (* 1 = 0.000893144 loss)
I0621 01:58:09.204455   388 solver.cpp:473] Iteration 280, lr = 0.01
I0621 01:58:21.418577   388 solver.cpp:213] Iteration 281, loss = 0.000890718
I0621 01:58:21.419402   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000891389 (* 1 = 0.000891389 loss)
I0621 01:58:21.419428   388 solver.cpp:473] Iteration 281, lr = 0.01
I0621 01:58:33.656368   388 solver.cpp:213] Iteration 282, loss = 0.000888382
I0621 01:58:33.656451   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000887366 (* 1 = 0.000887366 loss)
I0621 01:58:33.656473   388 solver.cpp:473] Iteration 282, lr = 0.01
I0621 01:58:45.943593   388 solver.cpp:213] Iteration 283, loss = 0.000887124
I0621 01:58:45.943676   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0008878 (* 1 = 0.0008878 loss)
I0621 01:58:45.943698   388 solver.cpp:473] Iteration 283, lr = 0.01
I0621 01:58:58.179436   388 solver.cpp:213] Iteration 284, loss = 0.000885002
I0621 01:58:58.179697   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000886088 (* 1 = 0.000886088 loss)
I0621 01:58:58.179733   388 solver.cpp:473] Iteration 284, lr = 0.01
I0621 01:59:10.430100   388 solver.cpp:213] Iteration 285, loss = 0.000882914
I0621 01:59:10.430186   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000882048 (* 1 = 0.000882048 loss)
I0621 01:59:10.430207   388 solver.cpp:473] Iteration 285, lr = 0.01
I0621 01:59:22.729581   388 solver.cpp:213] Iteration 286, loss = 0.000881115
I0621 01:59:22.729666   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000881114 (* 1 = 0.000881114 loss)
I0621 01:59:22.729689   388 solver.cpp:473] Iteration 286, lr = 0.01
I0621 01:59:35.019325   388 solver.cpp:213] Iteration 287, loss = 0.000879727
I0621 01:59:35.019562   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000880074 (* 1 = 0.000880074 loss)
I0621 01:59:35.019611   388 solver.cpp:473] Iteration 287, lr = 0.01
I0621 01:59:47.514575   388 solver.cpp:213] Iteration 288, loss = 0.000877118
I0621 01:59:47.514660   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000878533 (* 1 = 0.000878533 loss)
I0621 01:59:47.514683   388 solver.cpp:473] Iteration 288, lr = 0.01
I0621 01:59:59.777165   388 solver.cpp:213] Iteration 289, loss = 0.000875792
I0621 01:59:59.777248   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000876531 (* 1 = 0.000876531 loss)
I0621 01:59:59.777271   388 solver.cpp:473] Iteration 289, lr = 0.01
I0621 02:00:12.007555   388 solver.cpp:213] Iteration 290, loss = 0.000874106
I0621 02:00:12.007727   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000875633 (* 1 = 0.000875633 loss)
I0621 02:00:12.007752   388 solver.cpp:473] Iteration 290, lr = 0.01
I0621 02:00:24.250085   388 solver.cpp:213] Iteration 291, loss = 0.000872351
I0621 02:00:24.250171   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000872289 (* 1 = 0.000872289 loss)
I0621 02:00:24.250195   388 solver.cpp:473] Iteration 291, lr = 0.01
I0621 02:00:36.490838   388 solver.cpp:213] Iteration 292, loss = 0.000870635
I0621 02:00:36.490922   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000871936 (* 1 = 0.000871936 loss)
I0621 02:00:36.490945   388 solver.cpp:473] Iteration 292, lr = 0.01
I0621 02:00:48.702930   388 solver.cpp:213] Iteration 293, loss = 0.000868986
I0621 02:00:48.703104   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000869144 (* 1 = 0.000869144 loss)
I0621 02:00:48.703126   388 solver.cpp:473] Iteration 293, lr = 0.01
I0621 02:01:00.923087   388 solver.cpp:213] Iteration 294, loss = 0.000867187
I0621 02:01:00.923163   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000866748 (* 1 = 0.000866748 loss)
I0621 02:01:00.923184   388 solver.cpp:473] Iteration 294, lr = 0.01
I0621 02:01:13.151551   388 solver.cpp:213] Iteration 295, loss = 0.000865104
I0621 02:01:13.151628   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00086502 (* 1 = 0.00086502 loss)
I0621 02:01:13.151649   388 solver.cpp:473] Iteration 295, lr = 0.01
I0621 02:01:25.469233   388 solver.cpp:213] Iteration 296, loss = 0.00086346
I0621 02:01:25.469465   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000864168 (* 1 = 0.000864168 loss)
I0621 02:01:25.469494   388 solver.cpp:473] Iteration 296, lr = 0.01
I0621 02:01:37.795109   388 solver.cpp:213] Iteration 297, loss = 0.000861694
I0621 02:01:37.795192   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000863082 (* 1 = 0.000863082 loss)
I0621 02:01:37.795214   388 solver.cpp:473] Iteration 297, lr = 0.01
I0621 02:01:50.027184   388 solver.cpp:213] Iteration 298, loss = 0.00086005
I0621 02:01:50.027271   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000859055 (* 1 = 0.000859055 loss)
I0621 02:01:50.027293   388 solver.cpp:473] Iteration 298, lr = 0.01
I0621 02:02:02.381549   388 solver.cpp:213] Iteration 299, loss = 0.000857954
I0621 02:02:02.381745   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000857237 (* 1 = 0.000857237 loss)
I0621 02:02:02.381770   388 solver.cpp:473] Iteration 299, lr = 0.01
I0621 02:02:14.622628   388 solver.cpp:213] Iteration 300, loss = 0.000856989
I0621 02:02:14.622717   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000856521 (* 1 = 0.000856521 loss)
I0621 02:02:14.622738   388 solver.cpp:473] Iteration 300, lr = 0.01
I0621 02:02:26.944032   388 solver.cpp:213] Iteration 301, loss = 0.000854611
I0621 02:02:26.944115   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000854749 (* 1 = 0.000854749 loss)
I0621 02:02:26.944136   388 solver.cpp:473] Iteration 301, lr = 0.01
I0621 02:02:39.392379   388 solver.cpp:213] Iteration 302, loss = 0.000852918
I0621 02:02:39.392619   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000853128 (* 1 = 0.000853128 loss)
I0621 02:02:39.392668   388 solver.cpp:473] Iteration 302, lr = 0.01
I0621 02:02:51.692349   388 solver.cpp:213] Iteration 303, loss = 0.000851167
I0621 02:02:51.692432   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000849311 (* 1 = 0.000849311 loss)
I0621 02:02:51.692454   388 solver.cpp:473] Iteration 303, lr = 0.01
I0621 02:03:03.977618   388 solver.cpp:213] Iteration 304, loss = 0.000849459
I0621 02:03:03.977705   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000849612 (* 1 = 0.000849612 loss)
I0621 02:03:03.977727   388 solver.cpp:473] Iteration 304, lr = 0.01
I0621 02:03:16.256728   388 solver.cpp:213] Iteration 305, loss = 0.000848383
I0621 02:03:16.256981   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000848766 (* 1 = 0.000848766 loss)
I0621 02:03:16.257027   388 solver.cpp:473] Iteration 305, lr = 0.01
I0621 02:03:28.662683   388 solver.cpp:213] Iteration 306, loss = 0.000846646
I0621 02:03:28.664458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00084727 (* 1 = 0.00084727 loss)
I0621 02:03:28.664569   388 solver.cpp:473] Iteration 306, lr = 0.01
I0621 02:03:40.972435   388 solver.cpp:213] Iteration 307, loss = 0.000845032
I0621 02:03:40.972522   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000844571 (* 1 = 0.000844571 loss)
I0621 02:03:40.972545   388 solver.cpp:473] Iteration 307, lr = 0.01
I0621 02:03:53.296846   388 solver.cpp:213] Iteration 308, loss = 0.000842793
I0621 02:03:53.297019   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000842845 (* 1 = 0.000842845 loss)
I0621 02:03:53.297045   388 solver.cpp:473] Iteration 308, lr = 0.01
I0621 02:04:05.610849   388 solver.cpp:213] Iteration 309, loss = 0.000841737
I0621 02:04:05.610934   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000842309 (* 1 = 0.000842309 loss)
I0621 02:04:05.610956   388 solver.cpp:473] Iteration 309, lr = 0.01
I0621 02:04:17.856936   388 solver.cpp:213] Iteration 310, loss = 0.000840057
I0621 02:04:17.857019   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000838985 (* 1 = 0.000838985 loss)
I0621 02:04:17.857043   388 solver.cpp:473] Iteration 310, lr = 0.01
I0621 02:04:30.087466   388 solver.cpp:213] Iteration 311, loss = 0.000838241
I0621 02:04:30.087647   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000837877 (* 1 = 0.000837877 loss)
I0621 02:04:30.087671   388 solver.cpp:473] Iteration 311, lr = 0.01
I0621 02:04:42.369524   388 solver.cpp:213] Iteration 312, loss = 0.000836759
I0621 02:04:42.369604   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000836539 (* 1 = 0.000836539 loss)
I0621 02:04:42.369627   388 solver.cpp:473] Iteration 312, lr = 0.01
I0621 02:04:54.662181   388 solver.cpp:213] Iteration 313, loss = 0.00083472
I0621 02:04:54.662261   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000834544 (* 1 = 0.000834544 loss)
I0621 02:04:54.662283   388 solver.cpp:473] Iteration 313, lr = 0.01
I0621 02:05:07.030917   388 solver.cpp:213] Iteration 314, loss = 0.000833625
I0621 02:05:07.031193   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000833591 (* 1 = 0.000833591 loss)
I0621 02:05:07.031257   388 solver.cpp:473] Iteration 314, lr = 0.01
I0621 02:05:19.451370   388 solver.cpp:213] Iteration 315, loss = 0.000831968
I0621 02:05:19.451450   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000831942 (* 1 = 0.000831942 loss)
I0621 02:05:19.451472   388 solver.cpp:473] Iteration 315, lr = 0.01
I0621 02:05:31.825978   388 solver.cpp:213] Iteration 316, loss = 0.00083001
I0621 02:05:31.826062   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000829512 (* 1 = 0.000829512 loss)
I0621 02:05:31.826086   388 solver.cpp:473] Iteration 316, lr = 0.01
I0621 02:05:44.098953   388 solver.cpp:213] Iteration 317, loss = 0.000828446
I0621 02:05:44.099203   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000828482 (* 1 = 0.000828482 loss)
I0621 02:05:44.099264   388 solver.cpp:473] Iteration 317, lr = 0.01
I0621 02:05:56.452811   388 solver.cpp:213] Iteration 318, loss = 0.000826481
I0621 02:05:56.452896   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000827059 (* 1 = 0.000827059 loss)
I0621 02:05:56.452919   388 solver.cpp:473] Iteration 318, lr = 0.01
I0621 02:06:08.729471   388 solver.cpp:213] Iteration 319, loss = 0.000825787
I0621 02:06:08.729557   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000825368 (* 1 = 0.000825368 loss)
I0621 02:06:08.729580   388 solver.cpp:473] Iteration 319, lr = 0.01
I0621 02:06:20.974256   388 solver.cpp:213] Iteration 320, loss = 0.000823272
I0621 02:06:20.975004   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000823843 (* 1 = 0.000823843 loss)
I0621 02:06:20.975031   388 solver.cpp:473] Iteration 320, lr = 0.01
I0621 02:06:33.206570   388 solver.cpp:213] Iteration 321, loss = 0.000822176
I0621 02:06:33.206658   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00082203 (* 1 = 0.00082203 loss)
I0621 02:06:33.206681   388 solver.cpp:473] Iteration 321, lr = 0.01
I0621 02:06:45.484750   388 solver.cpp:213] Iteration 322, loss = 0.000820603
I0621 02:06:45.484830   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000820389 (* 1 = 0.000820389 loss)
I0621 02:06:45.484853   388 solver.cpp:473] Iteration 322, lr = 0.01
I0621 02:06:57.721020   388 solver.cpp:213] Iteration 323, loss = 0.000819259
I0621 02:06:57.721236   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000819561 (* 1 = 0.000819561 loss)
I0621 02:06:57.721269   388 solver.cpp:473] Iteration 323, lr = 0.01
I0621 02:07:10.032351   388 solver.cpp:213] Iteration 324, loss = 0.00081739
I0621 02:07:10.032433   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000818008 (* 1 = 0.000818008 loss)
I0621 02:07:10.032454   388 solver.cpp:473] Iteration 324, lr = 0.01
I0621 02:07:22.262784   388 solver.cpp:213] Iteration 325, loss = 0.000816053
I0621 02:07:22.262871   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000817129 (* 1 = 0.000817129 loss)
I0621 02:07:22.262893   388 solver.cpp:473] Iteration 325, lr = 0.01
I0621 02:07:34.479357   388 solver.cpp:213] Iteration 326, loss = 0.000814169
I0621 02:07:34.479593   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000814542 (* 1 = 0.000814542 loss)
I0621 02:07:34.479640   388 solver.cpp:473] Iteration 326, lr = 0.01
I0621 02:07:46.795939   388 solver.cpp:213] Iteration 327, loss = 0.000812921
I0621 02:07:46.796033   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000813879 (* 1 = 0.000813879 loss)
I0621 02:07:46.796058   388 solver.cpp:473] Iteration 327, lr = 0.01
I0621 02:07:59.132216   388 solver.cpp:213] Iteration 328, loss = 0.000811567
I0621 02:07:59.132299   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000811317 (* 1 = 0.000811317 loss)
I0621 02:07:59.132323   388 solver.cpp:473] Iteration 328, lr = 0.01
I0621 02:08:11.370231   388 solver.cpp:213] Iteration 329, loss = 0.000809918
I0621 02:08:11.370394   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000810099 (* 1 = 0.000810099 loss)
I0621 02:08:11.370420   388 solver.cpp:473] Iteration 329, lr = 0.01
I0621 02:08:23.636845   388 solver.cpp:213] Iteration 330, loss = 0.000808378
I0621 02:08:23.636937   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000807963 (* 1 = 0.000807963 loss)
I0621 02:08:23.636961   388 solver.cpp:473] Iteration 330, lr = 0.01
I0621 02:08:36.087671   388 solver.cpp:213] Iteration 331, loss = 0.000806845
I0621 02:08:36.087754   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000807423 (* 1 = 0.000807423 loss)
I0621 02:08:36.087777   388 solver.cpp:473] Iteration 331, lr = 0.01
I0621 02:08:48.421581   388 solver.cpp:213] Iteration 332, loss = 0.000805426
I0621 02:08:48.422760   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00080447 (* 1 = 0.00080447 loss)
I0621 02:08:48.422786   388 solver.cpp:473] Iteration 332, lr = 0.01
I0621 02:09:00.648797   388 solver.cpp:213] Iteration 333, loss = 0.000803811
I0621 02:09:00.648879   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000804072 (* 1 = 0.000804072 loss)
I0621 02:09:00.648908   388 solver.cpp:473] Iteration 333, lr = 0.01
I0621 02:09:12.984619   388 solver.cpp:213] Iteration 334, loss = 0.000802332
I0621 02:09:12.987550   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000803317 (* 1 = 0.000803317 loss)
I0621 02:09:12.987653   388 solver.cpp:473] Iteration 334, lr = 0.01
I0621 02:09:25.348742   388 solver.cpp:213] Iteration 335, loss = 0.000801032
I0621 02:09:25.349030   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000801019 (* 1 = 0.000801019 loss)
I0621 02:09:25.349079   388 solver.cpp:473] Iteration 335, lr = 0.01
I0621 02:09:37.579388   388 solver.cpp:213] Iteration 336, loss = 0.000799553
I0621 02:09:37.579476   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000800138 (* 1 = 0.000800138 loss)
I0621 02:09:37.579499   388 solver.cpp:473] Iteration 336, lr = 0.01
I0621 02:09:49.842135   388 solver.cpp:213] Iteration 337, loss = 0.000797704
I0621 02:09:49.842218   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000797837 (* 1 = 0.000797837 loss)
I0621 02:09:49.842241   388 solver.cpp:473] Iteration 337, lr = 0.01
I0621 02:10:02.153097   388 solver.cpp:213] Iteration 338, loss = 0.000795939
I0621 02:10:02.153381   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000796894 (* 1 = 0.000796894 loss)
I0621 02:10:02.153429   388 solver.cpp:473] Iteration 338, lr = 0.01
I0621 02:10:14.423053   388 solver.cpp:213] Iteration 339, loss = 0.000794937
I0621 02:10:14.423146   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000794434 (* 1 = 0.000794434 loss)
I0621 02:10:14.423169   388 solver.cpp:473] Iteration 339, lr = 0.01
I0621 02:10:26.653710   388 solver.cpp:213] Iteration 340, loss = 0.000793457
I0621 02:10:26.653794   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000793682 (* 1 = 0.000793682 loss)
I0621 02:10:26.653816   388 solver.cpp:473] Iteration 340, lr = 0.01
I0621 02:10:38.893637   388 solver.cpp:213] Iteration 341, loss = 0.000792002
I0621 02:10:38.893887   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000793141 (* 1 = 0.000793141 loss)
I0621 02:10:38.893932   388 solver.cpp:473] Iteration 341, lr = 0.01
I0621 02:10:51.189044   388 solver.cpp:213] Iteration 342, loss = 0.000790874
I0621 02:10:51.189131   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000790393 (* 1 = 0.000790393 loss)
I0621 02:10:51.189152   388 solver.cpp:473] Iteration 342, lr = 0.01
I0621 02:11:03.522941   388 solver.cpp:213] Iteration 343, loss = 0.000789056
I0621 02:11:03.523027   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000788145 (* 1 = 0.000788145 loss)
I0621 02:11:03.523052   388 solver.cpp:473] Iteration 343, lr = 0.01
I0621 02:11:15.865545   388 solver.cpp:213] Iteration 344, loss = 0.000787717
I0621 02:11:15.865768   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000786735 (* 1 = 0.000786735 loss)
I0621 02:11:15.865813   388 solver.cpp:473] Iteration 344, lr = 0.01
I0621 02:11:28.236877   388 solver.cpp:213] Iteration 345, loss = 0.000785786
I0621 02:11:28.236968   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000785969 (* 1 = 0.000785969 loss)
I0621 02:11:28.236994   388 solver.cpp:473] Iteration 345, lr = 0.01
I0621 02:11:40.512307   388 solver.cpp:213] Iteration 346, loss = 0.000784878
I0621 02:11:40.512378   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000784333 (* 1 = 0.000784333 loss)
I0621 02:11:40.512394   388 solver.cpp:473] Iteration 346, lr = 0.01
I0621 02:11:52.927155   388 solver.cpp:213] Iteration 347, loss = 0.000783434
I0621 02:11:52.927409   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000782925 (* 1 = 0.000782925 loss)
I0621 02:11:52.927451   388 solver.cpp:473] Iteration 347, lr = 0.01
I0621 02:12:05.297755   388 solver.cpp:213] Iteration 348, loss = 0.00078201
I0621 02:12:05.297842   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000782717 (* 1 = 0.000782717 loss)
I0621 02:12:05.297864   388 solver.cpp:473] Iteration 348, lr = 0.01
I0621 02:12:17.608546   388 solver.cpp:213] Iteration 349, loss = 0.000780548
I0621 02:12:17.608626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000781167 (* 1 = 0.000781167 loss)
I0621 02:12:17.608649   388 solver.cpp:473] Iteration 349, lr = 0.01
I0621 02:12:29.863001   388 solver.cpp:213] Iteration 350, loss = 0.000779063
I0621 02:12:29.863286   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000779081 (* 1 = 0.000779081 loss)
I0621 02:12:29.863311   388 solver.cpp:473] Iteration 350, lr = 0.01
I0621 02:12:42.168257   388 solver.cpp:213] Iteration 351, loss = 0.00077793
I0621 02:12:42.168339   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00077773 (* 1 = 0.00077773 loss)
I0621 02:12:42.168361   388 solver.cpp:473] Iteration 351, lr = 0.01
I0621 02:12:54.448233   388 solver.cpp:213] Iteration 352, loss = 0.000776099
I0621 02:12:54.448302   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000776763 (* 1 = 0.000776763 loss)
I0621 02:12:54.448318   388 solver.cpp:473] Iteration 352, lr = 0.01
I0621 02:13:06.783429   388 solver.cpp:213] Iteration 353, loss = 0.000774757
I0621 02:13:06.783634   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000774567 (* 1 = 0.000774567 loss)
I0621 02:13:06.783658   388 solver.cpp:473] Iteration 353, lr = 0.01
I0621 02:13:19.185513   388 solver.cpp:213] Iteration 354, loss = 0.000773923
I0621 02:13:19.185592   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000774188 (* 1 = 0.000774188 loss)
I0621 02:13:19.185616   388 solver.cpp:473] Iteration 354, lr = 0.01
I0621 02:13:31.417901   388 solver.cpp:213] Iteration 355, loss = 0.000772484
I0621 02:13:31.417989   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000772325 (* 1 = 0.000772325 loss)
I0621 02:13:31.418015   388 solver.cpp:473] Iteration 355, lr = 0.01
I0621 02:13:43.654849   388 solver.cpp:213] Iteration 356, loss = 0.000770764
I0621 02:13:43.655108   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000769886 (* 1 = 0.000769886 loss)
I0621 02:13:43.655167   388 solver.cpp:473] Iteration 356, lr = 0.01
I0621 02:13:55.930539   388 solver.cpp:213] Iteration 357, loss = 0.000769258
I0621 02:13:55.930619   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000768223 (* 1 = 0.000768223 loss)
I0621 02:13:55.930640   388 solver.cpp:473] Iteration 357, lr = 0.01
I0621 02:14:08.264106   388 solver.cpp:213] Iteration 358, loss = 0.000768053
I0621 02:14:08.264196   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000768663 (* 1 = 0.000768663 loss)
I0621 02:14:08.264220   388 solver.cpp:473] Iteration 358, lr = 0.01
I0621 02:14:20.589831   388 solver.cpp:213] Iteration 359, loss = 0.000766732
I0621 02:14:20.590081   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000767716 (* 1 = 0.000767716 loss)
I0621 02:14:20.590128   388 solver.cpp:473] Iteration 359, lr = 0.01
I0621 02:14:32.998262   388 solver.cpp:213] Iteration 360, loss = 0.000765396
I0621 02:14:32.998349   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000765604 (* 1 = 0.000765604 loss)
I0621 02:14:32.998371   388 solver.cpp:473] Iteration 360, lr = 0.01
I0621 02:14:45.256703   388 solver.cpp:213] Iteration 361, loss = 0.000764508
I0621 02:14:45.256788   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000765508 (* 1 = 0.000765508 loss)
I0621 02:14:45.256813   388 solver.cpp:473] Iteration 361, lr = 0.01
I0621 02:14:57.486829   388 solver.cpp:213] Iteration 362, loss = 0.000762301
I0621 02:14:57.487017   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000761924 (* 1 = 0.000761924 loss)
I0621 02:14:57.487042   388 solver.cpp:473] Iteration 362, lr = 0.01
I0621 02:15:09.702230   388 solver.cpp:213] Iteration 363, loss = 0.000761483
I0621 02:15:09.702318   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000762171 (* 1 = 0.000762171 loss)
I0621 02:15:09.702340   388 solver.cpp:473] Iteration 363, lr = 0.01
I0621 02:15:21.981485   388 solver.cpp:213] Iteration 364, loss = 0.000760123
I0621 02:15:21.981570   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000760229 (* 1 = 0.000760229 loss)
I0621 02:15:21.981591   388 solver.cpp:473] Iteration 364, lr = 0.01
I0621 02:15:34.209620   388 solver.cpp:213] Iteration 365, loss = 0.00075893
I0621 02:15:34.209861   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000758303 (* 1 = 0.000758303 loss)
I0621 02:15:34.209920   388 solver.cpp:473] Iteration 365, lr = 0.01
I0621 02:15:46.596447   388 solver.cpp:213] Iteration 366, loss = 0.000757255
I0621 02:15:46.596532   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000758182 (* 1 = 0.000758182 loss)
I0621 02:15:46.596557   388 solver.cpp:473] Iteration 366, lr = 0.01
I0621 02:15:58.958127   388 solver.cpp:213] Iteration 367, loss = 0.000755941
I0621 02:15:58.958209   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000755689 (* 1 = 0.000755689 loss)
I0621 02:15:58.958232   388 solver.cpp:473] Iteration 367, lr = 0.01
I0621 02:16:11.213201   388 solver.cpp:213] Iteration 368, loss = 0.000754578
I0621 02:16:11.223242   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000755051 (* 1 = 0.000755051 loss)
I0621 02:16:11.223336   388 solver.cpp:473] Iteration 368, lr = 0.01
I0621 02:16:23.489568   388 solver.cpp:213] Iteration 369, loss = 0.000753432
I0621 02:16:23.489646   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000755002 (* 1 = 0.000755002 loss)
I0621 02:16:23.489670   388 solver.cpp:473] Iteration 369, lr = 0.01
I0621 02:16:35.934373   388 solver.cpp:213] Iteration 370, loss = 0.000752306
I0621 02:16:35.934459   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000752492 (* 1 = 0.000752492 loss)
I0621 02:16:35.934481   388 solver.cpp:473] Iteration 370, lr = 0.01
I0621 02:16:48.290467   388 solver.cpp:213] Iteration 371, loss = 0.000750822
I0621 02:16:48.290958   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000750207 (* 1 = 0.000750207 loss)
I0621 02:16:48.290983   388 solver.cpp:473] Iteration 371, lr = 0.01
I0621 02:17:00.594714   388 solver.cpp:213] Iteration 372, loss = 0.000749456
I0621 02:17:00.594802   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000750134 (* 1 = 0.000750134 loss)
I0621 02:17:00.594826   388 solver.cpp:473] Iteration 372, lr = 0.01
I0621 02:17:12.851021   388 solver.cpp:213] Iteration 373, loss = 0.00074772
I0621 02:17:12.851110   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000748513 (* 1 = 0.000748513 loss)
I0621 02:17:12.851132   388 solver.cpp:473] Iteration 373, lr = 0.01
I0621 02:17:25.095192   388 solver.cpp:213] Iteration 374, loss = 0.000746559
I0621 02:17:25.095381   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000747029 (* 1 = 0.000747029 loss)
I0621 02:17:25.095407   388 solver.cpp:473] Iteration 374, lr = 0.01
I0621 02:17:37.391963   388 solver.cpp:213] Iteration 375, loss = 0.000745502
I0621 02:17:37.392047   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000746284 (* 1 = 0.000746284 loss)
I0621 02:17:37.392069   388 solver.cpp:473] Iteration 375, lr = 0.01
I0621 02:17:49.610256   388 solver.cpp:213] Iteration 376, loss = 0.000744597
I0621 02:17:49.610342   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000746511 (* 1 = 0.000746511 loss)
I0621 02:17:49.610363   388 solver.cpp:473] Iteration 376, lr = 0.01
I0621 02:18:01.843214   388 solver.cpp:213] Iteration 377, loss = 0.000743199
I0621 02:18:01.849268   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00074238 (* 1 = 0.00074238 loss)
I0621 02:18:01.849295   388 solver.cpp:473] Iteration 377, lr = 0.01
I0621 02:18:14.126509   388 solver.cpp:213] Iteration 378, loss = 0.000741775
I0621 02:18:14.126593   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000741926 (* 1 = 0.000741926 loss)
I0621 02:18:14.126616   388 solver.cpp:473] Iteration 378, lr = 0.01
I0621 02:18:26.352542   388 solver.cpp:213] Iteration 379, loss = 0.000740198
I0621 02:18:26.352627   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00073826 (* 1 = 0.00073826 loss)
I0621 02:18:26.352649   388 solver.cpp:473] Iteration 379, lr = 0.01
I0621 02:18:38.639153   388 solver.cpp:213] Iteration 380, loss = 0.000739155
I0621 02:18:38.639396   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000738757 (* 1 = 0.000738757 loss)
I0621 02:18:38.639431   388 solver.cpp:473] Iteration 380, lr = 0.01
I0621 02:18:51.005017   388 solver.cpp:213] Iteration 381, loss = 0.000738376
I0621 02:18:51.005105   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000739067 (* 1 = 0.000739067 loss)
I0621 02:18:51.005130   388 solver.cpp:473] Iteration 381, lr = 0.01
I0621 02:19:03.314769   388 solver.cpp:213] Iteration 382, loss = 0.000736611
I0621 02:19:03.314857   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000736981 (* 1 = 0.000736981 loss)
I0621 02:19:03.314879   388 solver.cpp:473] Iteration 382, lr = 0.01
I0621 02:19:15.620105   388 solver.cpp:213] Iteration 383, loss = 0.000735544
I0621 02:19:15.620358   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000734033 (* 1 = 0.000734033 loss)
I0621 02:19:15.620393   388 solver.cpp:473] Iteration 383, lr = 0.01
I0621 02:19:28.069422   388 solver.cpp:213] Iteration 384, loss = 0.000734363
I0621 02:19:28.069501   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000735506 (* 1 = 0.000735506 loss)
I0621 02:19:28.069525   388 solver.cpp:473] Iteration 384, lr = 0.01
I0621 02:19:40.429738   388 solver.cpp:213] Iteration 385, loss = 0.00073307
I0621 02:19:40.429831   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000732342 (* 1 = 0.000732342 loss)
I0621 02:19:40.429857   388 solver.cpp:473] Iteration 385, lr = 0.01
I0621 02:19:52.903900   388 solver.cpp:213] Iteration 386, loss = 0.000731864
I0621 02:19:52.904088   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000731408 (* 1 = 0.000731408 loss)
I0621 02:19:52.904112   388 solver.cpp:473] Iteration 386, lr = 0.01
I0621 02:20:05.191432   388 solver.cpp:213] Iteration 387, loss = 0.000730154
I0621 02:20:05.191514   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000730054 (* 1 = 0.000730054 loss)
I0621 02:20:05.191537   388 solver.cpp:473] Iteration 387, lr = 0.01
I0621 02:20:17.418692   388 solver.cpp:213] Iteration 388, loss = 0.000729189
I0621 02:20:17.418776   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000730183 (* 1 = 0.000730183 loss)
I0621 02:20:17.418798   388 solver.cpp:473] Iteration 388, lr = 0.01
I0621 02:20:29.707646   388 solver.cpp:213] Iteration 389, loss = 0.000728113
I0621 02:20:29.716330   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000728336 (* 1 = 0.000728336 loss)
I0621 02:20:29.716384   388 solver.cpp:473] Iteration 389, lr = 0.01
I0621 02:20:42.041597   388 solver.cpp:213] Iteration 390, loss = 0.000727089
I0621 02:20:42.041689   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000727944 (* 1 = 0.000727944 loss)
I0621 02:20:42.041717   388 solver.cpp:473] Iteration 390, lr = 0.01
I0621 02:20:54.289237   388 solver.cpp:213] Iteration 391, loss = 0.000725159
I0621 02:20:54.289320   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000725737 (* 1 = 0.000725737 loss)
I0621 02:20:54.289345   388 solver.cpp:473] Iteration 391, lr = 0.01
I0621 02:21:06.501956   388 solver.cpp:213] Iteration 392, loss = 0.000724771
I0621 02:21:06.502148   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000725551 (* 1 = 0.000725551 loss)
I0621 02:21:06.502174   388 solver.cpp:473] Iteration 392, lr = 0.01
I0621 02:21:18.765703   388 solver.cpp:213] Iteration 393, loss = 0.000723327
I0621 02:21:18.765784   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000723388 (* 1 = 0.000723388 loss)
I0621 02:21:18.765806   388 solver.cpp:473] Iteration 393, lr = 0.01
I0621 02:21:30.988680   388 solver.cpp:213] Iteration 394, loss = 0.000721837
I0621 02:21:30.988765   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000722107 (* 1 = 0.000722107 loss)
I0621 02:21:30.988787   388 solver.cpp:473] Iteration 394, lr = 0.01
I0621 02:21:43.200711   388 solver.cpp:213] Iteration 395, loss = 0.000721215
I0621 02:21:43.200978   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000721014 (* 1 = 0.000721014 loss)
I0621 02:21:43.201004   388 solver.cpp:473] Iteration 395, lr = 0.01
I0621 02:21:55.423372   388 solver.cpp:213] Iteration 396, loss = 0.000719587
I0621 02:21:55.423460   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000718888 (* 1 = 0.000718888 loss)
I0621 02:21:55.423481   388 solver.cpp:473] Iteration 396, lr = 0.01
I0621 02:22:07.630100   388 solver.cpp:213] Iteration 397, loss = 0.000718346
I0621 02:22:07.630177   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000718695 (* 1 = 0.000718695 loss)
I0621 02:22:07.630198   388 solver.cpp:473] Iteration 397, lr = 0.01
I0621 02:22:19.945017   388 solver.cpp:213] Iteration 398, loss = 0.000717168
I0621 02:22:19.945221   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000718378 (* 1 = 0.000718378 loss)
I0621 02:22:19.945256   388 solver.cpp:473] Iteration 398, lr = 0.01
I0621 02:22:32.240381   388 solver.cpp:213] Iteration 399, loss = 0.000716085
I0621 02:22:32.240465   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000716481 (* 1 = 0.000716481 loss)
I0621 02:22:32.240489   388 solver.cpp:473] Iteration 399, lr = 0.01
I0621 02:22:44.526067   388 solver.cpp:213] Iteration 400, loss = 0.00071467
I0621 02:22:44.526149   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000715275 (* 1 = 0.000715275 loss)
I0621 02:22:44.526171   388 solver.cpp:473] Iteration 400, lr = 0.01
I0621 02:22:56.797642   388 solver.cpp:213] Iteration 401, loss = 0.000713545
I0621 02:22:56.797894   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00071341 (* 1 = 0.00071341 loss)
I0621 02:22:56.797940   388 solver.cpp:473] Iteration 401, lr = 0.01
I0621 02:23:09.090658   388 solver.cpp:213] Iteration 402, loss = 0.000712404
I0621 02:23:09.090745   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000712699 (* 1 = 0.000712699 loss)
I0621 02:23:09.090769   388 solver.cpp:473] Iteration 402, lr = 0.01
I0621 02:23:21.328876   388 solver.cpp:213] Iteration 403, loss = 0.000711647
I0621 02:23:21.328953   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000711266 (* 1 = 0.000711266 loss)
I0621 02:23:21.328976   388 solver.cpp:473] Iteration 403, lr = 0.01
I0621 02:23:33.571036   388 solver.cpp:213] Iteration 404, loss = 0.000710078
I0621 02:23:33.571228   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000710277 (* 1 = 0.000710277 loss)
I0621 02:23:33.571252   388 solver.cpp:473] Iteration 404, lr = 0.01
I0621 02:23:45.789659   388 solver.cpp:213] Iteration 405, loss = 0.000709398
I0621 02:23:45.789742   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000709328 (* 1 = 0.000709328 loss)
I0621 02:23:45.789764   388 solver.cpp:473] Iteration 405, lr = 0.01
I0621 02:23:58.060705   388 solver.cpp:213] Iteration 406, loss = 0.000707933
I0621 02:23:58.060788   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000708509 (* 1 = 0.000708509 loss)
I0621 02:23:58.060809   388 solver.cpp:473] Iteration 406, lr = 0.01
I0621 02:24:10.324529   388 solver.cpp:213] Iteration 407, loss = 0.000706759
I0621 02:24:10.325353   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000705979 (* 1 = 0.000705979 loss)
I0621 02:24:10.325381   388 solver.cpp:473] Iteration 407, lr = 0.01
I0621 02:24:22.529341   388 solver.cpp:213] Iteration 408, loss = 0.00070578
I0621 02:24:22.529429   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00070508 (* 1 = 0.00070508 loss)
I0621 02:24:22.529451   388 solver.cpp:473] Iteration 408, lr = 0.01
I0621 02:24:34.748461   388 solver.cpp:213] Iteration 409, loss = 0.000704606
I0621 02:24:34.748543   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000704689 (* 1 = 0.000704689 loss)
I0621 02:24:34.748563   388 solver.cpp:473] Iteration 409, lr = 0.01
I0621 02:24:46.972414   388 solver.cpp:213] Iteration 410, loss = 0.000703533
I0621 02:24:46.972681   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000704264 (* 1 = 0.000704264 loss)
I0621 02:24:46.972717   388 solver.cpp:473] Iteration 410, lr = 0.01
I0621 02:24:59.394263   388 solver.cpp:213] Iteration 411, loss = 0.000702628
I0621 02:24:59.394348   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000703307 (* 1 = 0.000703307 loss)
I0621 02:24:59.394371   388 solver.cpp:473] Iteration 411, lr = 0.01
I0621 02:25:11.682238   388 solver.cpp:213] Iteration 412, loss = 0.00070128
I0621 02:25:11.682325   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000701725 (* 1 = 0.000701725 loss)
I0621 02:25:11.682348   388 solver.cpp:473] Iteration 412, lr = 0.01
I0621 02:25:23.920555   388 solver.cpp:213] Iteration 413, loss = 0.000699841
I0621 02:25:23.920737   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000699829 (* 1 = 0.000699829 loss)
I0621 02:25:23.920763   388 solver.cpp:473] Iteration 413, lr = 0.01
I0621 02:25:36.138965   388 solver.cpp:213] Iteration 414, loss = 0.000699054
I0621 02:25:36.139050   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000699294 (* 1 = 0.000699294 loss)
I0621 02:25:36.139080   388 solver.cpp:473] Iteration 414, lr = 0.01
I0621 02:25:48.406059   388 solver.cpp:213] Iteration 415, loss = 0.00069795
I0621 02:25:48.406138   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000697663 (* 1 = 0.000697663 loss)
I0621 02:25:48.406162   388 solver.cpp:473] Iteration 415, lr = 0.01
I0621 02:26:00.668745   388 solver.cpp:213] Iteration 416, loss = 0.000696692
I0621 02:26:00.668958   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000696876 (* 1 = 0.000696876 loss)
I0621 02:26:00.668988   388 solver.cpp:473] Iteration 416, lr = 0.01
I0621 02:26:12.945282   388 solver.cpp:213] Iteration 417, loss = 0.000695517
I0621 02:26:12.945363   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000696336 (* 1 = 0.000696336 loss)
I0621 02:26:12.945385   388 solver.cpp:473] Iteration 417, lr = 0.01
I0621 02:26:25.190341   388 solver.cpp:213] Iteration 418, loss = 0.000694737
I0621 02:26:25.190424   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000694942 (* 1 = 0.000694942 loss)
I0621 02:26:25.190448   388 solver.cpp:473] Iteration 418, lr = 0.01
I0621 02:26:37.433009   388 solver.cpp:213] Iteration 419, loss = 0.000693347
I0621 02:26:37.445632   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000693691 (* 1 = 0.000693691 loss)
I0621 02:26:37.445665   388 solver.cpp:473] Iteration 419, lr = 0.01
I0621 02:26:49.778195   388 solver.cpp:213] Iteration 420, loss = 0.000692156
I0621 02:26:49.778278   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000691563 (* 1 = 0.000691563 loss)
I0621 02:26:49.778302   388 solver.cpp:473] Iteration 420, lr = 0.01
I0621 02:27:01.997826   388 solver.cpp:213] Iteration 421, loss = 0.000691122
I0621 02:27:01.997908   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000691583 (* 1 = 0.000691583 loss)
I0621 02:27:01.997931   388 solver.cpp:473] Iteration 421, lr = 0.01
I0621 02:27:14.226295   388 solver.cpp:213] Iteration 422, loss = 0.000690353
I0621 02:27:14.226727   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000688963 (* 1 = 0.000688963 loss)
I0621 02:27:14.226752   388 solver.cpp:473] Iteration 422, lr = 0.01
I0621 02:27:26.504657   388 solver.cpp:213] Iteration 423, loss = 0.00068887
I0621 02:27:26.504741   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00069003 (* 1 = 0.00069003 loss)
I0621 02:27:26.504763   388 solver.cpp:473] Iteration 423, lr = 0.01
I0621 02:27:38.805881   388 solver.cpp:213] Iteration 424, loss = 0.000687605
I0621 02:27:38.805966   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000687402 (* 1 = 0.000687402 loss)
I0621 02:27:38.805989   388 solver.cpp:473] Iteration 424, lr = 0.01
I0621 02:27:51.067440   388 solver.cpp:213] Iteration 425, loss = 0.000686564
I0621 02:27:51.067646   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000685535 (* 1 = 0.000685535 loss)
I0621 02:27:51.067672   388 solver.cpp:473] Iteration 425, lr = 0.01
I0621 02:28:03.343519   388 solver.cpp:213] Iteration 426, loss = 0.00068578
I0621 02:28:03.343605   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000686364 (* 1 = 0.000686364 loss)
I0621 02:28:03.343627   388 solver.cpp:473] Iteration 426, lr = 0.01
I0621 02:28:15.563001   388 solver.cpp:213] Iteration 427, loss = 0.000684566
I0621 02:28:15.563094   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000683987 (* 1 = 0.000683987 loss)
I0621 02:28:15.563117   388 solver.cpp:473] Iteration 427, lr = 0.01
I0621 02:28:27.797273   388 solver.cpp:213] Iteration 428, loss = 0.000683929
I0621 02:28:27.797544   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000683727 (* 1 = 0.000683727 loss)
I0621 02:28:27.797570   388 solver.cpp:473] Iteration 428, lr = 0.01
I0621 02:28:40.016945   388 solver.cpp:213] Iteration 429, loss = 0.000682791
I0621 02:28:40.017030   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000682975 (* 1 = 0.000682975 loss)
I0621 02:28:40.017052   388 solver.cpp:473] Iteration 429, lr = 0.01
I0621 02:28:52.357900   388 solver.cpp:213] Iteration 430, loss = 0.000681573
I0621 02:28:52.357983   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000681894 (* 1 = 0.000681894 loss)
I0621 02:28:52.358006   388 solver.cpp:473] Iteration 430, lr = 0.01
I0621 02:29:04.779783   388 solver.cpp:213] Iteration 431, loss = 0.000680477
I0621 02:29:04.780011   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000679471 (* 1 = 0.000679471 loss)
I0621 02:29:04.780059   388 solver.cpp:473] Iteration 431, lr = 0.01
I0621 02:29:17.090467   388 solver.cpp:213] Iteration 432, loss = 0.000679591
I0621 02:29:17.090603   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000679839 (* 1 = 0.000679839 loss)
I0621 02:29:17.090654   388 solver.cpp:473] Iteration 432, lr = 0.01
I0621 02:29:29.374771   388 solver.cpp:213] Iteration 433, loss = 0.000678243
I0621 02:29:29.374855   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000679491 (* 1 = 0.000679491 loss)
I0621 02:29:29.374877   388 solver.cpp:473] Iteration 433, lr = 0.01
I0621 02:29:41.609735   388 solver.cpp:213] Iteration 434, loss = 0.000677528
I0621 02:29:41.609951   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000678869 (* 1 = 0.000678869 loss)
I0621 02:29:41.610010   388 solver.cpp:473] Iteration 434, lr = 0.01
I0621 02:29:53.947553   388 solver.cpp:213] Iteration 435, loss = 0.000676288
I0621 02:29:53.947638   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000676418 (* 1 = 0.000676418 loss)
I0621 02:29:53.947660   388 solver.cpp:473] Iteration 435, lr = 0.01
I0621 02:30:06.255072   388 solver.cpp:213] Iteration 436, loss = 0.000675094
I0621 02:30:06.255152   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000674869 (* 1 = 0.000674869 loss)
I0621 02:30:06.255187   388 solver.cpp:473] Iteration 436, lr = 0.01
I0621 02:30:18.578830   388 solver.cpp:213] Iteration 437, loss = 0.000674272
I0621 02:30:18.579010   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000672656 (* 1 = 0.000672656 loss)
I0621 02:30:18.579033   388 solver.cpp:473] Iteration 437, lr = 0.01
I0621 02:30:30.896081   388 solver.cpp:213] Iteration 438, loss = 0.000673089
I0621 02:30:30.896173   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000674805 (* 1 = 0.000674805 loss)
I0621 02:30:30.896195   388 solver.cpp:473] Iteration 438, lr = 0.01
I0621 02:30:43.154783   388 solver.cpp:213] Iteration 439, loss = 0.000672215
I0621 02:30:43.154870   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000672283 (* 1 = 0.000672283 loss)
I0621 02:30:43.154892   388 solver.cpp:473] Iteration 439, lr = 0.01
I0621 02:30:55.369513   388 solver.cpp:213] Iteration 440, loss = 0.000671149
I0621 02:30:55.369717   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000671564 (* 1 = 0.000671564 loss)
I0621 02:30:55.369743   388 solver.cpp:473] Iteration 440, lr = 0.01
I0621 02:31:07.614853   388 solver.cpp:213] Iteration 441, loss = 0.000669758
I0621 02:31:07.614941   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000668885 (* 1 = 0.000668885 loss)
I0621 02:31:07.614964   388 solver.cpp:473] Iteration 441, lr = 0.01
I0621 02:31:19.939194   388 solver.cpp:213] Iteration 442, loss = 0.000669122
I0621 02:31:19.939281   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000669873 (* 1 = 0.000669873 loss)
I0621 02:31:19.939304   388 solver.cpp:473] Iteration 442, lr = 0.01
I0621 02:31:32.177384   388 solver.cpp:213] Iteration 443, loss = 0.000667921
I0621 02:31:32.177582   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000668283 (* 1 = 0.000668283 loss)
I0621 02:31:32.177605   388 solver.cpp:473] Iteration 443, lr = 0.01
I0621 02:31:44.446321   388 solver.cpp:213] Iteration 444, loss = 0.000667232
I0621 02:31:44.446403   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000667612 (* 1 = 0.000667612 loss)
I0621 02:31:44.446429   388 solver.cpp:473] Iteration 444, lr = 0.01
I0621 02:31:56.726388   388 solver.cpp:213] Iteration 445, loss = 0.000666067
I0621 02:31:56.726475   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000665956 (* 1 = 0.000665956 loss)
I0621 02:31:56.726497   388 solver.cpp:473] Iteration 445, lr = 0.01
I0621 02:32:08.995651   388 solver.cpp:213] Iteration 446, loss = 0.000665001
I0621 02:32:08.995836   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000665226 (* 1 = 0.000665226 loss)
I0621 02:32:08.995859   388 solver.cpp:473] Iteration 446, lr = 0.01
I0621 02:32:21.248381   388 solver.cpp:213] Iteration 447, loss = 0.0006638
I0621 02:32:21.248466   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000664137 (* 1 = 0.000664137 loss)
I0621 02:32:21.248489   388 solver.cpp:473] Iteration 447, lr = 0.01
I0621 02:32:33.493131   388 solver.cpp:213] Iteration 448, loss = 0.000663133
I0621 02:32:33.493212   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000662482 (* 1 = 0.000662482 loss)
I0621 02:32:33.493234   388 solver.cpp:473] Iteration 448, lr = 0.01
I0621 02:32:45.798028   388 solver.cpp:213] Iteration 449, loss = 0.000662209
I0621 02:32:45.798277   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000662776 (* 1 = 0.000662776 loss)
I0621 02:32:45.798342   388 solver.cpp:473] Iteration 449, lr = 0.01
I0621 02:32:58.113234   388 solver.cpp:213] Iteration 450, loss = 0.000660775
I0621 02:32:58.113318   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000660221 (* 1 = 0.000660221 loss)
I0621 02:32:58.113342   388 solver.cpp:473] Iteration 450, lr = 0.01
I0621 02:33:10.349308   388 solver.cpp:213] Iteration 451, loss = 0.000659826
I0621 02:33:10.349392   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000659701 (* 1 = 0.000659701 loss)
I0621 02:33:10.349416   388 solver.cpp:473] Iteration 451, lr = 0.01
I0621 02:33:22.585759   388 solver.cpp:213] Iteration 452, loss = 0.000658476
I0621 02:33:22.585922   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000659301 (* 1 = 0.000659301 loss)
I0621 02:33:22.585945   388 solver.cpp:473] Iteration 452, lr = 0.01
I0621 02:33:34.835031   388 solver.cpp:213] Iteration 453, loss = 0.000658292
I0621 02:33:34.835132   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000659359 (* 1 = 0.000659359 loss)
I0621 02:33:34.835155   388 solver.cpp:473] Iteration 453, lr = 0.01
I0621 02:33:47.051921   388 solver.cpp:213] Iteration 454, loss = 0.000656934
I0621 02:33:47.052002   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000657803 (* 1 = 0.000657803 loss)
I0621 02:33:47.052024   388 solver.cpp:473] Iteration 454, lr = 0.01
I0621 02:33:59.491428   388 solver.cpp:213] Iteration 455, loss = 0.000656158
I0621 02:33:59.498307   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000657082 (* 1 = 0.000657082 loss)
I0621 02:33:59.498356   388 solver.cpp:473] Iteration 455, lr = 0.01
I0621 02:34:11.812716   388 solver.cpp:213] Iteration 456, loss = 0.000655107
I0621 02:34:11.812799   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00065622 (* 1 = 0.00065622 loss)
I0621 02:34:11.812878   388 solver.cpp:473] Iteration 456, lr = 0.01
I0621 02:34:24.074270   388 solver.cpp:213] Iteration 457, loss = 0.000654224
I0621 02:34:24.074353   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00065426 (* 1 = 0.00065426 loss)
I0621 02:34:24.074375   388 solver.cpp:473] Iteration 457, lr = 0.01
I0621 02:34:36.380560   388 solver.cpp:213] Iteration 458, loss = 0.000653494
I0621 02:34:36.380815   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000653275 (* 1 = 0.000653275 loss)
I0621 02:34:36.380861   388 solver.cpp:473] Iteration 458, lr = 0.01
I0621 02:34:48.656607   388 solver.cpp:213] Iteration 459, loss = 0.000651978
I0621 02:34:48.656693   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000652529 (* 1 = 0.000652529 loss)
I0621 02:34:48.656716   388 solver.cpp:473] Iteration 459, lr = 0.01
I0621 02:35:01.012009   388 solver.cpp:213] Iteration 460, loss = 0.000651147
I0621 02:35:01.012094   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000650155 (* 1 = 0.000650155 loss)
I0621 02:35:01.012116   388 solver.cpp:473] Iteration 460, lr = 0.01
I0621 02:35:13.446630   388 solver.cpp:213] Iteration 461, loss = 0.000650136
I0621 02:35:13.446857   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000649136 (* 1 = 0.000649136 loss)
I0621 02:35:13.447054   388 solver.cpp:473] Iteration 461, lr = 0.01
I0621 02:35:25.677870   388 solver.cpp:213] Iteration 462, loss = 0.000649381
I0621 02:35:25.677953   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000649396 (* 1 = 0.000649396 loss)
I0621 02:35:25.677975   388 solver.cpp:473] Iteration 462, lr = 0.01
I0621 02:35:37.930543   388 solver.cpp:213] Iteration 463, loss = 0.000648303
I0621 02:35:37.930627   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000647315 (* 1 = 0.000647315 loss)
I0621 02:35:37.930649   388 solver.cpp:473] Iteration 463, lr = 0.01
I0621 02:35:50.259838   388 solver.cpp:213] Iteration 464, loss = 0.000647161
I0621 02:35:50.260066   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000646978 (* 1 = 0.000646978 loss)
I0621 02:35:50.260100   388 solver.cpp:473] Iteration 464, lr = 0.01
I0621 02:36:02.563212   388 solver.cpp:213] Iteration 465, loss = 0.000646276
I0621 02:36:02.563299   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000645176 (* 1 = 0.000645176 loss)
I0621 02:36:02.563324   388 solver.cpp:473] Iteration 465, lr = 0.01
I0621 02:36:14.796227   388 solver.cpp:213] Iteration 466, loss = 0.000645582
I0621 02:36:14.796314   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000645002 (* 1 = 0.000645002 loss)
I0621 02:36:14.796336   388 solver.cpp:473] Iteration 466, lr = 0.01
I0621 02:36:27.014261   388 solver.cpp:213] Iteration 467, loss = 0.000644626
I0621 02:36:27.014451   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00064473 (* 1 = 0.00064473 loss)
I0621 02:36:27.014477   388 solver.cpp:473] Iteration 467, lr = 0.01
I0621 02:36:39.270217   388 solver.cpp:213] Iteration 468, loss = 0.000643488
I0621 02:36:39.270300   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000644101 (* 1 = 0.000644101 loss)
I0621 02:36:39.270323   388 solver.cpp:473] Iteration 468, lr = 0.01
I0621 02:36:51.481925   388 solver.cpp:213] Iteration 469, loss = 0.000642572
I0621 02:36:51.482007   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000643136 (* 1 = 0.000643136 loss)
I0621 02:36:51.482028   388 solver.cpp:473] Iteration 469, lr = 0.01
I0621 02:37:03.686723   388 solver.cpp:213] Iteration 470, loss = 0.000641493
I0621 02:37:03.686924   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000640641 (* 1 = 0.000640641 loss)
I0621 02:37:03.686947   388 solver.cpp:473] Iteration 470, lr = 0.01
I0621 02:37:15.983289   388 solver.cpp:213] Iteration 471, loss = 0.000640783
I0621 02:37:15.983377   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000639924 (* 1 = 0.000639924 loss)
I0621 02:37:15.983402   388 solver.cpp:473] Iteration 471, lr = 0.01
I0621 02:37:28.389452   388 solver.cpp:213] Iteration 472, loss = 0.000639699
I0621 02:37:28.389533   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000639612 (* 1 = 0.000639612 loss)
I0621 02:37:28.389556   388 solver.cpp:473] Iteration 472, lr = 0.01
I0621 02:37:40.703977   388 solver.cpp:213] Iteration 473, loss = 0.000638817
I0621 02:37:40.704170   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000639032 (* 1 = 0.000639032 loss)
I0621 02:37:40.704196   388 solver.cpp:473] Iteration 473, lr = 0.01
I0621 02:37:52.950453   388 solver.cpp:213] Iteration 474, loss = 0.000638141
I0621 02:37:52.950536   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000638404 (* 1 = 0.000638404 loss)
I0621 02:37:52.950559   388 solver.cpp:473] Iteration 474, lr = 0.01
I0621 02:38:05.309501   388 solver.cpp:213] Iteration 475, loss = 0.000637353
I0621 02:38:05.309588   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000637243 (* 1 = 0.000637243 loss)
I0621 02:38:05.309620   388 solver.cpp:473] Iteration 475, lr = 0.01
I0621 02:38:17.523633   388 solver.cpp:213] Iteration 476, loss = 0.000636177
I0621 02:38:17.523823   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000636171 (* 1 = 0.000636171 loss)
I0621 02:38:17.523847   388 solver.cpp:473] Iteration 476, lr = 0.01
I0621 02:38:29.895314   388 solver.cpp:213] Iteration 477, loss = 0.000635184
I0621 02:38:29.895400   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000633961 (* 1 = 0.000633961 loss)
I0621 02:38:29.895422   388 solver.cpp:473] Iteration 477, lr = 0.01
I0621 02:38:42.293344   388 solver.cpp:213] Iteration 478, loss = 0.000634287
I0621 02:38:42.293428   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000634601 (* 1 = 0.000634601 loss)
I0621 02:38:42.293452   388 solver.cpp:473] Iteration 478, lr = 0.01
I0621 02:38:54.597879   388 solver.cpp:213] Iteration 479, loss = 0.000633414
I0621 02:38:54.598125   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000633871 (* 1 = 0.000633871 loss)
I0621 02:38:54.598177   388 solver.cpp:473] Iteration 479, lr = 0.01
I0621 02:39:06.900136   388 solver.cpp:213] Iteration 480, loss = 0.000632369
I0621 02:39:06.900223   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000633723 (* 1 = 0.000633723 loss)
I0621 02:39:06.900248   388 solver.cpp:473] Iteration 480, lr = 0.01
I0621 02:39:19.234849   388 solver.cpp:213] Iteration 481, loss = 0.000631726
I0621 02:39:19.234935   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000632034 (* 1 = 0.000632034 loss)
I0621 02:39:19.234958   388 solver.cpp:473] Iteration 481, lr = 0.01
I0621 02:39:31.539016   388 solver.cpp:213] Iteration 482, loss = 0.000630546
I0621 02:39:31.539222   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000630972 (* 1 = 0.000630972 loss)
I0621 02:39:31.539247   388 solver.cpp:473] Iteration 482, lr = 0.01
I0621 02:39:43.887236   388 solver.cpp:213] Iteration 483, loss = 0.000629512
I0621 02:39:43.887318   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000629527 (* 1 = 0.000629527 loss)
I0621 02:39:43.887341   388 solver.cpp:473] Iteration 483, lr = 0.01
I0621 02:39:56.194983   388 solver.cpp:213] Iteration 484, loss = 0.00062899
I0621 02:39:56.195076   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000628719 (* 1 = 0.000628719 loss)
I0621 02:39:56.195101   388 solver.cpp:473] Iteration 484, lr = 0.01
I0621 02:40:08.555527   388 solver.cpp:213] Iteration 485, loss = 0.000627881
I0621 02:40:08.555811   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000628604 (* 1 = 0.000628604 loss)
I0621 02:40:08.555847   388 solver.cpp:473] Iteration 485, lr = 0.01
I0621 02:40:20.841125   388 solver.cpp:213] Iteration 486, loss = 0.000627297
I0621 02:40:20.841210   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000627315 (* 1 = 0.000627315 loss)
I0621 02:40:20.841233   388 solver.cpp:473] Iteration 486, lr = 0.01
I0621 02:40:33.128936   388 solver.cpp:213] Iteration 487, loss = 0.000625871
I0621 02:40:33.129024   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000624716 (* 1 = 0.000624716 loss)
I0621 02:40:33.129045   388 solver.cpp:473] Iteration 487, lr = 0.01
I0621 02:40:45.416767   388 solver.cpp:213] Iteration 488, loss = 0.000625434
I0621 02:40:45.416966   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000625205 (* 1 = 0.000625205 loss)
I0621 02:40:45.416992   388 solver.cpp:473] Iteration 488, lr = 0.01
I0621 02:40:57.715682   388 solver.cpp:213] Iteration 489, loss = 0.000624158
I0621 02:40:57.715767   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000624054 (* 1 = 0.000624054 loss)
I0621 02:40:57.715790   388 solver.cpp:473] Iteration 489, lr = 0.01
I0621 02:41:10.023207   388 solver.cpp:213] Iteration 490, loss = 0.000623701
I0621 02:41:10.023290   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000622925 (* 1 = 0.000622925 loss)
I0621 02:41:10.023313   388 solver.cpp:473] Iteration 490, lr = 0.01
I0621 02:41:22.252800   388 solver.cpp:213] Iteration 491, loss = 0.000622838
I0621 02:41:22.252984   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000622071 (* 1 = 0.000622071 loss)
I0621 02:41:22.253007   388 solver.cpp:473] Iteration 491, lr = 0.01
I0621 02:41:34.477139   388 solver.cpp:213] Iteration 492, loss = 0.000621725
I0621 02:41:34.477221   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000621162 (* 1 = 0.000621162 loss)
I0621 02:41:34.477243   388 solver.cpp:473] Iteration 492, lr = 0.01
I0621 02:41:46.680140   388 solver.cpp:213] Iteration 493, loss = 0.000620744
I0621 02:41:46.680225   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00062106 (* 1 = 0.00062106 loss)
I0621 02:41:46.680248   388 solver.cpp:473] Iteration 493, lr = 0.01
I0621 02:41:58.890574   388 solver.cpp:213] Iteration 494, loss = 0.00062
I0621 02:41:58.891079   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000620657 (* 1 = 0.000620657 loss)
I0621 02:41:58.891105   388 solver.cpp:473] Iteration 494, lr = 0.01
I0621 02:42:11.123347   388 solver.cpp:213] Iteration 495, loss = 0.000618951
I0621 02:42:11.123427   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000619532 (* 1 = 0.000619532 loss)
I0621 02:42:11.123448   388 solver.cpp:473] Iteration 495, lr = 0.01
I0621 02:42:23.352921   388 solver.cpp:213] Iteration 496, loss = 0.000618181
I0621 02:42:23.352999   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000617633 (* 1 = 0.000617633 loss)
I0621 02:42:23.353023   388 solver.cpp:473] Iteration 496, lr = 0.01
I0621 02:42:35.581292   388 solver.cpp:213] Iteration 497, loss = 0.000617489
I0621 02:42:35.581467   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000617348 (* 1 = 0.000617348 loss)
I0621 02:42:35.581491   388 solver.cpp:473] Iteration 497, lr = 0.01
I0621 02:42:47.788571   388 solver.cpp:213] Iteration 498, loss = 0.000616468
I0621 02:42:47.788647   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000615804 (* 1 = 0.000615804 loss)
I0621 02:42:47.788667   388 solver.cpp:473] Iteration 498, lr = 0.01
I0621 02:43:00.033152   388 solver.cpp:213] Iteration 499, loss = 0.000615455
I0621 02:43:00.033237   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000615491 (* 1 = 0.000615491 loss)
I0621 02:43:00.033260   388 solver.cpp:473] Iteration 499, lr = 0.01
I0621 02:43:09.955982   388 solver.cpp:362] Snapshotting to ./snapshot/latefusion-_iter_500.caffemodel
I0621 02:43:30.471364   388 solver.cpp:370] Snapshotting solver state to ./snapshot/latefusion-_iter_500.solverstate
I0621 02:43:34.314363   388 solver.cpp:291] Iteration 500, Testing net (#0)
I0621 02:47:20.704143   388 solver.cpp:342]     Test net output #0: seg-accuracy = 1
I0621 02:47:20.704329   388 solver.cpp:342]     Test net output #1: seg-loss = 0.000614786 (* 1 = 0.000614786 loss)
I0621 02:47:32.459267   388 solver.cpp:213] Iteration 500, loss = 0.000614634
I0621 02:47:32.459349   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00061481 (* 1 = 0.00061481 loss)
I0621 02:47:32.459372   388 solver.cpp:473] Iteration 500, lr = 0.01
I0621 02:47:44.763461   388 solver.cpp:213] Iteration 501, loss = 0.000613692
I0621 02:47:44.763584   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000613832 (* 1 = 0.000613832 loss)
I0621 02:47:44.763622   388 solver.cpp:473] Iteration 501, lr = 0.01
I0621 02:47:57.070911   388 solver.cpp:213] Iteration 502, loss = 0.000613116
I0621 02:47:57.071182   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000612085 (* 1 = 0.000612085 loss)
I0621 02:47:57.071244   388 solver.cpp:473] Iteration 502, lr = 0.01
I0621 02:48:09.402150   388 solver.cpp:213] Iteration 503, loss = 0.000612284
I0621 02:48:09.402230   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000612628 (* 1 = 0.000612628 loss)
I0621 02:48:09.402252   388 solver.cpp:473] Iteration 503, lr = 0.01
I0621 02:48:21.688418   388 solver.cpp:213] Iteration 504, loss = 0.000611486
I0621 02:48:21.688501   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000611289 (* 1 = 0.000611289 loss)
I0621 02:48:21.688524   388 solver.cpp:473] Iteration 504, lr = 0.01
I0621 02:48:33.972079   388 solver.cpp:213] Iteration 505, loss = 0.000610679
I0621 02:48:33.972261   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000610156 (* 1 = 0.000610156 loss)
I0621 02:48:33.972286   388 solver.cpp:473] Iteration 505, lr = 0.01
I0621 02:48:46.198966   388 solver.cpp:213] Iteration 506, loss = 0.000609554
I0621 02:48:46.199048   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000608823 (* 1 = 0.000608823 loss)
I0621 02:48:46.199079   388 solver.cpp:473] Iteration 506, lr = 0.01
I0621 02:48:58.443620   388 solver.cpp:213] Iteration 507, loss = 0.000608897
I0621 02:48:58.443697   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000608243 (* 1 = 0.000608243 loss)
I0621 02:48:58.443720   388 solver.cpp:473] Iteration 507, lr = 0.01
I0621 02:49:10.670075   388 solver.cpp:213] Iteration 508, loss = 0.000608042
I0621 02:49:10.670289   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000608021 (* 1 = 0.000608021 loss)
I0621 02:49:10.670316   388 solver.cpp:473] Iteration 508, lr = 0.01
I0621 02:49:23.075098   388 solver.cpp:213] Iteration 509, loss = 0.00060709
I0621 02:49:23.075187   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000606735 (* 1 = 0.000606735 loss)
I0621 02:49:23.075209   388 solver.cpp:473] Iteration 509, lr = 0.01
I0621 02:49:35.344684   388 solver.cpp:213] Iteration 510, loss = 0.00060623
I0621 02:49:35.344769   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00060569 (* 1 = 0.00060569 loss)
I0621 02:49:35.344792   388 solver.cpp:473] Iteration 510, lr = 0.01
I0621 02:49:47.581668   388 solver.cpp:213] Iteration 511, loss = 0.000605428
I0621 02:49:47.581856   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000603663 (* 1 = 0.000603663 loss)
I0621 02:49:47.581881   388 solver.cpp:473] Iteration 511, lr = 0.01
I0621 02:49:59.817760   388 solver.cpp:213] Iteration 512, loss = 0.000604605
I0621 02:49:59.817844   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000605509 (* 1 = 0.000605509 loss)
I0621 02:49:59.817865   388 solver.cpp:473] Iteration 512, lr = 0.01
I0621 02:50:12.053750   388 solver.cpp:213] Iteration 513, loss = 0.000603887
I0621 02:50:12.053831   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000603392 (* 1 = 0.000603392 loss)
I0621 02:50:12.053856   388 solver.cpp:473] Iteration 513, lr = 0.01
I0621 02:50:24.428427   388 solver.cpp:213] Iteration 514, loss = 0.000602931
I0621 02:50:24.428702   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000602195 (* 1 = 0.000602195 loss)
I0621 02:50:24.428741   388 solver.cpp:473] Iteration 514, lr = 0.01
I0621 02:50:36.829080   388 solver.cpp:213] Iteration 515, loss = 0.000602176
I0621 02:50:36.829160   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000601977 (* 1 = 0.000601977 loss)
I0621 02:50:36.829183   388 solver.cpp:473] Iteration 515, lr = 0.01
I0621 02:50:49.138880   388 solver.cpp:213] Iteration 516, loss = 0.000601389
I0621 02:50:49.138962   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000601496 (* 1 = 0.000601496 loss)
I0621 02:50:49.138985   388 solver.cpp:473] Iteration 516, lr = 0.01
I0621 02:51:01.432763   388 solver.cpp:213] Iteration 517, loss = 0.000600467
I0621 02:51:01.432999   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000601441 (* 1 = 0.000601441 loss)
I0621 02:51:01.433030   388 solver.cpp:473] Iteration 517, lr = 0.01
I0621 02:51:13.701750   388 solver.cpp:213] Iteration 518, loss = 0.000599904
I0621 02:51:13.701834   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00059967 (* 1 = 0.00059967 loss)
I0621 02:51:13.701858   388 solver.cpp:473] Iteration 518, lr = 0.01
I0621 02:51:25.996165   388 solver.cpp:213] Iteration 519, loss = 0.000598768
I0621 02:51:25.996253   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000599589 (* 1 = 0.000599589 loss)
I0621 02:51:25.996276   388 solver.cpp:473] Iteration 519, lr = 0.01
I0621 02:51:38.229362   388 solver.cpp:213] Iteration 520, loss = 0.000598168
I0621 02:51:38.229591   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000597613 (* 1 = 0.000597613 loss)
I0621 02:51:38.229617   388 solver.cpp:473] Iteration 520, lr = 0.01
I0621 02:51:50.595408   388 solver.cpp:213] Iteration 521, loss = 0.000597416
I0621 02:51:50.595492   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000596561 (* 1 = 0.000596561 loss)
I0621 02:51:50.595515   388 solver.cpp:473] Iteration 521, lr = 0.01
I0621 02:52:02.937561   388 solver.cpp:213] Iteration 522, loss = 0.000596829
I0621 02:52:02.937645   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000596643 (* 1 = 0.000596643 loss)
I0621 02:52:02.937669   388 solver.cpp:473] Iteration 522, lr = 0.01
I0621 02:52:15.188166   388 solver.cpp:213] Iteration 523, loss = 0.000595767
I0621 02:52:15.188349   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000595557 (* 1 = 0.000595557 loss)
I0621 02:52:15.188383   388 solver.cpp:473] Iteration 523, lr = 0.01
I0621 02:52:27.487285   388 solver.cpp:213] Iteration 524, loss = 0.000594887
I0621 02:52:27.487375   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000595451 (* 1 = 0.000595451 loss)
I0621 02:52:27.487397   388 solver.cpp:473] Iteration 524, lr = 0.01
I0621 02:52:39.803946   388 solver.cpp:213] Iteration 525, loss = 0.000594161
I0621 02:52:39.804028   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000593268 (* 1 = 0.000593268 loss)
I0621 02:52:39.804051   388 solver.cpp:473] Iteration 525, lr = 0.01
I0621 02:52:52.075568   388 solver.cpp:213] Iteration 526, loss = 0.000593351
I0621 02:52:52.076207   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000594828 (* 1 = 0.000594828 loss)
I0621 02:52:52.076261   388 solver.cpp:473] Iteration 526, lr = 0.01
I0621 02:53:04.374094   388 solver.cpp:213] Iteration 527, loss = 0.000592843
I0621 02:53:04.374176   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00059298 (* 1 = 0.00059298 loss)
I0621 02:53:04.374198   388 solver.cpp:473] Iteration 527, lr = 0.01
I0621 02:53:16.615125   388 solver.cpp:213] Iteration 528, loss = 0.000592096
I0621 02:53:16.615212   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000592816 (* 1 = 0.000592816 loss)
I0621 02:53:16.615236   388 solver.cpp:473] Iteration 528, lr = 0.01
I0621 02:53:28.848085   388 solver.cpp:213] Iteration 529, loss = 0.000590848
I0621 02:53:28.848258   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000590212 (* 1 = 0.000590212 loss)
I0621 02:53:28.848283   388 solver.cpp:473] Iteration 529, lr = 0.01
I0621 02:53:41.066705   388 solver.cpp:213] Iteration 530, loss = 0.000590317
I0621 02:53:41.066789   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00058978 (* 1 = 0.00058978 loss)
I0621 02:53:41.066812   388 solver.cpp:473] Iteration 530, lr = 0.01
I0621 02:53:53.285051   388 solver.cpp:213] Iteration 531, loss = 0.000589436
I0621 02:53:53.285130   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00058855 (* 1 = 0.00058855 loss)
I0621 02:53:53.285151   388 solver.cpp:473] Iteration 531, lr = 0.01
I0621 02:54:05.527894   388 solver.cpp:213] Iteration 532, loss = 0.000588653
I0621 02:54:05.528167   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000587874 (* 1 = 0.000587874 loss)
I0621 02:54:05.528226   388 solver.cpp:473] Iteration 532, lr = 0.01
I0621 02:54:17.850744   388 solver.cpp:213] Iteration 533, loss = 0.000587871
I0621 02:54:17.850829   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0005871 (* 1 = 0.0005871 loss)
I0621 02:54:17.850852   388 solver.cpp:473] Iteration 533, lr = 0.01
I0621 02:54:30.112907   388 solver.cpp:213] Iteration 534, loss = 0.000587009
I0621 02:54:30.112992   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000587816 (* 1 = 0.000587816 loss)
I0621 02:54:30.113015   388 solver.cpp:473] Iteration 534, lr = 0.01
I0621 02:54:42.484447   388 solver.cpp:213] Iteration 535, loss = 0.000586004
I0621 02:54:42.484634   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000585747 (* 1 = 0.000585747 loss)
I0621 02:54:42.484659   388 solver.cpp:473] Iteration 535, lr = 0.01
I0621 02:54:54.799551   388 solver.cpp:213] Iteration 536, loss = 0.000585598
I0621 02:54:54.799636   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000585848 (* 1 = 0.000585848 loss)
I0621 02:54:54.799659   388 solver.cpp:473] Iteration 536, lr = 0.01
I0621 02:55:07.021553   388 solver.cpp:213] Iteration 537, loss = 0.000584542
I0621 02:55:07.021639   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000585029 (* 1 = 0.000585029 loss)
I0621 02:55:07.021661   388 solver.cpp:473] Iteration 537, lr = 0.01
I0621 02:55:19.275025   388 solver.cpp:213] Iteration 538, loss = 0.000583905
I0621 02:55:19.275218   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000583479 (* 1 = 0.000583479 loss)
I0621 02:55:19.275241   388 solver.cpp:473] Iteration 538, lr = 0.01
I0621 02:55:31.496090   388 solver.cpp:213] Iteration 539, loss = 0.00058346
I0621 02:55:31.496173   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0005839 (* 1 = 0.0005839 loss)
I0621 02:55:31.496194   388 solver.cpp:473] Iteration 539, lr = 0.01
I0621 02:55:43.712620   388 solver.cpp:213] Iteration 540, loss = 0.000582746
I0621 02:55:43.712705   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000583538 (* 1 = 0.000583538 loss)
I0621 02:55:43.712728   388 solver.cpp:473] Iteration 540, lr = 0.01
I0621 02:55:56.007264   388 solver.cpp:213] Iteration 541, loss = 0.000581271
I0621 02:55:56.007469   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000580869 (* 1 = 0.000580869 loss)
I0621 02:55:56.007503   388 solver.cpp:473] Iteration 541, lr = 0.01
I0621 02:56:08.401127   388 solver.cpp:213] Iteration 542, loss = 0.000580871
I0621 02:56:08.401211   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0005813 (* 1 = 0.0005813 loss)
I0621 02:56:08.401237   388 solver.cpp:473] Iteration 542, lr = 0.01
I0621 02:56:20.905892   388 solver.cpp:213] Iteration 543, loss = 0.000580188
I0621 02:56:20.905978   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000580634 (* 1 = 0.000580634 loss)
I0621 02:56:20.906000   388 solver.cpp:473] Iteration 543, lr = 0.01
I0621 02:56:33.276656   388 solver.cpp:213] Iteration 544, loss = 0.000579444
I0621 02:56:33.276870   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000579434 (* 1 = 0.000579434 loss)
I0621 02:56:33.276896   388 solver.cpp:473] Iteration 544, lr = 0.01
I0621 02:56:45.562206   388 solver.cpp:213] Iteration 545, loss = 0.000578878
I0621 02:56:45.562290   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00057873 (* 1 = 0.00057873 loss)
I0621 02:56:45.562312   388 solver.cpp:473] Iteration 545, lr = 0.01
I0621 02:56:57.818286   388 solver.cpp:213] Iteration 546, loss = 0.000577939
I0621 02:56:57.818367   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000578416 (* 1 = 0.000578416 loss)
I0621 02:56:57.818390   388 solver.cpp:473] Iteration 546, lr = 0.01
I0621 02:57:10.041474   388 solver.cpp:213] Iteration 547, loss = 0.000577119
I0621 02:57:10.045946   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000577861 (* 1 = 0.000577861 loss)
I0621 02:57:10.045971   388 solver.cpp:473] Iteration 547, lr = 0.01
I0621 02:57:22.260022   388 solver.cpp:213] Iteration 548, loss = 0.000576366
I0621 02:57:22.260105   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00057606 (* 1 = 0.00057606 loss)
I0621 02:57:22.260128   388 solver.cpp:473] Iteration 548, lr = 0.01
I0621 02:57:34.489934   388 solver.cpp:213] Iteration 549, loss = 0.000575479
I0621 02:57:34.490011   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000576076 (* 1 = 0.000576076 loss)
I0621 02:57:34.490033   388 solver.cpp:473] Iteration 549, lr = 0.01
I0621 02:57:46.731993   388 solver.cpp:213] Iteration 550, loss = 0.000575108
I0621 02:57:46.732738   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000574998 (* 1 = 0.000574998 loss)
I0621 02:57:46.732782   388 solver.cpp:473] Iteration 550, lr = 0.01
I0621 02:57:59.050508   388 solver.cpp:213] Iteration 551, loss = 0.000574161
I0621 02:57:59.050591   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000574562 (* 1 = 0.000574562 loss)
I0621 02:57:59.050614   388 solver.cpp:473] Iteration 551, lr = 0.01
I0621 02:58:11.324283   388 solver.cpp:213] Iteration 552, loss = 0.000573477
I0621 02:58:11.324367   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000573414 (* 1 = 0.000573414 loss)
I0621 02:58:11.324388   388 solver.cpp:473] Iteration 552, lr = 0.01
I0621 02:58:23.628335   388 solver.cpp:213] Iteration 553, loss = 0.000572495
I0621 02:58:23.628545   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000571672 (* 1 = 0.000571672 loss)
I0621 02:58:23.628572   388 solver.cpp:473] Iteration 553, lr = 0.01
I0621 02:58:35.998599   388 solver.cpp:213] Iteration 554, loss = 0.000571846
I0621 02:58:35.998692   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000571883 (* 1 = 0.000571883 loss)
I0621 02:58:35.998718   388 solver.cpp:473] Iteration 554, lr = 0.01
I0621 02:58:48.319684   388 solver.cpp:213] Iteration 555, loss = 0.000571162
I0621 02:58:48.319767   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000570253 (* 1 = 0.000570253 loss)
I0621 02:58:48.319789   388 solver.cpp:473] Iteration 555, lr = 0.01
I0621 02:59:00.543406   388 solver.cpp:213] Iteration 556, loss = 0.000570154
I0621 02:59:00.543619   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000569865 (* 1 = 0.000569865 loss)
I0621 02:59:00.543648   388 solver.cpp:473] Iteration 556, lr = 0.01
I0621 02:59:13.006644   388 solver.cpp:213] Iteration 557, loss = 0.000569718
I0621 02:59:13.006731   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000569681 (* 1 = 0.000569681 loss)
I0621 02:59:13.006754   388 solver.cpp:473] Iteration 557, lr = 0.01
I0621 02:59:25.318162   388 solver.cpp:213] Iteration 558, loss = 0.00056892
I0621 02:59:25.318249   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000568875 (* 1 = 0.000568875 loss)
I0621 02:59:25.318272   388 solver.cpp:473] Iteration 558, lr = 0.01
I0621 02:59:37.626467   388 solver.cpp:213] Iteration 559, loss = 0.000568138
I0621 02:59:37.627161   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000568023 (* 1 = 0.000568023 loss)
I0621 02:59:37.627187   388 solver.cpp:473] Iteration 559, lr = 0.01
I0621 02:59:50.001078   388 solver.cpp:213] Iteration 560, loss = 0.000567549
I0621 02:59:50.001164   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000567649 (* 1 = 0.000567649 loss)
I0621 02:59:50.001188   388 solver.cpp:473] Iteration 560, lr = 0.01
I0621 03:00:02.205374   388 solver.cpp:213] Iteration 561, loss = 0.000566783
I0621 03:00:02.205454   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000566579 (* 1 = 0.000566579 loss)
I0621 03:00:02.205476   388 solver.cpp:473] Iteration 561, lr = 0.01
I0621 03:00:14.440655   388 solver.cpp:213] Iteration 562, loss = 0.000566223
I0621 03:00:14.440899   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000565976 (* 1 = 0.000565976 loss)
I0621 03:00:14.440958   388 solver.cpp:473] Iteration 562, lr = 0.01
I0621 03:00:26.726804   388 solver.cpp:213] Iteration 563, loss = 0.000565322
I0621 03:00:26.726889   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000565903 (* 1 = 0.000565903 loss)
I0621 03:00:26.726912   388 solver.cpp:473] Iteration 563, lr = 0.01
I0621 03:00:38.985939   388 solver.cpp:213] Iteration 564, loss = 0.000564429
I0621 03:00:38.986027   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000564821 (* 1 = 0.000564821 loss)
I0621 03:00:38.986049   388 solver.cpp:473] Iteration 564, lr = 0.01
I0621 03:00:51.340318   388 solver.cpp:213] Iteration 565, loss = 0.000564057
I0621 03:00:51.340569   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000563994 (* 1 = 0.000563994 loss)
I0621 03:00:51.340616   388 solver.cpp:473] Iteration 565, lr = 0.01
I0621 03:01:03.612716   388 solver.cpp:213] Iteration 566, loss = 0.000563066
I0621 03:01:03.612823   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000562049 (* 1 = 0.000562049 loss)
I0621 03:01:03.612846   388 solver.cpp:473] Iteration 566, lr = 0.01
I0621 03:01:15.916678   388 solver.cpp:213] Iteration 567, loss = 0.000562513
I0621 03:01:15.916764   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000562452 (* 1 = 0.000562452 loss)
I0621 03:01:15.916785   388 solver.cpp:473] Iteration 567, lr = 0.01
I0621 03:01:28.306766   388 solver.cpp:213] Iteration 568, loss = 0.000561731
I0621 03:01:28.306969   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000562067 (* 1 = 0.000562067 loss)
I0621 03:01:28.306993   388 solver.cpp:473] Iteration 568, lr = 0.01
I0621 03:01:40.575032   388 solver.cpp:213] Iteration 569, loss = 0.000560952
I0621 03:01:40.575129   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000559759 (* 1 = 0.000559759 loss)
I0621 03:01:40.575152   388 solver.cpp:473] Iteration 569, lr = 0.01
I0621 03:01:52.794745   388 solver.cpp:213] Iteration 570, loss = 0.000560448
I0621 03:01:52.794827   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000560409 (* 1 = 0.000560409 loss)
I0621 03:01:52.794849   388 solver.cpp:473] Iteration 570, lr = 0.01
I0621 03:02:05.038239   388 solver.cpp:213] Iteration 571, loss = 0.000559703
I0621 03:02:05.038458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000558962 (* 1 = 0.000558962 loss)
I0621 03:02:05.038504   388 solver.cpp:473] Iteration 571, lr = 0.01
I0621 03:02:17.283478   388 solver.cpp:213] Iteration 572, loss = 0.000559048
I0621 03:02:17.283561   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000558439 (* 1 = 0.000558439 loss)
I0621 03:02:17.283584   388 solver.cpp:473] Iteration 572, lr = 0.01
I0621 03:02:29.557895   388 solver.cpp:213] Iteration 573, loss = 0.000558379
I0621 03:02:29.557979   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000558005 (* 1 = 0.000558005 loss)
I0621 03:02:29.558001   388 solver.cpp:473] Iteration 573, lr = 0.01
I0621 03:02:41.824542   388 solver.cpp:213] Iteration 574, loss = 0.00055782
I0621 03:02:41.831135   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000556587 (* 1 = 0.000556587 loss)
I0621 03:02:41.831162   388 solver.cpp:473] Iteration 574, lr = 0.01
I0621 03:02:54.076839   388 solver.cpp:213] Iteration 575, loss = 0.000556659
I0621 03:02:54.076920   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000556799 (* 1 = 0.000556799 loss)
I0621 03:02:54.076943   388 solver.cpp:473] Iteration 575, lr = 0.01
I0621 03:03:06.280877   388 solver.cpp:213] Iteration 576, loss = 0.00055615
I0621 03:03:06.280966   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000556973 (* 1 = 0.000556973 loss)
I0621 03:03:06.280987   388 solver.cpp:473] Iteration 576, lr = 0.01
I0621 03:03:18.495543   388 solver.cpp:213] Iteration 577, loss = 0.000555276
I0621 03:03:18.495798   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000554951 (* 1 = 0.000554951 loss)
I0621 03:03:18.495858   388 solver.cpp:473] Iteration 577, lr = 0.01
I0621 03:03:30.955988   388 solver.cpp:213] Iteration 578, loss = 0.000554612
I0621 03:03:30.956074   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000554944 (* 1 = 0.000554944 loss)
I0621 03:03:30.956095   388 solver.cpp:473] Iteration 578, lr = 0.01
I0621 03:03:43.364159   388 solver.cpp:213] Iteration 579, loss = 0.000554181
I0621 03:03:43.364245   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000554004 (* 1 = 0.000554004 loss)
I0621 03:03:43.364269   388 solver.cpp:473] Iteration 579, lr = 0.01
I0621 03:03:55.668208   388 solver.cpp:213] Iteration 580, loss = 0.000553368
I0621 03:03:55.668447   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000553349 (* 1 = 0.000553349 loss)
I0621 03:03:55.668511   388 solver.cpp:473] Iteration 580, lr = 0.01
I0621 03:04:08.057306   388 solver.cpp:213] Iteration 581, loss = 0.00055288
I0621 03:04:08.057389   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000553217 (* 1 = 0.000553217 loss)
I0621 03:04:08.057410   388 solver.cpp:473] Iteration 581, lr = 0.01
I0621 03:04:20.383992   388 solver.cpp:213] Iteration 582, loss = 0.000552116
I0621 03:04:20.384074   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000551274 (* 1 = 0.000551274 loss)
I0621 03:04:20.384096   388 solver.cpp:473] Iteration 582, lr = 0.01
I0621 03:04:32.613013   388 solver.cpp:213] Iteration 583, loss = 0.000551461
I0621 03:04:32.613199   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000552277 (* 1 = 0.000552277 loss)
I0621 03:04:32.613224   388 solver.cpp:473] Iteration 583, lr = 0.01
I0621 03:04:44.834075   388 solver.cpp:213] Iteration 584, loss = 0.00055087
I0621 03:04:44.834159   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000551327 (* 1 = 0.000551327 loss)
I0621 03:04:44.834182   388 solver.cpp:473] Iteration 584, lr = 0.01
I0621 03:04:57.049702   388 solver.cpp:213] Iteration 585, loss = 0.000549834
I0621 03:04:57.049777   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000548174 (* 1 = 0.000548174 loss)
I0621 03:04:57.049799   388 solver.cpp:473] Iteration 585, lr = 0.01
I0621 03:05:09.267027   388 solver.cpp:213] Iteration 586, loss = 0.000549203
I0621 03:05:09.267283   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000550585 (* 1 = 0.000550585 loss)
I0621 03:05:09.267308   388 solver.cpp:473] Iteration 586, lr = 0.01
I0621 03:05:21.466673   388 solver.cpp:213] Iteration 587, loss = 0.0005486
I0621 03:05:21.466747   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000549 (* 1 = 0.000549 loss)
I0621 03:05:21.466768   388 solver.cpp:473] Iteration 587, lr = 0.01
I0621 03:05:33.672402   388 solver.cpp:213] Iteration 588, loss = 0.000547947
I0621 03:05:33.672485   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000547783 (* 1 = 0.000547783 loss)
I0621 03:05:33.672508   388 solver.cpp:473] Iteration 588, lr = 0.01
I0621 03:05:45.890873   388 solver.cpp:213] Iteration 589, loss = 0.00054742
I0621 03:05:45.891080   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000545777 (* 1 = 0.000545777 loss)
I0621 03:05:45.891106   388 solver.cpp:473] Iteration 589, lr = 0.01
I0621 03:05:58.103648   388 solver.cpp:213] Iteration 590, loss = 0.00054669
I0621 03:05:58.103726   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000547434 (* 1 = 0.000547434 loss)
I0621 03:05:58.103749   388 solver.cpp:473] Iteration 590, lr = 0.01
I0621 03:06:10.341208   388 solver.cpp:213] Iteration 591, loss = 0.000546017
I0621 03:06:10.341295   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000546438 (* 1 = 0.000546438 loss)
I0621 03:06:10.341316   388 solver.cpp:473] Iteration 591, lr = 0.01
I0621 03:06:22.575788   388 solver.cpp:213] Iteration 592, loss = 0.000545324
I0621 03:06:22.576007   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000545168 (* 1 = 0.000545168 loss)
I0621 03:06:22.576033   388 solver.cpp:473] Iteration 592, lr = 0.01
I0621 03:06:34.975878   388 solver.cpp:213] Iteration 593, loss = 0.000544771
I0621 03:06:34.975965   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000544319 (* 1 = 0.000544319 loss)
I0621 03:06:34.975987   388 solver.cpp:473] Iteration 593, lr = 0.01
I0621 03:06:47.278435   388 solver.cpp:213] Iteration 594, loss = 0.000543875
I0621 03:06:47.278520   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000543631 (* 1 = 0.000543631 loss)
I0621 03:06:47.278542   388 solver.cpp:473] Iteration 594, lr = 0.01
I0621 03:06:59.590139   388 solver.cpp:213] Iteration 595, loss = 0.000543563
I0621 03:06:59.590328   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000544168 (* 1 = 0.000544168 loss)
I0621 03:06:59.590351   388 solver.cpp:473] Iteration 595, lr = 0.01
I0621 03:07:11.909653   388 solver.cpp:213] Iteration 596, loss = 0.00054275
I0621 03:07:11.909754   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000542832 (* 1 = 0.000542832 loss)
I0621 03:07:11.909785   388 solver.cpp:473] Iteration 596, lr = 0.01
I0621 03:07:24.347609   388 solver.cpp:213] Iteration 597, loss = 0.000541655
I0621 03:07:24.347697   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000542452 (* 1 = 0.000542452 loss)
I0621 03:07:24.347721   388 solver.cpp:473] Iteration 597, lr = 0.01
I0621 03:07:36.688827   388 solver.cpp:213] Iteration 598, loss = 0.000541115
I0621 03:07:36.688999   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000541602 (* 1 = 0.000541602 loss)
I0621 03:07:36.689023   388 solver.cpp:473] Iteration 598, lr = 0.01
I0621 03:07:48.929646   388 solver.cpp:213] Iteration 599, loss = 0.000540502
I0621 03:07:48.929726   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000539511 (* 1 = 0.000539511 loss)
I0621 03:07:48.929749   388 solver.cpp:473] Iteration 599, lr = 0.01
I0621 03:08:01.157140   388 solver.cpp:213] Iteration 600, loss = 0.000539831
I0621 03:08:01.157215   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000539358 (* 1 = 0.000539358 loss)
I0621 03:08:01.157238   388 solver.cpp:473] Iteration 600, lr = 0.01
I0621 03:08:13.456356   388 solver.cpp:213] Iteration 601, loss = 0.000539166
I0621 03:08:13.456607   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000539566 (* 1 = 0.000539566 loss)
I0621 03:08:13.456666   388 solver.cpp:473] Iteration 601, lr = 0.01
I0621 03:08:25.865784   388 solver.cpp:213] Iteration 602, loss = 0.000538793
I0621 03:08:25.865869   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000537735 (* 1 = 0.000537735 loss)
I0621 03:08:25.865890   388 solver.cpp:473] Iteration 602, lr = 0.01
I0621 03:08:38.162451   388 solver.cpp:213] Iteration 603, loss = 0.000537858
I0621 03:08:38.162531   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000536977 (* 1 = 0.000536977 loss)
I0621 03:08:38.162552   388 solver.cpp:473] Iteration 603, lr = 0.01
I0621 03:08:50.424579   388 solver.cpp:213] Iteration 604, loss = 0.000537484
I0621 03:08:50.424839   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000537842 (* 1 = 0.000537842 loss)
I0621 03:08:50.424885   388 solver.cpp:473] Iteration 604, lr = 0.01
I0621 03:09:02.789366   388 solver.cpp:213] Iteration 605, loss = 0.000537004
I0621 03:09:02.789451   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000536459 (* 1 = 0.000536459 loss)
I0621 03:09:02.789476   388 solver.cpp:473] Iteration 605, lr = 0.01
I0621 03:09:15.169093   388 solver.cpp:213] Iteration 606, loss = 0.000536146
I0621 03:09:15.169178   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000536754 (* 1 = 0.000536754 loss)
I0621 03:09:15.169200   388 solver.cpp:473] Iteration 606, lr = 0.01
I0621 03:09:27.457811   388 solver.cpp:213] Iteration 607, loss = 0.00053539
I0621 03:09:27.458175   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00053588 (* 1 = 0.00053588 loss)
I0621 03:09:27.458199   388 solver.cpp:473] Iteration 607, lr = 0.01
I0621 03:09:39.707051   388 solver.cpp:213] Iteration 608, loss = 0.000534849
I0621 03:09:39.707136   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000535631 (* 1 = 0.000535631 loss)
I0621 03:09:39.707159   388 solver.cpp:473] Iteration 608, lr = 0.01
I0621 03:09:51.953856   388 solver.cpp:213] Iteration 609, loss = 0.000534365
I0621 03:09:51.953936   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000534293 (* 1 = 0.000534293 loss)
I0621 03:09:51.953958   388 solver.cpp:473] Iteration 609, lr = 0.01
I0621 03:10:04.206260   388 solver.cpp:213] Iteration 610, loss = 0.00053316
I0621 03:10:04.206456   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000533012 (* 1 = 0.000533012 loss)
I0621 03:10:04.206480   388 solver.cpp:473] Iteration 610, lr = 0.01
I0621 03:10:16.511188   388 solver.cpp:213] Iteration 611, loss = 0.00053289
I0621 03:10:16.511273   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000533323 (* 1 = 0.000533323 loss)
I0621 03:10:16.511296   388 solver.cpp:473] Iteration 611, lr = 0.01
I0621 03:10:28.752857   388 solver.cpp:213] Iteration 612, loss = 0.000532399
I0621 03:10:28.752941   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000531788 (* 1 = 0.000531788 loss)
I0621 03:10:28.752964   388 solver.cpp:473] Iteration 612, lr = 0.01
I0621 03:10:41.017527   388 solver.cpp:213] Iteration 613, loss = 0.000531365
I0621 03:10:41.017787   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000532262 (* 1 = 0.000532262 loss)
I0621 03:10:41.017850   388 solver.cpp:473] Iteration 613, lr = 0.01
I0621 03:10:53.338155   388 solver.cpp:213] Iteration 614, loss = 0.000530993
I0621 03:10:53.338235   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000531612 (* 1 = 0.000531612 loss)
I0621 03:10:53.338258   388 solver.cpp:473] Iteration 614, lr = 0.01
I0621 03:11:05.663468   388 solver.cpp:213] Iteration 615, loss = 0.000530422
I0621 03:11:05.663552   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000530675 (* 1 = 0.000530675 loss)
I0621 03:11:05.663573   388 solver.cpp:473] Iteration 615, lr = 0.01
I0621 03:11:18.006342   388 solver.cpp:213] Iteration 616, loss = 0.000529728
I0621 03:11:18.006566   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000530273 (* 1 = 0.000530273 loss)
I0621 03:11:18.006600   388 solver.cpp:473] Iteration 616, lr = 0.01
I0621 03:11:30.272414   388 solver.cpp:213] Iteration 617, loss = 0.000528992
I0621 03:11:30.272498   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000528672 (* 1 = 0.000528672 loss)
I0621 03:11:30.272521   388 solver.cpp:473] Iteration 617, lr = 0.01
I0621 03:11:42.514267   388 solver.cpp:213] Iteration 618, loss = 0.000528575
I0621 03:11:42.514349   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00052849 (* 1 = 0.00052849 loss)
I0621 03:11:42.514371   388 solver.cpp:473] Iteration 618, lr = 0.01
I0621 03:11:54.735782   388 solver.cpp:213] Iteration 619, loss = 0.00052796
I0621 03:11:54.735985   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000528506 (* 1 = 0.000528506 loss)
I0621 03:11:54.736018   388 solver.cpp:473] Iteration 619, lr = 0.01
I0621 03:12:07.055528   388 solver.cpp:213] Iteration 620, loss = 0.000527216
I0621 03:12:07.055614   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000527486 (* 1 = 0.000527486 loss)
I0621 03:12:07.055636   388 solver.cpp:473] Iteration 620, lr = 0.01
I0621 03:12:19.309716   388 solver.cpp:213] Iteration 621, loss = 0.000526756
I0621 03:12:19.309799   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000526876 (* 1 = 0.000526876 loss)
I0621 03:12:19.309821   388 solver.cpp:473] Iteration 621, lr = 0.01
I0621 03:12:31.532605   388 solver.cpp:213] Iteration 622, loss = 0.000526097
I0621 03:12:31.532774   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000526481 (* 1 = 0.000526481 loss)
I0621 03:12:31.532799   388 solver.cpp:473] Iteration 622, lr = 0.01
I0621 03:12:43.749964   388 solver.cpp:213] Iteration 623, loss = 0.000525392
I0621 03:12:43.750048   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000524852 (* 1 = 0.000524852 loss)
I0621 03:12:43.750071   388 solver.cpp:473] Iteration 623, lr = 0.01
I0621 03:12:55.979648   388 solver.cpp:213] Iteration 624, loss = 0.000524718
I0621 03:12:55.979743   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000525022 (* 1 = 0.000525022 loss)
I0621 03:12:55.979768   388 solver.cpp:473] Iteration 624, lr = 0.01
I0621 03:13:08.191644   388 solver.cpp:213] Iteration 625, loss = 0.000524243
I0621 03:13:08.194021   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000523952 (* 1 = 0.000523952 loss)
I0621 03:13:08.194049   388 solver.cpp:473] Iteration 625, lr = 0.01
I0621 03:13:20.393764   388 solver.cpp:213] Iteration 626, loss = 0.000523476
I0621 03:13:20.393848   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000523658 (* 1 = 0.000523658 loss)
I0621 03:13:20.393869   388 solver.cpp:473] Iteration 626, lr = 0.01
I0621 03:13:32.584992   388 solver.cpp:213] Iteration 627, loss = 0.000522988
I0621 03:13:32.585067   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000522908 (* 1 = 0.000522908 loss)
I0621 03:13:32.585086   388 solver.cpp:473] Iteration 627, lr = 0.01
I0621 03:13:44.970772   388 solver.cpp:213] Iteration 628, loss = 0.000522521
I0621 03:13:44.970995   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000523361 (* 1 = 0.000523361 loss)
I0621 03:13:44.971042   388 solver.cpp:473] Iteration 628, lr = 0.01
I0621 03:13:57.311820   388 solver.cpp:213] Iteration 629, loss = 0.000521596
I0621 03:13:57.311905   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000521907 (* 1 = 0.000521907 loss)
I0621 03:13:57.311928   388 solver.cpp:473] Iteration 629, lr = 0.01
I0621 03:14:09.748527   388 solver.cpp:213] Iteration 630, loss = 0.000521329
I0621 03:14:09.748610   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000521216 (* 1 = 0.000521216 loss)
I0621 03:14:09.748632   388 solver.cpp:473] Iteration 630, lr = 0.01
I0621 03:14:22.116490   388 solver.cpp:213] Iteration 631, loss = 0.000520519
I0621 03:14:22.116684   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000520969 (* 1 = 0.000520969 loss)
I0621 03:14:22.116709   388 solver.cpp:473] Iteration 631, lr = 0.01
I0621 03:14:34.396553   388 solver.cpp:213] Iteration 632, loss = 0.000519872
I0621 03:14:34.396633   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00051948 (* 1 = 0.00051948 loss)
I0621 03:14:34.396656   388 solver.cpp:473] Iteration 632, lr = 0.01
I0621 03:14:46.809483   388 solver.cpp:213] Iteration 633, loss = 0.000519076
I0621 03:14:46.809563   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000519901 (* 1 = 0.000519901 loss)
I0621 03:14:46.809587   388 solver.cpp:473] Iteration 633, lr = 0.01
I0621 03:14:59.138350   388 solver.cpp:213] Iteration 634, loss = 0.000518474
I0621 03:14:59.138608   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000518606 (* 1 = 0.000518606 loss)
I0621 03:14:59.138640   388 solver.cpp:473] Iteration 634, lr = 0.01
I0621 03:15:11.431857   388 solver.cpp:213] Iteration 635, loss = 0.000518014
I0621 03:15:11.431943   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000518537 (* 1 = 0.000518537 loss)
I0621 03:15:11.431967   388 solver.cpp:473] Iteration 635, lr = 0.01
I0621 03:15:23.659243   388 solver.cpp:213] Iteration 636, loss = 0.000517351
I0621 03:15:23.659325   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000517655 (* 1 = 0.000517655 loss)
I0621 03:15:23.659348   388 solver.cpp:473] Iteration 636, lr = 0.01
I0621 03:15:36.031813   388 solver.cpp:213] Iteration 637, loss = 0.000517073
I0621 03:15:36.031997   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000517193 (* 1 = 0.000517193 loss)
I0621 03:15:36.032023   388 solver.cpp:473] Iteration 637, lr = 0.01
I0621 03:15:48.379465   388 solver.cpp:213] Iteration 638, loss = 0.00051642
I0621 03:15:48.379551   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000516329 (* 1 = 0.000516329 loss)
I0621 03:15:48.379572   388 solver.cpp:473] Iteration 638, lr = 0.01
I0621 03:16:00.740650   388 solver.cpp:213] Iteration 639, loss = 0.000515899
I0621 03:16:00.740727   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000517101 (* 1 = 0.000517101 loss)
I0621 03:16:00.740751   388 solver.cpp:473] Iteration 639, lr = 0.01
I0621 03:16:13.019878   388 solver.cpp:213] Iteration 640, loss = 0.000515143
I0621 03:16:13.020133   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000515905 (* 1 = 0.000515905 loss)
I0621 03:16:13.020179   388 solver.cpp:473] Iteration 640, lr = 0.01
I0621 03:16:25.433881   388 solver.cpp:213] Iteration 641, loss = 0.000514497
I0621 03:16:25.433967   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000514836 (* 1 = 0.000514836 loss)
I0621 03:16:25.433990   388 solver.cpp:473] Iteration 641, lr = 0.01
I0621 03:16:37.740699   388 solver.cpp:213] Iteration 642, loss = 0.00051405
I0621 03:16:37.740787   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000513988 (* 1 = 0.000513988 loss)
I0621 03:16:37.740809   388 solver.cpp:473] Iteration 642, lr = 0.01
I0621 03:16:50.097396   388 solver.cpp:213] Iteration 643, loss = 0.00051352
I0621 03:16:50.097657   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000513142 (* 1 = 0.000513142 loss)
I0621 03:16:50.097718   388 solver.cpp:473] Iteration 643, lr = 0.01
I0621 03:17:02.404438   388 solver.cpp:213] Iteration 644, loss = 0.000512829
I0621 03:17:02.408690   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000512477 (* 1 = 0.000512477 loss)
I0621 03:17:02.408776   388 solver.cpp:473] Iteration 644, lr = 0.01
I0621 03:17:14.797994   388 solver.cpp:213] Iteration 645, loss = 0.000511994
I0621 03:17:14.798089   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000511788 (* 1 = 0.000511788 loss)
I0621 03:17:14.798112   388 solver.cpp:473] Iteration 645, lr = 0.01
I0621 03:17:27.088596   388 solver.cpp:213] Iteration 646, loss = 0.000511626
I0621 03:17:27.088784   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000511895 (* 1 = 0.000511895 loss)
I0621 03:17:27.088809   388 solver.cpp:473] Iteration 646, lr = 0.01
I0621 03:17:39.487499   388 solver.cpp:213] Iteration 647, loss = 0.000511107
I0621 03:17:39.487584   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000511022 (* 1 = 0.000511022 loss)
I0621 03:17:39.487607   388 solver.cpp:473] Iteration 647, lr = 0.01
I0621 03:17:51.869650   388 solver.cpp:213] Iteration 648, loss = 0.000510323
I0621 03:17:51.869735   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00051075 (* 1 = 0.00051075 loss)
I0621 03:17:51.869757   388 solver.cpp:473] Iteration 648, lr = 0.01
I0621 03:18:04.218240   388 solver.cpp:213] Iteration 649, loss = 0.000509825
I0621 03:18:04.218425   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000509934 (* 1 = 0.000509934 loss)
I0621 03:18:04.218451   388 solver.cpp:473] Iteration 649, lr = 0.01
I0621 03:18:16.526525   388 solver.cpp:213] Iteration 650, loss = 0.000509182
I0621 03:18:16.526609   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000508673 (* 1 = 0.000508673 loss)
I0621 03:18:16.526631   388 solver.cpp:473] Iteration 650, lr = 0.01
I0621 03:18:28.903262   388 solver.cpp:213] Iteration 651, loss = 0.000508638
I0621 03:18:28.903343   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000508621 (* 1 = 0.000508621 loss)
I0621 03:18:28.903367   388 solver.cpp:473] Iteration 651, lr = 0.01
I0621 03:18:41.185379   388 solver.cpp:213] Iteration 652, loss = 0.000507874
I0621 03:18:41.185607   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000507873 (* 1 = 0.000507873 loss)
I0621 03:18:41.185653   388 solver.cpp:473] Iteration 652, lr = 0.01
I0621 03:18:53.574650   388 solver.cpp:213] Iteration 653, loss = 0.000507562
I0621 03:18:53.574729   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000507527 (* 1 = 0.000507527 loss)
I0621 03:18:53.574753   388 solver.cpp:473] Iteration 653, lr = 0.01
I0621 03:19:05.896466   388 solver.cpp:213] Iteration 654, loss = 0.000506724
I0621 03:19:05.896550   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000506781 (* 1 = 0.000506781 loss)
I0621 03:19:05.896572   388 solver.cpp:473] Iteration 654, lr = 0.01
I0621 03:19:18.163372   388 solver.cpp:213] Iteration 655, loss = 0.000506384
I0621 03:19:18.163559   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000506321 (* 1 = 0.000506321 loss)
I0621 03:19:18.163586   388 solver.cpp:473] Iteration 655, lr = 0.01
I0621 03:19:30.478574   388 solver.cpp:213] Iteration 656, loss = 0.000505843
I0621 03:19:30.478659   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000506336 (* 1 = 0.000506336 loss)
I0621 03:19:30.478682   388 solver.cpp:473] Iteration 656, lr = 0.01
I0621 03:19:42.742533   388 solver.cpp:213] Iteration 657, loss = 0.000505197
I0621 03:19:42.742612   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000505425 (* 1 = 0.000505425 loss)
I0621 03:19:42.742635   388 solver.cpp:473] Iteration 657, lr = 0.01
I0621 03:19:54.993698   388 solver.cpp:213] Iteration 658, loss = 0.000504686
I0621 03:19:54.993891   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000504681 (* 1 = 0.000504681 loss)
I0621 03:19:54.993916   388 solver.cpp:473] Iteration 658, lr = 0.01
I0621 03:20:07.214094   388 solver.cpp:213] Iteration 659, loss = 0.000504096
I0621 03:20:07.214179   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000504251 (* 1 = 0.000504251 loss)
I0621 03:20:07.214200   388 solver.cpp:473] Iteration 659, lr = 0.01
I0621 03:20:19.418117   388 solver.cpp:213] Iteration 660, loss = 0.000503485
I0621 03:20:19.418202   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000504178 (* 1 = 0.000504178 loss)
I0621 03:20:19.418226   388 solver.cpp:473] Iteration 660, lr = 0.01
I0621 03:20:31.658069   388 solver.cpp:213] Iteration 661, loss = 0.000502797
I0621 03:20:31.663131   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000502861 (* 1 = 0.000502861 loss)
I0621 03:20:31.663156   388 solver.cpp:473] Iteration 661, lr = 0.01
I0621 03:20:43.882989   388 solver.cpp:213] Iteration 662, loss = 0.000502844
I0621 03:20:43.883080   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000503023 (* 1 = 0.000503023 loss)
I0621 03:20:43.883103   388 solver.cpp:473] Iteration 662, lr = 0.01
I0621 03:20:56.245973   388 solver.cpp:213] Iteration 663, loss = 0.000501962
I0621 03:20:56.246062   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000501709 (* 1 = 0.000501709 loss)
I0621 03:20:56.246085   388 solver.cpp:473] Iteration 663, lr = 0.01
I0621 03:21:08.521661   388 solver.cpp:213] Iteration 664, loss = 0.000501398
I0621 03:21:08.521845   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000501343 (* 1 = 0.000501343 loss)
I0621 03:21:08.521870   388 solver.cpp:473] Iteration 664, lr = 0.01
I0621 03:21:20.850787   388 solver.cpp:213] Iteration 665, loss = 0.000501003
I0621 03:21:20.850870   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000501289 (* 1 = 0.000501289 loss)
I0621 03:21:20.850893   388 solver.cpp:473] Iteration 665, lr = 0.01
I0621 03:21:33.186645   388 solver.cpp:213] Iteration 666, loss = 0.000500178
I0621 03:21:33.186725   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000500492 (* 1 = 0.000500492 loss)
I0621 03:21:33.186749   388 solver.cpp:473] Iteration 666, lr = 0.01
I0621 03:21:45.623359   388 solver.cpp:213] Iteration 667, loss = 0.000499775
I0621 03:21:45.623610   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000499062 (* 1 = 0.000499062 loss)
I0621 03:21:45.623657   388 solver.cpp:473] Iteration 667, lr = 0.01
I0621 03:21:57.988817   388 solver.cpp:213] Iteration 668, loss = 0.000499203
I0621 03:21:57.988903   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000499549 (* 1 = 0.000499549 loss)
I0621 03:21:57.988925   388 solver.cpp:473] Iteration 668, lr = 0.01
I0621 03:22:10.244006   388 solver.cpp:213] Iteration 669, loss = 0.000498596
I0621 03:22:10.244089   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000498791 (* 1 = 0.000498791 loss)
I0621 03:22:10.244112   388 solver.cpp:473] Iteration 669, lr = 0.01
I0621 03:22:22.542090   388 solver.cpp:213] Iteration 670, loss = 0.000497878
I0621 03:22:22.547137   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000497043 (* 1 = 0.000497043 loss)
I0621 03:22:22.547163   388 solver.cpp:473] Iteration 670, lr = 0.01
I0621 03:22:34.803784   388 solver.cpp:213] Iteration 671, loss = 0.000497411
I0621 03:22:34.803871   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000498297 (* 1 = 0.000498297 loss)
I0621 03:22:34.803894   388 solver.cpp:473] Iteration 671, lr = 0.01
I0621 03:22:47.022364   388 solver.cpp:213] Iteration 672, loss = 0.000496633
I0621 03:22:47.022454   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000496132 (* 1 = 0.000496132 loss)
I0621 03:22:47.022475   388 solver.cpp:473] Iteration 672, lr = 0.01
I0621 03:22:59.255388   388 solver.cpp:213] Iteration 673, loss = 0.00049621
I0621 03:22:59.255609   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000496259 (* 1 = 0.000496259 loss)
I0621 03:22:59.255640   388 solver.cpp:473] Iteration 673, lr = 0.01
I0621 03:23:11.699161   388 solver.cpp:213] Iteration 674, loss = 0.000495628
I0621 03:23:11.699244   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000494423 (* 1 = 0.000494423 loss)
I0621 03:23:11.699266   388 solver.cpp:473] Iteration 674, lr = 0.01
I0621 03:23:24.075640   388 solver.cpp:213] Iteration 675, loss = 0.00049531
I0621 03:23:24.075722   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000494315 (* 1 = 0.000494315 loss)
I0621 03:23:24.075745   388 solver.cpp:473] Iteration 675, lr = 0.01
I0621 03:23:36.341316   388 solver.cpp:213] Iteration 676, loss = 0.000494565
I0621 03:23:36.349033   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000494428 (* 1 = 0.000494428 loss)
I0621 03:23:36.349089   388 solver.cpp:473] Iteration 676, lr = 0.01
I0621 03:23:48.609194   388 solver.cpp:213] Iteration 677, loss = 0.000494016
I0621 03:23:48.609279   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00049423 (* 1 = 0.00049423 loss)
I0621 03:23:48.609302   388 solver.cpp:473] Iteration 677, lr = 0.01
I0621 03:24:00.997262   388 solver.cpp:213] Iteration 678, loss = 0.000493528
I0621 03:24:00.997349   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000492589 (* 1 = 0.000492589 loss)
I0621 03:24:00.997373   388 solver.cpp:473] Iteration 678, lr = 0.01
I0621 03:24:13.334054   388 solver.cpp:213] Iteration 679, loss = 0.000492856
I0621 03:24:13.334295   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000493731 (* 1 = 0.000493731 loss)
I0621 03:24:13.334333   388 solver.cpp:473] Iteration 679, lr = 0.01
I0621 03:24:25.726987   388 solver.cpp:213] Iteration 680, loss = 0.000492536
I0621 03:24:25.727075   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000492505 (* 1 = 0.000492505 loss)
I0621 03:24:25.727099   388 solver.cpp:473] Iteration 680, lr = 0.01
I0621 03:24:37.995095   388 solver.cpp:213] Iteration 681, loss = 0.000492014
I0621 03:24:37.995178   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000491477 (* 1 = 0.000491477 loss)
I0621 03:24:37.995208   388 solver.cpp:473] Iteration 681, lr = 0.01
I0621 03:24:50.350092   388 solver.cpp:213] Iteration 682, loss = 0.000491547
I0621 03:24:50.350273   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00049212 (* 1 = 0.00049212 loss)
I0621 03:24:50.350297   388 solver.cpp:473] Iteration 682, lr = 0.01
I0621 03:25:02.723342   388 solver.cpp:213] Iteration 683, loss = 0.000491009
I0621 03:25:02.723428   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000490427 (* 1 = 0.000490427 loss)
I0621 03:25:02.723449   388 solver.cpp:473] Iteration 683, lr = 0.01
I0621 03:25:15.143105   388 solver.cpp:213] Iteration 684, loss = 0.000490566
I0621 03:25:15.143187   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000490689 (* 1 = 0.000490689 loss)
I0621 03:25:15.143209   388 solver.cpp:473] Iteration 684, lr = 0.01
I0621 03:25:27.613652   388 solver.cpp:213] Iteration 685, loss = 0.000489626
I0621 03:25:27.613939   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00048891 (* 1 = 0.00048891 loss)
I0621 03:25:27.613976   388 solver.cpp:473] Iteration 685, lr = 0.01
I0621 03:25:40.064437   388 solver.cpp:213] Iteration 686, loss = 0.000489637
I0621 03:25:40.064522   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000490025 (* 1 = 0.000490025 loss)
I0621 03:25:40.064544   388 solver.cpp:473] Iteration 686, lr = 0.01
I0621 03:25:52.306628   388 solver.cpp:213] Iteration 687, loss = 0.00048865
I0621 03:25:52.306711   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000488196 (* 1 = 0.000488196 loss)
I0621 03:25:52.306733   388 solver.cpp:473] Iteration 687, lr = 0.01
I0621 03:26:04.697983   388 solver.cpp:213] Iteration 688, loss = 0.000488182
I0621 03:26:04.698199   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000487779 (* 1 = 0.000487779 loss)
I0621 03:26:04.698220   388 solver.cpp:473] Iteration 688, lr = 0.01
I0621 03:26:17.018889   388 solver.cpp:213] Iteration 689, loss = 0.000487567
I0621 03:26:17.018973   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000487149 (* 1 = 0.000487149 loss)
I0621 03:26:17.018996   388 solver.cpp:473] Iteration 689, lr = 0.01
I0621 03:26:29.287071   388 solver.cpp:213] Iteration 690, loss = 0.000487025
I0621 03:26:29.287158   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000486026 (* 1 = 0.000486026 loss)
I0621 03:26:29.287179   388 solver.cpp:473] Iteration 690, lr = 0.01
I0621 03:26:41.675303   388 solver.cpp:213] Iteration 691, loss = 0.000486556
I0621 03:26:41.675545   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000486411 (* 1 = 0.000486411 loss)
I0621 03:26:41.675607   388 solver.cpp:473] Iteration 691, lr = 0.01
I0621 03:26:54.033097   388 solver.cpp:213] Iteration 692, loss = 0.000485989
I0621 03:26:54.033182   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000486832 (* 1 = 0.000486832 loss)
I0621 03:26:54.033205   388 solver.cpp:473] Iteration 692, lr = 0.01
I0621 03:27:06.251947   388 solver.cpp:213] Iteration 693, loss = 0.000485497
I0621 03:27:06.252037   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000485519 (* 1 = 0.000485519 loss)
I0621 03:27:06.252058   388 solver.cpp:473] Iteration 693, lr = 0.01
I0621 03:27:18.496961   388 solver.cpp:213] Iteration 694, loss = 0.000485219
I0621 03:27:18.497143   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000485172 (* 1 = 0.000485172 loss)
I0621 03:27:18.497169   388 solver.cpp:473] Iteration 694, lr = 0.01
I0621 03:27:30.714279   388 solver.cpp:213] Iteration 695, loss = 0.000484719
I0621 03:27:30.714365   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000484532 (* 1 = 0.000484532 loss)
I0621 03:27:30.714387   388 solver.cpp:473] Iteration 695, lr = 0.01
I0621 03:27:43.023465   388 solver.cpp:213] Iteration 696, loss = 0.000484033
I0621 03:27:43.023555   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000484192 (* 1 = 0.000484192 loss)
I0621 03:27:43.023576   388 solver.cpp:473] Iteration 696, lr = 0.01
I0621 03:27:55.445755   388 solver.cpp:213] Iteration 697, loss = 0.00048357
I0621 03:27:55.445996   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000484039 (* 1 = 0.000484039 loss)
I0621 03:27:55.446043   388 solver.cpp:473] Iteration 697, lr = 0.01
I0621 03:28:07.797593   388 solver.cpp:213] Iteration 698, loss = 0.000483142
I0621 03:28:07.797680   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000483378 (* 1 = 0.000483378 loss)
I0621 03:28:07.797703   388 solver.cpp:473] Iteration 698, lr = 0.01
I0621 03:28:20.116120   388 solver.cpp:213] Iteration 699, loss = 0.000482347
I0621 03:28:20.116204   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000482207 (* 1 = 0.000482207 loss)
I0621 03:28:20.116226   388 solver.cpp:473] Iteration 699, lr = 0.01
I0621 03:28:32.424651   388 solver.cpp:213] Iteration 700, loss = 0.000481923
I0621 03:28:32.424831   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000481943 (* 1 = 0.000481943 loss)
I0621 03:28:32.424856   388 solver.cpp:473] Iteration 700, lr = 0.01
I0621 03:28:44.676116   388 solver.cpp:213] Iteration 701, loss = 0.000481447
I0621 03:28:44.676200   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000481397 (* 1 = 0.000481397 loss)
I0621 03:28:44.676223   388 solver.cpp:473] Iteration 701, lr = 0.01
I0621 03:28:56.916757   388 solver.cpp:213] Iteration 702, loss = 0.000480823
I0621 03:28:56.916839   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000480072 (* 1 = 0.000480072 loss)
I0621 03:28:56.916862   388 solver.cpp:473] Iteration 702, lr = 0.01
I0621 03:29:09.168244   388 solver.cpp:213] Iteration 703, loss = 0.000480397
I0621 03:29:09.168436   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000480553 (* 1 = 0.000480553 loss)
I0621 03:29:09.168462   388 solver.cpp:473] Iteration 703, lr = 0.01
I0621 03:29:21.501204   388 solver.cpp:213] Iteration 704, loss = 0.00047985
I0621 03:29:21.501286   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00048002 (* 1 = 0.00048002 loss)
I0621 03:29:21.501309   388 solver.cpp:473] Iteration 704, lr = 0.01
I0621 03:29:33.858080   388 solver.cpp:213] Iteration 705, loss = 0.000479278
I0621 03:29:33.858165   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000479279 (* 1 = 0.000479279 loss)
I0621 03:29:33.858188   388 solver.cpp:473] Iteration 705, lr = 0.01
I0621 03:29:46.213978   388 solver.cpp:213] Iteration 706, loss = 0.000478981
I0621 03:29:46.214221   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000479127 (* 1 = 0.000479127 loss)
I0621 03:29:46.214267   388 solver.cpp:473] Iteration 706, lr = 0.01
I0621 03:29:58.573541   388 solver.cpp:213] Iteration 707, loss = 0.000478151
I0621 03:29:58.573626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000477425 (* 1 = 0.000477425 loss)
I0621 03:29:58.573649   388 solver.cpp:473] Iteration 707, lr = 0.01
I0621 03:30:10.916394   388 solver.cpp:213] Iteration 708, loss = 0.000477785
I0621 03:30:10.916534   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000478325 (* 1 = 0.000478325 loss)
I0621 03:30:10.916574   388 solver.cpp:473] Iteration 708, lr = 0.01
I0621 03:30:23.219861   388 solver.cpp:213] Iteration 709, loss = 0.000477554
I0621 03:30:23.220041   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000477761 (* 1 = 0.000477761 loss)
I0621 03:30:23.220065   388 solver.cpp:473] Iteration 709, lr = 0.01
I0621 03:30:35.515245   388 solver.cpp:213] Iteration 710, loss = 0.000476872
I0621 03:30:35.515329   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000476934 (* 1 = 0.000476934 loss)
I0621 03:30:35.515350   388 solver.cpp:473] Iteration 710, lr = 0.01
I0621 03:30:47.810355   388 solver.cpp:213] Iteration 711, loss = 0.00047655
I0621 03:30:47.810441   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000476365 (* 1 = 0.000476365 loss)
I0621 03:30:47.810462   388 solver.cpp:473] Iteration 711, lr = 0.01
I0621 03:31:00.206110   388 solver.cpp:213] Iteration 712, loss = 0.000475955
I0621 03:31:00.206320   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000475608 (* 1 = 0.000475608 loss)
I0621 03:31:00.206344   388 solver.cpp:473] Iteration 712, lr = 0.01
I0621 03:31:12.537669   388 solver.cpp:213] Iteration 713, loss = 0.000475266
I0621 03:31:12.537755   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000474933 (* 1 = 0.000474933 loss)
I0621 03:31:12.537778   388 solver.cpp:473] Iteration 713, lr = 0.01
I0621 03:31:24.797502   388 solver.cpp:213] Iteration 714, loss = 0.000474849
I0621 03:31:24.797591   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000475236 (* 1 = 0.000475236 loss)
I0621 03:31:24.797616   388 solver.cpp:473] Iteration 714, lr = 0.01
I0621 03:31:37.215391   388 solver.cpp:213] Iteration 715, loss = 0.000474255
I0621 03:31:37.215629   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000474091 (* 1 = 0.000474091 loss)
I0621 03:31:37.215677   388 solver.cpp:473] Iteration 715, lr = 0.01
I0621 03:31:49.589162   388 solver.cpp:213] Iteration 716, loss = 0.000473766
I0621 03:31:49.589242   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000474092 (* 1 = 0.000474092 loss)
I0621 03:31:49.589267   388 solver.cpp:473] Iteration 716, lr = 0.01
I0621 03:32:01.974797   388 solver.cpp:213] Iteration 717, loss = 0.000473263
I0621 03:32:01.974880   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000472485 (* 1 = 0.000472485 loss)
I0621 03:32:01.974903   388 solver.cpp:473] Iteration 717, lr = 0.01
I0621 03:32:14.327287   388 solver.cpp:213] Iteration 718, loss = 0.000472876
I0621 03:32:14.327558   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000473507 (* 1 = 0.000473507 loss)
I0621 03:32:14.327605   388 solver.cpp:473] Iteration 718, lr = 0.01
I0621 03:32:26.574620   388 solver.cpp:213] Iteration 719, loss = 0.000472126
I0621 03:32:26.574707   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000471931 (* 1 = 0.000471931 loss)
I0621 03:32:26.574738   388 solver.cpp:473] Iteration 719, lr = 0.01
I0621 03:32:38.936604   388 solver.cpp:213] Iteration 720, loss = 0.000471942
I0621 03:32:38.936693   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000472088 (* 1 = 0.000472088 loss)
I0621 03:32:38.936717   388 solver.cpp:473] Iteration 720, lr = 0.01
I0621 03:32:51.457803   388 solver.cpp:213] Iteration 721, loss = 0.000471591
I0621 03:32:51.457998   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000471201 (* 1 = 0.000471201 loss)
I0621 03:32:51.458024   388 solver.cpp:473] Iteration 721, lr = 0.01
I0621 03:33:03.731571   388 solver.cpp:213] Iteration 722, loss = 0.000470821
I0621 03:33:03.731652   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000470113 (* 1 = 0.000470113 loss)
I0621 03:33:03.731673   388 solver.cpp:473] Iteration 722, lr = 0.01
I0621 03:33:15.994643   388 solver.cpp:213] Iteration 723, loss = 0.000470207
I0621 03:33:15.994738   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00046955 (* 1 = 0.00046955 loss)
I0621 03:33:15.994763   388 solver.cpp:473] Iteration 723, lr = 0.01
I0621 03:33:28.463116   388 solver.cpp:213] Iteration 724, loss = 0.000470004
I0621 03:33:28.463323   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000470765 (* 1 = 0.000470765 loss)
I0621 03:33:28.463348   388 solver.cpp:473] Iteration 724, lr = 0.01
I0621 03:33:40.789824   388 solver.cpp:213] Iteration 725, loss = 0.000469555
I0621 03:33:40.789919   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000469929 (* 1 = 0.000469929 loss)
I0621 03:33:40.789944   388 solver.cpp:473] Iteration 725, lr = 0.01
I0621 03:33:53.046917   388 solver.cpp:213] Iteration 726, loss = 0.000468947
I0621 03:33:53.047003   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000468909 (* 1 = 0.000468909 loss)
I0621 03:33:53.047025   388 solver.cpp:473] Iteration 726, lr = 0.01
I0621 03:34:05.393308   388 solver.cpp:213] Iteration 727, loss = 0.00046852
I0621 03:34:05.393494   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000467931 (* 1 = 0.000467931 loss)
I0621 03:34:05.393519   388 solver.cpp:473] Iteration 727, lr = 0.01
I0621 03:34:17.705013   388 solver.cpp:213] Iteration 728, loss = 0.000467971
I0621 03:34:17.705096   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000467958 (* 1 = 0.000467958 loss)
I0621 03:34:17.705118   388 solver.cpp:473] Iteration 728, lr = 0.01
I0621 03:34:29.956327   388 solver.cpp:213] Iteration 729, loss = 0.000467343
I0621 03:34:29.956406   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000467261 (* 1 = 0.000467261 loss)
I0621 03:34:29.956430   388 solver.cpp:473] Iteration 729, lr = 0.01
I0621 03:34:42.332195   388 solver.cpp:213] Iteration 730, loss = 0.000467112
I0621 03:34:42.332465   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000467029 (* 1 = 0.000467029 loss)
I0621 03:34:42.332494   388 solver.cpp:473] Iteration 730, lr = 0.01
I0621 03:34:54.593410   388 solver.cpp:213] Iteration 731, loss = 0.000466429
I0621 03:34:54.593497   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000466629 (* 1 = 0.000466629 loss)
I0621 03:34:54.593519   388 solver.cpp:473] Iteration 731, lr = 0.01
I0621 03:35:06.902714   388 solver.cpp:213] Iteration 732, loss = 0.000465862
I0621 03:35:06.902799   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000466124 (* 1 = 0.000466124 loss)
I0621 03:35:06.902822   388 solver.cpp:473] Iteration 732, lr = 0.01
I0621 03:35:19.128080   388 solver.cpp:213] Iteration 733, loss = 0.000465539
I0621 03:35:19.128305   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000466114 (* 1 = 0.000466114 loss)
I0621 03:35:19.128335   388 solver.cpp:473] Iteration 733, lr = 0.01
I0621 03:35:31.538494   388 solver.cpp:213] Iteration 734, loss = 0.000465024
I0621 03:35:31.538589   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000464883 (* 1 = 0.000464883 loss)
I0621 03:35:31.538612   388 solver.cpp:473] Iteration 734, lr = 0.01
I0621 03:35:43.866911   388 solver.cpp:213] Iteration 735, loss = 0.000464624
I0621 03:35:43.866997   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000465091 (* 1 = 0.000465091 loss)
I0621 03:35:43.867019   388 solver.cpp:473] Iteration 735, lr = 0.01
I0621 03:35:56.226596   388 solver.cpp:213] Iteration 736, loss = 0.000464058
I0621 03:35:56.227021   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000463913 (* 1 = 0.000463913 loss)
I0621 03:35:56.227077   388 solver.cpp:473] Iteration 736, lr = 0.01
I0621 03:36:08.614207   388 solver.cpp:213] Iteration 737, loss = 0.000463566
I0621 03:36:08.614295   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00046417 (* 1 = 0.00046417 loss)
I0621 03:36:08.614318   388 solver.cpp:473] Iteration 737, lr = 0.01
I0621 03:36:20.993149   388 solver.cpp:213] Iteration 738, loss = 0.000463051
I0621 03:36:20.993232   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000463158 (* 1 = 0.000463158 loss)
I0621 03:36:20.993253   388 solver.cpp:473] Iteration 738, lr = 0.01
I0621 03:36:33.334986   388 solver.cpp:213] Iteration 739, loss = 0.000462667
I0621 03:36:33.335178   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000462919 (* 1 = 0.000462919 loss)
I0621 03:36:33.335203   388 solver.cpp:473] Iteration 739, lr = 0.01
I0621 03:36:45.764946   388 solver.cpp:213] Iteration 740, loss = 0.00046239
I0621 03:36:45.765028   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000462557 (* 1 = 0.000462557 loss)
I0621 03:36:45.765051   388 solver.cpp:473] Iteration 740, lr = 0.01
I0621 03:36:58.109786   388 solver.cpp:213] Iteration 741, loss = 0.000461831
I0621 03:36:58.109870   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000461739 (* 1 = 0.000461739 loss)
I0621 03:36:58.109892   388 solver.cpp:473] Iteration 741, lr = 0.01
I0621 03:37:10.485774   388 solver.cpp:213] Iteration 742, loss = 0.000461227
I0621 03:37:10.486007   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000461284 (* 1 = 0.000461284 loss)
I0621 03:37:10.486054   388 solver.cpp:473] Iteration 742, lr = 0.01
I0621 03:37:22.870596   388 solver.cpp:213] Iteration 743, loss = 0.000460804
I0621 03:37:22.870682   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000461063 (* 1 = 0.000461063 loss)
I0621 03:37:22.870704   388 solver.cpp:473] Iteration 743, lr = 0.01
I0621 03:37:35.185708   388 solver.cpp:213] Iteration 744, loss = 0.000460202
I0621 03:37:35.185792   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000459771 (* 1 = 0.000459771 loss)
I0621 03:37:35.185816   388 solver.cpp:473] Iteration 744, lr = 0.01
I0621 03:37:47.679857   388 solver.cpp:213] Iteration 745, loss = 0.000459778
I0621 03:37:47.680132   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000460191 (* 1 = 0.000460191 loss)
I0621 03:37:47.680178   388 solver.cpp:473] Iteration 745, lr = 0.01
I0621 03:38:00.131394   388 solver.cpp:213] Iteration 746, loss = 0.000459309
I0621 03:38:00.131481   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000459041 (* 1 = 0.000459041 loss)
I0621 03:38:00.131505   388 solver.cpp:473] Iteration 746, lr = 0.01
I0621 03:38:12.491307   388 solver.cpp:213] Iteration 747, loss = 0.000458844
I0621 03:38:12.491394   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000458814 (* 1 = 0.000458814 loss)
I0621 03:38:12.491416   388 solver.cpp:473] Iteration 747, lr = 0.01
I0621 03:38:24.784453   388 solver.cpp:213] Iteration 748, loss = 0.000458542
I0621 03:38:24.784679   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000458958 (* 1 = 0.000458958 loss)
I0621 03:38:24.784718   388 solver.cpp:473] Iteration 748, lr = 0.01
I0621 03:38:37.093593   388 solver.cpp:213] Iteration 749, loss = 0.000458043
I0621 03:38:37.093672   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000457932 (* 1 = 0.000457932 loss)
I0621 03:38:37.093698   388 solver.cpp:473] Iteration 749, lr = 0.01
I0621 03:38:49.527503   388 solver.cpp:213] Iteration 750, loss = 0.000457487
I0621 03:38:49.527591   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000457632 (* 1 = 0.000457632 loss)
I0621 03:38:49.527613   388 solver.cpp:473] Iteration 750, lr = 0.01
I0621 03:39:01.821373   388 solver.cpp:213] Iteration 751, loss = 0.000457004
I0621 03:39:01.821629   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000456172 (* 1 = 0.000456172 loss)
I0621 03:39:01.821677   388 solver.cpp:473] Iteration 751, lr = 0.01
I0621 03:39:14.169066   388 solver.cpp:213] Iteration 752, loss = 0.000456687
I0621 03:39:14.169152   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000457052 (* 1 = 0.000457052 loss)
I0621 03:39:14.169173   388 solver.cpp:473] Iteration 752, lr = 0.01
I0621 03:39:26.431285   388 solver.cpp:213] Iteration 753, loss = 0.000456047
I0621 03:39:26.431372   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000456259 (* 1 = 0.000456259 loss)
I0621 03:39:26.431396   388 solver.cpp:473] Iteration 753, lr = 0.01
I0621 03:39:38.754043   388 solver.cpp:213] Iteration 754, loss = 0.000455701
I0621 03:39:38.754243   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000456109 (* 1 = 0.000456109 loss)
I0621 03:39:38.754268   388 solver.cpp:473] Iteration 754, lr = 0.01
I0621 03:39:51.018226   388 solver.cpp:213] Iteration 755, loss = 0.000455326
I0621 03:39:51.018312   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000455114 (* 1 = 0.000455114 loss)
I0621 03:39:51.018337   388 solver.cpp:473] Iteration 755, lr = 0.01
I0621 03:40:03.276865   388 solver.cpp:213] Iteration 756, loss = 0.000454826
I0621 03:40:03.276948   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000455009 (* 1 = 0.000455009 loss)
I0621 03:40:03.276971   388 solver.cpp:473] Iteration 756, lr = 0.01
I0621 03:40:15.558688   388 solver.cpp:213] Iteration 757, loss = 0.000454325
I0621 03:40:15.563132   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000454919 (* 1 = 0.000454919 loss)
I0621 03:40:15.563156   388 solver.cpp:473] Iteration 757, lr = 0.01
I0621 03:40:27.914535   388 solver.cpp:213] Iteration 758, loss = 0.000453913
I0621 03:40:27.914672   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000452728 (* 1 = 0.000452728 loss)
I0621 03:40:27.914700   388 solver.cpp:473] Iteration 758, lr = 0.01
I0621 03:40:40.298387   388 solver.cpp:213] Iteration 759, loss = 0.000453341
I0621 03:40:40.298466   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000454061 (* 1 = 0.000454061 loss)
I0621 03:40:40.298491   388 solver.cpp:473] Iteration 759, lr = 0.01
I0621 03:40:52.595208   388 solver.cpp:213] Iteration 760, loss = 0.000452978
I0621 03:40:52.595424   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000453173 (* 1 = 0.000453173 loss)
I0621 03:40:52.595453   388 solver.cpp:473] Iteration 760, lr = 0.01
I0621 03:41:05.014456   388 solver.cpp:213] Iteration 761, loss = 0.000452609
I0621 03:41:05.014542   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00045328 (* 1 = 0.00045328 loss)
I0621 03:41:05.014565   388 solver.cpp:473] Iteration 761, lr = 0.01
I0621 03:41:17.301221   388 solver.cpp:213] Iteration 762, loss = 0.000452145
I0621 03:41:17.301302   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000452611 (* 1 = 0.000452611 loss)
I0621 03:41:17.301324   388 solver.cpp:473] Iteration 762, lr = 0.01
I0621 03:41:29.531951   388 solver.cpp:213] Iteration 763, loss = 0.000451707
I0621 03:41:29.532227   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000451702 (* 1 = 0.000451702 loss)
I0621 03:41:29.532274   388 solver.cpp:473] Iteration 763, lr = 0.01
I0621 03:41:41.829773   388 solver.cpp:213] Iteration 764, loss = 0.00045105
I0621 03:41:41.829856   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000451468 (* 1 = 0.000451468 loss)
I0621 03:41:41.829888   388 solver.cpp:473] Iteration 764, lr = 0.01
I0621 03:41:54.147896   388 solver.cpp:213] Iteration 765, loss = 0.000450961
I0621 03:41:54.147977   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00045156 (* 1 = 0.00045156 loss)
I0621 03:41:54.148000   388 solver.cpp:473] Iteration 765, lr = 0.01
I0621 03:42:06.372649   388 solver.cpp:213] Iteration 766, loss = 0.000450301
I0621 03:42:06.372828   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000450129 (* 1 = 0.000450129 loss)
I0621 03:42:06.372853   388 solver.cpp:473] Iteration 766, lr = 0.01
I0621 03:42:18.634476   388 solver.cpp:213] Iteration 767, loss = 0.00044989
I0621 03:42:18.634557   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000449427 (* 1 = 0.000449427 loss)
I0621 03:42:18.634580   388 solver.cpp:473] Iteration 767, lr = 0.01
I0621 03:42:30.952502   388 solver.cpp:213] Iteration 768, loss = 0.000449244
I0621 03:42:30.952589   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000448802 (* 1 = 0.000448802 loss)
I0621 03:42:30.952610   388 solver.cpp:473] Iteration 768, lr = 0.01
I0621 03:42:43.401101   388 solver.cpp:213] Iteration 769, loss = 0.000448796
I0621 03:42:43.401340   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000448173 (* 1 = 0.000448173 loss)
I0621 03:42:43.401381   388 solver.cpp:473] Iteration 769, lr = 0.01
I0621 03:42:55.840226   388 solver.cpp:213] Iteration 770, loss = 0.000448544
I0621 03:42:55.840311   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000449309 (* 1 = 0.000449309 loss)
I0621 03:42:55.840333   388 solver.cpp:473] Iteration 770, lr = 0.01
I0621 03:43:08.139731   388 solver.cpp:213] Iteration 771, loss = 0.000448082
I0621 03:43:08.139818   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000447822 (* 1 = 0.000447822 loss)
I0621 03:43:08.139842   388 solver.cpp:473] Iteration 771, lr = 0.01
I0621 03:43:20.471967   388 solver.cpp:213] Iteration 772, loss = 0.00044757
I0621 03:43:20.472174   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000448062 (* 1 = 0.000448062 loss)
I0621 03:43:20.472199   388 solver.cpp:473] Iteration 772, lr = 0.01
I0621 03:43:32.756119   388 solver.cpp:213] Iteration 773, loss = 0.00044723
I0621 03:43:32.756202   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000447122 (* 1 = 0.000447122 loss)
I0621 03:43:32.756225   388 solver.cpp:473] Iteration 773, lr = 0.01
I0621 03:43:45.000567   388 solver.cpp:213] Iteration 774, loss = 0.000446824
I0621 03:43:45.000650   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000446756 (* 1 = 0.000446756 loss)
I0621 03:43:45.000674   388 solver.cpp:473] Iteration 774, lr = 0.01
I0621 03:43:57.225881   388 solver.cpp:213] Iteration 775, loss = 0.000446327
I0621 03:43:57.226058   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000446847 (* 1 = 0.000446847 loss)
I0621 03:43:57.226083   388 solver.cpp:473] Iteration 775, lr = 0.01
I0621 03:44:09.462091   388 solver.cpp:213] Iteration 776, loss = 0.000445784
I0621 03:44:09.462172   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000445988 (* 1 = 0.000445988 loss)
I0621 03:44:09.462196   388 solver.cpp:473] Iteration 776, lr = 0.01
I0621 03:44:21.843626   388 solver.cpp:213] Iteration 777, loss = 0.000445563
I0621 03:44:21.843725   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000445468 (* 1 = 0.000445468 loss)
I0621 03:44:21.843750   388 solver.cpp:473] Iteration 777, lr = 0.01
I0621 03:44:34.202883   388 solver.cpp:213] Iteration 778, loss = 0.000444972
I0621 03:44:34.203079   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000444813 (* 1 = 0.000444813 loss)
I0621 03:44:34.203105   388 solver.cpp:473] Iteration 778, lr = 0.01
I0621 03:44:46.512258   388 solver.cpp:213] Iteration 779, loss = 0.000444573
I0621 03:44:46.512338   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000444552 (* 1 = 0.000444552 loss)
I0621 03:44:46.512362   388 solver.cpp:473] Iteration 779, lr = 0.01
I0621 03:44:58.773344   388 solver.cpp:213] Iteration 780, loss = 0.000444066
I0621 03:44:58.773428   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000444748 (* 1 = 0.000444748 loss)
I0621 03:44:58.773452   388 solver.cpp:473] Iteration 780, lr = 0.01
I0621 03:45:11.191550   388 solver.cpp:213] Iteration 781, loss = 0.000443839
I0621 03:45:11.191772   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000444315 (* 1 = 0.000444315 loss)
I0621 03:45:11.191798   388 solver.cpp:473] Iteration 781, lr = 0.01
I0621 03:45:23.449883   388 solver.cpp:213] Iteration 782, loss = 0.000443363
I0621 03:45:23.449966   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000443555 (* 1 = 0.000443555 loss)
I0621 03:45:23.449990   388 solver.cpp:473] Iteration 782, lr = 0.01
I0621 03:45:35.709506   388 solver.cpp:213] Iteration 783, loss = 0.000442936
I0621 03:45:35.709592   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000443719 (* 1 = 0.000443719 loss)
I0621 03:45:35.709615   388 solver.cpp:473] Iteration 783, lr = 0.01
I0621 03:45:48.002218   388 solver.cpp:213] Iteration 784, loss = 0.000442327
I0621 03:45:48.002488   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000441635 (* 1 = 0.000441635 loss)
I0621 03:45:48.002547   388 solver.cpp:473] Iteration 784, lr = 0.01
I0621 03:46:00.329712   388 solver.cpp:213] Iteration 785, loss = 0.000442065
I0621 03:46:00.329800   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000441314 (* 1 = 0.000441314 loss)
I0621 03:46:00.329823   388 solver.cpp:473] Iteration 785, lr = 0.01
I0621 03:46:12.690045   388 solver.cpp:213] Iteration 786, loss = 0.000441541
I0621 03:46:12.690134   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000441933 (* 1 = 0.000441933 loss)
I0621 03:46:12.690155   388 solver.cpp:473] Iteration 786, lr = 0.01
I0621 03:46:25.086313   388 solver.cpp:213] Iteration 787, loss = 0.000441006
I0621 03:46:25.086520   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000441539 (* 1 = 0.000441539 loss)
I0621 03:46:25.086554   388 solver.cpp:473] Iteration 787, lr = 0.01
I0621 03:46:37.364626   388 solver.cpp:213] Iteration 788, loss = 0.000440475
I0621 03:46:37.364715   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000439802 (* 1 = 0.000439802 loss)
I0621 03:46:37.364738   388 solver.cpp:473] Iteration 788, lr = 0.01
I0621 03:46:49.765525   388 solver.cpp:213] Iteration 789, loss = 0.000440099
I0621 03:46:49.765612   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000439691 (* 1 = 0.000439691 loss)
I0621 03:46:49.765635   388 solver.cpp:473] Iteration 789, lr = 0.01
I0621 03:47:02.089792   388 solver.cpp:213] Iteration 790, loss = 0.000439603
I0621 03:47:02.090123   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000439301 (* 1 = 0.000439301 loss)
I0621 03:47:02.090170   388 solver.cpp:473] Iteration 790, lr = 0.01
I0621 03:47:14.448240   388 solver.cpp:213] Iteration 791, loss = 0.000439151
I0621 03:47:14.448331   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000439619 (* 1 = 0.000439619 loss)
I0621 03:47:14.448356   388 solver.cpp:473] Iteration 791, lr = 0.01
I0621 03:47:26.818349   388 solver.cpp:213] Iteration 792, loss = 0.000438861
I0621 03:47:26.818431   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000439523 (* 1 = 0.000439523 loss)
I0621 03:47:26.818454   388 solver.cpp:473] Iteration 792, lr = 0.01
I0621 03:47:39.158409   388 solver.cpp:213] Iteration 793, loss = 0.000438606
I0621 03:47:39.158629   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000438987 (* 1 = 0.000438987 loss)
I0621 03:47:39.158656   388 solver.cpp:473] Iteration 793, lr = 0.01
I0621 03:47:51.453572   388 solver.cpp:213] Iteration 794, loss = 0.000438104
I0621 03:47:51.453655   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000437506 (* 1 = 0.000437506 loss)
I0621 03:47:51.453680   388 solver.cpp:473] Iteration 794, lr = 0.01
I0621 03:48:03.726681   388 solver.cpp:213] Iteration 795, loss = 0.000437617
I0621 03:48:03.726768   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000437487 (* 1 = 0.000437487 loss)
I0621 03:48:03.726790   388 solver.cpp:473] Iteration 795, lr = 0.01
I0621 03:48:16.143872   388 solver.cpp:213] Iteration 796, loss = 0.000437268
I0621 03:48:16.144114   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0004367 (* 1 = 0.0004367 loss)
I0621 03:48:16.144171   388 solver.cpp:473] Iteration 796, lr = 0.01
I0621 03:48:28.588377   388 solver.cpp:213] Iteration 797, loss = 0.000436884
I0621 03:48:28.588464   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00043653 (* 1 = 0.00043653 loss)
I0621 03:48:28.588486   388 solver.cpp:473] Iteration 797, lr = 0.01
I0621 03:48:40.951418   388 solver.cpp:213] Iteration 798, loss = 0.000436557
I0621 03:48:40.951500   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000436329 (* 1 = 0.000436329 loss)
I0621 03:48:40.951524   388 solver.cpp:473] Iteration 798, lr = 0.01
I0621 03:48:53.226146   388 solver.cpp:213] Iteration 799, loss = 0.000436101
I0621 03:48:53.226399   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00043523 (* 1 = 0.00043523 loss)
I0621 03:48:53.226444   388 solver.cpp:473] Iteration 799, lr = 0.01
I0621 03:49:05.555106   388 solver.cpp:213] Iteration 800, loss = 0.000435694
I0621 03:49:05.555191   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000436025 (* 1 = 0.000436025 loss)
I0621 03:49:05.555215   388 solver.cpp:473] Iteration 800, lr = 0.01
I0621 03:49:17.872813   388 solver.cpp:213] Iteration 801, loss = 0.000435212
I0621 03:49:17.872898   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000435669 (* 1 = 0.000435669 loss)
I0621 03:49:17.872921   388 solver.cpp:473] Iteration 801, lr = 0.01
I0621 03:49:30.109498   388 solver.cpp:213] Iteration 802, loss = 0.000434752
I0621 03:49:30.109685   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00043478 (* 1 = 0.00043478 loss)
I0621 03:49:30.109710   388 solver.cpp:473] Iteration 802, lr = 0.01
I0621 03:49:42.410168   388 solver.cpp:213] Iteration 803, loss = 0.000434335
I0621 03:49:42.410250   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000434757 (* 1 = 0.000434757 loss)
I0621 03:49:42.410272   388 solver.cpp:473] Iteration 803, lr = 0.01
I0621 03:49:54.650239   388 solver.cpp:213] Iteration 804, loss = 0.000433975
I0621 03:49:54.650322   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000432992 (* 1 = 0.000432992 loss)
I0621 03:49:54.650346   388 solver.cpp:473] Iteration 804, lr = 0.01
I0621 03:50:07.046275   388 solver.cpp:213] Iteration 805, loss = 0.000433422
I0621 03:50:07.046466   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000433862 (* 1 = 0.000433862 loss)
I0621 03:50:07.046491   388 solver.cpp:473] Iteration 805, lr = 0.01
I0621 03:50:19.261983   388 solver.cpp:213] Iteration 806, loss = 0.000432956
I0621 03:50:19.262059   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000433247 (* 1 = 0.000433247 loss)
I0621 03:50:19.262084   388 solver.cpp:473] Iteration 806, lr = 0.01
I0621 03:50:31.523126   388 solver.cpp:213] Iteration 807, loss = 0.000432675
I0621 03:50:31.523210   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000433194 (* 1 = 0.000433194 loss)
I0621 03:50:31.523244   388 solver.cpp:473] Iteration 807, lr = 0.01
I0621 03:50:43.748093   388 solver.cpp:213] Iteration 808, loss = 0.000432465
I0621 03:50:43.748268   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000432973 (* 1 = 0.000432973 loss)
I0621 03:50:43.748293   388 solver.cpp:473] Iteration 808, lr = 0.01
I0621 03:50:55.969774   388 solver.cpp:213] Iteration 809, loss = 0.000431836
I0621 03:50:55.969858   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000432294 (* 1 = 0.000432294 loss)
I0621 03:50:55.969882   388 solver.cpp:473] Iteration 809, lr = 0.01
I0621 03:51:08.287045   388 solver.cpp:213] Iteration 810, loss = 0.000431184
I0621 03:51:08.287137   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000431215 (* 1 = 0.000431215 loss)
I0621 03:51:08.287159   388 solver.cpp:473] Iteration 810, lr = 0.01
I0621 03:51:20.620337   388 solver.cpp:213] Iteration 811, loss = 0.000431135
I0621 03:51:20.620566   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000431225 (* 1 = 0.000431225 loss)
I0621 03:51:20.620594   388 solver.cpp:473] Iteration 811, lr = 0.01
I0621 03:51:32.986511   388 solver.cpp:213] Iteration 812, loss = 0.000430538
I0621 03:51:32.986601   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000430116 (* 1 = 0.000430116 loss)
I0621 03:51:32.986624   388 solver.cpp:473] Iteration 812, lr = 0.01
I0621 03:51:45.287642   388 solver.cpp:213] Iteration 813, loss = 0.000430274
I0621 03:51:45.287724   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000430025 (* 1 = 0.000430025 loss)
I0621 03:51:45.287745   388 solver.cpp:473] Iteration 813, lr = 0.01
I0621 03:51:57.542804   388 solver.cpp:213] Iteration 814, loss = 0.000429978
I0621 03:51:57.562907   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000430024 (* 1 = 0.000430024 loss)
I0621 03:51:57.562940   388 solver.cpp:473] Iteration 814, lr = 0.01
I0621 03:52:10.033009   388 solver.cpp:213] Iteration 815, loss = 0.000429372
I0621 03:52:10.033100   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00042914 (* 1 = 0.00042914 loss)
I0621 03:52:10.033124   388 solver.cpp:473] Iteration 815, lr = 0.01
I0621 03:52:22.330657   388 solver.cpp:213] Iteration 816, loss = 0.000429079
I0621 03:52:22.330739   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000429345 (* 1 = 0.000429345 loss)
I0621 03:52:22.330761   388 solver.cpp:473] Iteration 816, lr = 0.01
I0621 03:52:34.684303   388 solver.cpp:213] Iteration 817, loss = 0.000428777
I0621 03:52:34.684538   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000428642 (* 1 = 0.000428642 loss)
I0621 03:52:34.684598   388 solver.cpp:473] Iteration 817, lr = 0.01
I0621 03:52:47.149255   388 solver.cpp:213] Iteration 818, loss = 0.000428285
I0621 03:52:47.149336   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00042802 (* 1 = 0.00042802 loss)
I0621 03:52:47.149358   388 solver.cpp:473] Iteration 818, lr = 0.01
I0621 03:52:59.441730   388 solver.cpp:213] Iteration 819, loss = 0.000427762
I0621 03:52:59.441818   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000427777 (* 1 = 0.000427777 loss)
I0621 03:52:59.441840   388 solver.cpp:473] Iteration 819, lr = 0.01
I0621 03:53:11.823168   388 solver.cpp:213] Iteration 820, loss = 0.000427239
I0621 03:53:11.823380   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000426844 (* 1 = 0.000426844 loss)
I0621 03:53:11.823424   388 solver.cpp:473] Iteration 820, lr = 0.01
I0621 03:53:24.189394   388 solver.cpp:213] Iteration 821, loss = 0.000427123
I0621 03:53:24.189477   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000427167 (* 1 = 0.000427167 loss)
I0621 03:53:24.189499   388 solver.cpp:473] Iteration 821, lr = 0.01
I0621 03:53:36.483175   388 solver.cpp:213] Iteration 822, loss = 0.000426542
I0621 03:53:36.483258   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00042647 (* 1 = 0.00042647 loss)
I0621 03:53:36.483279   388 solver.cpp:473] Iteration 822, lr = 0.01
I0621 03:53:48.742527   388 solver.cpp:213] Iteration 823, loss = 0.000426114
I0621 03:53:48.747117   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000425802 (* 1 = 0.000425802 loss)
I0621 03:53:48.747189   388 solver.cpp:473] Iteration 823, lr = 0.01
I0621 03:54:01.089305   388 solver.cpp:213] Iteration 824, loss = 0.000425616
I0621 03:54:01.089390   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000426233 (* 1 = 0.000426233 loss)
I0621 03:54:01.089413   388 solver.cpp:473] Iteration 824, lr = 0.01
I0621 03:54:13.321926   388 solver.cpp:213] Iteration 825, loss = 0.000425412
I0621 03:54:13.322007   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000425245 (* 1 = 0.000425245 loss)
I0621 03:54:13.322031   388 solver.cpp:473] Iteration 825, lr = 0.01
I0621 03:54:25.641598   388 solver.cpp:213] Iteration 826, loss = 0.000424876
I0621 03:54:25.649452   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000424187 (* 1 = 0.000424187 loss)
I0621 03:54:25.649494   388 solver.cpp:473] Iteration 826, lr = 0.01
I0621 03:54:37.978706   388 solver.cpp:213] Iteration 827, loss = 0.000424633
I0621 03:54:37.978798   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000424581 (* 1 = 0.000424581 loss)
I0621 03:54:37.978823   388 solver.cpp:473] Iteration 827, lr = 0.01
I0621 03:54:50.240593   388 solver.cpp:213] Iteration 828, loss = 0.000424041
I0621 03:54:50.240680   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000424419 (* 1 = 0.000424419 loss)
I0621 03:54:50.240702   388 solver.cpp:473] Iteration 828, lr = 0.01
I0621 03:55:02.512814   388 solver.cpp:213] Iteration 829, loss = 0.000423852
I0621 03:55:02.513043   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000423574 (* 1 = 0.000423574 loss)
I0621 03:55:02.513109   388 solver.cpp:473] Iteration 829, lr = 0.01
I0621 03:55:14.801843   388 solver.cpp:213] Iteration 830, loss = 0.000423414
I0621 03:55:14.801928   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000423713 (* 1 = 0.000423713 loss)
I0621 03:55:14.801951   388 solver.cpp:473] Iteration 830, lr = 0.01
I0621 03:55:27.086395   388 solver.cpp:213] Iteration 831, loss = 0.000423028
I0621 03:55:27.086483   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000423071 (* 1 = 0.000423071 loss)
I0621 03:55:27.086504   388 solver.cpp:473] Iteration 831, lr = 0.01
I0621 03:55:39.348595   388 solver.cpp:213] Iteration 832, loss = 0.000422698
I0621 03:55:39.348803   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000422834 (* 1 = 0.000422834 loss)
I0621 03:55:39.348829   388 solver.cpp:473] Iteration 832, lr = 0.01
I0621 03:55:51.654005   388 solver.cpp:213] Iteration 833, loss = 0.000422242
I0621 03:55:51.654088   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000422087 (* 1 = 0.000422087 loss)
I0621 03:55:51.654111   388 solver.cpp:473] Iteration 833, lr = 0.01
I0621 03:56:03.931638   388 solver.cpp:213] Iteration 834, loss = 0.000421747
I0621 03:56:03.932003   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00042177 (* 1 = 0.00042177 loss)
I0621 03:56:03.932067   388 solver.cpp:473] Iteration 834, lr = 0.01
I0621 03:56:16.227288   388 solver.cpp:213] Iteration 835, loss = 0.000421378
I0621 03:56:16.227485   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000421599 (* 1 = 0.000421599 loss)
I0621 03:56:16.227510   388 solver.cpp:473] Iteration 835, lr = 0.01
I0621 03:56:28.465176   388 solver.cpp:213] Iteration 836, loss = 0.00042111
I0621 03:56:28.465260   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000421758 (* 1 = 0.000421758 loss)
I0621 03:56:28.465282   388 solver.cpp:473] Iteration 836, lr = 0.01
I0621 03:56:40.699786   388 solver.cpp:213] Iteration 837, loss = 0.000420737
I0621 03:56:40.699867   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0004213 (* 1 = 0.0004213 loss)
I0621 03:56:40.699887   388 solver.cpp:473] Iteration 837, lr = 0.01
I0621 03:56:52.993028   388 solver.cpp:213] Iteration 838, loss = 0.000420255
I0621 03:56:52.993309   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000420876 (* 1 = 0.000420876 loss)
I0621 03:56:52.993342   388 solver.cpp:473] Iteration 838, lr = 0.01
I0621 03:57:05.295893   388 solver.cpp:213] Iteration 839, loss = 0.000419951
I0621 03:57:05.295974   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000419981 (* 1 = 0.000419981 loss)
I0621 03:57:05.295996   388 solver.cpp:473] Iteration 839, lr = 0.01
I0621 03:57:17.631503   388 solver.cpp:213] Iteration 840, loss = 0.00041945
I0621 03:57:17.631587   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000419605 (* 1 = 0.000419605 loss)
I0621 03:57:17.631608   388 solver.cpp:473] Iteration 840, lr = 0.01
I0621 03:57:29.982791   388 solver.cpp:213] Iteration 841, loss = 0.000419203
I0621 03:57:29.983085   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000419115 (* 1 = 0.000419115 loss)
I0621 03:57:29.983204   388 solver.cpp:473] Iteration 841, lr = 0.01
I0621 03:57:42.365551   388 solver.cpp:213] Iteration 842, loss = 0.000418937
I0621 03:57:42.365634   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000419088 (* 1 = 0.000419088 loss)
I0621 03:57:42.365656   388 solver.cpp:473] Iteration 842, lr = 0.01
I0621 03:57:54.736924   388 solver.cpp:213] Iteration 843, loss = 0.000418388
I0621 03:57:54.737023   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000418444 (* 1 = 0.000418444 loss)
I0621 03:57:54.737051   388 solver.cpp:473] Iteration 843, lr = 0.01
I0621 03:58:07.079540   388 solver.cpp:213] Iteration 844, loss = 0.000417968
I0621 03:58:07.080793   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000417917 (* 1 = 0.000417917 loss)
I0621 03:58:07.080819   388 solver.cpp:473] Iteration 844, lr = 0.01
I0621 03:58:19.324065   388 solver.cpp:213] Iteration 845, loss = 0.000417696
I0621 03:58:19.324151   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000417519 (* 1 = 0.000417519 loss)
I0621 03:58:19.324173   388 solver.cpp:473] Iteration 845, lr = 0.01
I0621 03:58:31.556215   388 solver.cpp:213] Iteration 846, loss = 0.000417431
I0621 03:58:31.556296   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000417028 (* 1 = 0.000417028 loss)
I0621 03:58:31.556319   388 solver.cpp:473] Iteration 846, lr = 0.01
I0621 03:58:43.770818   388 solver.cpp:213] Iteration 847, loss = 0.000416956
I0621 03:58:43.786502   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000417319 (* 1 = 0.000417319 loss)
I0621 03:58:43.787173   388 solver.cpp:473] Iteration 847, lr = 0.01
I0621 03:58:56.115098   388 solver.cpp:213] Iteration 848, loss = 0.000416557
I0621 03:58:56.115183   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000416236 (* 1 = 0.000416236 loss)
I0621 03:58:56.115206   388 solver.cpp:473] Iteration 848, lr = 0.01
I0621 03:59:08.390312   388 solver.cpp:213] Iteration 849, loss = 0.000416032
I0621 03:59:08.390391   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000415799 (* 1 = 0.000415799 loss)
I0621 03:59:08.390413   388 solver.cpp:473] Iteration 849, lr = 0.01
I0621 03:59:20.729954   388 solver.cpp:213] Iteration 850, loss = 0.00041563
I0621 03:59:20.730217   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000415802 (* 1 = 0.000415802 loss)
I0621 03:59:20.730243   388 solver.cpp:473] Iteration 850, lr = 0.01
I0621 03:59:33.007817   388 solver.cpp:213] Iteration 851, loss = 0.000415226
I0621 03:59:33.007899   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00041492 (* 1 = 0.00041492 loss)
I0621 03:59:33.007921   388 solver.cpp:473] Iteration 851, lr = 0.01
I0621 03:59:45.359417   388 solver.cpp:213] Iteration 852, loss = 0.000414878
I0621 03:59:45.359503   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000414137 (* 1 = 0.000414137 loss)
I0621 03:59:45.359525   388 solver.cpp:473] Iteration 852, lr = 0.01
I0621 03:59:57.612074   388 solver.cpp:213] Iteration 853, loss = 0.000414682
I0621 03:59:57.612259   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00041479 (* 1 = 0.00041479 loss)
I0621 03:59:57.612283   388 solver.cpp:473] Iteration 853, lr = 0.01
I0621 04:00:09.833099   388 solver.cpp:213] Iteration 854, loss = 0.000414102
I0621 04:00:09.833184   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000413198 (* 1 = 0.000413198 loss)
I0621 04:00:09.833206   388 solver.cpp:473] Iteration 854, lr = 0.01
I0621 04:00:22.094753   388 solver.cpp:213] Iteration 855, loss = 0.000413824
I0621 04:00:22.094878   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000413956 (* 1 = 0.000413956 loss)
I0621 04:00:22.094914   388 solver.cpp:473] Iteration 855, lr = 0.01
I0621 04:00:34.459187   388 solver.cpp:213] Iteration 856, loss = 0.000413674
I0621 04:00:34.459594   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000413416 (* 1 = 0.000413416 loss)
I0621 04:00:34.459633   388 solver.cpp:473] Iteration 856, lr = 0.01
I0621 04:00:46.913658   388 solver.cpp:213] Iteration 857, loss = 0.000412954
I0621 04:00:46.913743   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000412716 (* 1 = 0.000412716 loss)
I0621 04:00:46.913765   388 solver.cpp:473] Iteration 857, lr = 0.01
I0621 04:00:59.243489   388 solver.cpp:213] Iteration 858, loss = 0.000412786
I0621 04:00:59.243573   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000412645 (* 1 = 0.000412645 loss)
I0621 04:00:59.243597   388 solver.cpp:473] Iteration 858, lr = 0.01
I0621 04:01:11.654048   388 solver.cpp:213] Iteration 859, loss = 0.000412257
I0621 04:01:11.654244   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000412364 (* 1 = 0.000412364 loss)
I0621 04:01:11.654268   388 solver.cpp:473] Iteration 859, lr = 0.01
I0621 04:01:23.912593   388 solver.cpp:213] Iteration 860, loss = 0.000412007
I0621 04:01:23.912719   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000411805 (* 1 = 0.000411805 loss)
I0621 04:01:23.912758   388 solver.cpp:473] Iteration 860, lr = 0.01
I0621 04:01:36.312151   388 solver.cpp:213] Iteration 861, loss = 0.000411541
I0621 04:01:36.312235   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000411087 (* 1 = 0.000411087 loss)
I0621 04:01:36.312258   388 solver.cpp:473] Iteration 861, lr = 0.01
I0621 04:01:48.569432   388 solver.cpp:213] Iteration 862, loss = 0.000411222
I0621 04:01:48.569613   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00041103 (* 1 = 0.00041103 loss)
I0621 04:01:48.569638   388 solver.cpp:473] Iteration 862, lr = 0.01
I0621 04:02:00.786175   388 solver.cpp:213] Iteration 863, loss = 0.000410911
I0621 04:02:00.786254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000411055 (* 1 = 0.000411055 loss)
I0621 04:02:00.786276   388 solver.cpp:473] Iteration 863, lr = 0.01
I0621 04:02:13.096669   388 solver.cpp:213] Iteration 864, loss = 0.000410511
I0621 04:02:13.096755   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000410661 (* 1 = 0.000410661 loss)
I0621 04:02:13.096777   388 solver.cpp:473] Iteration 864, lr = 0.01
I0621 04:02:25.414813   388 solver.cpp:213] Iteration 865, loss = 0.000410191
I0621 04:02:25.415012   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000409488 (* 1 = 0.000409488 loss)
I0621 04:02:25.415040   388 solver.cpp:473] Iteration 865, lr = 0.01
I0621 04:02:37.807787   388 solver.cpp:213] Iteration 866, loss = 0.000409747
I0621 04:02:37.807876   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000409986 (* 1 = 0.000409986 loss)
I0621 04:02:37.807904   388 solver.cpp:473] Iteration 866, lr = 0.01
I0621 04:02:50.131552   388 solver.cpp:213] Iteration 867, loss = 0.000409437
I0621 04:02:50.131647   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000409701 (* 1 = 0.000409701 loss)
I0621 04:02:50.131680   388 solver.cpp:473] Iteration 867, lr = 0.01
I0621 04:03:02.445452   388 solver.cpp:213] Iteration 868, loss = 0.000409048
I0621 04:03:02.446578   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00040951 (* 1 = 0.00040951 loss)
I0621 04:03:02.446604   388 solver.cpp:473] Iteration 868, lr = 0.01
I0621 04:03:14.810186   388 solver.cpp:213] Iteration 869, loss = 0.000408654
I0621 04:03:14.810269   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000408208 (* 1 = 0.000408208 loss)
I0621 04:03:14.810292   388 solver.cpp:473] Iteration 869, lr = 0.01
I0621 04:03:27.190181   388 solver.cpp:213] Iteration 870, loss = 0.000408342
I0621 04:03:27.190260   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000408726 (* 1 = 0.000408726 loss)
I0621 04:03:27.190284   388 solver.cpp:473] Iteration 870, lr = 0.01
I0621 04:03:39.598758   388 solver.cpp:213] Iteration 871, loss = 0.000407966
I0621 04:03:39.605739   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000408298 (* 1 = 0.000408298 loss)
I0621 04:03:39.605772   388 solver.cpp:473] Iteration 871, lr = 0.01
I0621 04:03:51.923136   388 solver.cpp:213] Iteration 872, loss = 0.00040766
I0621 04:03:51.923219   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000408196 (* 1 = 0.000408196 loss)
I0621 04:03:51.923241   388 solver.cpp:473] Iteration 872, lr = 0.01
I0621 04:04:04.297302   388 solver.cpp:213] Iteration 873, loss = 0.000407132
I0621 04:04:04.297382   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00040687 (* 1 = 0.00040687 loss)
I0621 04:04:04.297404   388 solver.cpp:473] Iteration 873, lr = 0.01
I0621 04:04:16.613226   388 solver.cpp:213] Iteration 874, loss = 0.000406794
I0621 04:04:16.613482   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00040745 (* 1 = 0.00040745 loss)
I0621 04:04:16.613520   388 solver.cpp:473] Iteration 874, lr = 0.01
I0621 04:04:28.951411   388 solver.cpp:213] Iteration 875, loss = 0.000406649
I0621 04:04:28.951498   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000406407 (* 1 = 0.000406407 loss)
I0621 04:04:28.951520   388 solver.cpp:473] Iteration 875, lr = 0.01
I0621 04:04:41.243247   388 solver.cpp:213] Iteration 876, loss = 0.000406064
I0621 04:04:41.243327   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000405377 (* 1 = 0.000405377 loss)
I0621 04:04:41.243350   388 solver.cpp:473] Iteration 876, lr = 0.01
I0621 04:04:53.558536   388 solver.cpp:213] Iteration 877, loss = 0.000405713
I0621 04:04:53.558738   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000405573 (* 1 = 0.000405573 loss)
I0621 04:04:53.558766   388 solver.cpp:473] Iteration 877, lr = 0.01
I0621 04:05:05.926532   388 solver.cpp:213] Iteration 878, loss = 0.000405352
I0621 04:05:05.926617   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000405413 (* 1 = 0.000405413 loss)
I0621 04:05:05.926641   388 solver.cpp:473] Iteration 878, lr = 0.01
I0621 04:05:18.277357   388 solver.cpp:213] Iteration 879, loss = 0.000405052
I0621 04:05:18.277439   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000404826 (* 1 = 0.000404826 loss)
I0621 04:05:18.277462   388 solver.cpp:473] Iteration 879, lr = 0.01
I0621 04:05:30.628536   388 solver.cpp:213] Iteration 880, loss = 0.000404619
I0621 04:05:30.638602   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000404491 (* 1 = 0.000404491 loss)
I0621 04:05:30.638643   388 solver.cpp:473] Iteration 880, lr = 0.01
I0621 04:05:42.916667   388 solver.cpp:213] Iteration 881, loss = 0.000404162
I0621 04:05:42.916754   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000403949 (* 1 = 0.000403949 loss)
I0621 04:05:42.916782   388 solver.cpp:473] Iteration 881, lr = 0.01
I0621 04:05:55.320736   388 solver.cpp:213] Iteration 882, loss = 0.000403954
I0621 04:05:55.320822   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000404095 (* 1 = 0.000404095 loss)
I0621 04:05:55.320845   388 solver.cpp:473] Iteration 882, lr = 0.01
I0621 04:06:07.768944   388 solver.cpp:213] Iteration 883, loss = 0.000403739
I0621 04:06:07.769134   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000403046 (* 1 = 0.000403046 loss)
I0621 04:06:07.769160   388 solver.cpp:473] Iteration 883, lr = 0.01
I0621 04:06:20.044298   388 solver.cpp:213] Iteration 884, loss = 0.000403311
I0621 04:06:20.044384   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000403026 (* 1 = 0.000403026 loss)
I0621 04:06:20.044406   388 solver.cpp:473] Iteration 884, lr = 0.01
I0621 04:06:32.349885   388 solver.cpp:213] Iteration 885, loss = 0.000402673
I0621 04:06:32.349972   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000403088 (* 1 = 0.000403088 loss)
I0621 04:06:32.349995   388 solver.cpp:473] Iteration 885, lr = 0.01
I0621 04:06:44.678463   388 solver.cpp:213] Iteration 886, loss = 0.0004025
I0621 04:06:44.678721   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000402935 (* 1 = 0.000402935 loss)
I0621 04:06:44.678767   388 solver.cpp:473] Iteration 886, lr = 0.01
I0621 04:06:56.942590   388 solver.cpp:213] Iteration 887, loss = 0.000401912
I0621 04:06:56.942677   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000402458 (* 1 = 0.000402458 loss)
I0621 04:06:56.942700   388 solver.cpp:473] Iteration 887, lr = 0.01
I0621 04:07:09.267712   388 solver.cpp:213] Iteration 888, loss = 0.000401816
I0621 04:07:09.267797   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000401308 (* 1 = 0.000401308 loss)
I0621 04:07:09.267820   388 solver.cpp:473] Iteration 888, lr = 0.01
I0621 04:07:21.561256   388 solver.cpp:213] Iteration 889, loss = 0.000401464
I0621 04:07:21.561445   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000401507 (* 1 = 0.000401507 loss)
I0621 04:07:21.561473   388 solver.cpp:473] Iteration 889, lr = 0.01
I0621 04:07:33.804198   388 solver.cpp:213] Iteration 890, loss = 0.000401004
I0621 04:07:33.804283   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000400851 (* 1 = 0.000400851 loss)
I0621 04:07:33.804306   388 solver.cpp:473] Iteration 890, lr = 0.01
I0621 04:07:46.029490   388 solver.cpp:213] Iteration 891, loss = 0.000400808
I0621 04:07:46.029577   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000400788 (* 1 = 0.000400788 loss)
I0621 04:07:46.029598   388 solver.cpp:473] Iteration 891, lr = 0.01
I0621 04:07:58.246006   388 solver.cpp:213] Iteration 892, loss = 0.000400182
I0621 04:07:58.246189   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00039997 (* 1 = 0.00039997 loss)
I0621 04:07:58.246214   388 solver.cpp:473] Iteration 892, lr = 0.01
I0621 04:08:10.488222   388 solver.cpp:213] Iteration 893, loss = 0.000400092
I0621 04:08:10.488301   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000399691 (* 1 = 0.000399691 loss)
I0621 04:08:10.488322   388 solver.cpp:473] Iteration 893, lr = 0.01
I0621 04:08:22.713721   388 solver.cpp:213] Iteration 894, loss = 0.000399729
I0621 04:08:22.713793   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000399729 (* 1 = 0.000399729 loss)
I0621 04:08:22.713812   388 solver.cpp:473] Iteration 894, lr = 0.01
I0621 04:08:34.972944   388 solver.cpp:213] Iteration 895, loss = 0.000399337
I0621 04:08:34.973124   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000399338 (* 1 = 0.000399338 loss)
I0621 04:08:34.973147   388 solver.cpp:473] Iteration 895, lr = 0.01
I0621 04:08:47.202198   388 solver.cpp:213] Iteration 896, loss = 0.000398814
I0621 04:08:47.202270   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000398724 (* 1 = 0.000398724 loss)
I0621 04:08:47.202289   388 solver.cpp:473] Iteration 896, lr = 0.01
I0621 04:08:59.444152   388 solver.cpp:213] Iteration 897, loss = 0.000398889
I0621 04:08:59.444236   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000399666 (* 1 = 0.000399666 loss)
I0621 04:08:59.444259   388 solver.cpp:473] Iteration 897, lr = 0.01
I0621 04:09:11.654023   388 solver.cpp:213] Iteration 898, loss = 0.000398289
I0621 04:09:11.654186   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0003979 (* 1 = 0.0003979 loss)
I0621 04:09:11.654207   388 solver.cpp:473] Iteration 898, lr = 0.01
I0621 04:09:23.995270   388 solver.cpp:213] Iteration 899, loss = 0.000398127
I0621 04:09:23.995359   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000398437 (* 1 = 0.000398437 loss)
I0621 04:09:23.995381   388 solver.cpp:473] Iteration 899, lr = 0.01
I0621 04:09:36.304731   388 solver.cpp:213] Iteration 900, loss = 0.000397766
I0621 04:09:36.304816   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000397595 (* 1 = 0.000397595 loss)
I0621 04:09:36.304841   388 solver.cpp:473] Iteration 900, lr = 0.01
I0621 04:09:48.569702   388 solver.cpp:213] Iteration 901, loss = 0.000397347
I0621 04:09:48.569885   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000397741 (* 1 = 0.000397741 loss)
I0621 04:09:48.569911   388 solver.cpp:473] Iteration 901, lr = 0.01
I0621 04:10:00.916455   388 solver.cpp:213] Iteration 902, loss = 0.000397026
I0621 04:10:00.916539   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000397096 (* 1 = 0.000397096 loss)
I0621 04:10:00.916563   388 solver.cpp:473] Iteration 902, lr = 0.01
I0621 04:10:13.171548   388 solver.cpp:213] Iteration 903, loss = 0.000396541
I0621 04:10:13.171627   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000396423 (* 1 = 0.000396423 loss)
I0621 04:10:13.171653   388 solver.cpp:473] Iteration 903, lr = 0.01
I0621 04:10:25.434432   388 solver.cpp:213] Iteration 904, loss = 0.000396245
I0621 04:10:25.449235   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00039668 (* 1 = 0.00039668 loss)
I0621 04:10:25.449273   388 solver.cpp:473] Iteration 904, lr = 0.01
I0621 04:10:37.773363   388 solver.cpp:213] Iteration 905, loss = 0.000395803
I0621 04:10:37.773452   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000396335 (* 1 = 0.000396335 loss)
I0621 04:10:37.773474   388 solver.cpp:473] Iteration 905, lr = 0.01
I0621 04:10:50.091565   388 solver.cpp:213] Iteration 906, loss = 0.000395611
I0621 04:10:50.091650   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000395133 (* 1 = 0.000395133 loss)
I0621 04:10:50.091671   388 solver.cpp:473] Iteration 906, lr = 0.01
I0621 04:11:02.413656   388 solver.cpp:213] Iteration 907, loss = 0.000395303
I0621 04:11:02.413879   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000395902 (* 1 = 0.000395902 loss)
I0621 04:11:02.413913   388 solver.cpp:473] Iteration 907, lr = 0.01
I0621 04:11:14.849012   388 solver.cpp:213] Iteration 908, loss = 0.000394972
I0621 04:11:14.849094   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000395018 (* 1 = 0.000395018 loss)
I0621 04:11:14.849117   388 solver.cpp:473] Iteration 908, lr = 0.01
I0621 04:11:27.196745   388 solver.cpp:213] Iteration 909, loss = 0.000394426
I0621 04:11:27.196821   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000394706 (* 1 = 0.000394706 loss)
I0621 04:11:27.196844   388 solver.cpp:473] Iteration 909, lr = 0.01
I0621 04:11:39.621872   388 solver.cpp:213] Iteration 910, loss = 0.000394405
I0621 04:11:39.622108   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000394202 (* 1 = 0.000394202 loss)
I0621 04:11:39.622156   388 solver.cpp:473] Iteration 910, lr = 0.01
I0621 04:11:51.926333   388 solver.cpp:213] Iteration 911, loss = 0.000393964
I0621 04:11:51.926419   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000393561 (* 1 = 0.000393561 loss)
I0621 04:11:51.926445   388 solver.cpp:473] Iteration 911, lr = 0.01
I0621 04:12:04.236634   388 solver.cpp:213] Iteration 912, loss = 0.000393675
I0621 04:12:04.236711   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000393652 (* 1 = 0.000393652 loss)
I0621 04:12:04.236733   388 solver.cpp:473] Iteration 912, lr = 0.01
I0621 04:12:16.517329   388 solver.cpp:213] Iteration 913, loss = 0.000393164
I0621 04:12:16.517593   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000392933 (* 1 = 0.000392933 loss)
I0621 04:12:16.517639   388 solver.cpp:473] Iteration 913, lr = 0.01
I0621 04:12:28.873261   388 solver.cpp:213] Iteration 914, loss = 0.00039288
I0621 04:12:28.873347   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000393178 (* 1 = 0.000393178 loss)
I0621 04:12:28.873368   388 solver.cpp:473] Iteration 914, lr = 0.01
I0621 04:12:41.184124   388 solver.cpp:213] Iteration 915, loss = 0.000392584
I0621 04:12:41.184211   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000392983 (* 1 = 0.000392983 loss)
I0621 04:12:41.184234   388 solver.cpp:473] Iteration 915, lr = 0.01
I0621 04:12:53.500365   388 solver.cpp:213] Iteration 916, loss = 0.000392135
I0621 04:12:53.500617   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000392573 (* 1 = 0.000392573 loss)
I0621 04:12:53.500653   388 solver.cpp:473] Iteration 916, lr = 0.01
I0621 04:13:05.821934   388 solver.cpp:213] Iteration 917, loss = 0.000391894
I0621 04:13:05.822016   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000391896 (* 1 = 0.000391896 loss)
I0621 04:13:05.822039   388 solver.cpp:473] Iteration 917, lr = 0.01
I0621 04:13:18.133668   388 solver.cpp:213] Iteration 918, loss = 0.00039153
I0621 04:13:18.133749   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000391718 (* 1 = 0.000391718 loss)
I0621 04:13:18.133772   388 solver.cpp:473] Iteration 918, lr = 0.01
I0621 04:13:30.418712   388 solver.cpp:213] Iteration 919, loss = 0.000391121
I0621 04:13:30.418910   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000391206 (* 1 = 0.000391206 loss)
I0621 04:13:30.418936   388 solver.cpp:473] Iteration 919, lr = 0.01
I0621 04:13:42.798270   388 solver.cpp:213] Iteration 920, loss = 0.000390744
I0621 04:13:42.798357   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000390871 (* 1 = 0.000390871 loss)
I0621 04:13:42.798379   388 solver.cpp:473] Iteration 920, lr = 0.01
I0621 04:13:55.190330   388 solver.cpp:213] Iteration 921, loss = 0.000390349
I0621 04:13:55.190414   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00039049 (* 1 = 0.00039049 loss)
I0621 04:13:55.190438   388 solver.cpp:473] Iteration 921, lr = 0.01
I0621 04:14:07.504534   388 solver.cpp:213] Iteration 922, loss = 0.000390039
I0621 04:14:07.504739   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000389702 (* 1 = 0.000389702 loss)
I0621 04:14:07.504765   388 solver.cpp:473] Iteration 922, lr = 0.01
I0621 04:14:19.806540   388 solver.cpp:213] Iteration 923, loss = 0.000389895
I0621 04:14:19.806623   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000389246 (* 1 = 0.000389246 loss)
I0621 04:14:19.806646   388 solver.cpp:473] Iteration 923, lr = 0.01
I0621 04:14:32.175582   388 solver.cpp:213] Iteration 924, loss = 0.000389438
I0621 04:14:32.175664   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000388653 (* 1 = 0.000388653 loss)
I0621 04:14:32.175686   388 solver.cpp:473] Iteration 924, lr = 0.01
I0621 04:14:44.500166   388 solver.cpp:213] Iteration 925, loss = 0.000389216
I0621 04:14:44.500411   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000389427 (* 1 = 0.000389427 loss)
I0621 04:14:44.500473   388 solver.cpp:473] Iteration 925, lr = 0.01
I0621 04:14:56.809653   388 solver.cpp:213] Iteration 926, loss = 0.000388933
I0621 04:14:56.809736   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000389939 (* 1 = 0.000389939 loss)
I0621 04:14:56.809758   388 solver.cpp:473] Iteration 926, lr = 0.01
I0621 04:15:09.172379   388 solver.cpp:213] Iteration 927, loss = 0.000388667
I0621 04:15:09.172463   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000388444 (* 1 = 0.000388444 loss)
I0621 04:15:09.172487   388 solver.cpp:473] Iteration 927, lr = 0.01
I0621 04:15:21.478647   388 solver.cpp:213] Iteration 928, loss = 0.000388253
I0621 04:15:21.478881   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000388053 (* 1 = 0.000388053 loss)
I0621 04:15:21.478916   388 solver.cpp:473] Iteration 928, lr = 0.01
I0621 04:15:33.841888   388 solver.cpp:213] Iteration 929, loss = 0.00038792
I0621 04:15:33.841972   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000388493 (* 1 = 0.000388493 loss)
I0621 04:15:33.841995   388 solver.cpp:473] Iteration 929, lr = 0.01
I0621 04:15:46.222131   388 solver.cpp:213] Iteration 930, loss = 0.000387512
I0621 04:15:46.222216   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00038763 (* 1 = 0.00038763 loss)
I0621 04:15:46.222240   388 solver.cpp:473] Iteration 930, lr = 0.01
I0621 04:15:58.554944   388 solver.cpp:213] Iteration 931, loss = 0.000387264
I0621 04:15:58.555155   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000386853 (* 1 = 0.000386853 loss)
I0621 04:15:58.555189   388 solver.cpp:473] Iteration 931, lr = 0.01
I0621 04:16:10.851198   388 solver.cpp:213] Iteration 932, loss = 0.000386833
I0621 04:16:10.851285   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000386705 (* 1 = 0.000386705 loss)
I0621 04:16:10.851310   388 solver.cpp:473] Iteration 932, lr = 0.01
I0621 04:16:23.160410   388 solver.cpp:213] Iteration 933, loss = 0.000386485
I0621 04:16:23.160490   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000386621 (* 1 = 0.000386621 loss)
I0621 04:16:23.160514   388 solver.cpp:473] Iteration 933, lr = 0.01
I0621 04:16:35.483886   388 solver.cpp:213] Iteration 934, loss = 0.00038632
I0621 04:16:35.484159   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000386532 (* 1 = 0.000386532 loss)
I0621 04:16:35.484208   388 solver.cpp:473] Iteration 934, lr = 0.01
I0621 04:16:47.885212   388 solver.cpp:213] Iteration 935, loss = 0.000386066
I0621 04:16:47.885293   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000385709 (* 1 = 0.000385709 loss)
I0621 04:16:47.885315   388 solver.cpp:473] Iteration 935, lr = 0.01
I0621 04:17:00.183653   388 solver.cpp:213] Iteration 936, loss = 0.000385674
I0621 04:17:00.187201   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00038623 (* 1 = 0.00038623 loss)
I0621 04:17:00.187252   388 solver.cpp:473] Iteration 936, lr = 0.01
I0621 04:17:12.451917   388 solver.cpp:213] Iteration 937, loss = 0.000385301
I0621 04:17:12.452186   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000384139 (* 1 = 0.000384139 loss)
I0621 04:17:12.452263   388 solver.cpp:473] Iteration 937, lr = 0.01
I0621 04:17:24.854218   388 solver.cpp:213] Iteration 938, loss = 0.000385063
I0621 04:17:24.854302   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000385069 (* 1 = 0.000385069 loss)
I0621 04:17:24.854326   388 solver.cpp:473] Iteration 938, lr = 0.01
I0621 04:17:37.106907   388 solver.cpp:213] Iteration 939, loss = 0.000384609
I0621 04:17:37.106986   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0003852 (* 1 = 0.0003852 loss)
I0621 04:17:37.107031   388 solver.cpp:473] Iteration 939, lr = 0.01
I0621 04:17:49.360169   388 solver.cpp:213] Iteration 940, loss = 0.000384329
I0621 04:17:49.360373   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000384313 (* 1 = 0.000384313 loss)
I0621 04:17:49.360401   388 solver.cpp:473] Iteration 940, lr = 0.01
I0621 04:18:01.663615   388 solver.cpp:213] Iteration 941, loss = 0.000384112
I0621 04:18:01.663700   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000383776 (* 1 = 0.000383776 loss)
I0621 04:18:01.663723   388 solver.cpp:473] Iteration 941, lr = 0.01
I0621 04:18:13.953233   388 solver.cpp:213] Iteration 942, loss = 0.000383755
I0621 04:18:13.953313   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000383795 (* 1 = 0.000383795 loss)
I0621 04:18:13.953335   388 solver.cpp:473] Iteration 942, lr = 0.01
I0621 04:18:26.195780   388 solver.cpp:213] Iteration 943, loss = 0.000383297
I0621 04:18:26.196071   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000383383 (* 1 = 0.000383383 loss)
I0621 04:18:26.196102   388 solver.cpp:473] Iteration 943, lr = 0.01
I0621 04:18:38.572890   388 solver.cpp:213] Iteration 944, loss = 0.000383068
I0621 04:18:38.572974   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000382863 (* 1 = 0.000382863 loss)
I0621 04:18:38.572996   388 solver.cpp:473] Iteration 944, lr = 0.01
I0621 04:18:51.004915   388 solver.cpp:213] Iteration 945, loss = 0.000382696
I0621 04:18:51.004998   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000382337 (* 1 = 0.000382337 loss)
I0621 04:18:51.005026   388 solver.cpp:473] Iteration 945, lr = 0.01
I0621 04:19:03.232554   388 solver.cpp:213] Iteration 946, loss = 0.000382277
I0621 04:19:03.232731   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000381933 (* 1 = 0.000381933 loss)
I0621 04:19:03.232770   388 solver.cpp:473] Iteration 946, lr = 0.01
I0621 04:19:15.633338   388 solver.cpp:213] Iteration 947, loss = 0.00038207
I0621 04:19:15.633421   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00038259 (* 1 = 0.00038259 loss)
I0621 04:19:15.633445   388 solver.cpp:473] Iteration 947, lr = 0.01
I0621 04:19:27.890543   388 solver.cpp:213] Iteration 948, loss = 0.000381868
I0621 04:19:27.890625   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000382458 (* 1 = 0.000382458 loss)
I0621 04:19:27.890646   388 solver.cpp:473] Iteration 948, lr = 0.01
I0621 04:19:40.110621   388 solver.cpp:213] Iteration 949, loss = 0.000381374
I0621 04:19:40.110788   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000381949 (* 1 = 0.000381949 loss)
I0621 04:19:40.110813   388 solver.cpp:473] Iteration 949, lr = 0.01
I0621 04:19:52.334381   388 solver.cpp:213] Iteration 950, loss = 0.000381213
I0621 04:19:52.334465   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000381089 (* 1 = 0.000381089 loss)
I0621 04:19:52.334489   388 solver.cpp:473] Iteration 950, lr = 0.01
I0621 04:20:04.545720   388 solver.cpp:213] Iteration 951, loss = 0.000380902
I0621 04:20:04.545804   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000380537 (* 1 = 0.000380537 loss)
I0621 04:20:04.545826   388 solver.cpp:473] Iteration 951, lr = 0.01
I0621 04:20:16.782218   388 solver.cpp:213] Iteration 952, loss = 0.000380535
I0621 04:20:16.782403   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000380619 (* 1 = 0.000380619 loss)
I0621 04:20:16.782428   388 solver.cpp:473] Iteration 952, lr = 0.01
I0621 04:20:28.997126   388 solver.cpp:213] Iteration 953, loss = 0.000380162
I0621 04:20:28.997203   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000380317 (* 1 = 0.000380317 loss)
I0621 04:20:28.997225   388 solver.cpp:473] Iteration 953, lr = 0.01
I0621 04:20:41.215991   388 solver.cpp:213] Iteration 954, loss = 0.000379798
I0621 04:20:41.216074   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000379926 (* 1 = 0.000379926 loss)
I0621 04:20:41.216096   388 solver.cpp:473] Iteration 954, lr = 0.01
I0621 04:20:53.448072   388 solver.cpp:213] Iteration 955, loss = 0.000379685
I0621 04:20:53.448300   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00038033 (* 1 = 0.00038033 loss)
I0621 04:20:53.448324   388 solver.cpp:473] Iteration 955, lr = 0.01
I0621 04:21:05.704375   388 solver.cpp:213] Iteration 956, loss = 0.000379268
I0621 04:21:05.704457   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000379682 (* 1 = 0.000379682 loss)
I0621 04:21:05.704478   388 solver.cpp:473] Iteration 956, lr = 0.01
I0621 04:21:17.987197   388 solver.cpp:213] Iteration 957, loss = 0.00037896
I0621 04:21:17.987279   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000378399 (* 1 = 0.000378399 loss)
I0621 04:21:17.987301   388 solver.cpp:473] Iteration 957, lr = 0.01
I0621 04:21:30.274006   388 solver.cpp:213] Iteration 958, loss = 0.000378618
I0621 04:21:30.274184   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0003786 (* 1 = 0.0003786 loss)
I0621 04:21:30.274209   388 solver.cpp:473] Iteration 958, lr = 0.01
I0621 04:21:42.545596   388 solver.cpp:213] Iteration 959, loss = 0.000378385
I0621 04:21:42.545680   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000378582 (* 1 = 0.000378582 loss)
I0621 04:21:42.545701   388 solver.cpp:473] Iteration 959, lr = 0.01
I0621 04:21:55.006829   388 solver.cpp:213] Iteration 960, loss = 0.000378069
I0621 04:21:55.006958   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00037823 (* 1 = 0.00037823 loss)
I0621 04:21:55.006984   388 solver.cpp:473] Iteration 960, lr = 0.01
I0621 04:22:07.385843   388 solver.cpp:213] Iteration 961, loss = 0.000377845
I0621 04:22:07.386071   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000377722 (* 1 = 0.000377722 loss)
I0621 04:22:07.386106   388 solver.cpp:473] Iteration 961, lr = 0.01
I0621 04:22:19.644150   388 solver.cpp:213] Iteration 962, loss = 0.000377451
I0621 04:22:19.644233   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000377722 (* 1 = 0.000377722 loss)
I0621 04:22:19.644256   388 solver.cpp:473] Iteration 962, lr = 0.01
I0621 04:22:31.925568   388 solver.cpp:213] Iteration 963, loss = 0.000376963
I0621 04:22:31.925652   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00037719 (* 1 = 0.00037719 loss)
I0621 04:22:31.925673   388 solver.cpp:473] Iteration 963, lr = 0.01
I0621 04:22:44.252708   388 solver.cpp:213] Iteration 964, loss = 0.000376669
I0621 04:22:44.252928   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000377533 (* 1 = 0.000377533 loss)
I0621 04:22:44.252959   388 solver.cpp:473] Iteration 964, lr = 0.01
I0621 04:22:56.554510   388 solver.cpp:213] Iteration 965, loss = 0.000376507
I0621 04:22:56.554606   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00037724 (* 1 = 0.00037724 loss)
I0621 04:22:56.554630   388 solver.cpp:473] Iteration 965, lr = 0.01
I0621 04:23:08.819849   388 solver.cpp:213] Iteration 966, loss = 0.000376191
I0621 04:23:08.819932   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000376152 (* 1 = 0.000376152 loss)
I0621 04:23:08.819954   388 solver.cpp:473] Iteration 966, lr = 0.01
I0621 04:23:21.084111   388 solver.cpp:213] Iteration 967, loss = 0.000375761
I0621 04:23:21.084312   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000375586 (* 1 = 0.000375586 loss)
I0621 04:23:21.084338   388 solver.cpp:473] Iteration 967, lr = 0.01
I0621 04:23:33.316608   388 solver.cpp:213] Iteration 968, loss = 0.000375623
I0621 04:23:33.316694   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000375415 (* 1 = 0.000375415 loss)
I0621 04:23:33.316715   388 solver.cpp:473] Iteration 968, lr = 0.01
I0621 04:23:45.540784   388 solver.cpp:213] Iteration 969, loss = 0.000375019
I0621 04:23:45.540866   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000374472 (* 1 = 0.000374472 loss)
I0621 04:23:45.540889   388 solver.cpp:473] Iteration 969, lr = 0.01
I0621 04:23:57.755317   388 solver.cpp:213] Iteration 970, loss = 0.000374791
I0621 04:23:57.755498   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000374256 (* 1 = 0.000374256 loss)
I0621 04:23:57.755523   388 solver.cpp:473] Iteration 970, lr = 0.01
I0621 04:24:09.976169   388 solver.cpp:213] Iteration 971, loss = 0.000374524
I0621 04:24:09.976253   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000374524 (* 1 = 0.000374524 loss)
I0621 04:24:09.976274   388 solver.cpp:473] Iteration 971, lr = 0.01
I0621 04:24:22.202718   388 solver.cpp:213] Iteration 972, loss = 0.000374459
I0621 04:24:22.202790   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000374614 (* 1 = 0.000374614 loss)
I0621 04:24:22.202810   388 solver.cpp:473] Iteration 972, lr = 0.01
I0621 04:24:34.427474   388 solver.cpp:213] Iteration 973, loss = 0.000374055
I0621 04:24:34.427944   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000374167 (* 1 = 0.000374167 loss)
I0621 04:24:34.427969   388 solver.cpp:473] Iteration 973, lr = 0.01
I0621 04:24:46.650079   388 solver.cpp:213] Iteration 974, loss = 0.000373661
I0621 04:24:46.650146   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000374094 (* 1 = 0.000374094 loss)
I0621 04:24:46.650164   388 solver.cpp:473] Iteration 974, lr = 0.01
I0621 04:24:58.876955   388 solver.cpp:213] Iteration 975, loss = 0.00037356
I0621 04:24:58.877034   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000373615 (* 1 = 0.000373615 loss)
I0621 04:24:58.877055   388 solver.cpp:473] Iteration 975, lr = 0.01
I0621 04:25:11.121402   388 solver.cpp:213] Iteration 976, loss = 0.000373191
I0621 04:25:11.121626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000373411 (* 1 = 0.000373411 loss)
I0621 04:25:11.121670   388 solver.cpp:473] Iteration 976, lr = 0.01
I0621 04:25:23.434886   388 solver.cpp:213] Iteration 977, loss = 0.000372793
I0621 04:25:23.434968   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000372518 (* 1 = 0.000372518 loss)
I0621 04:25:23.434991   388 solver.cpp:473] Iteration 977, lr = 0.01
I0621 04:25:35.834782   388 solver.cpp:213] Iteration 978, loss = 0.000372624
I0621 04:25:35.834866   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000372774 (* 1 = 0.000372774 loss)
I0621 04:25:35.834888   388 solver.cpp:473] Iteration 978, lr = 0.01
I0621 04:25:48.160472   388 solver.cpp:213] Iteration 979, loss = 0.00037216
I0621 04:25:48.160707   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000372213 (* 1 = 0.000372213 loss)
I0621 04:25:48.160755   388 solver.cpp:473] Iteration 979, lr = 0.01
I0621 04:26:00.667655   388 solver.cpp:213] Iteration 980, loss = 0.000371867
I0621 04:26:00.667735   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000372158 (* 1 = 0.000372158 loss)
I0621 04:26:00.667758   388 solver.cpp:473] Iteration 980, lr = 0.01
I0621 04:26:12.976039   388 solver.cpp:213] Iteration 981, loss = 0.00037168
I0621 04:26:12.976121   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000371676 (* 1 = 0.000371676 loss)
I0621 04:26:12.976143   388 solver.cpp:473] Iteration 981, lr = 0.01
I0621 04:26:25.276351   388 solver.cpp:213] Iteration 982, loss = 0.000371329
I0621 04:26:25.276566   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000371062 (* 1 = 0.000371062 loss)
I0621 04:26:25.276600   388 solver.cpp:473] Iteration 982, lr = 0.01
I0621 04:26:37.640476   388 solver.cpp:213] Iteration 983, loss = 0.000371023
I0621 04:26:37.640561   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000371769 (* 1 = 0.000371769 loss)
I0621 04:26:37.640583   388 solver.cpp:473] Iteration 983, lr = 0.01
I0621 04:26:50.002001   388 solver.cpp:213] Iteration 984, loss = 0.000370703
I0621 04:26:50.002091   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000370679 (* 1 = 0.000370679 loss)
I0621 04:26:50.002118   388 solver.cpp:473] Iteration 984, lr = 0.01
I0621 04:27:02.412304   388 solver.cpp:213] Iteration 985, loss = 0.000370413
I0621 04:27:02.412521   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000370761 (* 1 = 0.000370761 loss)
I0621 04:27:02.412549   388 solver.cpp:473] Iteration 985, lr = 0.01
I0621 04:27:14.721724   388 solver.cpp:213] Iteration 986, loss = 0.00037015
I0621 04:27:14.721813   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000369444 (* 1 = 0.000369444 loss)
I0621 04:27:14.721837   388 solver.cpp:473] Iteration 986, lr = 0.01
I0621 04:27:27.002573   388 solver.cpp:213] Iteration 987, loss = 0.000369893
I0621 04:27:27.002660   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000369959 (* 1 = 0.000369959 loss)
I0621 04:27:27.002681   388 solver.cpp:473] Iteration 987, lr = 0.01
I0621 04:27:39.277993   388 solver.cpp:213] Iteration 988, loss = 0.000369441
I0621 04:27:39.278177   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000369357 (* 1 = 0.000369357 loss)
I0621 04:27:39.278204   388 solver.cpp:473] Iteration 988, lr = 0.01
I0621 04:27:51.582010   388 solver.cpp:213] Iteration 989, loss = 0.000369196
I0621 04:27:51.582090   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000368876 (* 1 = 0.000368876 loss)
I0621 04:27:51.582113   388 solver.cpp:473] Iteration 989, lr = 0.01
I0621 04:28:03.885071   388 solver.cpp:213] Iteration 990, loss = 0.000368952
I0621 04:28:03.885154   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000368544 (* 1 = 0.000368544 loss)
I0621 04:28:03.885175   388 solver.cpp:473] Iteration 990, lr = 0.01
I0621 04:28:16.152329   388 solver.cpp:213] Iteration 991, loss = 0.00036856
I0621 04:28:16.152580   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000368606 (* 1 = 0.000368606 loss)
I0621 04:28:16.152627   388 solver.cpp:473] Iteration 991, lr = 0.01
I0621 04:28:28.388847   388 solver.cpp:213] Iteration 992, loss = 0.000368275
I0621 04:28:28.388936   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000369118 (* 1 = 0.000369118 loss)
I0621 04:28:28.388960   388 solver.cpp:473] Iteration 992, lr = 0.01
I0621 04:28:40.687170   388 solver.cpp:213] Iteration 993, loss = 0.00036826
I0621 04:28:40.687258   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000367901 (* 1 = 0.000367901 loss)
I0621 04:28:40.687290   388 solver.cpp:473] Iteration 993, lr = 0.01
I0621 04:28:52.960299   388 solver.cpp:213] Iteration 994, loss = 0.000367648
I0621 04:28:52.960480   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000367977 (* 1 = 0.000367977 loss)
I0621 04:28:52.960505   388 solver.cpp:473] Iteration 994, lr = 0.01
I0621 04:29:05.200672   388 solver.cpp:213] Iteration 995, loss = 0.000367567
I0621 04:29:05.200755   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000367612 (* 1 = 0.000367612 loss)
I0621 04:29:05.200778   388 solver.cpp:473] Iteration 995, lr = 0.01
I0621 04:29:17.451480   388 solver.cpp:213] Iteration 996, loss = 0.000367171
I0621 04:29:17.451563   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00036675 (* 1 = 0.00036675 loss)
I0621 04:29:17.451584   388 solver.cpp:473] Iteration 996, lr = 0.01
I0621 04:29:29.735388   388 solver.cpp:213] Iteration 997, loss = 0.000366919
I0621 04:29:29.735633   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000366549 (* 1 = 0.000366549 loss)
I0621 04:29:29.735658   388 solver.cpp:473] Iteration 997, lr = 0.01
I0621 04:29:41.963625   388 solver.cpp:213] Iteration 998, loss = 0.000366608
I0621 04:29:41.963713   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00036666 (* 1 = 0.00036666 loss)
I0621 04:29:41.963737   388 solver.cpp:473] Iteration 998, lr = 0.01
I0621 04:29:54.269951   388 solver.cpp:213] Iteration 999, loss = 0.0003663
I0621 04:29:54.270071   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000366011 (* 1 = 0.000366011 loss)
I0621 04:29:54.270108   388 solver.cpp:473] Iteration 999, lr = 0.01
I0621 04:29:58.689978   388 solver.cpp:362] Snapshotting to ./snapshot/latefusion-_iter_1000.caffemodel
I0621 04:30:17.889194   388 solver.cpp:370] Snapshotting solver state to ./snapshot/latefusion-_iter_1000.solverstate
I0621 04:30:21.065117   388 solver.cpp:291] Iteration 1000, Testing net (#0)
I0621 04:34:07.516072   388 solver.cpp:342]     Test net output #0: seg-accuracy = 1
I0621 04:34:07.516286   388 solver.cpp:342]     Test net output #1: seg-loss = 0.000365994 (* 1 = 0.000365994 loss)
I0621 04:34:19.395668   388 solver.cpp:213] Iteration 1000, loss = 0.000365922
I0621 04:34:19.395747   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000365892 (* 1 = 0.000365892 loss)
I0621 04:34:19.395769   388 solver.cpp:473] Iteration 1000, lr = 0.01
I0621 04:34:31.694785   388 solver.cpp:213] Iteration 1001, loss = 0.000365807
I0621 04:34:31.694871   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000365572 (* 1 = 0.000365572 loss)
I0621 04:34:31.694893   388 solver.cpp:473] Iteration 1001, lr = 0.01
I0621 04:34:44.027021   388 solver.cpp:213] Iteration 1002, loss = 0.000365573
I0621 04:34:44.027223   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000365467 (* 1 = 0.000365467 loss)
I0621 04:34:44.027248   388 solver.cpp:473] Iteration 1002, lr = 0.01
I0621 04:34:56.286607   388 solver.cpp:213] Iteration 1003, loss = 0.000365019
I0621 04:34:56.286689   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000364331 (* 1 = 0.000364331 loss)
I0621 04:34:56.286711   388 solver.cpp:473] Iteration 1003, lr = 0.01
I0621 04:35:08.667480   388 solver.cpp:213] Iteration 1004, loss = 0.000364864
I0621 04:35:08.667565   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000364878 (* 1 = 0.000364878 loss)
I0621 04:35:08.667587   388 solver.cpp:473] Iteration 1004, lr = 0.01
I0621 04:35:20.973098   388 solver.cpp:213] Iteration 1005, loss = 0.000364457
I0621 04:35:20.973352   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000364194 (* 1 = 0.000364194 loss)
I0621 04:35:20.973398   388 solver.cpp:473] Iteration 1005, lr = 0.01
I0621 04:35:33.341203   388 solver.cpp:213] Iteration 1006, loss = 0.000364348
I0621 04:35:33.341286   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000364356 (* 1 = 0.000364356 loss)
I0621 04:35:33.341308   388 solver.cpp:473] Iteration 1006, lr = 0.01
I0621 04:35:45.661558   388 solver.cpp:213] Iteration 1007, loss = 0.000363928
I0621 04:35:45.661643   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000364033 (* 1 = 0.000364033 loss)
I0621 04:35:45.661667   388 solver.cpp:473] Iteration 1007, lr = 0.01
I0621 04:35:57.905704   388 solver.cpp:213] Iteration 1008, loss = 0.000363613
I0621 04:35:57.905891   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000363679 (* 1 = 0.000363679 loss)
I0621 04:35:57.905917   388 solver.cpp:473] Iteration 1008, lr = 0.01
I0621 04:36:10.144902   388 solver.cpp:213] Iteration 1009, loss = 0.000363541
I0621 04:36:10.144987   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000363409 (* 1 = 0.000363409 loss)
I0621 04:36:10.145010   388 solver.cpp:473] Iteration 1009, lr = 0.01
I0621 04:36:22.482357   388 solver.cpp:213] Iteration 1010, loss = 0.000363208
I0621 04:36:22.482441   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000363087 (* 1 = 0.000363087 loss)
I0621 04:36:22.482463   388 solver.cpp:473] Iteration 1010, lr = 0.01
I0621 04:36:34.803915   388 solver.cpp:213] Iteration 1011, loss = 0.000362907
I0621 04:36:34.804100   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000363125 (* 1 = 0.000363125 loss)
I0621 04:36:34.804123   388 solver.cpp:473] Iteration 1011, lr = 0.01
I0621 04:36:47.113698   388 solver.cpp:213] Iteration 1012, loss = 0.000362612
I0621 04:36:47.113782   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000362619 (* 1 = 0.000362619 loss)
I0621 04:36:47.113806   388 solver.cpp:473] Iteration 1012, lr = 0.01
I0621 04:36:59.452481   388 solver.cpp:213] Iteration 1013, loss = 0.00036233
I0621 04:36:59.452559   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000362672 (* 1 = 0.000362672 loss)
I0621 04:36:59.452582   388 solver.cpp:473] Iteration 1013, lr = 0.01
I0621 04:37:11.760609   388 solver.cpp:213] Iteration 1014, loss = 0.000362094
I0621 04:37:11.760887   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000362422 (* 1 = 0.000362422 loss)
I0621 04:37:11.760975   388 solver.cpp:473] Iteration 1014, lr = 0.01
I0621 04:37:24.008728   388 solver.cpp:213] Iteration 1015, loss = 0.000361572
I0621 04:37:24.008811   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000361288 (* 1 = 0.000361288 loss)
I0621 04:37:24.008846   388 solver.cpp:473] Iteration 1015, lr = 0.01
I0621 04:37:36.283468   388 solver.cpp:213] Iteration 1016, loss = 0.000361441
I0621 04:37:36.283552   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000360778 (* 1 = 0.000360778 loss)
I0621 04:37:36.283574   388 solver.cpp:473] Iteration 1016, lr = 0.01
I0621 04:37:48.520597   388 solver.cpp:213] Iteration 1017, loss = 0.000361161
I0621 04:37:48.521198   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000361731 (* 1 = 0.000361731 loss)
I0621 04:37:48.521260   388 solver.cpp:473] Iteration 1017, lr = 0.01
I0621 04:38:00.865013   388 solver.cpp:213] Iteration 1018, loss = 0.000360938
I0621 04:38:00.865136   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0003613 (* 1 = 0.0003613 loss)
I0621 04:38:00.865175   388 solver.cpp:473] Iteration 1018, lr = 0.01
I0621 04:38:13.204123   388 solver.cpp:213] Iteration 1019, loss = 0.000360744
I0621 04:38:13.204216   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000361034 (* 1 = 0.000361034 loss)
I0621 04:38:13.204241   388 solver.cpp:473] Iteration 1019, lr = 0.01
I0621 04:38:25.493901   388 solver.cpp:213] Iteration 1020, loss = 0.000360164
I0621 04:38:25.494098   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000360126 (* 1 = 0.000360126 loss)
I0621 04:38:25.494123   388 solver.cpp:473] Iteration 1020, lr = 0.01
I0621 04:38:37.981147   388 solver.cpp:213] Iteration 1021, loss = 0.00036
I0621 04:38:37.981230   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000360073 (* 1 = 0.000360073 loss)
I0621 04:38:37.981252   388 solver.cpp:473] Iteration 1021, lr = 0.01
I0621 04:38:50.268187   388 solver.cpp:213] Iteration 1022, loss = 0.000359708
I0621 04:38:50.268280   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000359674 (* 1 = 0.000359674 loss)
I0621 04:38:50.268304   388 solver.cpp:473] Iteration 1022, lr = 0.01
I0621 04:39:02.642160   388 solver.cpp:213] Iteration 1023, loss = 0.000359508
I0621 04:39:02.642349   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000359336 (* 1 = 0.000359336 loss)
I0621 04:39:02.642375   388 solver.cpp:473] Iteration 1023, lr = 0.01
I0621 04:39:14.967372   388 solver.cpp:213] Iteration 1024, loss = 0.000359188
I0621 04:39:14.967458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000359417 (* 1 = 0.000359417 loss)
I0621 04:39:14.967479   388 solver.cpp:473] Iteration 1024, lr = 0.01
I0621 04:39:27.249007   388 solver.cpp:213] Iteration 1025, loss = 0.000358851
I0621 04:39:27.249089   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00035889 (* 1 = 0.00035889 loss)
I0621 04:39:27.249111   388 solver.cpp:473] Iteration 1025, lr = 0.01
I0621 04:39:39.555249   388 solver.cpp:213] Iteration 1026, loss = 0.000358597
I0621 04:39:39.555495   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000358534 (* 1 = 0.000358534 loss)
I0621 04:39:39.555536   388 solver.cpp:473] Iteration 1026, lr = 0.01
I0621 04:39:51.904258   388 solver.cpp:213] Iteration 1027, loss = 0.000358442
I0621 04:39:51.904345   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000358463 (* 1 = 0.000358463 loss)
I0621 04:39:51.904366   388 solver.cpp:473] Iteration 1027, lr = 0.01
I0621 04:40:04.147718   388 solver.cpp:213] Iteration 1028, loss = 0.000358283
I0621 04:40:04.147797   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000358844 (* 1 = 0.000358844 loss)
I0621 04:40:04.147820   388 solver.cpp:473] Iteration 1028, lr = 0.01
I0621 04:40:16.431015   388 solver.cpp:213] Iteration 1029, loss = 0.000357912
I0621 04:40:16.431224   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00035841 (* 1 = 0.00035841 loss)
I0621 04:40:16.431252   388 solver.cpp:473] Iteration 1029, lr = 0.01
I0621 04:40:28.847235   388 solver.cpp:213] Iteration 1030, loss = 0.000357409
I0621 04:40:28.847321   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000357369 (* 1 = 0.000357369 loss)
I0621 04:40:28.847345   388 solver.cpp:473] Iteration 1030, lr = 0.01
I0621 04:40:41.263505   388 solver.cpp:213] Iteration 1031, loss = 0.000357333
I0621 04:40:41.263602   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000357639 (* 1 = 0.000357639 loss)
I0621 04:40:41.263628   388 solver.cpp:473] Iteration 1031, lr = 0.01
I0621 04:40:53.638404   388 solver.cpp:213] Iteration 1032, loss = 0.000356975
I0621 04:40:53.638672   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000356286 (* 1 = 0.000356286 loss)
I0621 04:40:53.638710   388 solver.cpp:473] Iteration 1032, lr = 0.01
I0621 04:41:06.067840   388 solver.cpp:213] Iteration 1033, loss = 0.000356749
I0621 04:41:06.067926   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000357436 (* 1 = 0.000357436 loss)
I0621 04:41:06.067950   388 solver.cpp:473] Iteration 1033, lr = 0.01
I0621 04:41:18.482121   388 solver.cpp:213] Iteration 1034, loss = 0.000356391
I0621 04:41:18.482208   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00035663 (* 1 = 0.00035663 loss)
I0621 04:41:18.482234   388 solver.cpp:473] Iteration 1034, lr = 0.01
I0621 04:41:30.853046   388 solver.cpp:213] Iteration 1035, loss = 0.000356192
I0621 04:41:30.853253   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000356246 (* 1 = 0.000356246 loss)
I0621 04:41:30.853286   388 solver.cpp:473] Iteration 1035, lr = 0.01
I0621 04:41:43.122141   388 solver.cpp:213] Iteration 1036, loss = 0.000355916
I0621 04:41:43.122228   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000356028 (* 1 = 0.000356028 loss)
I0621 04:41:43.122252   388 solver.cpp:473] Iteration 1036, lr = 0.01
I0621 04:41:55.488486   388 solver.cpp:213] Iteration 1037, loss = 0.000355595
I0621 04:41:55.488567   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000355929 (* 1 = 0.000355929 loss)
I0621 04:41:55.488590   388 solver.cpp:473] Iteration 1037, lr = 0.01
I0621 04:42:07.744488   388 solver.cpp:213] Iteration 1038, loss = 0.000355344
I0621 04:42:07.747823   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000355418 (* 1 = 0.000355418 loss)
I0621 04:42:07.747922   388 solver.cpp:473] Iteration 1038, lr = 0.01
I0621 04:42:20.187990   388 solver.cpp:213] Iteration 1039, loss = 0.000354988
I0621 04:42:20.188092   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000355621 (* 1 = 0.000355621 loss)
I0621 04:42:20.188125   388 solver.cpp:473] Iteration 1039, lr = 0.01
I0621 04:42:32.506996   388 solver.cpp:213] Iteration 1040, loss = 0.000354738
I0621 04:42:32.507091   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000354482 (* 1 = 0.000354482 loss)
I0621 04:42:32.507115   388 solver.cpp:473] Iteration 1040, lr = 0.01
I0621 04:42:44.763509   388 solver.cpp:213] Iteration 1041, loss = 0.000354442
I0621 04:42:44.763705   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000354389 (* 1 = 0.000354389 loss)
I0621 04:42:44.763730   388 solver.cpp:473] Iteration 1041, lr = 0.01
I0621 04:42:57.179230   388 solver.cpp:213] Iteration 1042, loss = 0.00035427
I0621 04:42:57.179312   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000354519 (* 1 = 0.000354519 loss)
I0621 04:42:57.179335   388 solver.cpp:473] Iteration 1042, lr = 0.01
I0621 04:43:09.544195   388 solver.cpp:213] Iteration 1043, loss = 0.00035392
I0621 04:43:09.544288   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000354562 (* 1 = 0.000354562 loss)
I0621 04:43:09.544314   388 solver.cpp:473] Iteration 1043, lr = 0.01
I0621 04:43:21.976411   388 solver.cpp:213] Iteration 1044, loss = 0.000353853
I0621 04:43:21.976657   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000353972 (* 1 = 0.000353972 loss)
I0621 04:43:21.976713   388 solver.cpp:473] Iteration 1044, lr = 0.01
I0621 04:43:34.405212   388 solver.cpp:213] Iteration 1045, loss = 0.000353433
I0621 04:43:34.405297   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000353443 (* 1 = 0.000353443 loss)
I0621 04:43:34.405321   388 solver.cpp:473] Iteration 1045, lr = 0.01
I0621 04:43:46.692654   388 solver.cpp:213] Iteration 1046, loss = 0.000353193
I0621 04:43:46.692736   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000353607 (* 1 = 0.000353607 loss)
I0621 04:43:46.692759   388 solver.cpp:473] Iteration 1046, lr = 0.01
I0621 04:43:59.000671   388 solver.cpp:213] Iteration 1047, loss = 0.000352907
I0621 04:43:59.000957   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000352493 (* 1 = 0.000352493 loss)
I0621 04:43:59.001005   388 solver.cpp:473] Iteration 1047, lr = 0.01
I0621 04:44:11.474977   388 solver.cpp:213] Iteration 1048, loss = 0.000352527
I0621 04:44:11.475059   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000352416 (* 1 = 0.000352416 loss)
I0621 04:44:11.475090   388 solver.cpp:473] Iteration 1048, lr = 0.01
I0621 04:44:23.755376   388 solver.cpp:213] Iteration 1049, loss = 0.000352389
I0621 04:44:23.755462   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000351945 (* 1 = 0.000351945 loss)
I0621 04:44:23.755486   388 solver.cpp:473] Iteration 1049, lr = 0.01
I0621 04:44:36.120434   388 solver.cpp:213] Iteration 1050, loss = 0.00035222
I0621 04:44:36.120626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000352094 (* 1 = 0.000352094 loss)
I0621 04:44:36.120654   388 solver.cpp:473] Iteration 1050, lr = 0.01
I0621 04:44:48.374322   388 solver.cpp:213] Iteration 1051, loss = 0.000351851
I0621 04:44:48.374406   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000351677 (* 1 = 0.000351677 loss)
I0621 04:44:48.374429   388 solver.cpp:473] Iteration 1051, lr = 0.01
I0621 04:45:00.738250   388 solver.cpp:213] Iteration 1052, loss = 0.000351585
I0621 04:45:00.738334   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000352261 (* 1 = 0.000352261 loss)
I0621 04:45:00.738356   388 solver.cpp:473] Iteration 1052, lr = 0.01
I0621 04:45:13.014281   388 solver.cpp:213] Iteration 1053, loss = 0.000351232
I0621 04:45:13.014456   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000351505 (* 1 = 0.000351505 loss)
I0621 04:45:13.014479   388 solver.cpp:473] Iteration 1053, lr = 0.01
I0621 04:45:25.265578   388 solver.cpp:213] Iteration 1054, loss = 0.000350985
I0621 04:45:25.265662   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000350992 (* 1 = 0.000350992 loss)
I0621 04:45:25.265686   388 solver.cpp:473] Iteration 1054, lr = 0.01
I0621 04:45:37.705102   388 solver.cpp:213] Iteration 1055, loss = 0.000350724
I0621 04:45:37.705188   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00035095 (* 1 = 0.00035095 loss)
I0621 04:45:37.705210   388 solver.cpp:473] Iteration 1055, lr = 0.01
I0621 04:45:50.029645   388 solver.cpp:213] Iteration 1056, loss = 0.000350528
I0621 04:45:50.029875   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000350352 (* 1 = 0.000350352 loss)
I0621 04:45:50.029909   388 solver.cpp:473] Iteration 1056, lr = 0.01
I0621 04:46:02.345721   388 solver.cpp:213] Iteration 1057, loss = 0.000350238
I0621 04:46:02.345809   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000350946 (* 1 = 0.000350946 loss)
I0621 04:46:02.345832   388 solver.cpp:473] Iteration 1057, lr = 0.01
I0621 04:46:14.716861   388 solver.cpp:213] Iteration 1058, loss = 0.000350077
I0621 04:46:14.716945   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000350037 (* 1 = 0.000350037 loss)
I0621 04:46:14.716967   388 solver.cpp:473] Iteration 1058, lr = 0.01
I0621 04:46:27.030005   388 solver.cpp:213] Iteration 1059, loss = 0.000349696
I0621 04:46:27.030292   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000349703 (* 1 = 0.000349703 loss)
I0621 04:46:27.030341   388 solver.cpp:473] Iteration 1059, lr = 0.01
I0621 04:46:39.479274   388 solver.cpp:213] Iteration 1060, loss = 0.000349553
I0621 04:46:39.479352   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000349967 (* 1 = 0.000349967 loss)
I0621 04:46:39.479375   388 solver.cpp:473] Iteration 1060, lr = 0.01
I0621 04:46:51.829465   388 solver.cpp:213] Iteration 1061, loss = 0.000349139
I0621 04:46:51.829555   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000349947 (* 1 = 0.000349947 loss)
I0621 04:46:51.829576   388 solver.cpp:473] Iteration 1061, lr = 0.01
I0621 04:47:04.116237   388 solver.cpp:213] Iteration 1062, loss = 0.000348979
I0621 04:47:04.116457   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000348902 (* 1 = 0.000348902 loss)
I0621 04:47:04.116492   388 solver.cpp:473] Iteration 1062, lr = 0.01
I0621 04:47:16.486781   388 solver.cpp:213] Iteration 1063, loss = 0.000348741
I0621 04:47:16.486863   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000348982 (* 1 = 0.000348982 loss)
I0621 04:47:16.486886   388 solver.cpp:473] Iteration 1063, lr = 0.01
I0621 04:47:28.778484   388 solver.cpp:213] Iteration 1064, loss = 0.000348392
I0621 04:47:28.778568   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000347873 (* 1 = 0.000347873 loss)
I0621 04:47:28.778596   388 solver.cpp:473] Iteration 1064, lr = 0.01
I0621 04:47:41.063828   388 solver.cpp:213] Iteration 1065, loss = 0.000348184
I0621 04:47:41.064050   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000347632 (* 1 = 0.000347632 loss)
I0621 04:47:41.064092   388 solver.cpp:473] Iteration 1065, lr = 0.01
I0621 04:47:53.448376   388 solver.cpp:213] Iteration 1066, loss = 0.000347864
I0621 04:47:53.448460   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000348204 (* 1 = 0.000348204 loss)
I0621 04:47:53.448483   388 solver.cpp:473] Iteration 1066, lr = 0.01
I0621 04:48:05.700776   388 solver.cpp:213] Iteration 1067, loss = 0.000347677
I0621 04:48:05.700855   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000347709 (* 1 = 0.000347709 loss)
I0621 04:48:05.700875   388 solver.cpp:473] Iteration 1067, lr = 0.01
I0621 04:48:18.002490   388 solver.cpp:213] Iteration 1068, loss = 0.000347273
I0621 04:48:18.002702   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000347274 (* 1 = 0.000347274 loss)
I0621 04:48:18.002759   388 solver.cpp:473] Iteration 1068, lr = 0.01
I0621 04:48:30.277509   388 solver.cpp:213] Iteration 1069, loss = 0.000347149
I0621 04:48:30.277598   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000347132 (* 1 = 0.000347132 loss)
I0621 04:48:30.277622   388 solver.cpp:473] Iteration 1069, lr = 0.01
I0621 04:48:42.615468   388 solver.cpp:213] Iteration 1070, loss = 0.000346883
I0621 04:48:42.615605   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000346877 (* 1 = 0.000346877 loss)
I0621 04:48:42.615658   388 solver.cpp:473] Iteration 1070, lr = 0.01
I0621 04:48:54.920579   388 solver.cpp:213] Iteration 1071, loss = 0.000346551
I0621 04:48:54.920820   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000346414 (* 1 = 0.000346414 loss)
I0621 04:48:54.920874   388 solver.cpp:473] Iteration 1071, lr = 0.01
I0621 04:49:07.287642   388 solver.cpp:213] Iteration 1072, loss = 0.000346314
I0621 04:49:07.287765   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000346323 (* 1 = 0.000346323 loss)
I0621 04:49:07.287804   388 solver.cpp:473] Iteration 1072, lr = 0.01
I0621 04:49:19.722378   388 solver.cpp:213] Iteration 1073, loss = 0.000346155
I0621 04:49:19.722506   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000345155 (* 1 = 0.000345155 loss)
I0621 04:49:19.722540   388 solver.cpp:473] Iteration 1073, lr = 0.01
I0621 04:49:32.095633   388 solver.cpp:213] Iteration 1074, loss = 0.000345905
I0621 04:49:32.095902   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000345871 (* 1 = 0.000345871 loss)
I0621 04:49:32.095950   388 solver.cpp:473] Iteration 1074, lr = 0.01
I0621 04:49:44.399142   388 solver.cpp:213] Iteration 1075, loss = 0.000345477
I0621 04:49:44.399226   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000345839 (* 1 = 0.000345839 loss)
I0621 04:49:44.399248   388 solver.cpp:473] Iteration 1075, lr = 0.01
I0621 04:49:56.803046   388 solver.cpp:213] Iteration 1076, loss = 0.000345202
I0621 04:49:56.803138   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000344914 (* 1 = 0.000344914 loss)
I0621 04:49:56.803166   388 solver.cpp:473] Iteration 1076, lr = 0.01
I0621 04:50:09.075520   388 solver.cpp:213] Iteration 1077, loss = 0.00034504
I0621 04:50:09.075736   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000345099 (* 1 = 0.000345099 loss)
I0621 04:50:09.075767   388 solver.cpp:473] Iteration 1077, lr = 0.01
I0621 04:50:21.460717   388 solver.cpp:213] Iteration 1078, loss = 0.000344845
I0621 04:50:21.460803   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000344735 (* 1 = 0.000344735 loss)
I0621 04:50:21.460825   388 solver.cpp:473] Iteration 1078, lr = 0.01
I0621 04:50:33.824911   388 solver.cpp:213] Iteration 1079, loss = 0.000344542
I0621 04:50:33.824996   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000344311 (* 1 = 0.000344311 loss)
I0621 04:50:33.825021   388 solver.cpp:473] Iteration 1079, lr = 0.01
I0621 04:50:46.194104   388 solver.cpp:213] Iteration 1080, loss = 0.000344271
I0621 04:50:46.194325   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000344132 (* 1 = 0.000344132 loss)
I0621 04:50:46.194377   388 solver.cpp:473] Iteration 1080, lr = 0.01
I0621 04:50:58.478283   388 solver.cpp:213] Iteration 1081, loss = 0.000343976
I0621 04:50:58.478368   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000343561 (* 1 = 0.000343561 loss)
I0621 04:50:58.478392   388 solver.cpp:473] Iteration 1081, lr = 0.01
I0621 04:51:10.746192   388 solver.cpp:213] Iteration 1082, loss = 0.00034379
I0621 04:51:10.746273   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000343178 (* 1 = 0.000343178 loss)
I0621 04:51:10.746294   388 solver.cpp:473] Iteration 1082, lr = 0.01
I0621 04:51:22.993718   388 solver.cpp:213] Iteration 1083, loss = 0.000343547
I0621 04:51:22.993947   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000343902 (* 1 = 0.000343902 loss)
I0621 04:51:22.993980   388 solver.cpp:473] Iteration 1083, lr = 0.01
I0621 04:51:35.340042   388 solver.cpp:213] Iteration 1084, loss = 0.000343196
I0621 04:51:35.340136   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000343003 (* 1 = 0.000343003 loss)
I0621 04:51:35.340162   388 solver.cpp:473] Iteration 1084, lr = 0.01
I0621 04:51:47.674010   388 solver.cpp:213] Iteration 1085, loss = 0.000343011
I0621 04:51:47.674090   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000343036 (* 1 = 0.000343036 loss)
I0621 04:51:47.674113   388 solver.cpp:473] Iteration 1085, lr = 0.01
I0621 04:51:59.919420   388 solver.cpp:213] Iteration 1086, loss = 0.0003428
I0621 04:51:59.920245   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000342914 (* 1 = 0.000342914 loss)
I0621 04:51:59.920271   388 solver.cpp:473] Iteration 1086, lr = 0.01
I0621 04:52:12.250898   388 solver.cpp:213] Iteration 1087, loss = 0.000342515
I0621 04:52:12.250980   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000342266 (* 1 = 0.000342266 loss)
I0621 04:52:12.251003   388 solver.cpp:473] Iteration 1087, lr = 0.01
I0621 04:52:24.576354   388 solver.cpp:213] Iteration 1088, loss = 0.000342291
I0621 04:52:24.576441   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000342552 (* 1 = 0.000342552 loss)
I0621 04:52:24.576463   388 solver.cpp:473] Iteration 1088, lr = 0.01
I0621 04:52:36.847268   388 solver.cpp:213] Iteration 1089, loss = 0.000341901
I0621 04:52:36.847524   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000341598 (* 1 = 0.000341598 loss)
I0621 04:52:36.847559   388 solver.cpp:473] Iteration 1089, lr = 0.01
I0621 04:52:49.149698   388 solver.cpp:213] Iteration 1090, loss = 0.000341665
I0621 04:52:49.149785   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000342014 (* 1 = 0.000342014 loss)
I0621 04:52:49.149809   388 solver.cpp:473] Iteration 1090, lr = 0.01
I0621 04:53:01.428344   388 solver.cpp:213] Iteration 1091, loss = 0.000341406
I0621 04:53:01.428428   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00034128 (* 1 = 0.00034128 loss)
I0621 04:53:01.428452   388 solver.cpp:473] Iteration 1091, lr = 0.01
I0621 04:53:13.721652   388 solver.cpp:213] Iteration 1092, loss = 0.000341109
I0621 04:53:13.721915   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000341265 (* 1 = 0.000341265 loss)
I0621 04:53:13.721961   388 solver.cpp:473] Iteration 1092, lr = 0.01
I0621 04:53:26.075531   388 solver.cpp:213] Iteration 1093, loss = 0.000341014
I0621 04:53:26.075683   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000340905 (* 1 = 0.000340905 loss)
I0621 04:53:26.075711   388 solver.cpp:473] Iteration 1093, lr = 0.01
I0621 04:53:38.432730   388 solver.cpp:213] Iteration 1094, loss = 0.000340814
I0621 04:53:38.432813   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000340677 (* 1 = 0.000340677 loss)
I0621 04:53:38.432837   388 solver.cpp:473] Iteration 1094, lr = 0.01
I0621 04:53:50.749047   388 solver.cpp:213] Iteration 1095, loss = 0.000340397
I0621 04:53:50.749266   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000340402 (* 1 = 0.000340402 loss)
I0621 04:53:50.749297   388 solver.cpp:473] Iteration 1095, lr = 0.01
I0621 04:54:03.075275   388 solver.cpp:213] Iteration 1096, loss = 0.000340217
I0621 04:54:03.079164   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00033988 (* 1 = 0.00033988 loss)
I0621 04:54:03.079234   388 solver.cpp:473] Iteration 1096, lr = 0.01
I0621 04:54:15.399019   388 solver.cpp:213] Iteration 1097, loss = 0.000339852
I0621 04:54:15.399124   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000340247 (* 1 = 0.000340247 loss)
I0621 04:54:15.399149   388 solver.cpp:473] Iteration 1097, lr = 0.01
I0621 04:54:27.750248   388 solver.cpp:213] Iteration 1098, loss = 0.000339798
I0621 04:54:27.750434   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000339994 (* 1 = 0.000339994 loss)
I0621 04:54:27.750478   388 solver.cpp:473] Iteration 1098, lr = 0.01
I0621 04:54:40.094902   388 solver.cpp:213] Iteration 1099, loss = 0.000339584
I0621 04:54:40.094985   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000339718 (* 1 = 0.000339718 loss)
I0621 04:54:40.095010   388 solver.cpp:473] Iteration 1099, lr = 0.01
I0621 04:54:52.561518   388 solver.cpp:213] Iteration 1100, loss = 0.000339165
I0621 04:54:52.561602   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000338648 (* 1 = 0.000338648 loss)
I0621 04:54:52.561626   388 solver.cpp:473] Iteration 1100, lr = 0.01
I0621 04:55:04.870167   388 solver.cpp:213] Iteration 1101, loss = 0.000339084
I0621 04:55:04.870409   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000338982 (* 1 = 0.000338982 loss)
I0621 04:55:04.870471   388 solver.cpp:473] Iteration 1101, lr = 0.01
I0621 04:55:17.275635   388 solver.cpp:213] Iteration 1102, loss = 0.000338716
I0621 04:55:17.275722   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00033878 (* 1 = 0.00033878 loss)
I0621 04:55:17.275744   388 solver.cpp:473] Iteration 1102, lr = 0.01
I0621 04:55:29.620651   388 solver.cpp:213] Iteration 1103, loss = 0.000338389
I0621 04:55:29.620736   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000338111 (* 1 = 0.000338111 loss)
I0621 04:55:29.620757   388 solver.cpp:473] Iteration 1103, lr = 0.01
I0621 04:55:41.977108   388 solver.cpp:213] Iteration 1104, loss = 0.000338324
I0621 04:55:41.977340   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000338867 (* 1 = 0.000338867 loss)
I0621 04:55:41.977376   388 solver.cpp:473] Iteration 1104, lr = 0.01
I0621 04:55:54.291164   388 solver.cpp:213] Iteration 1105, loss = 0.00033813
I0621 04:55:54.291247   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000338023 (* 1 = 0.000338023 loss)
I0621 04:55:54.291270   388 solver.cpp:473] Iteration 1105, lr = 0.01
I0621 04:56:06.685425   388 solver.cpp:213] Iteration 1106, loss = 0.000337693
I0621 04:56:06.685497   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000337881 (* 1 = 0.000337881 loss)
I0621 04:56:06.685516   388 solver.cpp:473] Iteration 1106, lr = 0.01
I0621 04:56:19.179128   388 solver.cpp:213] Iteration 1107, loss = 0.000337471
I0621 04:56:19.179872   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000337668 (* 1 = 0.000337668 loss)
I0621 04:56:19.179925   388 solver.cpp:473] Iteration 1107, lr = 0.01
I0621 04:56:31.624794   388 solver.cpp:213] Iteration 1108, loss = 0.000337309
I0621 04:56:31.624879   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000337344 (* 1 = 0.000337344 loss)
I0621 04:56:31.624902   388 solver.cpp:473] Iteration 1108, lr = 0.01
I0621 04:56:43.907321   388 solver.cpp:213] Iteration 1109, loss = 0.000337063
I0621 04:56:43.907407   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000337305 (* 1 = 0.000337305 loss)
I0621 04:56:43.907431   388 solver.cpp:473] Iteration 1109, lr = 0.01
I0621 04:56:56.301378   388 solver.cpp:213] Iteration 1110, loss = 0.000336725
I0621 04:56:56.301590   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000336433 (* 1 = 0.000336433 loss)
I0621 04:56:56.301617   388 solver.cpp:473] Iteration 1110, lr = 0.01
I0621 04:57:08.712623   388 solver.cpp:213] Iteration 1111, loss = 0.000336493
I0621 04:57:08.712712   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000336587 (* 1 = 0.000336587 loss)
I0621 04:57:08.712735   388 solver.cpp:473] Iteration 1111, lr = 0.01
I0621 04:57:21.049505   388 solver.cpp:213] Iteration 1112, loss = 0.000336359
I0621 04:57:21.049589   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000335917 (* 1 = 0.000335917 loss)
I0621 04:57:21.049613   388 solver.cpp:473] Iteration 1112, lr = 0.01
I0621 04:57:33.311025   388 solver.cpp:213] Iteration 1113, loss = 0.000336008
I0621 04:57:33.311285   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000335795 (* 1 = 0.000335795 loss)
I0621 04:57:33.311332   388 solver.cpp:473] Iteration 1113, lr = 0.01
I0621 04:57:45.657320   388 solver.cpp:213] Iteration 1114, loss = 0.000335738
I0621 04:57:45.657407   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000335316 (* 1 = 0.000335316 loss)
I0621 04:57:45.657438   388 solver.cpp:473] Iteration 1114, lr = 0.01
I0621 04:57:58.070185   388 solver.cpp:213] Iteration 1115, loss = 0.000335526
I0621 04:57:58.070269   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000335735 (* 1 = 0.000335735 loss)
I0621 04:57:58.070292   388 solver.cpp:473] Iteration 1115, lr = 0.01
I0621 04:58:10.437660   388 solver.cpp:213] Iteration 1116, loss = 0.000335395
I0621 04:58:10.437892   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000334923 (* 1 = 0.000334923 loss)
I0621 04:58:10.437939   388 solver.cpp:473] Iteration 1116, lr = 0.01
I0621 04:58:22.802917   388 solver.cpp:213] Iteration 1117, loss = 0.00033513
I0621 04:58:22.803000   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000334411 (* 1 = 0.000334411 loss)
I0621 04:58:22.803022   388 solver.cpp:473] Iteration 1117, lr = 0.01
I0621 04:58:35.168864   388 solver.cpp:213] Iteration 1118, loss = 0.000334815
I0621 04:58:35.168946   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000334887 (* 1 = 0.000334887 loss)
I0621 04:58:35.168972   388 solver.cpp:473] Iteration 1118, lr = 0.01
I0621 04:58:47.490170   388 solver.cpp:213] Iteration 1119, loss = 0.000334679
I0621 04:58:47.490399   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00033476 (* 1 = 0.00033476 loss)
I0621 04:58:47.490432   388 solver.cpp:473] Iteration 1119, lr = 0.01
I0621 04:58:59.739346   388 solver.cpp:213] Iteration 1120, loss = 0.000334335
I0621 04:58:59.739428   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000334412 (* 1 = 0.000334412 loss)
I0621 04:58:59.739450   388 solver.cpp:473] Iteration 1120, lr = 0.01
I0621 04:59:11.970846   388 solver.cpp:213] Iteration 1121, loss = 0.000334164
I0621 04:59:11.970928   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00033452 (* 1 = 0.00033452 loss)
I0621 04:59:11.970952   388 solver.cpp:473] Iteration 1121, lr = 0.01
I0621 04:59:24.295250   388 solver.cpp:213] Iteration 1122, loss = 0.000333762
I0621 04:59:24.295492   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000333548 (* 1 = 0.000333548 loss)
I0621 04:59:24.295541   388 solver.cpp:473] Iteration 1122, lr = 0.01
I0621 04:59:36.590375   388 solver.cpp:213] Iteration 1123, loss = 0.00033361
I0621 04:59:36.590461   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000334424 (* 1 = 0.000334424 loss)
I0621 04:59:36.590481   388 solver.cpp:473] Iteration 1123, lr = 0.01
I0621 04:59:48.848134   388 solver.cpp:213] Iteration 1124, loss = 0.000333344
I0621 04:59:48.848223   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000333602 (* 1 = 0.000333602 loss)
I0621 04:59:48.848247   388 solver.cpp:473] Iteration 1124, lr = 0.01
I0621 05:00:01.158576   388 solver.cpp:213] Iteration 1125, loss = 0.000333142
I0621 05:00:01.158815   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00033251 (* 1 = 0.00033251 loss)
I0621 05:00:01.158859   388 solver.cpp:473] Iteration 1125, lr = 0.01
I0621 05:00:13.602560   388 solver.cpp:213] Iteration 1126, loss = 0.000333016
I0621 05:00:13.602645   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000333016 (* 1 = 0.000333016 loss)
I0621 05:00:13.602669   388 solver.cpp:473] Iteration 1126, lr = 0.01
I0621 05:00:25.894235   388 solver.cpp:213] Iteration 1127, loss = 0.000332771
I0621 05:00:25.894315   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000333082 (* 1 = 0.000333082 loss)
I0621 05:00:25.894337   388 solver.cpp:473] Iteration 1127, lr = 0.01
I0621 05:00:38.220394   388 solver.cpp:213] Iteration 1128, loss = 0.000332466
I0621 05:00:38.220633   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000332375 (* 1 = 0.000332375 loss)
I0621 05:00:38.220684   388 solver.cpp:473] Iteration 1128, lr = 0.01
I0621 05:00:50.623142   388 solver.cpp:213] Iteration 1129, loss = 0.000332179
I0621 05:00:50.623229   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000332257 (* 1 = 0.000332257 loss)
I0621 05:00:50.623252   388 solver.cpp:473] Iteration 1129, lr = 0.01
I0621 05:01:03.062077   388 solver.cpp:213] Iteration 1130, loss = 0.000331923
I0621 05:01:03.062166   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000331847 (* 1 = 0.000331847 loss)
I0621 05:01:03.062189   388 solver.cpp:473] Iteration 1130, lr = 0.01
I0621 05:01:15.375144   388 solver.cpp:213] Iteration 1131, loss = 0.000331884
I0621 05:01:15.375429   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000331976 (* 1 = 0.000331976 loss)
I0621 05:01:15.375478   388 solver.cpp:473] Iteration 1131, lr = 0.01
I0621 05:01:27.650979   388 solver.cpp:213] Iteration 1132, loss = 0.000331547
I0621 05:01:27.651136   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000331313 (* 1 = 0.000331313 loss)
I0621 05:01:27.651180   388 solver.cpp:473] Iteration 1132, lr = 0.01
I0621 05:01:39.896391   388 solver.cpp:213] Iteration 1133, loss = 0.000331146
I0621 05:01:39.896473   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000330943 (* 1 = 0.000330943 loss)
I0621 05:01:39.896497   388 solver.cpp:473] Iteration 1133, lr = 0.01
I0621 05:01:52.210629   388 solver.cpp:213] Iteration 1134, loss = 0.000331149
I0621 05:01:52.210880   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000330813 (* 1 = 0.000330813 loss)
I0621 05:01:52.210927   388 solver.cpp:473] Iteration 1134, lr = 0.01
I0621 05:02:04.534168   388 solver.cpp:213] Iteration 1135, loss = 0.000331037
I0621 05:02:04.534253   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00033087 (* 1 = 0.00033087 loss)
I0621 05:02:04.534276   388 solver.cpp:473] Iteration 1135, lr = 0.01
I0621 05:02:16.836041   388 solver.cpp:213] Iteration 1136, loss = 0.000330506
I0621 05:02:16.836122   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000330248 (* 1 = 0.000330248 loss)
I0621 05:02:16.836144   388 solver.cpp:473] Iteration 1136, lr = 0.01
I0621 05:02:29.137156   388 solver.cpp:213] Iteration 1137, loss = 0.000330199
I0621 05:02:29.137347   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000330005 (* 1 = 0.000330005 loss)
I0621 05:02:29.137373   388 solver.cpp:473] Iteration 1137, lr = 0.01
I0621 05:02:41.400399   388 solver.cpp:213] Iteration 1138, loss = 0.000330045
I0621 05:02:41.400481   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000329415 (* 1 = 0.000329415 loss)
I0621 05:02:41.400503   388 solver.cpp:473] Iteration 1138, lr = 0.01
I0621 05:02:53.667740   388 solver.cpp:213] Iteration 1139, loss = 0.0003298
I0621 05:02:53.667825   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000330198 (* 1 = 0.000330198 loss)
I0621 05:02:53.667847   388 solver.cpp:473] Iteration 1139, lr = 0.01
I0621 05:03:05.935950   388 solver.cpp:213] Iteration 1140, loss = 0.000329721
I0621 05:03:05.936195   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000330151 (* 1 = 0.000330151 loss)
I0621 05:03:05.936228   388 solver.cpp:473] Iteration 1140, lr = 0.01
I0621 05:03:18.338592   388 solver.cpp:213] Iteration 1141, loss = 0.00032942
I0621 05:03:18.338675   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000329467 (* 1 = 0.000329467 loss)
I0621 05:03:18.338698   388 solver.cpp:473] Iteration 1141, lr = 0.01
I0621 05:03:30.611500   388 solver.cpp:213] Iteration 1142, loss = 0.000329131
I0621 05:03:30.611578   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032897 (* 1 = 0.00032897 loss)
I0621 05:03:30.611600   388 solver.cpp:473] Iteration 1142, lr = 0.01
I0621 05:03:42.858981   388 solver.cpp:213] Iteration 1143, loss = 0.000329005
I0621 05:03:42.859165   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032895 (* 1 = 0.00032895 loss)
I0621 05:03:42.859190   388 solver.cpp:473] Iteration 1143, lr = 0.01
I0621 05:03:55.121767   388 solver.cpp:213] Iteration 1144, loss = 0.000328597
I0621 05:03:55.121850   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000328095 (* 1 = 0.000328095 loss)
I0621 05:03:55.121872   388 solver.cpp:473] Iteration 1144, lr = 0.01
I0621 05:04:07.393254   388 solver.cpp:213] Iteration 1145, loss = 0.00032838
I0621 05:04:07.393338   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000328702 (* 1 = 0.000328702 loss)
I0621 05:04:07.393362   388 solver.cpp:473] Iteration 1145, lr = 0.01
I0621 05:04:19.831288   388 solver.cpp:213] Iteration 1146, loss = 0.00032838
I0621 05:04:19.831550   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000328574 (* 1 = 0.000328574 loss)
I0621 05:04:19.831605   388 solver.cpp:473] Iteration 1146, lr = 0.01
I0621 05:04:32.217700   388 solver.cpp:213] Iteration 1147, loss = 0.000327993
I0621 05:04:32.217784   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000327637 (* 1 = 0.000327637 loss)
I0621 05:04:32.217808   388 solver.cpp:473] Iteration 1147, lr = 0.01
I0621 05:04:44.564246   388 solver.cpp:213] Iteration 1148, loss = 0.000327868
I0621 05:04:44.564340   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000327756 (* 1 = 0.000327756 loss)
I0621 05:04:44.564364   388 solver.cpp:473] Iteration 1148, lr = 0.01
I0621 05:04:56.902499   388 solver.cpp:213] Iteration 1149, loss = 0.000327546
I0621 05:04:56.903861   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000327213 (* 1 = 0.000327213 loss)
I0621 05:04:56.903918   388 solver.cpp:473] Iteration 1149, lr = 0.01
I0621 05:05:09.324458   388 solver.cpp:213] Iteration 1150, loss = 0.000327422
I0621 05:05:09.324579   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000327405 (* 1 = 0.000327405 loss)
I0621 05:05:09.324630   388 solver.cpp:473] Iteration 1150, lr = 0.01
I0621 05:05:21.773573   388 solver.cpp:213] Iteration 1151, loss = 0.000327114
I0621 05:05:21.773663   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000326984 (* 1 = 0.000326984 loss)
I0621 05:05:21.773684   388 solver.cpp:473] Iteration 1151, lr = 0.01
I0621 05:05:34.034657   388 solver.cpp:213] Iteration 1152, loss = 0.000326906
I0621 05:05:34.034876   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000327179 (* 1 = 0.000327179 loss)
I0621 05:05:34.034906   388 solver.cpp:473] Iteration 1152, lr = 0.01
I0621 05:05:46.444355   388 solver.cpp:213] Iteration 1153, loss = 0.000326648
I0621 05:05:46.444442   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000326199 (* 1 = 0.000326199 loss)
I0621 05:05:46.444464   388 solver.cpp:473] Iteration 1153, lr = 0.01
I0621 05:05:58.732486   388 solver.cpp:213] Iteration 1154, loss = 0.00032645
I0621 05:05:58.732570   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032657 (* 1 = 0.00032657 loss)
I0621 05:05:58.732592   388 solver.cpp:473] Iteration 1154, lr = 0.01
I0621 05:06:11.002077   388 solver.cpp:213] Iteration 1155, loss = 0.000326131
I0621 05:06:11.002326   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032658 (* 1 = 0.00032658 loss)
I0621 05:06:11.002372   388 solver.cpp:473] Iteration 1155, lr = 0.01
I0621 05:06:23.251199   388 solver.cpp:213] Iteration 1156, loss = 0.000325993
I0621 05:06:23.251279   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000326665 (* 1 = 0.000326665 loss)
I0621 05:06:23.251302   388 solver.cpp:473] Iteration 1156, lr = 0.01
I0621 05:06:35.652456   388 solver.cpp:213] Iteration 1157, loss = 0.000325764
I0621 05:06:35.652541   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000325188 (* 1 = 0.000325188 loss)
I0621 05:06:35.652565   388 solver.cpp:473] Iteration 1157, lr = 0.01
I0621 05:06:47.974817   388 solver.cpp:213] Iteration 1158, loss = 0.000325469
I0621 05:06:47.975054   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032581 (* 1 = 0.00032581 loss)
I0621 05:06:47.975108   388 solver.cpp:473] Iteration 1158, lr = 0.01
I0621 05:07:00.379348   388 solver.cpp:213] Iteration 1159, loss = 0.000325112
I0621 05:07:00.379432   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000324834 (* 1 = 0.000324834 loss)
I0621 05:07:00.379456   388 solver.cpp:473] Iteration 1159, lr = 0.01
I0621 05:07:12.645186   388 solver.cpp:213] Iteration 1160, loss = 0.000324915
I0621 05:07:12.645254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000324996 (* 1 = 0.000324996 loss)
I0621 05:07:12.645270   388 solver.cpp:473] Iteration 1160, lr = 0.01
I0621 05:07:25.032928   388 solver.cpp:213] Iteration 1161, loss = 0.000324899
I0621 05:07:25.033174   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032506 (* 1 = 0.00032506 loss)
I0621 05:07:25.033236   388 solver.cpp:473] Iteration 1161, lr = 0.01
I0621 05:07:37.322279   388 solver.cpp:213] Iteration 1162, loss = 0.000324701
I0621 05:07:37.322361   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032458 (* 1 = 0.00032458 loss)
I0621 05:07:37.322384   388 solver.cpp:473] Iteration 1162, lr = 0.01
I0621 05:07:49.835919   388 solver.cpp:213] Iteration 1163, loss = 0.000324329
I0621 05:07:49.836014   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00032407 (* 1 = 0.00032407 loss)
I0621 05:07:49.836038   388 solver.cpp:473] Iteration 1163, lr = 0.01
I0621 05:08:02.210106   388 solver.cpp:213] Iteration 1164, loss = 0.000324227
I0621 05:08:02.210402   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000324066 (* 1 = 0.000324066 loss)
I0621 05:08:02.210448   388 solver.cpp:473] Iteration 1164, lr = 0.01
I0621 05:08:14.527639   388 solver.cpp:213] Iteration 1165, loss = 0.000323985
I0621 05:08:14.527726   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000323974 (* 1 = 0.000323974 loss)
I0621 05:08:14.527748   388 solver.cpp:473] Iteration 1165, lr = 0.01
I0621 05:08:26.900486   388 solver.cpp:213] Iteration 1166, loss = 0.000323666
I0621 05:08:26.900576   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000323422 (* 1 = 0.000323422 loss)
I0621 05:08:26.900599   388 solver.cpp:473] Iteration 1166, lr = 0.01
I0621 05:08:39.247473   388 solver.cpp:213] Iteration 1167, loss = 0.00032359
I0621 05:08:39.247675   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000323242 (* 1 = 0.000323242 loss)
I0621 05:08:39.247700   388 solver.cpp:473] Iteration 1167, lr = 0.01
I0621 05:08:51.733161   388 solver.cpp:213] Iteration 1168, loss = 0.000323146
I0621 05:08:51.733258   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000323827 (* 1 = 0.000323827 loss)
I0621 05:08:51.733281   388 solver.cpp:473] Iteration 1168, lr = 0.01
I0621 05:09:04.114328   388 solver.cpp:213] Iteration 1169, loss = 0.000322854
I0621 05:09:04.114410   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000322746 (* 1 = 0.000322746 loss)
I0621 05:09:04.114434   388 solver.cpp:473] Iteration 1169, lr = 0.01
I0621 05:09:16.531657   388 solver.cpp:213] Iteration 1170, loss = 0.000322923
I0621 05:09:16.532295   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000322916 (* 1 = 0.000322916 loss)
I0621 05:09:16.532322   388 solver.cpp:473] Iteration 1170, lr = 0.01
I0621 05:09:28.814553   388 solver.cpp:213] Iteration 1171, loss = 0.000322472
I0621 05:09:28.814638   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000322214 (* 1 = 0.000322214 loss)
I0621 05:09:28.814661   388 solver.cpp:473] Iteration 1171, lr = 0.01
I0621 05:09:41.122756   388 solver.cpp:213] Iteration 1172, loss = 0.000322284
I0621 05:09:41.122858   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000322451 (* 1 = 0.000322451 loss)
I0621 05:09:41.122889   388 solver.cpp:473] Iteration 1172, lr = 0.01
I0621 05:09:53.375447   388 solver.cpp:213] Iteration 1173, loss = 0.000322002
I0621 05:09:53.376404   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000322374 (* 1 = 0.000322374 loss)
I0621 05:09:53.376430   388 solver.cpp:473] Iteration 1173, lr = 0.01
I0621 05:10:05.653451   388 solver.cpp:213] Iteration 1174, loss = 0.000322049
I0621 05:10:05.653534   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000322054 (* 1 = 0.000322054 loss)
I0621 05:10:05.653558   388 solver.cpp:473] Iteration 1174, lr = 0.01
I0621 05:10:17.936317   388 solver.cpp:213] Iteration 1175, loss = 0.000321704
I0621 05:10:17.936403   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000321668 (* 1 = 0.000321668 loss)
I0621 05:10:17.936424   388 solver.cpp:473] Iteration 1175, lr = 0.01
I0621 05:10:30.301144   388 solver.cpp:213] Iteration 1176, loss = 0.0003214
I0621 05:10:30.301403   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000320584 (* 1 = 0.000320584 loss)
I0621 05:10:30.301450   388 solver.cpp:473] Iteration 1176, lr = 0.01
I0621 05:10:42.665534   388 solver.cpp:213] Iteration 1177, loss = 0.000321204
I0621 05:10:42.665622   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000320914 (* 1 = 0.000320914 loss)
I0621 05:10:42.665645   388 solver.cpp:473] Iteration 1177, lr = 0.01
I0621 05:10:54.968592   388 solver.cpp:213] Iteration 1178, loss = 0.000321153
I0621 05:10:54.968677   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000321391 (* 1 = 0.000321391 loss)
I0621 05:10:54.968699   388 solver.cpp:473] Iteration 1178, lr = 0.01
I0621 05:11:07.300794   388 solver.cpp:213] Iteration 1179, loss = 0.000320823
I0621 05:11:07.301029   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000321101 (* 1 = 0.000321101 loss)
I0621 05:11:07.301077   388 solver.cpp:473] Iteration 1179, lr = 0.01
I0621 05:11:19.711997   388 solver.cpp:213] Iteration 1180, loss = 0.000320643
I0621 05:11:19.712080   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000320825 (* 1 = 0.000320825 loss)
I0621 05:11:19.712102   388 solver.cpp:473] Iteration 1180, lr = 0.01
I0621 05:11:32.037199   388 solver.cpp:213] Iteration 1181, loss = 0.000320355
I0621 05:11:32.037298   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000320589 (* 1 = 0.000320589 loss)
I0621 05:11:32.037329   388 solver.cpp:473] Iteration 1181, lr = 0.01
I0621 05:11:44.368667   388 solver.cpp:213] Iteration 1182, loss = 0.000320169
I0621 05:11:44.368862   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000320092 (* 1 = 0.000320092 loss)
I0621 05:11:44.368887   388 solver.cpp:473] Iteration 1182, lr = 0.01
I0621 05:11:56.714798   388 solver.cpp:213] Iteration 1183, loss = 0.000320021
I0621 05:11:56.714884   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000320161 (* 1 = 0.000320161 loss)
I0621 05:11:56.714908   388 solver.cpp:473] Iteration 1183, lr = 0.01
I0621 05:12:08.998518   388 solver.cpp:213] Iteration 1184, loss = 0.000319763
I0621 05:12:08.998606   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000319703 (* 1 = 0.000319703 loss)
I0621 05:12:08.998628   388 solver.cpp:473] Iteration 1184, lr = 0.01
I0621 05:12:21.253036   388 solver.cpp:213] Iteration 1185, loss = 0.000319484
I0621 05:12:21.253201   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000319493 (* 1 = 0.000319493 loss)
I0621 05:12:21.253226   388 solver.cpp:473] Iteration 1185, lr = 0.01
I0621 05:12:33.590976   388 solver.cpp:213] Iteration 1186, loss = 0.000319367
I0621 05:12:33.591058   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000319299 (* 1 = 0.000319299 loss)
I0621 05:12:33.591086   388 solver.cpp:473] Iteration 1186, lr = 0.01
I0621 05:12:45.903237   388 solver.cpp:213] Iteration 1187, loss = 0.000319133
I0621 05:12:45.903326   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000319137 (* 1 = 0.000319137 loss)
I0621 05:12:45.903349   388 solver.cpp:473] Iteration 1187, lr = 0.01
I0621 05:12:58.240063   388 solver.cpp:213] Iteration 1188, loss = 0.000318926
I0621 05:12:58.240312   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000319523 (* 1 = 0.000319523 loss)
I0621 05:12:58.240345   388 solver.cpp:473] Iteration 1188, lr = 0.01
I0621 05:13:10.636032   388 solver.cpp:213] Iteration 1189, loss = 0.000318706
I0621 05:13:10.636116   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000318546 (* 1 = 0.000318546 loss)
I0621 05:13:10.636139   388 solver.cpp:473] Iteration 1189, lr = 0.01
I0621 05:13:23.049805   388 solver.cpp:213] Iteration 1190, loss = 0.000318403
I0621 05:13:23.049891   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000318172 (* 1 = 0.000318172 loss)
I0621 05:13:23.049916   388 solver.cpp:473] Iteration 1190, lr = 0.01
I0621 05:13:35.316345   388 solver.cpp:213] Iteration 1191, loss = 0.000318141
I0621 05:13:35.316524   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000318555 (* 1 = 0.000318555 loss)
I0621 05:13:35.316550   388 solver.cpp:473] Iteration 1191, lr = 0.01
I0621 05:13:47.594749   388 solver.cpp:213] Iteration 1192, loss = 0.000317931
I0621 05:13:47.594830   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00031808 (* 1 = 0.00031808 loss)
I0621 05:13:47.594853   388 solver.cpp:473] Iteration 1192, lr = 0.01
I0621 05:13:59.930562   388 solver.cpp:213] Iteration 1193, loss = 0.000317796
I0621 05:13:59.930647   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00031804 (* 1 = 0.00031804 loss)
I0621 05:13:59.930671   388 solver.cpp:473] Iteration 1193, lr = 0.01
I0621 05:14:12.228531   388 solver.cpp:213] Iteration 1194, loss = 0.000317669
I0621 05:14:12.228711   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000317781 (* 1 = 0.000317781 loss)
I0621 05:14:12.228735   388 solver.cpp:473] Iteration 1194, lr = 0.01
I0621 05:14:24.503623   388 solver.cpp:213] Iteration 1195, loss = 0.000317332
I0621 05:14:24.503715   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000316945 (* 1 = 0.000316945 loss)
I0621 05:14:24.503741   388 solver.cpp:473] Iteration 1195, lr = 0.01
I0621 05:14:36.806921   388 solver.cpp:213] Iteration 1196, loss = 0.000316998
I0621 05:14:36.807004   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000317045 (* 1 = 0.000317045 loss)
I0621 05:14:36.807027   388 solver.cpp:473] Iteration 1196, lr = 0.01
I0621 05:14:49.056522   388 solver.cpp:213] Iteration 1197, loss = 0.000316997
I0621 05:14:49.056831   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000316899 (* 1 = 0.000316899 loss)
I0621 05:14:49.056857   388 solver.cpp:473] Iteration 1197, lr = 0.01
I0621 05:15:01.382135   388 solver.cpp:213] Iteration 1198, loss = 0.00031672
I0621 05:15:01.382216   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000317098 (* 1 = 0.000317098 loss)
I0621 05:15:01.382246   388 solver.cpp:473] Iteration 1198, lr = 0.01
I0621 05:15:13.797211   388 solver.cpp:213] Iteration 1199, loss = 0.000316541
I0621 05:15:13.797296   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000316706 (* 1 = 0.000316706 loss)
I0621 05:15:13.797319   388 solver.cpp:473] Iteration 1199, lr = 0.01
I0621 05:15:26.175554   388 solver.cpp:213] Iteration 1200, loss = 0.000316318
I0621 05:15:26.175814   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000316177 (* 1 = 0.000316177 loss)
I0621 05:15:26.175860   388 solver.cpp:473] Iteration 1200, lr = 0.01
I0621 05:15:38.480322   388 solver.cpp:213] Iteration 1201, loss = 0.000315982
I0621 05:15:38.480412   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00031611 (* 1 = 0.00031611 loss)
I0621 05:15:38.480435   388 solver.cpp:473] Iteration 1201, lr = 0.01
I0621 05:15:50.822521   388 solver.cpp:213] Iteration 1202, loss = 0.00031589
I0621 05:15:50.822612   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000315679 (* 1 = 0.000315679 loss)
I0621 05:15:50.822635   388 solver.cpp:473] Iteration 1202, lr = 0.01
I0621 05:16:03.209736   388 solver.cpp:213] Iteration 1203, loss = 0.00031558
I0621 05:16:03.209978   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000315734 (* 1 = 0.000315734 loss)
I0621 05:16:03.210011   388 solver.cpp:473] Iteration 1203, lr = 0.01
I0621 05:16:15.559165   388 solver.cpp:213] Iteration 1204, loss = 0.000315535
I0621 05:16:15.559247   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000315401 (* 1 = 0.000315401 loss)
I0621 05:16:15.559269   388 solver.cpp:473] Iteration 1204, lr = 0.01
I0621 05:16:27.896070   388 solver.cpp:213] Iteration 1205, loss = 0.000315539
I0621 05:16:27.896152   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0003152 (* 1 = 0.0003152 loss)
I0621 05:16:27.896174   388 solver.cpp:473] Iteration 1205, lr = 0.01
I0621 05:16:40.165320   388 solver.cpp:213] Iteration 1206, loss = 0.000314897
I0621 05:16:40.165534   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000314596 (* 1 = 0.000314596 loss)
I0621 05:16:40.165561   388 solver.cpp:473] Iteration 1206, lr = 0.01
I0621 05:16:52.612476   388 solver.cpp:213] Iteration 1207, loss = 0.000314718
I0621 05:16:52.612553   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000314493 (* 1 = 0.000314493 loss)
I0621 05:16:52.612577   388 solver.cpp:473] Iteration 1207, lr = 0.01
I0621 05:17:04.948885   388 solver.cpp:213] Iteration 1208, loss = 0.000314576
I0621 05:17:04.948973   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000314233 (* 1 = 0.000314233 loss)
I0621 05:17:04.948997   388 solver.cpp:473] Iteration 1208, lr = 0.01
I0621 05:17:17.303059   388 solver.cpp:213] Iteration 1209, loss = 0.000314381
I0621 05:17:17.304420   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000314594 (* 1 = 0.000314594 loss)
I0621 05:17:17.304482   388 solver.cpp:473] Iteration 1209, lr = 0.01
I0621 05:17:29.644996   388 solver.cpp:213] Iteration 1210, loss = 0.000314199
I0621 05:17:29.645082   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000314368 (* 1 = 0.000314368 loss)
I0621 05:17:29.645107   388 solver.cpp:473] Iteration 1210, lr = 0.01
I0621 05:17:41.897071   388 solver.cpp:213] Iteration 1211, loss = 0.000313906
I0621 05:17:41.897156   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000313928 (* 1 = 0.000313928 loss)
I0621 05:17:41.897179   388 solver.cpp:473] Iteration 1211, lr = 0.01
I0621 05:17:54.231396   388 solver.cpp:213] Iteration 1212, loss = 0.000313849
I0621 05:17:54.231663   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000313775 (* 1 = 0.000313775 loss)
I0621 05:17:54.231709   388 solver.cpp:473] Iteration 1212, lr = 0.01
I0621 05:18:06.507099   388 solver.cpp:213] Iteration 1213, loss = 0.000313578
I0621 05:18:06.507186   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000313687 (* 1 = 0.000313687 loss)
I0621 05:18:06.507208   388 solver.cpp:473] Iteration 1213, lr = 0.01
I0621 05:18:18.768023   388 solver.cpp:213] Iteration 1214, loss = 0.000313285
I0621 05:18:18.768107   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000313426 (* 1 = 0.000313426 loss)
I0621 05:18:18.768131   388 solver.cpp:473] Iteration 1214, lr = 0.01
I0621 05:18:30.999670   388 solver.cpp:213] Iteration 1215, loss = 0.000312985
I0621 05:18:31.000082   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000312699 (* 1 = 0.000312699 loss)
I0621 05:18:31.000107   388 solver.cpp:473] Iteration 1215, lr = 0.01
I0621 05:18:43.347456   388 solver.cpp:213] Iteration 1216, loss = 0.000312901
I0621 05:18:43.355375   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000312833 (* 1 = 0.000312833 loss)
I0621 05:18:43.355423   388 solver.cpp:473] Iteration 1216, lr = 0.01
I0621 05:18:55.679606   388 solver.cpp:213] Iteration 1217, loss = 0.000312778
I0621 05:18:55.679688   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000312956 (* 1 = 0.000312956 loss)
I0621 05:18:55.679710   388 solver.cpp:473] Iteration 1217, lr = 0.01
I0621 05:19:07.947998   388 solver.cpp:213] Iteration 1218, loss = 0.000312505
I0621 05:19:07.948175   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000312649 (* 1 = 0.000312649 loss)
I0621 05:19:07.948199   388 solver.cpp:473] Iteration 1218, lr = 0.01
I0621 05:19:20.196880   388 solver.cpp:213] Iteration 1219, loss = 0.000312382
I0621 05:19:20.196967   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00031223 (* 1 = 0.00031223 loss)
I0621 05:19:20.196988   388 solver.cpp:473] Iteration 1219, lr = 0.01
I0621 05:19:32.481006   388 solver.cpp:213] Iteration 1220, loss = 0.000312073
I0621 05:19:32.481091   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000312344 (* 1 = 0.000312344 loss)
I0621 05:19:32.481112   388 solver.cpp:473] Iteration 1220, lr = 0.01
I0621 05:19:44.755760   388 solver.cpp:213] Iteration 1221, loss = 0.000311923
I0621 05:19:44.755950   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000311497 (* 1 = 0.000311497 loss)
I0621 05:19:44.755978   388 solver.cpp:473] Iteration 1221, lr = 0.01
I0621 05:19:56.998200   388 solver.cpp:213] Iteration 1222, loss = 0.000311648
I0621 05:19:56.998286   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000311428 (* 1 = 0.000311428 loss)
I0621 05:19:56.998309   388 solver.cpp:473] Iteration 1222, lr = 0.01
I0621 05:20:09.232708   388 solver.cpp:213] Iteration 1223, loss = 0.000311327
I0621 05:20:09.232795   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000311588 (* 1 = 0.000311588 loss)
I0621 05:20:09.232820   388 solver.cpp:473] Iteration 1223, lr = 0.01
I0621 05:20:21.679296   388 solver.cpp:213] Iteration 1224, loss = 0.000311137
I0621 05:20:21.679558   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000311447 (* 1 = 0.000311447 loss)
I0621 05:20:21.679605   388 solver.cpp:473] Iteration 1224, lr = 0.01
I0621 05:20:34.101626   388 solver.cpp:213] Iteration 1225, loss = 0.000311074
I0621 05:20:34.101712   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000311179 (* 1 = 0.000311179 loss)
I0621 05:20:34.101735   388 solver.cpp:473] Iteration 1225, lr = 0.01
I0621 05:20:46.409155   388 solver.cpp:213] Iteration 1226, loss = 0.000310775
I0621 05:20:46.409277   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000310534 (* 1 = 0.000310534 loss)
I0621 05:20:46.409314   388 solver.cpp:473] Iteration 1226, lr = 0.01
I0621 05:20:58.768743   388 solver.cpp:213] Iteration 1227, loss = 0.000310608
I0621 05:20:58.768940   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000310173 (* 1 = 0.000310173 loss)
I0621 05:20:58.768966   388 solver.cpp:473] Iteration 1227, lr = 0.01
I0621 05:21:11.153286   388 solver.cpp:213] Iteration 1228, loss = 0.000310464
I0621 05:21:11.153388   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000310252 (* 1 = 0.000310252 loss)
I0621 05:21:11.153419   388 solver.cpp:473] Iteration 1228, lr = 0.01
I0621 05:21:23.408416   388 solver.cpp:213] Iteration 1229, loss = 0.000310213
I0621 05:21:23.408496   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000309865 (* 1 = 0.000309865 loss)
I0621 05:21:23.408519   388 solver.cpp:473] Iteration 1229, lr = 0.01
I0621 05:21:35.696527   388 solver.cpp:213] Iteration 1230, loss = 0.00030993
I0621 05:21:35.696728   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000309655 (* 1 = 0.000309655 loss)
I0621 05:21:35.696753   388 solver.cpp:473] Iteration 1230, lr = 0.01
I0621 05:21:48.031357   388 solver.cpp:213] Iteration 1231, loss = 0.000309688
I0621 05:21:48.031440   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000309742 (* 1 = 0.000309742 loss)
I0621 05:21:48.031462   388 solver.cpp:473] Iteration 1231, lr = 0.01
I0621 05:22:00.305933   388 solver.cpp:213] Iteration 1232, loss = 0.000309624
I0621 05:22:00.306011   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000309766 (* 1 = 0.000309766 loss)
I0621 05:22:00.306035   388 solver.cpp:473] Iteration 1232, lr = 0.01
I0621 05:22:12.600409   388 solver.cpp:213] Iteration 1233, loss = 0.000309503
I0621 05:22:12.600647   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000308863 (* 1 = 0.000308863 loss)
I0621 05:22:12.600708   388 solver.cpp:473] Iteration 1233, lr = 0.01
I0621 05:22:24.939693   388 solver.cpp:213] Iteration 1234, loss = 0.000309246
I0621 05:22:24.939785   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000309693 (* 1 = 0.000309693 loss)
I0621 05:22:24.939807   388 solver.cpp:473] Iteration 1234, lr = 0.01
I0621 05:22:37.305630   388 solver.cpp:213] Iteration 1235, loss = 0.000308899
I0621 05:22:37.305711   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000308557 (* 1 = 0.000308557 loss)
I0621 05:22:37.305733   388 solver.cpp:473] Iteration 1235, lr = 0.01
I0621 05:22:49.559897   388 solver.cpp:213] Iteration 1236, loss = 0.000308913
I0621 05:22:49.560080   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000309068 (* 1 = 0.000309068 loss)
I0621 05:22:49.560103   388 solver.cpp:473] Iteration 1236, lr = 0.01
I0621 05:23:01.859154   388 solver.cpp:213] Iteration 1237, loss = 0.000308654
I0621 05:23:01.859237   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000308261 (* 1 = 0.000308261 loss)
I0621 05:23:01.859261   388 solver.cpp:473] Iteration 1237, lr = 0.01
I0621 05:23:14.389837   388 solver.cpp:213] Iteration 1238, loss = 0.000308337
I0621 05:23:14.389920   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000308211 (* 1 = 0.000308211 loss)
I0621 05:23:14.389945   388 solver.cpp:473] Iteration 1238, lr = 0.01
I0621 05:23:26.655545   388 solver.cpp:213] Iteration 1239, loss = 0.000308109
I0621 05:23:26.655773   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000308249 (* 1 = 0.000308249 loss)
I0621 05:23:26.655820   388 solver.cpp:473] Iteration 1239, lr = 0.01
I0621 05:23:38.990567   388 solver.cpp:213] Iteration 1240, loss = 0.000308066
I0621 05:23:38.990649   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000308123 (* 1 = 0.000308123 loss)
I0621 05:23:38.990672   388 solver.cpp:473] Iteration 1240, lr = 0.01
I0621 05:23:51.351486   388 solver.cpp:213] Iteration 1241, loss = 0.000307771
I0621 05:23:51.351565   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000307486 (* 1 = 0.000307486 loss)
I0621 05:23:51.351588   388 solver.cpp:473] Iteration 1241, lr = 0.01
I0621 05:24:03.775862   388 solver.cpp:213] Iteration 1242, loss = 0.000307658
I0621 05:24:03.782707   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000307933 (* 1 = 0.000307933 loss)
I0621 05:24:03.782734   388 solver.cpp:473] Iteration 1242, lr = 0.01
I0621 05:24:16.051808   388 solver.cpp:213] Iteration 1243, loss = 0.000307274
I0621 05:24:16.051905   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000306876 (* 1 = 0.000306876 loss)
I0621 05:24:16.051930   388 solver.cpp:473] Iteration 1243, lr = 0.01
I0621 05:24:28.369828   388 solver.cpp:213] Iteration 1244, loss = 0.000307176
I0621 05:24:28.369910   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000307023 (* 1 = 0.000307023 loss)
I0621 05:24:28.369933   388 solver.cpp:473] Iteration 1244, lr = 0.01
I0621 05:24:40.682379   388 solver.cpp:213] Iteration 1245, loss = 0.000306988
I0621 05:24:40.682711   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00030706 (* 1 = 0.00030706 loss)
I0621 05:24:40.682737   388 solver.cpp:473] Iteration 1245, lr = 0.01
I0621 05:24:53.026259   388 solver.cpp:213] Iteration 1246, loss = 0.000306764
I0621 05:24:53.026350   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00030685 (* 1 = 0.00030685 loss)
I0621 05:24:53.026371   388 solver.cpp:473] Iteration 1246, lr = 0.01
I0621 05:25:05.474474   388 solver.cpp:213] Iteration 1247, loss = 0.00030668
I0621 05:25:05.474597   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00030638 (* 1 = 0.00030638 loss)
I0621 05:25:05.474634   388 solver.cpp:473] Iteration 1247, lr = 0.01
I0621 05:25:17.876651   388 solver.cpp:213] Iteration 1248, loss = 0.000306283
I0621 05:25:17.876992   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000306325 (* 1 = 0.000306325 loss)
I0621 05:25:17.877022   388 solver.cpp:473] Iteration 1248, lr = 0.01
I0621 05:25:30.185930   388 solver.cpp:213] Iteration 1249, loss = 0.000306236
I0621 05:25:30.186017   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00030618 (* 1 = 0.00030618 loss)
I0621 05:25:30.186040   388 solver.cpp:473] Iteration 1249, lr = 0.01
I0621 05:25:42.488445   388 solver.cpp:213] Iteration 1250, loss = 0.00030606
I0621 05:25:42.488533   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000305683 (* 1 = 0.000305683 loss)
I0621 05:25:42.488554   388 solver.cpp:473] Iteration 1250, lr = 0.01
I0621 05:25:54.898264   388 solver.cpp:213] Iteration 1251, loss = 0.000305824
I0621 05:25:54.898509   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000306207 (* 1 = 0.000306207 loss)
I0621 05:25:54.898573   388 solver.cpp:473] Iteration 1251, lr = 0.01
I0621 05:26:07.221181   388 solver.cpp:213] Iteration 1252, loss = 0.000305571
I0621 05:26:07.221266   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000305452 (* 1 = 0.000305452 loss)
I0621 05:26:07.221288   388 solver.cpp:473] Iteration 1252, lr = 0.01
I0621 05:26:19.597966   388 solver.cpp:213] Iteration 1253, loss = 0.000305528
I0621 05:26:19.598047   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000306274 (* 1 = 0.000306274 loss)
I0621 05:26:19.598069   388 solver.cpp:473] Iteration 1253, lr = 0.01
I0621 05:26:31.943341   388 solver.cpp:213] Iteration 1254, loss = 0.000305046
I0621 05:26:31.943584   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000305068 (* 1 = 0.000305068 loss)
I0621 05:26:31.943647   388 solver.cpp:473] Iteration 1254, lr = 0.01
I0621 05:26:44.207962   388 solver.cpp:213] Iteration 1255, loss = 0.000304857
I0621 05:26:44.208045   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000304862 (* 1 = 0.000304862 loss)
I0621 05:26:44.208067   388 solver.cpp:473] Iteration 1255, lr = 0.01
I0621 05:26:56.545104   388 solver.cpp:213] Iteration 1256, loss = 0.00030481
I0621 05:26:56.545187   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000304375 (* 1 = 0.000304375 loss)
I0621 05:26:56.545209   388 solver.cpp:473] Iteration 1256, lr = 0.01
I0621 05:27:08.854265   388 solver.cpp:213] Iteration 1257, loss = 0.000304533
I0621 05:27:08.854516   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000304754 (* 1 = 0.000304754 loss)
I0621 05:27:08.854579   388 solver.cpp:473] Iteration 1257, lr = 0.01
I0621 05:27:21.161734   388 solver.cpp:213] Iteration 1258, loss = 0.000304462
I0621 05:27:21.161814   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000303607 (* 1 = 0.000303607 loss)
I0621 05:27:21.161835   388 solver.cpp:473] Iteration 1258, lr = 0.01
I0621 05:27:33.498371   388 solver.cpp:213] Iteration 1259, loss = 0.000304283
I0621 05:27:33.498459   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000304125 (* 1 = 0.000304125 loss)
I0621 05:27:33.498482   388 solver.cpp:473] Iteration 1259, lr = 0.01
I0621 05:27:45.793007   388 solver.cpp:213] Iteration 1260, loss = 0.000303945
I0621 05:27:45.793249   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000303867 (* 1 = 0.000303867 loss)
I0621 05:27:45.793309   388 solver.cpp:473] Iteration 1260, lr = 0.01
I0621 05:27:58.131387   388 solver.cpp:213] Iteration 1261, loss = 0.000303847
I0621 05:27:58.131471   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000303479 (* 1 = 0.000303479 loss)
I0621 05:27:58.131494   388 solver.cpp:473] Iteration 1261, lr = 0.01
I0621 05:28:10.455073   388 solver.cpp:213] Iteration 1262, loss = 0.000303509
I0621 05:28:10.455158   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000303299 (* 1 = 0.000303299 loss)
I0621 05:28:10.455180   388 solver.cpp:473] Iteration 1262, lr = 0.01
I0621 05:28:22.883723   388 solver.cpp:213] Iteration 1263, loss = 0.000303496
I0621 05:28:22.884002   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000303512 (* 1 = 0.000303512 loss)
I0621 05:28:22.884057   388 solver.cpp:473] Iteration 1263, lr = 0.01
I0621 05:28:35.226503   388 solver.cpp:213] Iteration 1264, loss = 0.000303165
I0621 05:28:35.226580   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000303394 (* 1 = 0.000303394 loss)
I0621 05:28:35.226603   388 solver.cpp:473] Iteration 1264, lr = 0.01
I0621 05:28:47.532219   388 solver.cpp:213] Iteration 1265, loss = 0.000303081
I0621 05:28:47.532306   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000303186 (* 1 = 0.000303186 loss)
I0621 05:28:47.532330   388 solver.cpp:473] Iteration 1265, lr = 0.01
I0621 05:28:59.875175   388 solver.cpp:213] Iteration 1266, loss = 0.000302765
I0621 05:28:59.882251   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000302565 (* 1 = 0.000302565 loss)
I0621 05:28:59.882277   388 solver.cpp:473] Iteration 1266, lr = 0.01
I0621 05:29:12.129995   388 solver.cpp:213] Iteration 1267, loss = 0.000302724
I0621 05:29:12.130082   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000302665 (* 1 = 0.000302665 loss)
I0621 05:29:12.130106   388 solver.cpp:473] Iteration 1267, lr = 0.01
I0621 05:29:24.443284   388 solver.cpp:213] Iteration 1268, loss = 0.000302474
I0621 05:29:24.443369   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000302349 (* 1 = 0.000302349 loss)
I0621 05:29:24.443392   388 solver.cpp:473] Iteration 1268, lr = 0.01
I0621 05:29:36.701982   388 solver.cpp:213] Iteration 1269, loss = 0.000302163
I0621 05:29:36.702183   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000302313 (* 1 = 0.000302313 loss)
I0621 05:29:36.702219   388 solver.cpp:473] Iteration 1269, lr = 0.01
I0621 05:29:49.161538   388 solver.cpp:213] Iteration 1270, loss = 0.000301923
I0621 05:29:49.161622   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000301955 (* 1 = 0.000301955 loss)
I0621 05:29:49.161644   388 solver.cpp:473] Iteration 1270, lr = 0.01
I0621 05:30:01.427088   388 solver.cpp:213] Iteration 1271, loss = 0.000301831
I0621 05:30:01.427170   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000301582 (* 1 = 0.000301582 loss)
I0621 05:30:01.427192   388 solver.cpp:473] Iteration 1271, lr = 0.01
I0621 05:30:13.852299   388 solver.cpp:213] Iteration 1272, loss = 0.000301662
I0621 05:30:13.852577   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000301876 (* 1 = 0.000301876 loss)
I0621 05:30:13.852622   388 solver.cpp:473] Iteration 1272, lr = 0.01
I0621 05:30:26.154558   388 solver.cpp:213] Iteration 1273, loss = 0.000301478
I0621 05:30:26.154641   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000301698 (* 1 = 0.000301698 loss)
I0621 05:30:26.154664   388 solver.cpp:473] Iteration 1273, lr = 0.01
I0621 05:30:38.475713   388 solver.cpp:213] Iteration 1274, loss = 0.000301214
I0621 05:30:38.475859   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000301375 (* 1 = 0.000301375 loss)
I0621 05:30:38.475929   388 solver.cpp:473] Iteration 1274, lr = 0.01
I0621 05:30:50.932319   388 solver.cpp:213] Iteration 1275, loss = 0.000301013
I0621 05:30:50.932597   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000300896 (* 1 = 0.000300896 loss)
I0621 05:30:50.932646   388 solver.cpp:473] Iteration 1275, lr = 0.01
I0621 05:31:03.200623   388 solver.cpp:213] Iteration 1276, loss = 0.000300866
I0621 05:31:03.200708   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000300639 (* 1 = 0.000300639 loss)
I0621 05:31:03.200731   388 solver.cpp:473] Iteration 1276, lr = 0.01
I0621 05:31:15.468257   388 solver.cpp:213] Iteration 1277, loss = 0.000300643
I0621 05:31:15.468344   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000300756 (* 1 = 0.000300756 loss)
I0621 05:31:15.468367   388 solver.cpp:473] Iteration 1277, lr = 0.01
I0621 05:31:27.740727   388 solver.cpp:213] Iteration 1278, loss = 0.000300592
I0621 05:31:27.747136   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00030062 (* 1 = 0.00030062 loss)
I0621 05:31:27.747162   388 solver.cpp:473] Iteration 1278, lr = 0.01
I0621 05:31:40.014382   388 solver.cpp:213] Iteration 1279, loss = 0.000300375
I0621 05:31:40.014483   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000300204 (* 1 = 0.000300204 loss)
I0621 05:31:40.014506   388 solver.cpp:473] Iteration 1279, lr = 0.01
I0621 05:31:52.363989   388 solver.cpp:213] Iteration 1280, loss = 0.000300087
I0621 05:31:52.364089   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000300332 (* 1 = 0.000300332 loss)
I0621 05:31:52.364114   388 solver.cpp:473] Iteration 1280, lr = 0.01
I0621 05:32:04.600071   388 solver.cpp:213] Iteration 1281, loss = 0.000299957
I0621 05:32:04.600276   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000300294 (* 1 = 0.000300294 loss)
I0621 05:32:04.600301   388 solver.cpp:473] Iteration 1281, lr = 0.01
I0621 05:32:16.866753   388 solver.cpp:213] Iteration 1282, loss = 0.000299654
I0621 05:32:16.866853   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000299935 (* 1 = 0.000299935 loss)
I0621 05:32:16.866878   388 solver.cpp:473] Iteration 1282, lr = 0.01
I0621 05:32:29.170313   388 solver.cpp:213] Iteration 1283, loss = 0.00029955
I0621 05:32:29.170416   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000299532 (* 1 = 0.000299532 loss)
I0621 05:32:29.170439   388 solver.cpp:473] Iteration 1283, lr = 0.01
I0621 05:32:41.580391   388 solver.cpp:213] Iteration 1284, loss = 0.000299239
I0621 05:32:41.580706   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000300054 (* 1 = 0.000300054 loss)
I0621 05:32:41.580759   388 solver.cpp:473] Iteration 1284, lr = 0.01
I0621 05:32:53.904003   388 solver.cpp:213] Iteration 1285, loss = 0.000299294
I0621 05:32:53.904109   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000298669 (* 1 = 0.000298669 loss)
I0621 05:32:53.904131   388 solver.cpp:473] Iteration 1285, lr = 0.01
I0621 05:33:06.135069   388 solver.cpp:213] Iteration 1286, loss = 0.000299018
I0621 05:33:06.135170   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000298985 (* 1 = 0.000298985 loss)
I0621 05:33:06.135193   388 solver.cpp:473] Iteration 1286, lr = 0.01
I0621 05:33:18.382869   388 solver.cpp:213] Iteration 1287, loss = 0.000298786
I0621 05:33:18.383067   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000298354 (* 1 = 0.000298354 loss)
I0621 05:33:18.383095   388 solver.cpp:473] Iteration 1287, lr = 0.01
I0621 05:33:30.628829   388 solver.cpp:213] Iteration 1288, loss = 0.000298594
I0621 05:33:30.628928   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000298385 (* 1 = 0.000298385 loss)
I0621 05:33:30.628950   388 solver.cpp:473] Iteration 1288, lr = 0.01
I0621 05:33:42.895764   388 solver.cpp:213] Iteration 1289, loss = 0.000298384
I0621 05:33:42.895867   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000298196 (* 1 = 0.000298196 loss)
I0621 05:33:42.895892   388 solver.cpp:473] Iteration 1289, lr = 0.01
I0621 05:33:55.217612   388 solver.cpp:213] Iteration 1290, loss = 0.000298284
I0621 05:33:55.217901   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000298216 (* 1 = 0.000298216 loss)
I0621 05:33:55.217947   388 solver.cpp:473] Iteration 1290, lr = 0.01
I0621 05:34:07.576645   388 solver.cpp:213] Iteration 1291, loss = 0.000297981
I0621 05:34:07.576742   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000297894 (* 1 = 0.000297894 loss)
I0621 05:34:07.576764   388 solver.cpp:473] Iteration 1291, lr = 0.01
I0621 05:34:19.960307   388 solver.cpp:213] Iteration 1292, loss = 0.000297876
I0621 05:34:19.960419   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00029779 (* 1 = 0.00029779 loss)
I0621 05:34:19.960444   388 solver.cpp:473] Iteration 1292, lr = 0.01
I0621 05:34:32.223866   388 solver.cpp:213] Iteration 1293, loss = 0.000297786
I0621 05:34:32.224244   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000297793 (* 1 = 0.000297793 loss)
I0621 05:34:32.224280   388 solver.cpp:473] Iteration 1293, lr = 0.01
I0621 05:34:44.672870   388 solver.cpp:213] Iteration 1294, loss = 0.000297445
I0621 05:34:44.672974   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00029714 (* 1 = 0.00029714 loss)
I0621 05:34:44.672997   388 solver.cpp:473] Iteration 1294, lr = 0.01
I0621 05:34:57.005832   388 solver.cpp:213] Iteration 1295, loss = 0.000297177
I0621 05:34:57.005931   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000297133 (* 1 = 0.000297133 loss)
I0621 05:34:57.005955   388 solver.cpp:473] Iteration 1295, lr = 0.01
I0621 05:35:09.333362   388 solver.cpp:213] Iteration 1296, loss = 0.000297024
I0621 05:35:09.333626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000297245 (* 1 = 0.000297245 loss)
I0621 05:35:09.333659   388 solver.cpp:473] Iteration 1296, lr = 0.01
I0621 05:35:21.715924   388 solver.cpp:213] Iteration 1297, loss = 0.00029694
I0621 05:35:21.716027   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000296908 (* 1 = 0.000296908 loss)
I0621 05:35:21.716048   388 solver.cpp:473] Iteration 1297, lr = 0.01
I0621 05:35:34.043057   388 solver.cpp:213] Iteration 1298, loss = 0.000296627
I0621 05:35:34.043169   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000296469 (* 1 = 0.000296469 loss)
I0621 05:35:34.043191   388 solver.cpp:473] Iteration 1298, lr = 0.01
I0621 05:35:46.289640   388 solver.cpp:213] Iteration 1299, loss = 0.000296529
I0621 05:35:46.289842   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000296463 (* 1 = 0.000296463 loss)
I0621 05:35:46.289867   388 solver.cpp:473] Iteration 1299, lr = 0.01
I0621 05:35:58.578660   388 solver.cpp:213] Iteration 1300, loss = 0.000296361
I0621 05:35:58.578763   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000295718 (* 1 = 0.000295718 loss)
I0621 05:35:58.578786   388 solver.cpp:473] Iteration 1300, lr = 0.01
I0621 05:36:10.929534   388 solver.cpp:213] Iteration 1301, loss = 0.000296129
I0621 05:36:10.929633   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000296251 (* 1 = 0.000296251 loss)
I0621 05:36:10.929656   388 solver.cpp:473] Iteration 1301, lr = 0.01
I0621 05:36:23.173524   388 solver.cpp:213] Iteration 1302, loss = 0.000295981
I0621 05:36:23.173804   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00029583 (* 1 = 0.00029583 loss)
I0621 05:36:23.173864   388 solver.cpp:473] Iteration 1302, lr = 0.01
I0621 05:36:35.657956   388 solver.cpp:213] Iteration 1303, loss = 0.000295658
I0621 05:36:35.658073   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000295368 (* 1 = 0.000295368 loss)
I0621 05:36:35.658100   388 solver.cpp:473] Iteration 1303, lr = 0.01
I0621 05:36:48.030077   388 solver.cpp:213] Iteration 1304, loss = 0.000295584
I0621 05:36:48.030191   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000295569 (* 1 = 0.000295569 loss)
I0621 05:36:48.030217   388 solver.cpp:473] Iteration 1304, lr = 0.01
I0621 05:37:00.387684   388 solver.cpp:213] Iteration 1305, loss = 0.000295497
I0621 05:37:00.387892   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000294946 (* 1 = 0.000294946 loss)
I0621 05:37:00.387922   388 solver.cpp:473] Iteration 1305, lr = 0.01
I0621 05:37:12.724293   388 solver.cpp:213] Iteration 1306, loss = 0.000295196
I0621 05:37:12.724393   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000295219 (* 1 = 0.000295219 loss)
I0621 05:37:12.724416   388 solver.cpp:473] Iteration 1306, lr = 0.01
I0621 05:37:25.027112   388 solver.cpp:213] Iteration 1307, loss = 0.000295114
I0621 05:37:25.027209   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000295441 (* 1 = 0.000295441 loss)
I0621 05:37:25.027233   388 solver.cpp:473] Iteration 1307, lr = 0.01
I0621 05:37:37.383306   388 solver.cpp:213] Iteration 1308, loss = 0.000294901
I0621 05:37:37.383535   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000294416 (* 1 = 0.000294416 loss)
I0621 05:37:37.383568   388 solver.cpp:473] Iteration 1308, lr = 0.01
I0621 05:37:49.724179   388 solver.cpp:213] Iteration 1309, loss = 0.000294697
I0621 05:37:49.724282   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000294575 (* 1 = 0.000294575 loss)
I0621 05:37:49.724305   388 solver.cpp:473] Iteration 1309, lr = 0.01
I0621 05:38:02.037231   388 solver.cpp:213] Iteration 1310, loss = 0.000294487
I0621 05:38:02.037334   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000294223 (* 1 = 0.000294223 loss)
I0621 05:38:02.037360   388 solver.cpp:473] Iteration 1310, lr = 0.01
I0621 05:38:14.331351   388 solver.cpp:213] Iteration 1311, loss = 0.000294334
I0621 05:38:14.331565   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000293986 (* 1 = 0.000293986 loss)
I0621 05:38:14.331617   388 solver.cpp:473] Iteration 1311, lr = 0.01
I0621 05:38:26.584025   388 solver.cpp:213] Iteration 1312, loss = 0.000294202
I0621 05:38:26.584112   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000294253 (* 1 = 0.000294253 loss)
I0621 05:38:26.584136   388 solver.cpp:473] Iteration 1312, lr = 0.01
I0621 05:38:39.035044   388 solver.cpp:213] Iteration 1313, loss = 0.000293892
I0621 05:38:39.035142   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000293863 (* 1 = 0.000293863 loss)
I0621 05:38:39.035166   388 solver.cpp:473] Iteration 1313, lr = 0.01
I0621 05:38:51.394708   388 solver.cpp:213] Iteration 1314, loss = 0.000293809
I0621 05:38:51.394975   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000293845 (* 1 = 0.000293845 loss)
I0621 05:38:51.395023   388 solver.cpp:473] Iteration 1314, lr = 0.01
I0621 05:39:03.676777   388 solver.cpp:213] Iteration 1315, loss = 0.00029364
I0621 05:39:03.676862   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000293474 (* 1 = 0.000293474 loss)
I0621 05:39:03.676884   388 solver.cpp:473] Iteration 1315, lr = 0.01
I0621 05:39:16.019023   388 solver.cpp:213] Iteration 1316, loss = 0.000293313
I0621 05:39:16.019114   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00029373 (* 1 = 0.00029373 loss)
I0621 05:39:16.019136   388 solver.cpp:473] Iteration 1316, lr = 0.01
I0621 05:39:28.476464   388 solver.cpp:213] Iteration 1317, loss = 0.000293322
I0621 05:39:28.476725   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000293151 (* 1 = 0.000293151 loss)
I0621 05:39:28.476788   388 solver.cpp:473] Iteration 1317, lr = 0.01
I0621 05:39:40.952059   388 solver.cpp:213] Iteration 1318, loss = 0.000293088
I0621 05:39:40.952144   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000293349 (* 1 = 0.000293349 loss)
I0621 05:39:40.952167   388 solver.cpp:473] Iteration 1318, lr = 0.01
I0621 05:39:53.342335   388 solver.cpp:213] Iteration 1319, loss = 0.000292971
I0621 05:39:53.342417   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000293187 (* 1 = 0.000293187 loss)
I0621 05:39:53.342442   388 solver.cpp:473] Iteration 1319, lr = 0.01
I0621 05:40:05.685914   388 solver.cpp:213] Iteration 1320, loss = 0.000292818
I0621 05:40:05.686225   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00029307 (* 1 = 0.00029307 loss)
I0621 05:40:05.686333   388 solver.cpp:473] Iteration 1320, lr = 0.01
I0621 05:40:17.982676   388 solver.cpp:213] Iteration 1321, loss = 0.000292652
I0621 05:40:17.982758   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000292747 (* 1 = 0.000292747 loss)
I0621 05:40:17.982780   388 solver.cpp:473] Iteration 1321, lr = 0.01
I0621 05:40:30.371815   388 solver.cpp:213] Iteration 1322, loss = 0.000292298
I0621 05:40:30.379763   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000292293 (* 1 = 0.000292293 loss)
I0621 05:40:30.379817   388 solver.cpp:473] Iteration 1322, lr = 0.01
I0621 05:40:42.661972   388 solver.cpp:213] Iteration 1323, loss = 0.000292231
I0621 05:40:42.662204   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000292184 (* 1 = 0.000292184 loss)
I0621 05:40:42.662228   388 solver.cpp:473] Iteration 1323, lr = 0.01
I0621 05:40:54.950165   388 solver.cpp:213] Iteration 1324, loss = 0.000291922
I0621 05:40:54.950247   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000291773 (* 1 = 0.000291773 loss)
I0621 05:40:54.950268   388 solver.cpp:473] Iteration 1324, lr = 0.01
I0621 05:41:07.194949   388 solver.cpp:213] Iteration 1325, loss = 0.000291746
I0621 05:41:07.195035   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000291746 (* 1 = 0.000291746 loss)
I0621 05:41:07.195058   388 solver.cpp:473] Iteration 1325, lr = 0.01
I0621 05:41:19.421145   388 solver.cpp:213] Iteration 1326, loss = 0.000291781
I0621 05:41:19.421315   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00029214 (* 1 = 0.00029214 loss)
I0621 05:41:19.421339   388 solver.cpp:473] Iteration 1326, lr = 0.01
I0621 05:41:31.641934   388 solver.cpp:213] Iteration 1327, loss = 0.000291302
I0621 05:41:31.642020   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000291714 (* 1 = 0.000291714 loss)
I0621 05:41:31.642043   388 solver.cpp:473] Iteration 1327, lr = 0.01
I0621 05:41:43.924804   388 solver.cpp:213] Iteration 1328, loss = 0.000291302
I0621 05:41:43.924886   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000291041 (* 1 = 0.000291041 loss)
I0621 05:41:43.924908   388 solver.cpp:473] Iteration 1328, lr = 0.01
I0621 05:41:56.221259   388 solver.cpp:213] Iteration 1329, loss = 0.000291051
I0621 05:41:56.221477   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000290852 (* 1 = 0.000290852 loss)
I0621 05:41:56.221508   388 solver.cpp:473] Iteration 1329, lr = 0.01
I0621 05:42:08.558300   388 solver.cpp:213] Iteration 1330, loss = 0.000290939
I0621 05:42:08.558388   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000291386 (* 1 = 0.000291386 loss)
I0621 05:42:08.558411   388 solver.cpp:473] Iteration 1330, lr = 0.01
I0621 05:42:20.830225   388 solver.cpp:213] Iteration 1331, loss = 0.000290714
I0621 05:42:20.830314   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000290603 (* 1 = 0.000290603 loss)
I0621 05:42:20.830337   388 solver.cpp:473] Iteration 1331, lr = 0.01
I0621 05:42:33.153622   388 solver.cpp:213] Iteration 1332, loss = 0.000290561
I0621 05:42:33.153846   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000290729 (* 1 = 0.000290729 loss)
I0621 05:42:33.153882   388 solver.cpp:473] Iteration 1332, lr = 0.01
I0621 05:42:45.484357   388 solver.cpp:213] Iteration 1333, loss = 0.000290314
I0621 05:42:45.484443   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000290251 (* 1 = 0.000290251 loss)
I0621 05:42:45.484465   388 solver.cpp:473] Iteration 1333, lr = 0.01
I0621 05:42:57.794847   388 solver.cpp:213] Iteration 1334, loss = 0.000290123
I0621 05:42:57.794936   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000290317 (* 1 = 0.000290317 loss)
I0621 05:42:57.794960   388 solver.cpp:473] Iteration 1334, lr = 0.01
I0621 05:43:10.071668   388 solver.cpp:213] Iteration 1335, loss = 0.000290011
I0621 05:43:10.071871   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000290083 (* 1 = 0.000290083 loss)
I0621 05:43:10.071897   388 solver.cpp:473] Iteration 1335, lr = 0.01
I0621 05:43:22.329452   388 solver.cpp:213] Iteration 1336, loss = 0.000289822
I0621 05:43:22.329538   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000289547 (* 1 = 0.000289547 loss)
I0621 05:43:22.329571   388 solver.cpp:473] Iteration 1336, lr = 0.01
I0621 05:43:34.650946   388 solver.cpp:213] Iteration 1337, loss = 0.00028963
I0621 05:43:34.651029   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000289558 (* 1 = 0.000289558 loss)
I0621 05:43:34.651052   388 solver.cpp:473] Iteration 1337, lr = 0.01
I0621 05:43:47.059821   388 solver.cpp:213] Iteration 1338, loss = 0.000289528
I0621 05:43:47.060034   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000289273 (* 1 = 0.000289273 loss)
I0621 05:43:47.060067   388 solver.cpp:473] Iteration 1338, lr = 0.01
I0621 05:43:59.519927   388 solver.cpp:213] Iteration 1339, loss = 0.000289357
I0621 05:43:59.520009   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00028919 (* 1 = 0.00028919 loss)
I0621 05:43:59.520031   388 solver.cpp:473] Iteration 1339, lr = 0.01
I0621 05:44:11.846904   388 solver.cpp:213] Iteration 1340, loss = 0.000289126
I0621 05:44:11.846993   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00028865 (* 1 = 0.00028865 loss)
I0621 05:44:11.847017   388 solver.cpp:473] Iteration 1340, lr = 0.01
I0621 05:44:24.097759   388 solver.cpp:213] Iteration 1341, loss = 0.000288937
I0621 05:44:24.097928   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000289235 (* 1 = 0.000289235 loss)
I0621 05:44:24.097951   388 solver.cpp:473] Iteration 1341, lr = 0.01
I0621 05:44:36.456092   388 solver.cpp:213] Iteration 1342, loss = 0.000288805
I0621 05:44:36.456184   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000289092 (* 1 = 0.000289092 loss)
I0621 05:44:36.456210   388 solver.cpp:473] Iteration 1342, lr = 0.01
I0621 05:44:48.730798   388 solver.cpp:213] Iteration 1343, loss = 0.000288577
I0621 05:44:48.730881   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000288394 (* 1 = 0.000288394 loss)
I0621 05:44:48.730904   388 solver.cpp:473] Iteration 1343, lr = 0.01
I0621 05:45:00.978109   388 solver.cpp:213] Iteration 1344, loss = 0.000288311
I0621 05:45:00.978363   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000288151 (* 1 = 0.000288151 loss)
I0621 05:45:00.978410   388 solver.cpp:473] Iteration 1344, lr = 0.01
I0621 05:45:13.361121   388 solver.cpp:213] Iteration 1345, loss = 0.000288223
I0621 05:45:13.361214   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000288005 (* 1 = 0.000288005 loss)
I0621 05:45:13.361239   388 solver.cpp:473] Iteration 1345, lr = 0.01
I0621 05:45:25.677031   388 solver.cpp:213] Iteration 1346, loss = 0.000288078
I0621 05:45:25.677114   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000287923 (* 1 = 0.000287923 loss)
I0621 05:45:25.677136   388 solver.cpp:473] Iteration 1346, lr = 0.01
I0621 05:45:38.057588   388 solver.cpp:213] Iteration 1347, loss = 0.000287912
I0621 05:45:38.066023   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000287989 (* 1 = 0.000287989 loss)
I0621 05:45:38.066074   388 solver.cpp:473] Iteration 1347, lr = 0.01
I0621 05:45:50.452282   388 solver.cpp:213] Iteration 1348, loss = 0.000287802
I0621 05:45:50.452366   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000288005 (* 1 = 0.000288005 loss)
I0621 05:45:50.452389   388 solver.cpp:473] Iteration 1348, lr = 0.01
I0621 05:46:02.749964   388 solver.cpp:213] Iteration 1349, loss = 0.000287601
I0621 05:46:02.750049   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000287425 (* 1 = 0.000287425 loss)
I0621 05:46:02.750072   388 solver.cpp:473] Iteration 1349, lr = 0.01
I0621 05:46:14.975563   388 solver.cpp:213] Iteration 1350, loss = 0.000287388
I0621 05:46:14.975742   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000287473 (* 1 = 0.000287473 loss)
I0621 05:46:14.975767   388 solver.cpp:473] Iteration 1350, lr = 0.01
I0621 05:46:27.195297   388 solver.cpp:213] Iteration 1351, loss = 0.000287205
I0621 05:46:27.195374   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000287011 (* 1 = 0.000287011 loss)
I0621 05:46:27.195395   388 solver.cpp:473] Iteration 1351, lr = 0.01
I0621 05:46:39.463206   388 solver.cpp:213] Iteration 1352, loss = 0.000287145
I0621 05:46:39.463284   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000287063 (* 1 = 0.000287063 loss)
I0621 05:46:39.463306   388 solver.cpp:473] Iteration 1352, lr = 0.01
I0621 05:46:51.768277   388 solver.cpp:213] Iteration 1353, loss = 0.000286884
I0621 05:46:51.768537   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000286821 (* 1 = 0.000286821 loss)
I0621 05:46:51.768582   388 solver.cpp:473] Iteration 1353, lr = 0.01
I0621 05:47:04.250658   388 solver.cpp:213] Iteration 1354, loss = 0.000286603
I0621 05:47:04.250742   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000286411 (* 1 = 0.000286411 loss)
I0621 05:47:04.250764   388 solver.cpp:473] Iteration 1354, lr = 0.01
I0621 05:47:16.549635   388 solver.cpp:213] Iteration 1355, loss = 0.00028648
I0621 05:47:16.549718   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000286456 (* 1 = 0.000286456 loss)
I0621 05:47:16.549741   388 solver.cpp:473] Iteration 1355, lr = 0.01
I0621 05:47:28.859216   388 solver.cpp:213] Iteration 1356, loss = 0.000286243
I0621 05:47:28.859712   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000286225 (* 1 = 0.000286225 loss)
I0621 05:47:28.859737   388 solver.cpp:473] Iteration 1356, lr = 0.01
I0621 05:47:41.248699   388 solver.cpp:213] Iteration 1357, loss = 0.000286145
I0621 05:47:41.248781   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000286073 (* 1 = 0.000286073 loss)
I0621 05:47:41.248803   388 solver.cpp:473] Iteration 1357, lr = 0.01
I0621 05:47:53.539476   388 solver.cpp:213] Iteration 1358, loss = 0.000285962
I0621 05:47:53.539557   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000286403 (* 1 = 0.000286403 loss)
I0621 05:47:53.539580   388 solver.cpp:473] Iteration 1358, lr = 0.01
I0621 05:48:05.908247   388 solver.cpp:213] Iteration 1359, loss = 0.00028574
I0621 05:48:05.908465   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000286153 (* 1 = 0.000286153 loss)
I0621 05:48:05.908511   388 solver.cpp:473] Iteration 1359, lr = 0.01
I0621 05:48:18.168715   388 solver.cpp:213] Iteration 1360, loss = 0.000285594
I0621 05:48:18.168802   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000285784 (* 1 = 0.000285784 loss)
I0621 05:48:18.168823   388 solver.cpp:473] Iteration 1360, lr = 0.01
I0621 05:48:30.547344   388 solver.cpp:213] Iteration 1361, loss = 0.00028543
I0621 05:48:30.547442   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000285293 (* 1 = 0.000285293 loss)
I0621 05:48:30.547469   388 solver.cpp:473] Iteration 1361, lr = 0.01
I0621 05:48:42.962980   388 solver.cpp:213] Iteration 1362, loss = 0.000285429
I0621 05:48:42.963187   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000285329 (* 1 = 0.000285329 loss)
I0621 05:48:42.963218   388 solver.cpp:473] Iteration 1362, lr = 0.01
I0621 05:48:55.299427   388 solver.cpp:213] Iteration 1363, loss = 0.000285125
I0621 05:48:55.299507   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000285284 (* 1 = 0.000285284 loss)
I0621 05:48:55.299530   388 solver.cpp:473] Iteration 1363, lr = 0.01
I0621 05:49:07.567719   388 solver.cpp:213] Iteration 1364, loss = 0.000285028
I0621 05:49:07.567807   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000285091 (* 1 = 0.000285091 loss)
I0621 05:49:07.567831   388 solver.cpp:473] Iteration 1364, lr = 0.01
I0621 05:49:19.826885   388 solver.cpp:213] Iteration 1365, loss = 0.000284688
I0621 05:49:19.827172   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000284305 (* 1 = 0.000284305 loss)
I0621 05:49:19.827236   388 solver.cpp:473] Iteration 1365, lr = 0.01
I0621 05:49:32.087909   388 solver.cpp:213] Iteration 1366, loss = 0.000284494
I0621 05:49:32.087995   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000284615 (* 1 = 0.000284615 loss)
I0621 05:49:32.088016   388 solver.cpp:473] Iteration 1366, lr = 0.01
I0621 05:49:44.513244   388 solver.cpp:213] Iteration 1367, loss = 0.00028438
I0621 05:49:44.513329   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000284141 (* 1 = 0.000284141 loss)
I0621 05:49:44.513352   388 solver.cpp:473] Iteration 1367, lr = 0.01
I0621 05:49:56.922283   388 solver.cpp:213] Iteration 1368, loss = 0.000284218
I0621 05:49:56.922545   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000284263 (* 1 = 0.000284263 loss)
I0621 05:49:56.922595   388 solver.cpp:473] Iteration 1368, lr = 0.01
I0621 05:50:09.418714   388 solver.cpp:213] Iteration 1369, loss = 0.000284214
I0621 05:50:09.418794   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000284231 (* 1 = 0.000284231 loss)
I0621 05:50:09.418817   388 solver.cpp:473] Iteration 1369, lr = 0.01
I0621 05:50:21.757664   388 solver.cpp:213] Iteration 1370, loss = 0.000283904
I0621 05:50:21.757750   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000283183 (* 1 = 0.000283183 loss)
I0621 05:50:21.757773   388 solver.cpp:473] Iteration 1370, lr = 0.01
I0621 05:50:34.024065   388 solver.cpp:213] Iteration 1371, loss = 0.000283745
I0621 05:50:34.024240   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000283755 (* 1 = 0.000283755 loss)
I0621 05:50:34.024267   388 solver.cpp:473] Iteration 1371, lr = 0.01
I0621 05:50:46.319854   388 solver.cpp:213] Iteration 1372, loss = 0.000283558
I0621 05:50:46.319950   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000283396 (* 1 = 0.000283396 loss)
I0621 05:50:46.319983   388 solver.cpp:473] Iteration 1372, lr = 0.01
I0621 05:50:58.687546   388 solver.cpp:213] Iteration 1373, loss = 0.000283482
I0621 05:50:58.687626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000283274 (* 1 = 0.000283274 loss)
I0621 05:50:58.687649   388 solver.cpp:473] Iteration 1373, lr = 0.01
I0621 05:51:10.953969   388 solver.cpp:213] Iteration 1374, loss = 0.000283109
I0621 05:51:10.954206   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000282876 (* 1 = 0.000282876 loss)
I0621 05:51:10.954252   388 solver.cpp:473] Iteration 1374, lr = 0.01
I0621 05:51:23.321957   388 solver.cpp:213] Iteration 1375, loss = 0.000283158
I0621 05:51:23.322042   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000283254 (* 1 = 0.000283254 loss)
I0621 05:51:23.322064   388 solver.cpp:473] Iteration 1375, lr = 0.01
I0621 05:51:35.582929   388 solver.cpp:213] Iteration 1376, loss = 0.0002828
I0621 05:51:35.583014   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000283496 (* 1 = 0.000283496 loss)
I0621 05:51:35.583037   388 solver.cpp:473] Iteration 1376, lr = 0.01
I0621 05:51:47.863812   388 solver.cpp:213] Iteration 1377, loss = 0.000282645
I0621 05:51:47.863986   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000282901 (* 1 = 0.000282901 loss)
I0621 05:51:47.864012   388 solver.cpp:473] Iteration 1377, lr = 0.01
I0621 05:52:00.215440   388 solver.cpp:213] Iteration 1378, loss = 0.000282509
I0621 05:52:00.215515   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000282605 (* 1 = 0.000282605 loss)
I0621 05:52:00.215538   388 solver.cpp:473] Iteration 1378, lr = 0.01
I0621 05:52:12.468839   388 solver.cpp:213] Iteration 1379, loss = 0.000282428
I0621 05:52:12.468919   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00028257 (* 1 = 0.00028257 loss)
I0621 05:52:12.468940   388 solver.cpp:473] Iteration 1379, lr = 0.01
I0621 05:52:24.704710   388 solver.cpp:213] Iteration 1380, loss = 0.000282122
I0621 05:52:24.704968   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000282249 (* 1 = 0.000282249 loss)
I0621 05:52:24.705031   388 solver.cpp:473] Iteration 1380, lr = 0.01
I0621 05:52:36.954330   388 solver.cpp:213] Iteration 1381, loss = 0.000282012
I0621 05:52:36.954416   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000282415 (* 1 = 0.000282415 loss)
I0621 05:52:36.954438   388 solver.cpp:473] Iteration 1381, lr = 0.01
I0621 05:52:49.253734   388 solver.cpp:213] Iteration 1382, loss = 0.00028197
I0621 05:52:49.253820   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000282025 (* 1 = 0.000282025 loss)
I0621 05:52:49.253842   388 solver.cpp:473] Iteration 1382, lr = 0.01
I0621 05:53:01.659767   388 solver.cpp:213] Iteration 1383, loss = 0.000281696
I0621 05:53:01.660012   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000281178 (* 1 = 0.000281178 loss)
I0621 05:53:01.660058   388 solver.cpp:473] Iteration 1383, lr = 0.01
I0621 05:53:14.152461   388 solver.cpp:213] Iteration 1384, loss = 0.000281463
I0621 05:53:14.152545   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000281258 (* 1 = 0.000281258 loss)
I0621 05:53:14.152570   388 solver.cpp:473] Iteration 1384, lr = 0.01
I0621 05:53:26.417054   388 solver.cpp:213] Iteration 1385, loss = 0.000281355
I0621 05:53:26.417138   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000281542 (* 1 = 0.000281542 loss)
I0621 05:53:26.417161   388 solver.cpp:473] Iteration 1385, lr = 0.01
I0621 05:53:38.713218   388 solver.cpp:213] Iteration 1386, loss = 0.000281152
I0621 05:53:38.713413   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00028097 (* 1 = 0.00028097 loss)
I0621 05:53:38.713438   388 solver.cpp:473] Iteration 1386, lr = 0.01
I0621 05:53:50.936586   388 solver.cpp:213] Iteration 1387, loss = 0.000281149
I0621 05:53:50.936668   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000281318 (* 1 = 0.000281318 loss)
I0621 05:53:50.936691   388 solver.cpp:473] Iteration 1387, lr = 0.01
I0621 05:54:03.245800   388 solver.cpp:213] Iteration 1388, loss = 0.00028078
I0621 05:54:03.245921   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000280392 (* 1 = 0.000280392 loss)
I0621 05:54:03.245960   388 solver.cpp:473] Iteration 1388, lr = 0.01
I0621 05:54:15.591734   388 solver.cpp:213] Iteration 1389, loss = 0.000280847
I0621 05:54:15.597769   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000280797 (* 1 = 0.000280797 loss)
I0621 05:54:15.597834   388 solver.cpp:473] Iteration 1389, lr = 0.01
I0621 05:54:27.868278   388 solver.cpp:213] Iteration 1390, loss = 0.000280659
I0621 05:54:27.868363   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000279984 (* 1 = 0.000279984 loss)
I0621 05:54:27.868386   388 solver.cpp:473] Iteration 1390, lr = 0.01
I0621 05:54:40.201350   388 solver.cpp:213] Iteration 1391, loss = 0.000280405
I0621 05:54:40.201441   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000280757 (* 1 = 0.000280757 loss)
I0621 05:54:40.201465   388 solver.cpp:473] Iteration 1391, lr = 0.01
I0621 05:54:52.554128   388 solver.cpp:213] Iteration 1392, loss = 0.000280212
I0621 05:54:52.554373   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000280387 (* 1 = 0.000280387 loss)
I0621 05:54:52.554421   388 solver.cpp:473] Iteration 1392, lr = 0.01
I0621 05:55:04.944213   388 solver.cpp:213] Iteration 1393, loss = 0.000280009
I0621 05:55:04.944298   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000279962 (* 1 = 0.000279962 loss)
I0621 05:55:04.944320   388 solver.cpp:473] Iteration 1393, lr = 0.01
I0621 05:55:17.238970   388 solver.cpp:213] Iteration 1394, loss = 0.000279819
I0621 05:55:17.239056   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000280289 (* 1 = 0.000280289 loss)
I0621 05:55:17.239086   388 solver.cpp:473] Iteration 1394, lr = 0.01
I0621 05:55:29.624338   388 solver.cpp:213] Iteration 1395, loss = 0.000279637
I0621 05:55:29.628901   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000279758 (* 1 = 0.000279758 loss)
I0621 05:55:29.628933   388 solver.cpp:473] Iteration 1395, lr = 0.01
I0621 05:55:41.948117   388 solver.cpp:213] Iteration 1396, loss = 0.000279527
I0621 05:55:41.948204   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000279472 (* 1 = 0.000279472 loss)
I0621 05:55:41.948225   388 solver.cpp:473] Iteration 1396, lr = 0.01
I0621 05:55:54.277798   388 solver.cpp:213] Iteration 1397, loss = 0.000279303
I0621 05:55:54.277883   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000279625 (* 1 = 0.000279625 loss)
I0621 05:55:54.277904   388 solver.cpp:473] Iteration 1397, lr = 0.01
I0621 05:56:06.688684   388 solver.cpp:213] Iteration 1398, loss = 0.000279138
I0621 05:56:06.688992   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000279323 (* 1 = 0.000279323 loss)
I0621 05:56:06.689085   388 solver.cpp:473] Iteration 1398, lr = 0.01
I0621 05:56:18.995110   388 solver.cpp:213] Iteration 1399, loss = 0.00027907
I0621 05:56:18.995232   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00027964 (* 1 = 0.00027964 loss)
I0621 05:56:18.995288   388 solver.cpp:473] Iteration 1399, lr = 0.01
I0621 05:56:31.315044   388 solver.cpp:213] Iteration 1400, loss = 0.000278988
I0621 05:56:31.315135   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000278574 (* 1 = 0.000278574 loss)
I0621 05:56:31.315160   388 solver.cpp:473] Iteration 1400, lr = 0.01
I0621 05:56:43.810317   388 solver.cpp:213] Iteration 1401, loss = 0.000278737
I0621 05:56:43.810539   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000278903 (* 1 = 0.000278903 loss)
I0621 05:56:43.810570   388 solver.cpp:473] Iteration 1401, lr = 0.01
I0621 05:56:56.107563   388 solver.cpp:213] Iteration 1402, loss = 0.00027864
I0621 05:56:56.107643   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000278248 (* 1 = 0.000278248 loss)
I0621 05:56:56.107673   388 solver.cpp:473] Iteration 1402, lr = 0.01
I0621 05:57:08.426412   388 solver.cpp:213] Iteration 1403, loss = 0.000278389
I0621 05:57:08.426494   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000278333 (* 1 = 0.000278333 loss)
I0621 05:57:08.426517   388 solver.cpp:473] Iteration 1403, lr = 0.01
I0621 05:57:20.743717   388 solver.cpp:213] Iteration 1404, loss = 0.000278254
I0621 05:57:20.743937   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000278343 (* 1 = 0.000278343 loss)
I0621 05:57:20.743991   388 solver.cpp:473] Iteration 1404, lr = 0.01
I0621 05:57:33.150864   388 solver.cpp:213] Iteration 1405, loss = 0.000278159
I0621 05:57:33.150951   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00027841 (* 1 = 0.00027841 loss)
I0621 05:57:33.150974   388 solver.cpp:473] Iteration 1405, lr = 0.01
I0621 05:57:45.491518   388 solver.cpp:213] Iteration 1406, loss = 0.000277864
I0621 05:57:45.491600   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000277577 (* 1 = 0.000277577 loss)
I0621 05:57:45.491621   388 solver.cpp:473] Iteration 1406, lr = 0.01
I0621 05:57:57.874620   388 solver.cpp:213] Iteration 1407, loss = 0.000277803
I0621 05:57:57.874796   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000277951 (* 1 = 0.000277951 loss)
I0621 05:57:57.874822   388 solver.cpp:473] Iteration 1407, lr = 0.01
I0621 05:58:10.185137   388 solver.cpp:213] Iteration 1408, loss = 0.000277562
I0621 05:58:10.185223   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000277407 (* 1 = 0.000277407 loss)
I0621 05:58:10.185246   388 solver.cpp:473] Iteration 1408, lr = 0.01
I0621 05:58:22.517474   388 solver.cpp:213] Iteration 1409, loss = 0.000277454
I0621 05:58:22.517562   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000277231 (* 1 = 0.000277231 loss)
I0621 05:58:22.517585   388 solver.cpp:473] Iteration 1409, lr = 0.01
I0621 05:58:34.783761   388 solver.cpp:213] Iteration 1410, loss = 0.000277172
I0621 05:58:34.784003   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000276838 (* 1 = 0.000276838 loss)
I0621 05:58:34.784039   388 solver.cpp:473] Iteration 1410, lr = 0.01
I0621 05:58:47.145480   388 solver.cpp:213] Iteration 1411, loss = 0.000277039
I0621 05:58:47.145557   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000277295 (* 1 = 0.000277295 loss)
I0621 05:58:47.145581   388 solver.cpp:473] Iteration 1411, lr = 0.01
I0621 05:58:59.556351   388 solver.cpp:213] Iteration 1412, loss = 0.000276936
I0621 05:58:59.556437   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00027627 (* 1 = 0.00027627 loss)
I0621 05:58:59.556458   388 solver.cpp:473] Iteration 1412, lr = 0.01
I0621 05:59:11.948259   388 solver.cpp:213] Iteration 1413, loss = 0.000276892
I0621 05:59:11.948464   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00027663 (* 1 = 0.00027663 loss)
I0621 05:59:11.948490   388 solver.cpp:473] Iteration 1413, lr = 0.01
I0621 05:59:24.285938   388 solver.cpp:213] Iteration 1414, loss = 0.000276611
I0621 05:59:24.286026   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000276101 (* 1 = 0.000276101 loss)
I0621 05:59:24.286046   388 solver.cpp:473] Iteration 1414, lr = 0.01
I0621 05:59:36.645858   388 solver.cpp:213] Iteration 1415, loss = 0.000276549
I0621 05:59:36.647024   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000276936 (* 1 = 0.000276936 loss)
I0621 05:59:36.647202   388 solver.cpp:473] Iteration 1415, lr = 0.01
I0621 05:59:48.974386   388 solver.cpp:213] Iteration 1416, loss = 0.000276255
I0621 05:59:48.974740   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000276308 (* 1 = 0.000276308 loss)
I0621 05:59:48.974853   388 solver.cpp:473] Iteration 1416, lr = 0.01
I0621 06:00:01.361127   388 solver.cpp:213] Iteration 1417, loss = 0.000276207
I0621 06:00:01.361225   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000276319 (* 1 = 0.000276319 loss)
I0621 06:00:01.361249   388 solver.cpp:473] Iteration 1417, lr = 0.01
I0621 06:00:13.649379   388 solver.cpp:213] Iteration 1418, loss = 0.000275968
I0621 06:00:13.649471   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000276183 (* 1 = 0.000276183 loss)
I0621 06:00:13.649497   388 solver.cpp:473] Iteration 1418, lr = 0.01
I0621 06:00:26.026085   388 solver.cpp:213] Iteration 1419, loss = 0.000275957
I0621 06:00:26.026345   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000275492 (* 1 = 0.000275492 loss)
I0621 06:00:26.026407   388 solver.cpp:473] Iteration 1419, lr = 0.01
I0621 06:00:38.424439   388 solver.cpp:213] Iteration 1420, loss = 0.000275595
I0621 06:00:38.424530   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000276186 (* 1 = 0.000276186 loss)
I0621 06:00:38.424551   388 solver.cpp:473] Iteration 1420, lr = 0.01
I0621 06:00:50.687445   388 solver.cpp:213] Iteration 1421, loss = 0.00027548
I0621 06:00:50.687531   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000275045 (* 1 = 0.000275045 loss)
I0621 06:00:50.687553   388 solver.cpp:473] Iteration 1421, lr = 0.01
I0621 06:01:03.015774   388 solver.cpp:213] Iteration 1422, loss = 0.000275339
I0621 06:01:03.016304   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000275396 (* 1 = 0.000275396 loss)
I0621 06:01:03.016360   388 solver.cpp:473] Iteration 1422, lr = 0.01
I0621 06:01:15.338577   388 solver.cpp:213] Iteration 1423, loss = 0.000275174
I0621 06:01:15.338656   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000275244 (* 1 = 0.000275244 loss)
I0621 06:01:15.338678   388 solver.cpp:473] Iteration 1423, lr = 0.01
I0621 06:01:27.652156   388 solver.cpp:213] Iteration 1424, loss = 0.000275139
I0621 06:01:27.652240   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000275052 (* 1 = 0.000275052 loss)
I0621 06:01:27.652264   388 solver.cpp:473] Iteration 1424, lr = 0.01
I0621 06:01:40.061409   388 solver.cpp:213] Iteration 1425, loss = 0.000274857
I0621 06:01:40.061651   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000275093 (* 1 = 0.000275093 loss)
I0621 06:01:40.061717   388 solver.cpp:473] Iteration 1425, lr = 0.01
I0621 06:01:52.440800   388 solver.cpp:213] Iteration 1426, loss = 0.000274758
I0621 06:01:52.440896   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000274929 (* 1 = 0.000274929 loss)
I0621 06:01:52.440923   388 solver.cpp:473] Iteration 1426, lr = 0.01
I0621 06:02:04.801393   388 solver.cpp:213] Iteration 1427, loss = 0.000274602
I0621 06:02:04.801476   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000275211 (* 1 = 0.000275211 loss)
I0621 06:02:04.801501   388 solver.cpp:473] Iteration 1427, lr = 0.01
I0621 06:02:17.187793   388 solver.cpp:213] Iteration 1428, loss = 0.000274416
I0621 06:02:17.188060   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000274239 (* 1 = 0.000274239 loss)
I0621 06:02:17.188105   388 solver.cpp:473] Iteration 1428, lr = 0.01
I0621 06:02:29.590024   388 solver.cpp:213] Iteration 1429, loss = 0.000274206
I0621 06:02:29.590111   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000274666 (* 1 = 0.000274666 loss)
I0621 06:02:29.590133   388 solver.cpp:473] Iteration 1429, lr = 0.01
I0621 06:02:41.874207   388 solver.cpp:213] Iteration 1430, loss = 0.000274188
I0621 06:02:41.874295   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000274094 (* 1 = 0.000274094 loss)
I0621 06:02:41.874317   388 solver.cpp:473] Iteration 1430, lr = 0.01
I0621 06:02:54.134923   388 solver.cpp:213] Iteration 1431, loss = 0.000273977
I0621 06:02:54.135130   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000274061 (* 1 = 0.000274061 loss)
I0621 06:02:54.135155   388 solver.cpp:473] Iteration 1431, lr = 0.01
I0621 06:03:06.414433   388 solver.cpp:213] Iteration 1432, loss = 0.000273846
I0621 06:03:06.414515   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00027365 (* 1 = 0.00027365 loss)
I0621 06:03:06.414537   388 solver.cpp:473] Iteration 1432, lr = 0.01
I0621 06:03:18.687139   388 solver.cpp:213] Iteration 1433, loss = 0.000273693
I0621 06:03:18.687227   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000274026 (* 1 = 0.000274026 loss)
I0621 06:03:18.687252   388 solver.cpp:473] Iteration 1433, lr = 0.01
I0621 06:03:30.908475   388 solver.cpp:213] Iteration 1434, loss = 0.000273544
I0621 06:03:30.908661   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000273436 (* 1 = 0.000273436 loss)
I0621 06:03:30.908685   388 solver.cpp:473] Iteration 1434, lr = 0.01
I0621 06:03:43.150123   388 solver.cpp:213] Iteration 1435, loss = 0.000273324
I0621 06:03:43.150208   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000273332 (* 1 = 0.000273332 loss)
I0621 06:03:43.150230   388 solver.cpp:473] Iteration 1435, lr = 0.01
I0621 06:03:55.358808   388 solver.cpp:213] Iteration 1436, loss = 0.000273189
I0621 06:03:55.358894   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000273254 (* 1 = 0.000273254 loss)
I0621 06:03:55.358916   388 solver.cpp:473] Iteration 1436, lr = 0.01
I0621 06:04:07.654772   388 solver.cpp:213] Iteration 1437, loss = 0.000272922
I0621 06:04:07.654973   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000272405 (* 1 = 0.000272405 loss)
I0621 06:04:07.655000   388 solver.cpp:473] Iteration 1437, lr = 0.01
I0621 06:04:19.943552   388 solver.cpp:213] Iteration 1438, loss = 0.000272759
I0621 06:04:19.946617   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000272603 (* 1 = 0.000272603 loss)
I0621 06:04:19.946648   388 solver.cpp:473] Iteration 1438, lr = 0.01
I0621 06:04:32.464805   388 solver.cpp:213] Iteration 1439, loss = 0.00027271
I0621 06:04:32.464889   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00027268 (* 1 = 0.00027268 loss)
I0621 06:04:32.464912   388 solver.cpp:473] Iteration 1439, lr = 0.01
I0621 06:04:44.843390   388 solver.cpp:213] Iteration 1440, loss = 0.000272651
I0621 06:04:44.843577   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000272923 (* 1 = 0.000272923 loss)
I0621 06:04:44.843602   388 solver.cpp:473] Iteration 1440, lr = 0.01
I0621 06:04:57.068141   388 solver.cpp:213] Iteration 1441, loss = 0.000272442
I0621 06:04:57.068223   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000272348 (* 1 = 0.000272348 loss)
I0621 06:04:57.068244   388 solver.cpp:473] Iteration 1441, lr = 0.01
I0621 06:05:09.388770   388 solver.cpp:213] Iteration 1442, loss = 0.000272289
I0621 06:05:09.388854   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000272154 (* 1 = 0.000272154 loss)
I0621 06:05:09.388876   388 solver.cpp:473] Iteration 1442, lr = 0.01
I0621 06:05:21.701815   388 solver.cpp:213] Iteration 1443, loss = 0.000271984
I0621 06:05:21.701992   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000271913 (* 1 = 0.000271913 loss)
I0621 06:05:21.702018   388 solver.cpp:473] Iteration 1443, lr = 0.01
I0621 06:05:34.037127   388 solver.cpp:213] Iteration 1444, loss = 0.000271929
I0621 06:05:34.037211   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000272026 (* 1 = 0.000272026 loss)
I0621 06:05:34.037235   388 solver.cpp:473] Iteration 1444, lr = 0.01
I0621 06:05:46.394798   388 solver.cpp:213] Iteration 1445, loss = 0.000271756
I0621 06:05:46.394881   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000271787 (* 1 = 0.000271787 loss)
I0621 06:05:46.394904   388 solver.cpp:473] Iteration 1445, lr = 0.01
I0621 06:05:58.660310   388 solver.cpp:213] Iteration 1446, loss = 0.000271582
I0621 06:05:58.660554   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000271511 (* 1 = 0.000271511 loss)
I0621 06:05:58.660603   388 solver.cpp:473] Iteration 1446, lr = 0.01
I0621 06:06:11.072950   388 solver.cpp:213] Iteration 1447, loss = 0.000271506
I0621 06:06:11.073042   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000271429 (* 1 = 0.000271429 loss)
I0621 06:06:11.073067   388 solver.cpp:473] Iteration 1447, lr = 0.01
I0621 06:06:23.470947   388 solver.cpp:213] Iteration 1448, loss = 0.000271301
I0621 06:06:23.471034   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000271227 (* 1 = 0.000271227 loss)
I0621 06:06:23.471055   388 solver.cpp:473] Iteration 1448, lr = 0.01
I0621 06:06:35.848243   388 solver.cpp:213] Iteration 1449, loss = 0.00027089
I0621 06:06:35.848455   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000271344 (* 1 = 0.000271344 loss)
I0621 06:06:35.848487   388 solver.cpp:473] Iteration 1449, lr = 0.01
I0621 06:06:48.272145   388 solver.cpp:213] Iteration 1450, loss = 0.000270932
I0621 06:06:48.272263   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000271018 (* 1 = 0.000271018 loss)
I0621 06:06:48.272297   388 solver.cpp:473] Iteration 1450, lr = 0.01
I0621 06:07:00.618306   388 solver.cpp:213] Iteration 1451, loss = 0.00027082
I0621 06:07:00.618389   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000270799 (* 1 = 0.000270799 loss)
I0621 06:07:00.618412   388 solver.cpp:473] Iteration 1451, lr = 0.01
I0621 06:07:12.951205   388 solver.cpp:213] Iteration 1452, loss = 0.000270627
I0621 06:07:12.951424   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000270944 (* 1 = 0.000270944 loss)
I0621 06:07:12.951447   388 solver.cpp:473] Iteration 1452, lr = 0.01
I0621 06:07:25.393215   388 solver.cpp:213] Iteration 1453, loss = 0.000270478
I0621 06:07:25.393299   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000270485 (* 1 = 0.000270485 loss)
I0621 06:07:25.393321   388 solver.cpp:473] Iteration 1453, lr = 0.01
I0621 06:07:37.731165   388 solver.cpp:213] Iteration 1454, loss = 0.000270341
I0621 06:07:37.732308   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00027021 (* 1 = 0.00027021 loss)
I0621 06:07:37.732389   388 solver.cpp:473] Iteration 1454, lr = 0.01
I0621 06:07:50.259459   388 solver.cpp:213] Iteration 1455, loss = 0.000270171
I0621 06:07:50.259727   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000270229 (* 1 = 0.000270229 loss)
I0621 06:07:50.259774   388 solver.cpp:473] Iteration 1455, lr = 0.01
I0621 06:08:02.604677   388 solver.cpp:213] Iteration 1456, loss = 0.000270021
I0621 06:08:02.604760   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000270432 (* 1 = 0.000270432 loss)
I0621 06:08:02.604784   388 solver.cpp:473] Iteration 1456, lr = 0.01
I0621 06:08:14.973219   388 solver.cpp:213] Iteration 1457, loss = 0.000269943
I0621 06:08:14.973306   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000269657 (* 1 = 0.000269657 loss)
I0621 06:08:14.973328   388 solver.cpp:473] Iteration 1457, lr = 0.01
I0621 06:08:27.224297   388 solver.cpp:213] Iteration 1458, loss = 0.000269633
I0621 06:08:27.224572   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000270019 (* 1 = 0.000270019 loss)
I0621 06:08:27.224622   388 solver.cpp:473] Iteration 1458, lr = 0.01
I0621 06:08:39.594235   388 solver.cpp:213] Iteration 1459, loss = 0.000269709
I0621 06:08:39.594317   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000269914 (* 1 = 0.000269914 loss)
I0621 06:08:39.594341   388 solver.cpp:473] Iteration 1459, lr = 0.01
I0621 06:08:51.999197   388 solver.cpp:213] Iteration 1460, loss = 0.000269459
I0621 06:08:51.999284   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000269332 (* 1 = 0.000269332 loss)
I0621 06:08:51.999306   388 solver.cpp:473] Iteration 1460, lr = 0.01
I0621 06:09:04.336704   388 solver.cpp:213] Iteration 1461, loss = 0.000269275
I0621 06:09:04.336915   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000269377 (* 1 = 0.000269377 loss)
I0621 06:09:04.336941   388 solver.cpp:473] Iteration 1461, lr = 0.01
I0621 06:09:16.653632   388 solver.cpp:213] Iteration 1462, loss = 0.000269104
I0621 06:09:16.653714   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000269595 (* 1 = 0.000269595 loss)
I0621 06:09:16.653736   388 solver.cpp:473] Iteration 1462, lr = 0.01
I0621 06:09:28.918681   388 solver.cpp:213] Iteration 1463, loss = 0.000269076
I0621 06:09:28.918769   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000268973 (* 1 = 0.000268973 loss)
I0621 06:09:28.918792   388 solver.cpp:473] Iteration 1463, lr = 0.01
I0621 06:09:41.193792   388 solver.cpp:213] Iteration 1464, loss = 0.000268912
I0621 06:09:41.193977   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000269264 (* 1 = 0.000269264 loss)
I0621 06:09:41.194001   388 solver.cpp:473] Iteration 1464, lr = 0.01
I0621 06:09:53.443447   388 solver.cpp:213] Iteration 1465, loss = 0.000268618
I0621 06:09:53.443531   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00026839 (* 1 = 0.00026839 loss)
I0621 06:09:53.443553   388 solver.cpp:473] Iteration 1465, lr = 0.01
I0621 06:10:05.742095   388 solver.cpp:213] Iteration 1466, loss = 0.000268538
I0621 06:10:05.742180   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000268614 (* 1 = 0.000268614 loss)
I0621 06:10:05.742203   388 solver.cpp:473] Iteration 1466, lr = 0.01
I0621 06:10:18.097488   388 solver.cpp:213] Iteration 1467, loss = 0.000268387
I0621 06:10:18.097681   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000268494 (* 1 = 0.000268494 loss)
I0621 06:10:18.097704   388 solver.cpp:473] Iteration 1467, lr = 0.01
I0621 06:10:30.422965   388 solver.cpp:213] Iteration 1468, loss = 0.000268126
I0621 06:10:30.423048   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000268036 (* 1 = 0.000268036 loss)
I0621 06:10:30.423079   388 solver.cpp:473] Iteration 1468, lr = 0.01
I0621 06:10:42.678299   388 solver.cpp:213] Iteration 1469, loss = 0.000268204
I0621 06:10:42.678386   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000268045 (* 1 = 0.000268045 loss)
I0621 06:10:42.678409   388 solver.cpp:473] Iteration 1469, lr = 0.01
I0621 06:10:54.907441   388 solver.cpp:213] Iteration 1470, loss = 0.000267902
I0621 06:10:54.907732   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000268191 (* 1 = 0.000268191 loss)
I0621 06:10:54.907757   388 solver.cpp:473] Iteration 1470, lr = 0.01
I0621 06:11:07.161562   388 solver.cpp:213] Iteration 1471, loss = 0.000267813
I0621 06:11:07.161648   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000268356 (* 1 = 0.000268356 loss)
I0621 06:11:07.161670   388 solver.cpp:473] Iteration 1471, lr = 0.01
I0621 06:11:19.413648   388 solver.cpp:213] Iteration 1472, loss = 0.000267743
I0621 06:11:19.413735   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000267617 (* 1 = 0.000267617 loss)
I0621 06:11:19.413758   388 solver.cpp:473] Iteration 1472, lr = 0.01
I0621 06:11:31.836598   388 solver.cpp:213] Iteration 1473, loss = 0.000267538
I0621 06:11:31.836900   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000267944 (* 1 = 0.000267944 loss)
I0621 06:11:31.836964   388 solver.cpp:473] Iteration 1473, lr = 0.01
I0621 06:11:44.220536   388 solver.cpp:213] Iteration 1474, loss = 0.000267289
I0621 06:11:44.220623   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000267353 (* 1 = 0.000267353 loss)
I0621 06:11:44.220648   388 solver.cpp:473] Iteration 1474, lr = 0.01
I0621 06:11:56.478137   388 solver.cpp:213] Iteration 1475, loss = 0.000267252
I0621 06:11:56.478216   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000267285 (* 1 = 0.000267285 loss)
I0621 06:11:56.478240   388 solver.cpp:473] Iteration 1475, lr = 0.01
I0621 06:12:08.820837   388 solver.cpp:213] Iteration 1476, loss = 0.000267042
I0621 06:12:08.821081   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000267337 (* 1 = 0.000267337 loss)
I0621 06:12:08.821125   388 solver.cpp:473] Iteration 1476, lr = 0.01
I0621 06:12:21.155552   388 solver.cpp:213] Iteration 1477, loss = 0.000266782
I0621 06:12:21.155634   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00026638 (* 1 = 0.00026638 loss)
I0621 06:12:21.155656   388 solver.cpp:473] Iteration 1477, lr = 0.01
I0621 06:12:33.436157   388 solver.cpp:213] Iteration 1478, loss = 0.000266771
I0621 06:12:33.436235   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000267193 (* 1 = 0.000267193 loss)
I0621 06:12:33.436259   388 solver.cpp:473] Iteration 1478, lr = 0.01
I0621 06:12:45.877049   388 solver.cpp:213] Iteration 1479, loss = 0.000266643
I0621 06:12:45.877225   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000266456 (* 1 = 0.000266456 loss)
I0621 06:12:45.877249   388 solver.cpp:473] Iteration 1479, lr = 0.01
I0621 06:12:58.213320   388 solver.cpp:213] Iteration 1480, loss = 0.000266386
I0621 06:12:58.213407   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000266089 (* 1 = 0.000266089 loss)
I0621 06:12:58.213429   388 solver.cpp:473] Iteration 1480, lr = 0.01
I0621 06:13:10.498803   388 solver.cpp:213] Iteration 1481, loss = 0.000266223
I0621 06:13:10.498885   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000266264 (* 1 = 0.000266264 loss)
I0621 06:13:10.498908   388 solver.cpp:473] Iteration 1481, lr = 0.01
I0621 06:13:22.790969   388 solver.cpp:213] Iteration 1482, loss = 0.000266113
I0621 06:13:22.793514   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000266287 (* 1 = 0.000266287 loss)
I0621 06:13:22.793540   388 solver.cpp:473] Iteration 1482, lr = 0.01
I0621 06:13:35.022675   388 solver.cpp:213] Iteration 1483, loss = 0.00026601
I0621 06:13:35.022756   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000266058 (* 1 = 0.000266058 loss)
I0621 06:13:35.022778   388 solver.cpp:473] Iteration 1483, lr = 0.01
I0621 06:13:47.259186   388 solver.cpp:213] Iteration 1484, loss = 0.000265892
I0621 06:13:47.259270   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00026637 (* 1 = 0.00026637 loss)
I0621 06:13:47.259292   388 solver.cpp:473] Iteration 1484, lr = 0.01
I0621 06:13:59.585175   388 solver.cpp:213] Iteration 1485, loss = 0.000265717
I0621 06:13:59.585363   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000265473 (* 1 = 0.000265473 loss)
I0621 06:13:59.585393   388 solver.cpp:473] Iteration 1485, lr = 0.01
I0621 06:14:11.886137   388 solver.cpp:213] Iteration 1486, loss = 0.00026556
I0621 06:14:11.886224   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000265969 (* 1 = 0.000265969 loss)
I0621 06:14:11.886248   388 solver.cpp:473] Iteration 1486, lr = 0.01
I0621 06:14:24.346426   388 solver.cpp:213] Iteration 1487, loss = 0.000265454
I0621 06:14:24.346508   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000265211 (* 1 = 0.000265211 loss)
I0621 06:14:24.346529   388 solver.cpp:473] Iteration 1487, lr = 0.01
I0621 06:14:36.576774   388 solver.cpp:213] Iteration 1488, loss = 0.000265297
I0621 06:14:36.576992   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000265273 (* 1 = 0.000265273 loss)
I0621 06:14:36.577030   388 solver.cpp:473] Iteration 1488, lr = 0.01
I0621 06:14:48.862566   388 solver.cpp:213] Iteration 1489, loss = 0.00026513
I0621 06:14:48.862668   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000264708 (* 1 = 0.000264708 loss)
I0621 06:14:48.862692   388 solver.cpp:473] Iteration 1489, lr = 0.01
I0621 06:15:01.218194   388 solver.cpp:213] Iteration 1490, loss = 0.000264946
I0621 06:15:01.218274   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00026465 (* 1 = 0.00026465 loss)
I0621 06:15:01.218297   388 solver.cpp:473] Iteration 1490, lr = 0.01
I0621 06:15:13.475337   388 solver.cpp:213] Iteration 1491, loss = 0.000264814
I0621 06:15:13.475579   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000264696 (* 1 = 0.000264696 loss)
I0621 06:15:13.475630   388 solver.cpp:473] Iteration 1491, lr = 0.01
I0621 06:15:25.815979   388 solver.cpp:213] Iteration 1492, loss = 0.000264794
I0621 06:15:25.816061   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00026511 (* 1 = 0.00026511 loss)
I0621 06:15:25.816083   388 solver.cpp:473] Iteration 1492, lr = 0.01
I0621 06:15:38.134409   388 solver.cpp:213] Iteration 1493, loss = 0.000264523
I0621 06:15:38.134490   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000264168 (* 1 = 0.000264168 loss)
I0621 06:15:38.134513   388 solver.cpp:473] Iteration 1493, lr = 0.01
I0621 06:15:50.447325   388 solver.cpp:213] Iteration 1494, loss = 0.000264442
I0621 06:15:50.447541   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000264372 (* 1 = 0.000264372 loss)
I0621 06:15:50.447569   388 solver.cpp:473] Iteration 1494, lr = 0.01
I0621 06:16:02.755012   388 solver.cpp:213] Iteration 1495, loss = 0.000264251
I0621 06:16:02.755101   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000264335 (* 1 = 0.000264335 loss)
I0621 06:16:02.755125   388 solver.cpp:473] Iteration 1495, lr = 0.01
I0621 06:16:15.060844   388 solver.cpp:213] Iteration 1496, loss = 0.000264095
I0621 06:16:15.060930   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000264538 (* 1 = 0.000264538 loss)
I0621 06:16:15.060952   388 solver.cpp:473] Iteration 1496, lr = 0.01
I0621 06:16:27.583717   388 solver.cpp:213] Iteration 1497, loss = 0.000263884
I0621 06:16:27.583966   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000263369 (* 1 = 0.000263369 loss)
I0621 06:16:27.584013   388 solver.cpp:473] Iteration 1497, lr = 0.01
I0621 06:16:40.022562   388 solver.cpp:213] Iteration 1498, loss = 0.000263669
I0621 06:16:40.022645   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000263299 (* 1 = 0.000263299 loss)
I0621 06:16:40.022667   388 solver.cpp:473] Iteration 1498, lr = 0.01
I0621 06:16:52.391974   388 solver.cpp:213] Iteration 1499, loss = 0.000263614
I0621 06:16:52.392055   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000263844 (* 1 = 0.000263844 loss)
I0621 06:16:52.392079   388 solver.cpp:473] Iteration 1499, lr = 0.01
I0621 06:16:55.843611   388 solver.cpp:362] Snapshotting to ./snapshot/latefusion-_iter_1500.caffemodel
I0621 06:17:14.507087   388 solver.cpp:370] Snapshotting solver state to ./snapshot/latefusion-_iter_1500.solverstate
I0621 06:17:17.830222   388 solver.cpp:291] Iteration 1500, Testing net (#0)
I0621 06:21:04.340447   388 solver.cpp:342]     Test net output #0: seg-accuracy = 1
I0621 06:21:04.340646   388 solver.cpp:342]     Test net output #1: seg-loss = 0.000263482 (* 1 = 0.000263482 loss)
I0621 06:21:16.131880   388 solver.cpp:213] Iteration 1500, loss = 0.000263507
I0621 06:21:16.131968   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00026377 (* 1 = 0.00026377 loss)
I0621 06:21:16.131990   388 solver.cpp:473] Iteration 1500, lr = 0.01
I0621 06:21:28.360587   388 solver.cpp:213] Iteration 1501, loss = 0.000263317
I0621 06:21:28.360668   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000263589 (* 1 = 0.000263589 loss)
I0621 06:21:28.360692   388 solver.cpp:473] Iteration 1501, lr = 0.01
I0621 06:21:40.580709   388 solver.cpp:213] Iteration 1502, loss = 0.000263109
I0621 06:21:40.580919   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000263694 (* 1 = 0.000263694 loss)
I0621 06:21:40.580942   388 solver.cpp:473] Iteration 1502, lr = 0.01
I0621 06:21:52.905524   388 solver.cpp:213] Iteration 1503, loss = 0.00026313
I0621 06:21:52.905608   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262966 (* 1 = 0.000262966 loss)
I0621 06:21:52.905630   388 solver.cpp:473] Iteration 1503, lr = 0.01
I0621 06:22:05.130663   388 solver.cpp:213] Iteration 1504, loss = 0.000262961
I0621 06:22:05.130745   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262447 (* 1 = 0.000262447 loss)
I0621 06:22:05.130767   388 solver.cpp:473] Iteration 1504, lr = 0.01
I0621 06:22:17.395781   388 solver.cpp:213] Iteration 1505, loss = 0.000262832
I0621 06:22:17.395995   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262707 (* 1 = 0.000262707 loss)
I0621 06:22:17.396026   388 solver.cpp:473] Iteration 1505, lr = 0.01
I0621 06:22:29.720942   388 solver.cpp:213] Iteration 1506, loss = 0.000262671
I0621 06:22:29.721024   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262416 (* 1 = 0.000262416 loss)
I0621 06:22:29.721047   388 solver.cpp:473] Iteration 1506, lr = 0.01
I0621 06:22:42.092368   388 solver.cpp:213] Iteration 1507, loss = 0.000262515
I0621 06:22:42.092442   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262623 (* 1 = 0.000262623 loss)
I0621 06:22:42.092463   388 solver.cpp:473] Iteration 1507, lr = 0.01
I0621 06:22:54.435796   388 solver.cpp:213] Iteration 1508, loss = 0.000262343
I0621 06:22:54.436053   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262507 (* 1 = 0.000262507 loss)
I0621 06:22:54.436099   388 solver.cpp:473] Iteration 1508, lr = 0.01
I0621 06:23:06.786869   388 solver.cpp:213] Iteration 1509, loss = 0.000262145
I0621 06:23:06.786952   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262126 (* 1 = 0.000262126 loss)
I0621 06:23:06.786975   388 solver.cpp:473] Iteration 1509, lr = 0.01
I0621 06:23:19.058179   388 solver.cpp:213] Iteration 1510, loss = 0.000262109
I0621 06:23:19.058262   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000262295 (* 1 = 0.000262295 loss)
I0621 06:23:19.058284   388 solver.cpp:473] Iteration 1510, lr = 0.01
I0621 06:23:31.397719   388 solver.cpp:213] Iteration 1511, loss = 0.00026189
I0621 06:23:31.397945   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000261357 (* 1 = 0.000261357 loss)
I0621 06:23:31.397977   388 solver.cpp:473] Iteration 1511, lr = 0.01
I0621 06:23:43.730183   388 solver.cpp:213] Iteration 1512, loss = 0.000261503
I0621 06:23:43.730268   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000261887 (* 1 = 0.000261887 loss)
I0621 06:23:43.730288   388 solver.cpp:473] Iteration 1512, lr = 0.01
I0621 06:23:56.054805   388 solver.cpp:213] Iteration 1513, loss = 0.000261541
I0621 06:23:56.054889   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000261181 (* 1 = 0.000261181 loss)
I0621 06:23:56.054911   388 solver.cpp:473] Iteration 1513, lr = 0.01
I0621 06:24:08.440902   388 solver.cpp:213] Iteration 1514, loss = 0.000261486
I0621 06:24:08.447132   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000261589 (* 1 = 0.000261589 loss)
I0621 06:24:08.447159   388 solver.cpp:473] Iteration 1514, lr = 0.01
I0621 06:24:20.728207   388 solver.cpp:213] Iteration 1515, loss = 0.00026133
I0621 06:24:20.728291   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000261522 (* 1 = 0.000261522 loss)
I0621 06:24:20.728313   388 solver.cpp:473] Iteration 1515, lr = 0.01
I0621 06:24:33.053030   388 solver.cpp:213] Iteration 1516, loss = 0.00026108
I0621 06:24:33.053112   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000261136 (* 1 = 0.000261136 loss)
I0621 06:24:33.053134   388 solver.cpp:473] Iteration 1516, lr = 0.01
I0621 06:24:45.405329   388 solver.cpp:213] Iteration 1517, loss = 0.000260929
I0621 06:24:45.405601   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000260937 (* 1 = 0.000260937 loss)
I0621 06:24:45.405647   388 solver.cpp:473] Iteration 1517, lr = 0.01
I0621 06:24:57.821595   388 solver.cpp:213] Iteration 1518, loss = 0.000260817
I0621 06:24:57.821686   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000261092 (* 1 = 0.000261092 loss)
I0621 06:24:57.821708   388 solver.cpp:473] Iteration 1518, lr = 0.01
I0621 06:25:10.079741   388 solver.cpp:213] Iteration 1519, loss = 0.000260758
I0621 06:25:10.079828   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000260414 (* 1 = 0.000260414 loss)
I0621 06:25:10.079851   388 solver.cpp:473] Iteration 1519, lr = 0.01
I0621 06:25:22.363656   388 solver.cpp:213] Iteration 1520, loss = 0.000260713
I0621 06:25:22.363925   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000260839 (* 1 = 0.000260839 loss)
I0621 06:25:22.363972   388 solver.cpp:473] Iteration 1520, lr = 0.01
I0621 06:25:34.733249   388 solver.cpp:213] Iteration 1521, loss = 0.000260475
I0621 06:25:34.733335   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000260183 (* 1 = 0.000260183 loss)
I0621 06:25:34.733358   388 solver.cpp:473] Iteration 1521, lr = 0.01
I0621 06:25:46.975302   388 solver.cpp:213] Iteration 1522, loss = 0.000260353
I0621 06:25:46.975385   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000260533 (* 1 = 0.000260533 loss)
I0621 06:25:46.975407   388 solver.cpp:473] Iteration 1522, lr = 0.01
I0621 06:25:59.316577   388 solver.cpp:213] Iteration 1523, loss = 0.000260167
I0621 06:25:59.316800   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259846 (* 1 = 0.000259846 loss)
I0621 06:25:59.316829   388 solver.cpp:473] Iteration 1523, lr = 0.01
I0621 06:26:11.647156   388 solver.cpp:213] Iteration 1524, loss = 0.000260136
I0621 06:26:11.647248   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00026005 (* 1 = 0.00026005 loss)
I0621 06:26:11.647272   388 solver.cpp:473] Iteration 1524, lr = 0.01
I0621 06:26:23.999521   388 solver.cpp:213] Iteration 1525, loss = 0.000259823
I0621 06:26:23.999614   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259759 (* 1 = 0.000259759 loss)
I0621 06:26:23.999639   388 solver.cpp:473] Iteration 1525, lr = 0.01
I0621 06:26:36.261307   388 solver.cpp:213] Iteration 1526, loss = 0.000259771
I0621 06:26:36.261549   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259882 (* 1 = 0.000259882 loss)
I0621 06:26:36.261581   388 solver.cpp:473] Iteration 1526, lr = 0.01
I0621 06:26:48.580924   388 solver.cpp:213] Iteration 1527, loss = 0.000259689
I0621 06:26:48.581008   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259907 (* 1 = 0.000259907 loss)
I0621 06:26:48.581030   388 solver.cpp:473] Iteration 1527, lr = 0.01
I0621 06:27:01.029949   388 solver.cpp:213] Iteration 1528, loss = 0.0002595
I0621 06:27:01.030035   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259044 (* 1 = 0.000259044 loss)
I0621 06:27:01.030058   388 solver.cpp:473] Iteration 1528, lr = 0.01
I0621 06:27:13.257647   388 solver.cpp:213] Iteration 1529, loss = 0.000259476
I0621 06:27:13.257829   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259889 (* 1 = 0.000259889 loss)
I0621 06:27:13.257854   388 solver.cpp:473] Iteration 1529, lr = 0.01
I0621 06:27:25.684676   388 solver.cpp:213] Iteration 1530, loss = 0.000259165
I0621 06:27:25.684764   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259208 (* 1 = 0.000259208 loss)
I0621 06:27:25.684787   388 solver.cpp:473] Iteration 1530, lr = 0.01
I0621 06:27:37.941715   388 solver.cpp:213] Iteration 1531, loss = 0.000259221
I0621 06:27:37.941799   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000259233 (* 1 = 0.000259233 loss)
I0621 06:27:37.941823   388 solver.cpp:473] Iteration 1531, lr = 0.01
I0621 06:27:50.227119   388 solver.cpp:213] Iteration 1532, loss = 0.000258912
I0621 06:27:50.227310   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000258716 (* 1 = 0.000258716 loss)
I0621 06:27:50.227334   388 solver.cpp:473] Iteration 1532, lr = 0.01
I0621 06:28:02.519814   388 solver.cpp:213] Iteration 1533, loss = 0.000258882
I0621 06:28:02.519897   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000258893 (* 1 = 0.000258893 loss)
I0621 06:28:02.519922   388 solver.cpp:473] Iteration 1533, lr = 0.01
I0621 06:28:14.920851   388 solver.cpp:213] Iteration 1534, loss = 0.000258608
I0621 06:28:14.920934   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00025885 (* 1 = 0.00025885 loss)
I0621 06:28:14.920956   388 solver.cpp:473] Iteration 1534, lr = 0.01
I0621 06:28:27.220774   388 solver.cpp:213] Iteration 1535, loss = 0.000258437
I0621 06:28:27.220964   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000258564 (* 1 = 0.000258564 loss)
I0621 06:28:27.220988   388 solver.cpp:473] Iteration 1535, lr = 0.01
I0621 06:28:39.545464   388 solver.cpp:213] Iteration 1536, loss = 0.000258411
I0621 06:28:39.545552   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000258562 (* 1 = 0.000258562 loss)
I0621 06:28:39.545572   388 solver.cpp:473] Iteration 1536, lr = 0.01
I0621 06:28:52.000623   388 solver.cpp:213] Iteration 1537, loss = 0.000258251
I0621 06:28:52.000707   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000258365 (* 1 = 0.000258365 loss)
I0621 06:28:52.000730   388 solver.cpp:473] Iteration 1537, lr = 0.01
I0621 06:29:04.353462   388 solver.cpp:213] Iteration 1538, loss = 0.00025798
I0621 06:29:04.353744   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000257906 (* 1 = 0.000257906 loss)
I0621 06:29:04.353791   388 solver.cpp:473] Iteration 1538, lr = 0.01
I0621 06:29:16.803211   388 solver.cpp:213] Iteration 1539, loss = 0.000257959
I0621 06:29:16.803297   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000257376 (* 1 = 0.000257376 loss)
I0621 06:29:16.803318   388 solver.cpp:473] Iteration 1539, lr = 0.01
I0621 06:29:29.093884   388 solver.cpp:213] Iteration 1540, loss = 0.000257827
I0621 06:29:29.093966   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000258029 (* 1 = 0.000258029 loss)
I0621 06:29:29.093988   388 solver.cpp:473] Iteration 1540, lr = 0.01
I0621 06:29:41.444275   388 solver.cpp:213] Iteration 1541, loss = 0.000257684
I0621 06:29:41.444463   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000257649 (* 1 = 0.000257649 loss)
I0621 06:29:41.444486   388 solver.cpp:473] Iteration 1541, lr = 0.01
I0621 06:29:53.785951   388 solver.cpp:213] Iteration 1542, loss = 0.000257557
I0621 06:29:53.786046   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000258007 (* 1 = 0.000258007 loss)
I0621 06:29:53.786075   388 solver.cpp:473] Iteration 1542, lr = 0.01
I0621 06:30:06.144268   388 solver.cpp:213] Iteration 1543, loss = 0.000257434
I0621 06:30:06.144345   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000257665 (* 1 = 0.000257665 loss)
I0621 06:30:06.144368   388 solver.cpp:473] Iteration 1543, lr = 0.01
I0621 06:30:18.447978   388 solver.cpp:213] Iteration 1544, loss = 0.000257268
I0621 06:30:18.448194   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002569 (* 1 = 0.0002569 loss)
I0621 06:30:18.448236   388 solver.cpp:473] Iteration 1544, lr = 0.01
I0621 06:30:30.768108   388 solver.cpp:213] Iteration 1545, loss = 0.00025717
I0621 06:30:30.768196   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000257442 (* 1 = 0.000257442 loss)
I0621 06:30:30.768218   388 solver.cpp:473] Iteration 1545, lr = 0.01
I0621 06:30:43.085322   388 solver.cpp:213] Iteration 1546, loss = 0.000257052
I0621 06:30:43.085402   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000257145 (* 1 = 0.000257145 loss)
I0621 06:30:43.085423   388 solver.cpp:473] Iteration 1546, lr = 0.01
I0621 06:30:55.307293   388 solver.cpp:213] Iteration 1547, loss = 0.000256828
I0621 06:30:55.307528   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000257027 (* 1 = 0.000257027 loss)
I0621 06:30:55.307574   388 solver.cpp:473] Iteration 1547, lr = 0.01
I0621 06:31:07.547199   388 solver.cpp:213] Iteration 1548, loss = 0.000256712
I0621 06:31:07.547288   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000256786 (* 1 = 0.000256786 loss)
I0621 06:31:07.547309   388 solver.cpp:473] Iteration 1548, lr = 0.01
I0621 06:31:19.776831   388 solver.cpp:213] Iteration 1549, loss = 0.000256539
I0621 06:31:19.776914   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000256249 (* 1 = 0.000256249 loss)
I0621 06:31:19.776937   388 solver.cpp:473] Iteration 1549, lr = 0.01
I0621 06:31:32.011353   388 solver.cpp:213] Iteration 1550, loss = 0.000256462
I0621 06:31:32.011548   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000256463 (* 1 = 0.000256463 loss)
I0621 06:31:32.011574   388 solver.cpp:473] Iteration 1550, lr = 0.01
I0621 06:31:44.274456   388 solver.cpp:213] Iteration 1551, loss = 0.000256282
I0621 06:31:44.274539   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000256003 (* 1 = 0.000256003 loss)
I0621 06:31:44.274561   388 solver.cpp:473] Iteration 1551, lr = 0.01
I0621 06:31:56.489065   388 solver.cpp:213] Iteration 1552, loss = 0.00025611
I0621 06:31:56.489140   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000256236 (* 1 = 0.000256236 loss)
I0621 06:31:56.489162   388 solver.cpp:473] Iteration 1552, lr = 0.01
I0621 06:32:08.771435   388 solver.cpp:213] Iteration 1553, loss = 0.000255974
I0621 06:32:08.771625   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000255697 (* 1 = 0.000255697 loss)
I0621 06:32:08.771651   388 solver.cpp:473] Iteration 1553, lr = 0.01
I0621 06:32:21.181968   388 solver.cpp:213] Iteration 1554, loss = 0.000255907
I0621 06:32:21.182067   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000256017 (* 1 = 0.000256017 loss)
I0621 06:32:21.182098   388 solver.cpp:473] Iteration 1554, lr = 0.01
I0621 06:32:33.646242   388 solver.cpp:213] Iteration 1555, loss = 0.000255809
I0621 06:32:33.646322   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000256084 (* 1 = 0.000256084 loss)
I0621 06:32:33.646345   388 solver.cpp:473] Iteration 1555, lr = 0.01
I0621 06:32:46.006374   388 solver.cpp:213] Iteration 1556, loss = 0.000255619
I0621 06:32:46.006811   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000255734 (* 1 = 0.000255734 loss)
I0621 06:32:46.006839   388 solver.cpp:473] Iteration 1556, lr = 0.01
I0621 06:32:58.280849   388 solver.cpp:213] Iteration 1557, loss = 0.000255565
I0621 06:32:58.280932   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000255361 (* 1 = 0.000255361 loss)
I0621 06:32:58.280954   388 solver.cpp:473] Iteration 1557, lr = 0.01
I0621 06:33:10.539386   388 solver.cpp:213] Iteration 1558, loss = 0.000255373
I0621 06:33:10.539469   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000255623 (* 1 = 0.000255623 loss)
I0621 06:33:10.539490   388 solver.cpp:473] Iteration 1558, lr = 0.01
I0621 06:33:22.766316   388 solver.cpp:213] Iteration 1559, loss = 0.000255262
I0621 06:33:22.766511   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000255531 (* 1 = 0.000255531 loss)
I0621 06:33:22.766535   388 solver.cpp:473] Iteration 1559, lr = 0.01
I0621 06:33:34.994031   388 solver.cpp:213] Iteration 1560, loss = 0.000255124
I0621 06:33:34.994117   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000255113 (* 1 = 0.000255113 loss)
I0621 06:33:34.994138   388 solver.cpp:473] Iteration 1560, lr = 0.01
I0621 06:33:47.218538   388 solver.cpp:213] Iteration 1561, loss = 0.000254847
I0621 06:33:47.218621   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000255131 (* 1 = 0.000255131 loss)
I0621 06:33:47.218644   388 solver.cpp:473] Iteration 1561, lr = 0.01
I0621 06:33:59.465869   388 solver.cpp:213] Iteration 1562, loss = 0.000254909
I0621 06:33:59.466037   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000254674 (* 1 = 0.000254674 loss)
I0621 06:33:59.466060   388 solver.cpp:473] Iteration 1562, lr = 0.01
I0621 06:34:11.700498   388 solver.cpp:213] Iteration 1563, loss = 0.000254757
I0621 06:34:11.700578   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000254396 (* 1 = 0.000254396 loss)
I0621 06:34:11.700600   388 solver.cpp:473] Iteration 1563, lr = 0.01
I0621 06:34:23.920006   388 solver.cpp:213] Iteration 1564, loss = 0.000254643
I0621 06:34:23.920083   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000254046 (* 1 = 0.000254046 loss)
I0621 06:34:23.920104   388 solver.cpp:473] Iteration 1564, lr = 0.01
I0621 06:34:36.137352   388 solver.cpp:213] Iteration 1565, loss = 0.000254432
I0621 06:34:36.137540   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000254616 (* 1 = 0.000254616 loss)
I0621 06:34:36.137567   388 solver.cpp:473] Iteration 1565, lr = 0.01
I0621 06:34:48.381937   388 solver.cpp:213] Iteration 1566, loss = 0.000254235
I0621 06:34:48.382020   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000254356 (* 1 = 0.000254356 loss)
I0621 06:34:48.382043   388 solver.cpp:473] Iteration 1566, lr = 0.01
I0621 06:35:00.674422   388 solver.cpp:213] Iteration 1567, loss = 0.000254084
I0621 06:35:00.674489   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00025347 (* 1 = 0.00025347 loss)
I0621 06:35:00.674504   388 solver.cpp:473] Iteration 1567, lr = 0.01
I0621 06:35:13.093749   388 solver.cpp:213] Iteration 1568, loss = 0.000254048
I0621 06:35:13.094002   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000253807 (* 1 = 0.000253807 loss)
I0621 06:35:13.094046   388 solver.cpp:473] Iteration 1568, lr = 0.01
I0621 06:35:25.582113   388 solver.cpp:213] Iteration 1569, loss = 0.000253887
I0621 06:35:25.582196   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000253684 (* 1 = 0.000253684 loss)
I0621 06:35:25.582219   388 solver.cpp:473] Iteration 1569, lr = 0.01
I0621 06:35:37.992400   388 solver.cpp:213] Iteration 1570, loss = 0.000253713
I0621 06:35:37.992487   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00025372 (* 1 = 0.00025372 loss)
I0621 06:35:37.992509   388 solver.cpp:473] Iteration 1570, lr = 0.01
I0621 06:35:50.277451   388 solver.cpp:213] Iteration 1571, loss = 0.000253625
I0621 06:35:50.277667   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000254204 (* 1 = 0.000254204 loss)
I0621 06:35:50.277704   388 solver.cpp:473] Iteration 1571, lr = 0.01
I0621 06:36:02.562810   388 solver.cpp:213] Iteration 1572, loss = 0.000253483
I0621 06:36:02.562891   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000253556 (* 1 = 0.000253556 loss)
I0621 06:36:02.562912   388 solver.cpp:473] Iteration 1572, lr = 0.01
I0621 06:36:14.833189   388 solver.cpp:213] Iteration 1573, loss = 0.000253198
I0621 06:36:14.833272   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000253364 (* 1 = 0.000253364 loss)
I0621 06:36:14.833294   388 solver.cpp:473] Iteration 1573, lr = 0.01
I0621 06:36:27.117501   388 solver.cpp:213] Iteration 1574, loss = 0.000253227
I0621 06:36:27.117740   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000253466 (* 1 = 0.000253466 loss)
I0621 06:36:27.117772   388 solver.cpp:473] Iteration 1574, lr = 0.01
I0621 06:36:39.383806   388 solver.cpp:213] Iteration 1575, loss = 0.000253018
I0621 06:36:39.383888   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00025337 (* 1 = 0.00025337 loss)
I0621 06:36:39.383910   388 solver.cpp:473] Iteration 1575, lr = 0.01
I0621 06:36:51.737989   388 solver.cpp:213] Iteration 1576, loss = 0.0002529
I0621 06:36:51.738086   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000252973 (* 1 = 0.000252973 loss)
I0621 06:36:51.738113   388 solver.cpp:473] Iteration 1576, lr = 0.01
I0621 06:37:03.998370   388 solver.cpp:213] Iteration 1577, loss = 0.000252829
I0621 06:37:03.998600   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000253038 (* 1 = 0.000253038 loss)
I0621 06:37:03.998641   388 solver.cpp:473] Iteration 1577, lr = 0.01
I0621 06:37:16.310101   388 solver.cpp:213] Iteration 1578, loss = 0.000252717
I0621 06:37:16.310209   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000252994 (* 1 = 0.000252994 loss)
I0621 06:37:16.310240   388 solver.cpp:473] Iteration 1578, lr = 0.01
I0621 06:37:28.632446   388 solver.cpp:213] Iteration 1579, loss = 0.000252573
I0621 06:37:28.632529   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000252418 (* 1 = 0.000252418 loss)
I0621 06:37:28.632551   388 solver.cpp:473] Iteration 1579, lr = 0.01
I0621 06:37:40.900774   388 solver.cpp:213] Iteration 1580, loss = 0.000252357
I0621 06:37:40.901047   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000252517 (* 1 = 0.000252517 loss)
I0621 06:37:40.901072   388 solver.cpp:473] Iteration 1580, lr = 0.01
I0621 06:37:53.152818   388 solver.cpp:213] Iteration 1581, loss = 0.00025225
I0621 06:37:53.152904   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000252378 (* 1 = 0.000252378 loss)
I0621 06:37:53.152925   388 solver.cpp:473] Iteration 1581, lr = 0.01
I0621 06:38:05.594475   388 solver.cpp:213] Iteration 1582, loss = 0.000252117
I0621 06:38:05.594557   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000251798 (* 1 = 0.000251798 loss)
I0621 06:38:05.594578   388 solver.cpp:473] Iteration 1582, lr = 0.01
I0621 06:38:17.964874   388 solver.cpp:213] Iteration 1583, loss = 0.000251971
I0621 06:38:17.967494   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000252084 (* 1 = 0.000252084 loss)
I0621 06:38:17.967520   388 solver.cpp:473] Iteration 1583, lr = 0.01
I0621 06:38:30.363735   388 solver.cpp:213] Iteration 1584, loss = 0.000251879
I0621 06:38:30.363818   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000252185 (* 1 = 0.000252185 loss)
I0621 06:38:30.363839   388 solver.cpp:473] Iteration 1584, lr = 0.01
I0621 06:38:42.629168   388 solver.cpp:213] Iteration 1585, loss = 0.000251667
I0621 06:38:42.629254   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000251715 (* 1 = 0.000251715 loss)
I0621 06:38:42.629276   388 solver.cpp:473] Iteration 1585, lr = 0.01
I0621 06:38:54.958428   388 solver.cpp:213] Iteration 1586, loss = 0.000251647
I0621 06:38:54.958693   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000251928 (* 1 = 0.000251928 loss)
I0621 06:38:54.958739   388 solver.cpp:473] Iteration 1586, lr = 0.01
I0621 06:39:07.359082   388 solver.cpp:213] Iteration 1587, loss = 0.000251493
I0621 06:39:07.359170   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000251289 (* 1 = 0.000251289 loss)
I0621 06:39:07.359194   388 solver.cpp:473] Iteration 1587, lr = 0.01
I0621 06:39:19.812369   388 solver.cpp:213] Iteration 1588, loss = 0.000251364
I0621 06:39:19.812460   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000251244 (* 1 = 0.000251244 loss)
I0621 06:39:19.812485   388 solver.cpp:473] Iteration 1588, lr = 0.01
I0621 06:39:32.184476   388 solver.cpp:213] Iteration 1589, loss = 0.000251244
I0621 06:39:32.184700   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000251396 (* 1 = 0.000251396 loss)
I0621 06:39:32.184746   388 solver.cpp:473] Iteration 1589, lr = 0.01
I0621 06:39:44.538771   388 solver.cpp:213] Iteration 1590, loss = 0.000251065
I0621 06:39:44.538858   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000250942 (* 1 = 0.000250942 loss)
I0621 06:39:44.538880   388 solver.cpp:473] Iteration 1590, lr = 0.01
I0621 06:39:56.867791   388 solver.cpp:213] Iteration 1591, loss = 0.000250977
I0621 06:39:56.867898   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000250494 (* 1 = 0.000250494 loss)
I0621 06:39:56.867930   388 solver.cpp:473] Iteration 1591, lr = 0.01
I0621 06:40:09.162318   388 solver.cpp:213] Iteration 1592, loss = 0.000250913
I0621 06:40:09.162561   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000250772 (* 1 = 0.000250772 loss)
I0621 06:40:09.162605   388 solver.cpp:473] Iteration 1592, lr = 0.01
I0621 06:40:21.478207   388 solver.cpp:213] Iteration 1593, loss = 0.00025083
I0621 06:40:21.478272   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002512 (* 1 = 0.0002512 loss)
I0621 06:40:21.478289   388 solver.cpp:473] Iteration 1593, lr = 0.01
I0621 06:40:33.774097   388 solver.cpp:213] Iteration 1594, loss = 0.000250557
I0621 06:40:33.774180   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000250494 (* 1 = 0.000250494 loss)
I0621 06:40:33.774204   388 solver.cpp:473] Iteration 1594, lr = 0.01
I0621 06:40:46.067431   388 solver.cpp:213] Iteration 1595, loss = 0.00025029
I0621 06:40:46.067678   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000250381 (* 1 = 0.000250381 loss)
I0621 06:40:46.067709   388 solver.cpp:473] Iteration 1595, lr = 0.01
I0621 06:40:58.383867   388 solver.cpp:213] Iteration 1596, loss = 0.000250227
I0621 06:40:58.383950   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000250306 (* 1 = 0.000250306 loss)
I0621 06:40:58.383973   388 solver.cpp:473] Iteration 1596, lr = 0.01
I0621 06:41:10.752768   388 solver.cpp:213] Iteration 1597, loss = 0.000250277
I0621 06:41:10.752853   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000250342 (* 1 = 0.000250342 loss)
I0621 06:41:10.752876   388 solver.cpp:473] Iteration 1597, lr = 0.01
I0621 06:41:23.041671   388 solver.cpp:213] Iteration 1598, loss = 0.000250045
I0621 06:41:23.041864   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000249994 (* 1 = 0.000249994 loss)
I0621 06:41:23.041890   388 solver.cpp:473] Iteration 1598, lr = 0.01
I0621 06:41:35.363955   388 solver.cpp:213] Iteration 1599, loss = 0.000249956
I0621 06:41:35.364035   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000249841 (* 1 = 0.000249841 loss)
I0621 06:41:35.364058   388 solver.cpp:473] Iteration 1599, lr = 0.01
I0621 06:41:47.799320   388 solver.cpp:213] Iteration 1600, loss = 0.000249804
I0621 06:41:47.799406   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000249719 (* 1 = 0.000249719 loss)
I0621 06:41:47.799427   388 solver.cpp:473] Iteration 1600, lr = 0.01
I0621 06:42:00.079625   388 solver.cpp:213] Iteration 1601, loss = 0.000249647
I0621 06:42:00.079848   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024962 (* 1 = 0.00024962 loss)
I0621 06:42:00.079872   388 solver.cpp:473] Iteration 1601, lr = 0.01
I0621 06:42:12.409055   388 solver.cpp:213] Iteration 1602, loss = 0.000249551
I0621 06:42:12.409137   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000249695 (* 1 = 0.000249695 loss)
I0621 06:42:12.409158   388 solver.cpp:473] Iteration 1602, lr = 0.01
I0621 06:42:24.794575   388 solver.cpp:213] Iteration 1603, loss = 0.000249382
I0621 06:42:24.794663   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000249713 (* 1 = 0.000249713 loss)
I0621 06:42:24.794685   388 solver.cpp:473] Iteration 1603, lr = 0.01
I0621 06:42:37.126674   388 solver.cpp:213] Iteration 1604, loss = 0.000249231
I0621 06:42:37.126857   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248833 (* 1 = 0.000248833 loss)
I0621 06:42:37.126883   388 solver.cpp:473] Iteration 1604, lr = 0.01
I0621 06:42:49.363359   388 solver.cpp:213] Iteration 1605, loss = 0.00024912
I0621 06:42:49.363440   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000249504 (* 1 = 0.000249504 loss)
I0621 06:42:49.363461   388 solver.cpp:473] Iteration 1605, lr = 0.01
I0621 06:43:01.656793   388 solver.cpp:213] Iteration 1606, loss = 0.000249033
I0621 06:43:01.656879   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248845 (* 1 = 0.000248845 loss)
I0621 06:43:01.656903   388 solver.cpp:473] Iteration 1606, lr = 0.01
I0621 06:43:14.003754   388 solver.cpp:213] Iteration 1607, loss = 0.000248768
I0621 06:43:14.003989   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248766 (* 1 = 0.000248766 loss)
I0621 06:43:14.004036   388 solver.cpp:473] Iteration 1607, lr = 0.01
I0621 06:43:26.334473   388 solver.cpp:213] Iteration 1608, loss = 0.000248804
I0621 06:43:26.334563   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248632 (* 1 = 0.000248632 loss)
I0621 06:43:26.334586   388 solver.cpp:473] Iteration 1608, lr = 0.01
I0621 06:43:38.572011   388 solver.cpp:213] Iteration 1609, loss = 0.000248629
I0621 06:43:38.572093   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248891 (* 1 = 0.000248891 loss)
I0621 06:43:38.572116   388 solver.cpp:473] Iteration 1609, lr = 0.01
I0621 06:43:50.835474   388 solver.cpp:213] Iteration 1610, loss = 0.000248591
I0621 06:43:50.835669   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248467 (* 1 = 0.000248467 loss)
I0621 06:43:50.835695   388 solver.cpp:473] Iteration 1610, lr = 0.01
I0621 06:44:03.065230   388 solver.cpp:213] Iteration 1611, loss = 0.000248331
I0621 06:44:03.065313   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248006 (* 1 = 0.000248006 loss)
I0621 06:44:03.065336   388 solver.cpp:473] Iteration 1611, lr = 0.01
I0621 06:44:15.352293   388 solver.cpp:213] Iteration 1612, loss = 0.000248325
I0621 06:44:15.352380   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024847 (* 1 = 0.00024847 loss)
I0621 06:44:15.352402   388 solver.cpp:473] Iteration 1612, lr = 0.01
I0621 06:44:27.672345   388 solver.cpp:213] Iteration 1613, loss = 0.000248159
I0621 06:44:27.672536   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000247864 (* 1 = 0.000247864 loss)
I0621 06:44:27.672564   388 solver.cpp:473] Iteration 1613, lr = 0.01
I0621 06:44:39.967330   388 solver.cpp:213] Iteration 1614, loss = 0.000248014
I0621 06:44:39.967412   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248011 (* 1 = 0.000248011 loss)
I0621 06:44:39.967434   388 solver.cpp:473] Iteration 1614, lr = 0.01
I0621 06:44:52.396302   388 solver.cpp:213] Iteration 1615, loss = 0.000247875
I0621 06:44:52.396389   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000247838 (* 1 = 0.000247838 loss)
I0621 06:44:52.396412   388 solver.cpp:473] Iteration 1615, lr = 0.01
I0621 06:45:04.735851   388 solver.cpp:213] Iteration 1616, loss = 0.000247638
I0621 06:45:04.736078   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000248173 (* 1 = 0.000248173 loss)
I0621 06:45:04.736117   388 solver.cpp:473] Iteration 1616, lr = 0.01
I0621 06:45:17.099503   388 solver.cpp:213] Iteration 1617, loss = 0.00024765
I0621 06:45:17.099578   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000247769 (* 1 = 0.000247769 loss)
I0621 06:45:17.099601   388 solver.cpp:473] Iteration 1617, lr = 0.01
I0621 06:45:29.419051   388 solver.cpp:213] Iteration 1618, loss = 0.000247428
I0621 06:45:29.419147   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000247518 (* 1 = 0.000247518 loss)
I0621 06:45:29.419169   388 solver.cpp:473] Iteration 1618, lr = 0.01
I0621 06:45:41.687163   388 solver.cpp:213] Iteration 1619, loss = 0.000247326
I0621 06:45:41.687345   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000247504 (* 1 = 0.000247504 loss)
I0621 06:45:41.687369   388 solver.cpp:473] Iteration 1619, lr = 0.01
I0621 06:45:53.949971   388 solver.cpp:213] Iteration 1620, loss = 0.000247242
I0621 06:45:53.950055   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024712 (* 1 = 0.00024712 loss)
I0621 06:45:53.950078   388 solver.cpp:473] Iteration 1620, lr = 0.01
I0621 06:46:06.250092   388 solver.cpp:213] Iteration 1621, loss = 0.000247102
I0621 06:46:06.250175   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000247432 (* 1 = 0.000247432 loss)
I0621 06:46:06.250197   388 solver.cpp:473] Iteration 1621, lr = 0.01
I0621 06:46:18.594635   388 solver.cpp:213] Iteration 1622, loss = 0.000246871
I0621 06:46:18.594841   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000246924 (* 1 = 0.000246924 loss)
I0621 06:46:18.594893   388 solver.cpp:473] Iteration 1622, lr = 0.01
I0621 06:46:30.893206   388 solver.cpp:213] Iteration 1623, loss = 0.000246684
I0621 06:46:30.893292   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000246934 (* 1 = 0.000246934 loss)
I0621 06:46:30.893314   388 solver.cpp:473] Iteration 1623, lr = 0.01
I0621 06:46:43.211225   388 solver.cpp:213] Iteration 1624, loss = 0.00024668
I0621 06:46:43.211302   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000246611 (* 1 = 0.000246611 loss)
I0621 06:46:43.211325   388 solver.cpp:473] Iteration 1624, lr = 0.01
I0621 06:46:55.465872   388 solver.cpp:213] Iteration 1625, loss = 0.000246619
I0621 06:46:55.466086   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000246235 (* 1 = 0.000246235 loss)
I0621 06:46:55.466111   388 solver.cpp:473] Iteration 1625, lr = 0.01
I0621 06:47:07.732079   388 solver.cpp:213] Iteration 1626, loss = 0.000246475
I0621 06:47:07.732161   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000246291 (* 1 = 0.000246291 loss)
I0621 06:47:07.732183   388 solver.cpp:473] Iteration 1626, lr = 0.01
I0621 06:47:20.030587   388 solver.cpp:213] Iteration 1627, loss = 0.000246297
I0621 06:47:20.030681   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000246035 (* 1 = 0.000246035 loss)
I0621 06:47:20.030705   388 solver.cpp:473] Iteration 1627, lr = 0.01
I0621 06:47:32.303809   388 solver.cpp:213] Iteration 1628, loss = 0.000246151
I0621 06:47:32.304059   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245835 (* 1 = 0.000245835 loss)
I0621 06:47:32.304108   388 solver.cpp:473] Iteration 1628, lr = 0.01
I0621 06:47:44.624665   388 solver.cpp:213] Iteration 1629, loss = 0.000246071
I0621 06:47:44.624750   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245753 (* 1 = 0.000245753 loss)
I0621 06:47:44.624773   388 solver.cpp:473] Iteration 1629, lr = 0.01
I0621 06:47:57.103160   388 solver.cpp:213] Iteration 1630, loss = 0.00024598
I0621 06:47:57.103247   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245775 (* 1 = 0.000245775 loss)
I0621 06:47:57.103271   388 solver.cpp:473] Iteration 1630, lr = 0.01
I0621 06:48:09.438616   388 solver.cpp:213] Iteration 1631, loss = 0.000245957
I0621 06:48:09.438870   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245609 (* 1 = 0.000245609 loss)
I0621 06:48:09.438917   388 solver.cpp:473] Iteration 1631, lr = 0.01
I0621 06:48:21.705477   388 solver.cpp:213] Iteration 1632, loss = 0.000245756
I0621 06:48:21.705559   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002459 (* 1 = 0.0002459 loss)
I0621 06:48:21.705579   388 solver.cpp:473] Iteration 1632, lr = 0.01
I0621 06:48:34.031769   388 solver.cpp:213] Iteration 1633, loss = 0.00024568
I0621 06:48:34.031853   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245969 (* 1 = 0.000245969 loss)
I0621 06:48:34.031877   388 solver.cpp:473] Iteration 1633, lr = 0.01
I0621 06:48:46.403854   388 solver.cpp:213] Iteration 1634, loss = 0.000245502
I0621 06:48:46.404054   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245691 (* 1 = 0.000245691 loss)
I0621 06:48:46.404145   388 solver.cpp:473] Iteration 1634, lr = 0.01
I0621 06:48:58.893148   388 solver.cpp:213] Iteration 1635, loss = 0.000245197
I0621 06:48:58.893234   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245321 (* 1 = 0.000245321 loss)
I0621 06:48:58.893257   388 solver.cpp:473] Iteration 1635, lr = 0.01
I0621 06:49:11.179517   388 solver.cpp:213] Iteration 1636, loss = 0.000245198
I0621 06:49:11.179599   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245287 (* 1 = 0.000245287 loss)
I0621 06:49:11.179621   388 solver.cpp:473] Iteration 1636, lr = 0.01
I0621 06:49:23.846637   388 solver.cpp:213] Iteration 1637, loss = 0.000245053
I0621 06:49:23.846901   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000245095 (* 1 = 0.000245095 loss)
I0621 06:49:23.846947   388 solver.cpp:473] Iteration 1637, lr = 0.01
I0621 06:49:36.221146   388 solver.cpp:213] Iteration 1638, loss = 0.000245009
I0621 06:49:36.221271   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024503 (* 1 = 0.00024503 loss)
I0621 06:49:36.221314   388 solver.cpp:473] Iteration 1638, lr = 0.01
I0621 06:49:48.470677   388 solver.cpp:213] Iteration 1639, loss = 0.000244725
I0621 06:49:48.470762   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000244878 (* 1 = 0.000244878 loss)
I0621 06:49:48.470784   388 solver.cpp:473] Iteration 1639, lr = 0.01
I0621 06:50:00.793452   388 solver.cpp:213] Iteration 1640, loss = 0.000244627
I0621 06:50:00.794965   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000244493 (* 1 = 0.000244493 loss)
I0621 06:50:00.794994   388 solver.cpp:473] Iteration 1640, lr = 0.01
I0621 06:50:13.126528   388 solver.cpp:213] Iteration 1641, loss = 0.00024456
I0621 06:50:13.126616   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000244772 (* 1 = 0.000244772 loss)
I0621 06:50:13.126637   388 solver.cpp:473] Iteration 1641, lr = 0.01
I0621 06:50:25.390739   388 solver.cpp:213] Iteration 1642, loss = 0.000244591
I0621 06:50:25.390821   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024422 (* 1 = 0.00024422 loss)
I0621 06:50:25.390844   388 solver.cpp:473] Iteration 1642, lr = 0.01
I0621 06:50:37.609961   388 solver.cpp:213] Iteration 1643, loss = 0.000244376
I0621 06:50:37.610154   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024447 (* 1 = 0.00024447 loss)
I0621 06:50:37.610179   388 solver.cpp:473] Iteration 1643, lr = 0.01
I0621 06:50:49.840224   388 solver.cpp:213] Iteration 1644, loss = 0.000244217
I0621 06:50:49.840306   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000244217 (* 1 = 0.000244217 loss)
I0621 06:50:49.840328   388 solver.cpp:473] Iteration 1644, lr = 0.01
I0621 06:51:02.059897   388 solver.cpp:213] Iteration 1645, loss = 0.000244233
I0621 06:51:02.059985   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000244105 (* 1 = 0.000244105 loss)
I0621 06:51:02.060008   388 solver.cpp:473] Iteration 1645, lr = 0.01
I0621 06:51:14.337505   388 solver.cpp:213] Iteration 1646, loss = 0.000243971
I0621 06:51:14.337756   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000244021 (* 1 = 0.000244021 loss)
I0621 06:51:14.337805   388 solver.cpp:473] Iteration 1646, lr = 0.01
I0621 06:51:26.684489   388 solver.cpp:213] Iteration 1647, loss = 0.00024392
I0621 06:51:26.684576   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243948 (* 1 = 0.000243948 loss)
I0621 06:51:26.684597   388 solver.cpp:473] Iteration 1647, lr = 0.01
I0621 06:51:38.939275   388 solver.cpp:213] Iteration 1648, loss = 0.000243639
I0621 06:51:38.939357   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243343 (* 1 = 0.000243343 loss)
I0621 06:51:38.939379   388 solver.cpp:473] Iteration 1648, lr = 0.01
I0621 06:51:51.232410   388 solver.cpp:213] Iteration 1649, loss = 0.000243626
I0621 06:51:51.232641   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243693 (* 1 = 0.000243693 loss)
I0621 06:51:51.232677   388 solver.cpp:473] Iteration 1649, lr = 0.01
I0621 06:52:03.559906   388 solver.cpp:213] Iteration 1650, loss = 0.000243546
I0621 06:52:03.559991   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243154 (* 1 = 0.000243154 loss)
I0621 06:52:03.560014   388 solver.cpp:473] Iteration 1650, lr = 0.01
I0621 06:52:15.873926   388 solver.cpp:213] Iteration 1651, loss = 0.00024346
I0621 06:52:15.874009   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243399 (* 1 = 0.000243399 loss)
I0621 06:52:15.874032   388 solver.cpp:473] Iteration 1651, lr = 0.01
I0621 06:52:28.284746   388 solver.cpp:213] Iteration 1652, loss = 0.000243239
I0621 06:52:28.284931   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243128 (* 1 = 0.000243128 loss)
I0621 06:52:28.284956   388 solver.cpp:473] Iteration 1652, lr = 0.01
I0621 06:52:40.681273   388 solver.cpp:213] Iteration 1653, loss = 0.000243046
I0621 06:52:40.681354   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243222 (* 1 = 0.000243222 loss)
I0621 06:52:40.681377   388 solver.cpp:473] Iteration 1653, lr = 0.01
I0621 06:52:53.008087   388 solver.cpp:213] Iteration 1654, loss = 0.000242945
I0621 06:52:53.008174   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000242787 (* 1 = 0.000242787 loss)
I0621 06:52:53.008196   388 solver.cpp:473] Iteration 1654, lr = 0.01
I0621 06:53:05.287591   388 solver.cpp:213] Iteration 1655, loss = 0.000242922
I0621 06:53:05.287878   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000243346 (* 1 = 0.000243346 loss)
I0621 06:53:05.287926   388 solver.cpp:473] Iteration 1655, lr = 0.01
I0621 06:53:17.622678   388 solver.cpp:213] Iteration 1656, loss = 0.000242756
I0621 06:53:17.622767   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000242815 (* 1 = 0.000242815 loss)
I0621 06:53:17.622789   388 solver.cpp:473] Iteration 1656, lr = 0.01
I0621 06:53:29.932021   388 solver.cpp:213] Iteration 1657, loss = 0.000242763
I0621 06:53:29.932104   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000242915 (* 1 = 0.000242915 loss)
I0621 06:53:29.932126   388 solver.cpp:473] Iteration 1657, lr = 0.01
I0621 06:53:42.222465   388 solver.cpp:213] Iteration 1658, loss = 0.000242553
I0621 06:53:42.222728   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000242432 (* 1 = 0.000242432 loss)
I0621 06:53:42.222774   388 solver.cpp:473] Iteration 1658, lr = 0.01
I0621 06:53:54.568722   388 solver.cpp:213] Iteration 1659, loss = 0.000242409
I0621 06:53:54.568807   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024226 (* 1 = 0.00024226 loss)
I0621 06:53:54.568830   388 solver.cpp:473] Iteration 1659, lr = 0.01
I0621 06:54:06.819263   388 solver.cpp:213] Iteration 1660, loss = 0.000242143
I0621 06:54:06.819373   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000241909 (* 1 = 0.000241909 loss)
I0621 06:54:06.819422   388 solver.cpp:473] Iteration 1660, lr = 0.01
I0621 06:54:19.211171   388 solver.cpp:213] Iteration 1661, loss = 0.000242146
I0621 06:54:19.211374   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000242411 (* 1 = 0.000242411 loss)
I0621 06:54:19.211405   388 solver.cpp:473] Iteration 1661, lr = 0.01
I0621 06:54:31.466408   388 solver.cpp:213] Iteration 1662, loss = 0.000242019
I0621 06:54:31.466493   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000242156 (* 1 = 0.000242156 loss)
I0621 06:54:31.466516   388 solver.cpp:473] Iteration 1662, lr = 0.01
I0621 06:54:43.708817   388 solver.cpp:213] Iteration 1663, loss = 0.000241842
I0621 06:54:43.708902   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000242083 (* 1 = 0.000242083 loss)
I0621 06:54:43.708925   388 solver.cpp:473] Iteration 1663, lr = 0.01
I0621 06:54:55.960053   388 solver.cpp:213] Iteration 1664, loss = 0.00024186
I0621 06:54:55.960301   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000241669 (* 1 = 0.000241669 loss)
I0621 06:54:55.960363   388 solver.cpp:473] Iteration 1664, lr = 0.01
I0621 06:55:08.275821   388 solver.cpp:213] Iteration 1665, loss = 0.000241636
I0621 06:55:08.275900   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000241578 (* 1 = 0.000241578 loss)
I0621 06:55:08.275923   388 solver.cpp:473] Iteration 1665, lr = 0.01
I0621 06:55:20.563812   388 solver.cpp:213] Iteration 1666, loss = 0.000241589
I0621 06:55:20.563897   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000241607 (* 1 = 0.000241607 loss)
I0621 06:55:20.563920   388 solver.cpp:473] Iteration 1666, lr = 0.01
I0621 06:55:32.832833   388 solver.cpp:213] Iteration 1667, loss = 0.000241549
I0621 06:55:32.833015   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000241527 (* 1 = 0.000241527 loss)
I0621 06:55:32.833047   388 solver.cpp:473] Iteration 1667, lr = 0.01
I0621 06:55:45.297179   388 solver.cpp:213] Iteration 1668, loss = 0.000241393
I0621 06:55:45.297265   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000241224 (* 1 = 0.000241224 loss)
I0621 06:55:45.297288   388 solver.cpp:473] Iteration 1668, lr = 0.01
I0621 06:55:57.754829   388 solver.cpp:213] Iteration 1669, loss = 0.000241185
I0621 06:55:57.754914   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000240936 (* 1 = 0.000240936 loss)
I0621 06:55:57.754935   388 solver.cpp:473] Iteration 1669, lr = 0.01
I0621 06:56:10.018084   388 solver.cpp:213] Iteration 1670, loss = 0.000240985
I0621 06:56:10.018316   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024099 (* 1 = 0.00024099 loss)
I0621 06:56:10.018352   388 solver.cpp:473] Iteration 1670, lr = 0.01
I0621 06:56:22.333416   388 solver.cpp:213] Iteration 1671, loss = 0.000240908
I0621 06:56:22.333498   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002409 (* 1 = 0.0002409 loss)
I0621 06:56:22.333519   388 solver.cpp:473] Iteration 1671, lr = 0.01
I0621 06:56:34.578687   388 solver.cpp:213] Iteration 1672, loss = 0.000240847
I0621 06:56:34.578766   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000240873 (* 1 = 0.000240873 loss)
I0621 06:56:34.578788   388 solver.cpp:473] Iteration 1672, lr = 0.01
I0621 06:56:46.806464   388 solver.cpp:213] Iteration 1673, loss = 0.000240729
I0621 06:56:46.809587   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000240732 (* 1 = 0.000240732 loss)
I0621 06:56:46.809646   388 solver.cpp:473] Iteration 1673, lr = 0.01
I0621 06:56:59.041208   388 solver.cpp:213] Iteration 1674, loss = 0.000240757
I0621 06:56:59.041297   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00024083 (* 1 = 0.00024083 loss)
I0621 06:56:59.041321   388 solver.cpp:473] Iteration 1674, lr = 0.01
I0621 06:57:11.277920   388 solver.cpp:213] Iteration 1675, loss = 0.000240482
I0621 06:57:11.278041   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000240285 (* 1 = 0.000240285 loss)
I0621 06:57:11.278081   388 solver.cpp:473] Iteration 1675, lr = 0.01
I0621 06:57:23.609874   388 solver.cpp:213] Iteration 1676, loss = 0.000240307
I0621 06:57:23.610121   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000240331 (* 1 = 0.000240331 loss)
I0621 06:57:23.610167   388 solver.cpp:473] Iteration 1676, lr = 0.01
I0621 06:57:35.943095   388 solver.cpp:213] Iteration 1677, loss = 0.00024032
I0621 06:57:35.943178   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000240603 (* 1 = 0.000240603 loss)
I0621 06:57:35.943200   388 solver.cpp:473] Iteration 1677, lr = 0.01
I0621 06:57:48.228677   388 solver.cpp:213] Iteration 1678, loss = 0.000240036
I0621 06:57:48.228763   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023982 (* 1 = 0.00023982 loss)
I0621 06:57:48.228785   388 solver.cpp:473] Iteration 1678, lr = 0.01
I0621 06:58:00.510752   388 solver.cpp:213] Iteration 1679, loss = 0.000240083
I0621 06:58:00.511005   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000240085 (* 1 = 0.000240085 loss)
I0621 06:58:00.511052   388 solver.cpp:473] Iteration 1679, lr = 0.01
I0621 06:58:12.753422   388 solver.cpp:213] Iteration 1680, loss = 0.00023984
I0621 06:58:12.753504   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023996 (* 1 = 0.00023996 loss)
I0621 06:58:12.753526   388 solver.cpp:473] Iteration 1680, lr = 0.01
I0621 06:58:24.987529   388 solver.cpp:213] Iteration 1681, loss = 0.000239697
I0621 06:58:24.987617   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000239659 (* 1 = 0.000239659 loss)
I0621 06:58:24.987638   388 solver.cpp:473] Iteration 1681, lr = 0.01
I0621 06:58:37.205176   388 solver.cpp:213] Iteration 1682, loss = 0.000239652
I0621 06:58:37.205366   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000239751 (* 1 = 0.000239751 loss)
I0621 06:58:37.205390   388 solver.cpp:473] Iteration 1682, lr = 0.01
I0621 06:58:49.491714   388 solver.cpp:213] Iteration 1683, loss = 0.000239446
I0621 06:58:49.491798   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023899 (* 1 = 0.00023899 loss)
I0621 06:58:49.491821   388 solver.cpp:473] Iteration 1683, lr = 0.01
I0621 06:59:01.703328   388 solver.cpp:213] Iteration 1684, loss = 0.000239548
I0621 06:59:01.703397   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000239631 (* 1 = 0.000239631 loss)
I0621 06:59:01.703418   388 solver.cpp:473] Iteration 1684, lr = 0.01
I0621 06:59:13.926816   388 solver.cpp:213] Iteration 1685, loss = 0.000239232
I0621 06:59:13.927038   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000239342 (* 1 = 0.000239342 loss)
I0621 06:59:13.927099   388 solver.cpp:473] Iteration 1685, lr = 0.01
I0621 06:59:26.154770   388 solver.cpp:213] Iteration 1686, loss = 0.000239199
I0621 06:59:26.154860   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000239049 (* 1 = 0.000239049 loss)
I0621 06:59:26.154882   388 solver.cpp:473] Iteration 1686, lr = 0.01
I0621 06:59:38.385939   388 solver.cpp:213] Iteration 1687, loss = 0.000238929
I0621 06:59:38.386025   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000239053 (* 1 = 0.000239053 loss)
I0621 06:59:38.386049   388 solver.cpp:473] Iteration 1687, lr = 0.01
I0621 06:59:50.611672   388 solver.cpp:213] Iteration 1688, loss = 0.000238903
I0621 06:59:50.611984   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238844 (* 1 = 0.000238844 loss)
I0621 06:59:50.612092   388 solver.cpp:473] Iteration 1688, lr = 0.01
I0621 07:00:02.919598   388 solver.cpp:213] Iteration 1689, loss = 0.000238749
I0621 07:00:02.919682   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238705 (* 1 = 0.000238705 loss)
I0621 07:00:02.919708   388 solver.cpp:473] Iteration 1689, lr = 0.01
I0621 07:00:15.142115   388 solver.cpp:213] Iteration 1690, loss = 0.000238708
I0621 07:00:15.142199   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023834 (* 1 = 0.00023834 loss)
I0621 07:00:15.142221   388 solver.cpp:473] Iteration 1690, lr = 0.01
I0621 07:00:27.368656   388 solver.cpp:213] Iteration 1691, loss = 0.000238538
I0621 07:00:27.368844   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238476 (* 1 = 0.000238476 loss)
I0621 07:00:27.368868   388 solver.cpp:473] Iteration 1691, lr = 0.01
I0621 07:00:39.590582   388 solver.cpp:213] Iteration 1692, loss = 0.000238576
I0621 07:00:39.590662   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238639 (* 1 = 0.000238639 loss)
I0621 07:00:39.590683   388 solver.cpp:473] Iteration 1692, lr = 0.01
I0621 07:00:51.836311   388 solver.cpp:213] Iteration 1693, loss = 0.00023835
I0621 07:00:51.836427   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238469 (* 1 = 0.000238469 loss)
I0621 07:00:51.836472   388 solver.cpp:473] Iteration 1693, lr = 0.01
I0621 07:01:04.024408   388 solver.cpp:213] Iteration 1694, loss = 0.000238194
I0621 07:01:04.024580   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238081 (* 1 = 0.000238081 loss)
I0621 07:01:04.024605   388 solver.cpp:473] Iteration 1694, lr = 0.01
I0621 07:01:16.295879   388 solver.cpp:213] Iteration 1695, loss = 0.000238096
I0621 07:01:16.295965   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238155 (* 1 = 0.000238155 loss)
I0621 07:01:16.295989   388 solver.cpp:473] Iteration 1695, lr = 0.01
I0621 07:01:28.593036   388 solver.cpp:213] Iteration 1696, loss = 0.00023813
I0621 07:01:28.593118   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237728 (* 1 = 0.000237728 loss)
I0621 07:01:28.593142   388 solver.cpp:473] Iteration 1696, lr = 0.01
I0621 07:01:40.943954   388 solver.cpp:213] Iteration 1697, loss = 0.000237945
I0621 07:01:40.944277   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237997 (* 1 = 0.000237997 loss)
I0621 07:01:40.944385   388 solver.cpp:473] Iteration 1697, lr = 0.01
I0621 07:01:53.337528   388 solver.cpp:213] Iteration 1698, loss = 0.000237726
I0621 07:01:53.337613   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000238237 (* 1 = 0.000238237 loss)
I0621 07:01:53.337636   388 solver.cpp:473] Iteration 1698, lr = 0.01
I0621 07:02:05.710899   388 solver.cpp:213] Iteration 1699, loss = 0.000237502
I0621 07:02:05.710988   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237437 (* 1 = 0.000237437 loss)
I0621 07:02:05.711012   388 solver.cpp:473] Iteration 1699, lr = 0.01
I0621 07:02:18.101150   388 solver.cpp:213] Iteration 1700, loss = 0.000237567
I0621 07:02:18.101335   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237655 (* 1 = 0.000237655 loss)
I0621 07:02:18.101359   388 solver.cpp:473] Iteration 1700, lr = 0.01
I0621 07:02:30.390758   388 solver.cpp:213] Iteration 1701, loss = 0.000237332
I0621 07:02:30.390846   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237342 (* 1 = 0.000237342 loss)
I0621 07:02:30.390867   388 solver.cpp:473] Iteration 1701, lr = 0.01
I0621 07:02:42.647709   388 solver.cpp:213] Iteration 1702, loss = 0.000237215
I0621 07:02:42.647791   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237055 (* 1 = 0.000237055 loss)
I0621 07:02:42.647814   388 solver.cpp:473] Iteration 1702, lr = 0.01
I0621 07:02:55.098717   388 solver.cpp:213] Iteration 1703, loss = 0.000237125
I0621 07:02:55.098968   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237044 (* 1 = 0.000237044 loss)
I0621 07:02:55.099006   388 solver.cpp:473] Iteration 1703, lr = 0.01
I0621 07:03:07.333675   388 solver.cpp:213] Iteration 1704, loss = 0.00023704
I0621 07:03:07.333762   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000237358 (* 1 = 0.000237358 loss)
I0621 07:03:07.333786   388 solver.cpp:473] Iteration 1704, lr = 0.01
I0621 07:03:19.621454   388 solver.cpp:213] Iteration 1705, loss = 0.000237019
I0621 07:03:19.621539   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023685 (* 1 = 0.00023685 loss)
I0621 07:03:19.621562   388 solver.cpp:473] Iteration 1705, lr = 0.01
I0621 07:03:31.972930   388 solver.cpp:213] Iteration 1706, loss = 0.000236833
I0621 07:03:31.973153   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002367 (* 1 = 0.0002367 loss)
I0621 07:03:31.973186   388 solver.cpp:473] Iteration 1706, lr = 0.01
I0621 07:03:44.419317   388 solver.cpp:213] Iteration 1707, loss = 0.000236702
I0621 07:03:44.419400   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236403 (* 1 = 0.000236403 loss)
I0621 07:03:44.419423   388 solver.cpp:473] Iteration 1707, lr = 0.01
I0621 07:03:56.708416   388 solver.cpp:213] Iteration 1708, loss = 0.000236553
I0621 07:03:56.708501   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236305 (* 1 = 0.000236305 loss)
I0621 07:03:56.708524   388 solver.cpp:473] Iteration 1708, lr = 0.01
I0621 07:04:08.959653   388 solver.cpp:213] Iteration 1709, loss = 0.000236497
I0621 07:04:08.959854   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236929 (* 1 = 0.000236929 loss)
I0621 07:04:08.959880   388 solver.cpp:473] Iteration 1709, lr = 0.01
I0621 07:04:21.203222   388 solver.cpp:213] Iteration 1710, loss = 0.000236423
I0621 07:04:21.203308   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236717 (* 1 = 0.000236717 loss)
I0621 07:04:21.203332   388 solver.cpp:473] Iteration 1710, lr = 0.01
I0621 07:04:33.456996   388 solver.cpp:213] Iteration 1711, loss = 0.000236322
I0621 07:04:33.457082   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236657 (* 1 = 0.000236657 loss)
I0621 07:04:33.457104   388 solver.cpp:473] Iteration 1711, lr = 0.01
I0621 07:04:45.684278   388 solver.cpp:213] Iteration 1712, loss = 0.000236202
I0621 07:04:45.684458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236233 (* 1 = 0.000236233 loss)
I0621 07:04:45.684483   388 solver.cpp:473] Iteration 1712, lr = 0.01
I0621 07:04:57.902859   388 solver.cpp:213] Iteration 1713, loss = 0.000235934
I0621 07:04:57.902946   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236231 (* 1 = 0.000236231 loss)
I0621 07:04:57.902968   388 solver.cpp:473] Iteration 1713, lr = 0.01
I0621 07:05:10.117221   388 solver.cpp:213] Iteration 1714, loss = 0.000235987
I0621 07:05:10.117311   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000236205 (* 1 = 0.000236205 loss)
I0621 07:05:10.117334   388 solver.cpp:473] Iteration 1714, lr = 0.01
I0621 07:05:22.337281   388 solver.cpp:213] Iteration 1715, loss = 0.000235787
I0621 07:05:22.337458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235786 (* 1 = 0.000235786 loss)
I0621 07:05:22.337483   388 solver.cpp:473] Iteration 1715, lr = 0.01
I0621 07:05:34.550074   388 solver.cpp:213] Iteration 1716, loss = 0.00023559
I0621 07:05:34.550159   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235193 (* 1 = 0.000235193 loss)
I0621 07:05:34.550184   388 solver.cpp:473] Iteration 1716, lr = 0.01
I0621 07:05:46.774288   388 solver.cpp:213] Iteration 1717, loss = 0.00023552
I0621 07:05:46.774380   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023543 (* 1 = 0.00023543 loss)
I0621 07:05:46.774408   388 solver.cpp:473] Iteration 1717, lr = 0.01
I0621 07:05:59.069525   388 solver.cpp:213] Iteration 1718, loss = 0.000235485
I0621 07:05:59.069829   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235862 (* 1 = 0.000235862 loss)
I0621 07:05:59.069892   388 solver.cpp:473] Iteration 1718, lr = 0.01
I0621 07:06:11.320823   388 solver.cpp:213] Iteration 1719, loss = 0.000235281
I0621 07:06:11.320912   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235207 (* 1 = 0.000235207 loss)
I0621 07:06:11.320935   388 solver.cpp:473] Iteration 1719, lr = 0.01
I0621 07:06:23.553241   388 solver.cpp:213] Iteration 1720, loss = 0.000235206
I0621 07:06:23.553313   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235195 (* 1 = 0.000235195 loss)
I0621 07:06:23.553333   388 solver.cpp:473] Iteration 1720, lr = 0.01
I0621 07:06:35.845221   388 solver.cpp:213] Iteration 1721, loss = 0.000235025
I0621 07:06:35.845474   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235385 (* 1 = 0.000235385 loss)
I0621 07:06:35.845502   388 solver.cpp:473] Iteration 1721, lr = 0.01
I0621 07:06:48.220566   388 solver.cpp:213] Iteration 1722, loss = 0.000235009
I0621 07:06:48.220650   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235211 (* 1 = 0.000235211 loss)
I0621 07:06:48.220674   388 solver.cpp:473] Iteration 1722, lr = 0.01
I0621 07:07:00.526916   388 solver.cpp:213] Iteration 1723, loss = 0.000234943
I0621 07:07:00.527004   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235434 (* 1 = 0.000235434 loss)
I0621 07:07:00.527027   388 solver.cpp:473] Iteration 1723, lr = 0.01
I0621 07:07:12.811672   388 solver.cpp:213] Iteration 1724, loss = 0.000234789
I0621 07:07:12.811913   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000235082 (* 1 = 0.000235082 loss)
I0621 07:07:12.811938   388 solver.cpp:473] Iteration 1724, lr = 0.01
I0621 07:07:25.097633   388 solver.cpp:213] Iteration 1725, loss = 0.000234676
I0621 07:07:25.097718   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000234724 (* 1 = 0.000234724 loss)
I0621 07:07:25.097741   388 solver.cpp:473] Iteration 1725, lr = 0.01
I0621 07:07:37.557540   388 solver.cpp:213] Iteration 1726, loss = 0.000234573
I0621 07:07:37.557637   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000234731 (* 1 = 0.000234731 loss)
I0621 07:07:37.557660   388 solver.cpp:473] Iteration 1726, lr = 0.01
I0621 07:07:49.808221   388 solver.cpp:213] Iteration 1727, loss = 0.000234414
I0621 07:07:49.814834   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233819 (* 1 = 0.000233819 loss)
I0621 07:07:49.814891   388 solver.cpp:473] Iteration 1727, lr = 0.01
I0621 07:08:02.198951   388 solver.cpp:213] Iteration 1728, loss = 0.000234247
I0621 07:08:02.199038   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233863 (* 1 = 0.000233863 loss)
I0621 07:08:02.199059   388 solver.cpp:473] Iteration 1728, lr = 0.01
I0621 07:08:14.487417   388 solver.cpp:213] Iteration 1729, loss = 0.000234267
I0621 07:08:14.487489   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233847 (* 1 = 0.000233847 loss)
I0621 07:08:14.487512   388 solver.cpp:473] Iteration 1729, lr = 0.01
I0621 07:08:26.788085   388 solver.cpp:213] Iteration 1730, loss = 0.000234122
I0621 07:08:26.788290   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233969 (* 1 = 0.000233969 loss)
I0621 07:08:26.788338   388 solver.cpp:473] Iteration 1730, lr = 0.01
I0621 07:08:39.112982   388 solver.cpp:213] Iteration 1731, loss = 0.000233989
I0621 07:08:39.113082   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000234256 (* 1 = 0.000234256 loss)
I0621 07:08:39.113106   388 solver.cpp:473] Iteration 1731, lr = 0.01
I0621 07:08:51.454357   388 solver.cpp:213] Iteration 1732, loss = 0.000233867
I0621 07:08:51.454457   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000234062 (* 1 = 0.000234062 loss)
I0621 07:08:51.454483   388 solver.cpp:473] Iteration 1732, lr = 0.01
I0621 07:09:03.735350   388 solver.cpp:213] Iteration 1733, loss = 0.000233761
I0621 07:09:03.735554   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023382 (* 1 = 0.00023382 loss)
I0621 07:09:03.735589   388 solver.cpp:473] Iteration 1733, lr = 0.01
I0621 07:09:16.096832   388 solver.cpp:213] Iteration 1734, loss = 0.000233701
I0621 07:09:16.096928   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023401 (* 1 = 0.00023401 loss)
I0621 07:09:16.096951   388 solver.cpp:473] Iteration 1734, lr = 0.01
I0621 07:09:28.410774   388 solver.cpp:213] Iteration 1735, loss = 0.00023361
I0621 07:09:28.410873   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233602 (* 1 = 0.000233602 loss)
I0621 07:09:28.410908   388 solver.cpp:473] Iteration 1735, lr = 0.01
I0621 07:09:40.740634   388 solver.cpp:213] Iteration 1736, loss = 0.000233364
I0621 07:09:40.740934   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232878 (* 1 = 0.000232878 loss)
I0621 07:09:40.740989   388 solver.cpp:473] Iteration 1736, lr = 0.01
I0621 07:09:53.019032   388 solver.cpp:213] Iteration 1737, loss = 0.000233193
I0621 07:09:53.019143   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233163 (* 1 = 0.000233163 loss)
I0621 07:09:53.019167   388 solver.cpp:473] Iteration 1737, lr = 0.01
I0621 07:10:05.317934   388 solver.cpp:213] Iteration 1738, loss = 0.000233117
I0621 07:10:05.318028   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232913 (* 1 = 0.000232913 loss)
I0621 07:10:05.318051   388 solver.cpp:473] Iteration 1738, lr = 0.01
I0621 07:10:17.630112   388 solver.cpp:213] Iteration 1739, loss = 0.00023301
I0621 07:10:17.630370   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233061 (* 1 = 0.000233061 loss)
I0621 07:10:17.630417   388 solver.cpp:473] Iteration 1739, lr = 0.01
I0621 07:10:29.939905   388 solver.cpp:213] Iteration 1740, loss = 0.000232975
I0621 07:10:29.940006   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233303 (* 1 = 0.000233303 loss)
I0621 07:10:29.940029   388 solver.cpp:473] Iteration 1740, lr = 0.01
I0621 07:10:42.206997   388 solver.cpp:213] Iteration 1741, loss = 0.000232827
I0621 07:10:42.207098   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232287 (* 1 = 0.000232287 loss)
I0621 07:10:42.207121   388 solver.cpp:473] Iteration 1741, lr = 0.01
I0621 07:10:54.496865   388 solver.cpp:213] Iteration 1742, loss = 0.000232738
I0621 07:10:54.497151   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232653 (* 1 = 0.000232653 loss)
I0621 07:10:54.497210   388 solver.cpp:473] Iteration 1742, lr = 0.01
I0621 07:11:06.962148   388 solver.cpp:213] Iteration 1743, loss = 0.000232729
I0621 07:11:06.962272   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000233022 (* 1 = 0.000233022 loss)
I0621 07:11:06.962314   388 solver.cpp:473] Iteration 1743, lr = 0.01
I0621 07:11:19.258677   388 solver.cpp:213] Iteration 1744, loss = 0.000232545
I0621 07:11:19.258770   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232486 (* 1 = 0.000232486 loss)
I0621 07:11:19.258793   388 solver.cpp:473] Iteration 1744, lr = 0.01
I0621 07:11:31.619760   388 solver.cpp:213] Iteration 1745, loss = 0.000232329
I0621 07:11:31.619971   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232236 (* 1 = 0.000232236 loss)
I0621 07:11:31.619995   388 solver.cpp:473] Iteration 1745, lr = 0.01
I0621 07:11:43.886729   388 solver.cpp:213] Iteration 1746, loss = 0.000232338
I0621 07:11:43.886828   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232192 (* 1 = 0.000232192 loss)
I0621 07:11:43.886852   388 solver.cpp:473] Iteration 1746, lr = 0.01
I0621 07:11:56.159678   388 solver.cpp:213] Iteration 1747, loss = 0.00023221
I0621 07:11:56.159778   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232204 (* 1 = 0.000232204 loss)
I0621 07:11:56.159800   388 solver.cpp:473] Iteration 1747, lr = 0.01
I0621 07:12:08.494660   388 solver.cpp:213] Iteration 1748, loss = 0.000231953
I0621 07:12:08.494925   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231727 (* 1 = 0.000231727 loss)
I0621 07:12:08.494971   388 solver.cpp:473] Iteration 1748, lr = 0.01
I0621 07:12:20.777667   388 solver.cpp:213] Iteration 1749, loss = 0.000232019
I0621 07:12:20.777766   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000232056 (* 1 = 0.000232056 loss)
I0621 07:12:20.777791   388 solver.cpp:473] Iteration 1749, lr = 0.01
I0621 07:12:33.116374   388 solver.cpp:213] Iteration 1750, loss = 0.00023188
I0621 07:12:33.116488   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231732 (* 1 = 0.000231732 loss)
I0621 07:12:33.116513   388 solver.cpp:473] Iteration 1750, lr = 0.01
I0621 07:12:45.516721   388 solver.cpp:213] Iteration 1751, loss = 0.000231685
I0621 07:12:45.516976   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231663 (* 1 = 0.000231663 loss)
I0621 07:12:45.517002   388 solver.cpp:473] Iteration 1751, lr = 0.01
I0621 07:12:57.884835   388 solver.cpp:213] Iteration 1752, loss = 0.000231749
I0621 07:12:57.884938   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231255 (* 1 = 0.000231255 loss)
I0621 07:12:57.884961   388 solver.cpp:473] Iteration 1752, lr = 0.01
I0621 07:13:10.176290   388 solver.cpp:213] Iteration 1753, loss = 0.000231602
I0621 07:13:10.176389   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231494 (* 1 = 0.000231494 loss)
I0621 07:13:10.176411   388 solver.cpp:473] Iteration 1753, lr = 0.01
I0621 07:13:22.529141   388 solver.cpp:213] Iteration 1754, loss = 0.000231543
I0621 07:13:22.529364   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231664 (* 1 = 0.000231664 loss)
I0621 07:13:22.529386   388 solver.cpp:473] Iteration 1754, lr = 0.01
I0621 07:13:34.821974   388 solver.cpp:213] Iteration 1755, loss = 0.000231354
I0621 07:13:34.822072   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231583 (* 1 = 0.000231583 loss)
I0621 07:13:34.822095   388 solver.cpp:473] Iteration 1755, lr = 0.01
I0621 07:13:47.064826   388 solver.cpp:213] Iteration 1756, loss = 0.000231163
I0621 07:13:47.064929   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231207 (* 1 = 0.000231207 loss)
I0621 07:13:47.064950   388 solver.cpp:473] Iteration 1756, lr = 0.01
I0621 07:13:59.332293   388 solver.cpp:213] Iteration 1757, loss = 0.000231096
I0621 07:13:59.332566   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231288 (* 1 = 0.000231288 loss)
I0621 07:13:59.332623   388 solver.cpp:473] Iteration 1757, lr = 0.01
I0621 07:14:11.585824   388 solver.cpp:213] Iteration 1758, loss = 0.000230934
I0621 07:14:11.585911   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231231 (* 1 = 0.000231231 loss)
I0621 07:14:11.585933   388 solver.cpp:473] Iteration 1758, lr = 0.01
I0621 07:14:23.859375   388 solver.cpp:213] Iteration 1759, loss = 0.000230928
I0621 07:14:23.859474   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231109 (* 1 = 0.000231109 loss)
I0621 07:14:23.859498   388 solver.cpp:473] Iteration 1759, lr = 0.01
I0621 07:14:36.204071   388 solver.cpp:213] Iteration 1760, loss = 0.000230827
I0621 07:14:36.204365   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000231054 (* 1 = 0.000231054 loss)
I0621 07:14:36.204416   388 solver.cpp:473] Iteration 1760, lr = 0.01
I0621 07:14:48.545191   388 solver.cpp:213] Iteration 1761, loss = 0.000230614
I0621 07:14:48.545277   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000230351 (* 1 = 0.000230351 loss)
I0621 07:14:48.545301   388 solver.cpp:473] Iteration 1761, lr = 0.01
I0621 07:15:00.795804   388 solver.cpp:213] Iteration 1762, loss = 0.00023047
I0621 07:15:00.795918   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000230552 (* 1 = 0.000230552 loss)
I0621 07:15:00.795940   388 solver.cpp:473] Iteration 1762, lr = 0.01
I0621 07:15:13.034227   388 solver.cpp:213] Iteration 1763, loss = 0.000230374
I0621 07:15:13.034432   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000230453 (* 1 = 0.000230453 loss)
I0621 07:15:13.034457   388 solver.cpp:473] Iteration 1763, lr = 0.01
I0621 07:15:25.301219   388 solver.cpp:213] Iteration 1764, loss = 0.000230299
I0621 07:15:25.301301   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00023053 (* 1 = 0.00023053 loss)
I0621 07:15:25.301324   388 solver.cpp:473] Iteration 1764, lr = 0.01
I0621 07:15:37.663204   388 solver.cpp:213] Iteration 1765, loss = 0.000230202
I0621 07:15:37.663286   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000230103 (* 1 = 0.000230103 loss)
I0621 07:15:37.663311   388 solver.cpp:473] Iteration 1765, lr = 0.01
I0621 07:15:49.901051   388 solver.cpp:213] Iteration 1766, loss = 0.000230109
I0621 07:15:49.901321   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000230018 (* 1 = 0.000230018 loss)
I0621 07:15:49.901370   388 solver.cpp:473] Iteration 1766, lr = 0.01
I0621 07:16:02.230842   388 solver.cpp:213] Iteration 1767, loss = 0.000229985
I0621 07:16:02.230928   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229606 (* 1 = 0.000229606 loss)
I0621 07:16:02.230950   388 solver.cpp:473] Iteration 1767, lr = 0.01
I0621 07:16:14.488488   388 solver.cpp:213] Iteration 1768, loss = 0.00022988
I0621 07:16:14.488574   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229816 (* 1 = 0.000229816 loss)
I0621 07:16:14.488598   388 solver.cpp:473] Iteration 1768, lr = 0.01
I0621 07:16:26.778197   388 solver.cpp:213] Iteration 1769, loss = 0.000229783
I0621 07:16:26.778453   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229713 (* 1 = 0.000229713 loss)
I0621 07:16:26.778501   388 solver.cpp:473] Iteration 1769, lr = 0.01
I0621 07:16:39.140239   388 solver.cpp:213] Iteration 1770, loss = 0.000229675
I0621 07:16:39.140328   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229852 (* 1 = 0.000229852 loss)
I0621 07:16:39.140353   388 solver.cpp:473] Iteration 1770, lr = 0.01
I0621 07:16:51.502593   388 solver.cpp:213] Iteration 1771, loss = 0.000229554
I0621 07:16:51.502676   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229438 (* 1 = 0.000229438 loss)
I0621 07:16:51.502701   388 solver.cpp:473] Iteration 1771, lr = 0.01
I0621 07:17:03.743654   388 solver.cpp:213] Iteration 1772, loss = 0.000229471
I0621 07:17:03.743898   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229589 (* 1 = 0.000229589 loss)
I0621 07:17:03.743947   388 solver.cpp:473] Iteration 1772, lr = 0.01
I0621 07:17:16.067404   388 solver.cpp:213] Iteration 1773, loss = 0.000229381
I0621 07:17:16.067482   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229367 (* 1 = 0.000229367 loss)
I0621 07:17:16.067505   388 solver.cpp:473] Iteration 1773, lr = 0.01
I0621 07:17:28.292908   388 solver.cpp:213] Iteration 1774, loss = 0.000229284
I0621 07:17:28.292995   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229278 (* 1 = 0.000229278 loss)
I0621 07:17:28.293017   388 solver.cpp:473] Iteration 1774, lr = 0.01
I0621 07:17:40.638260   388 solver.cpp:213] Iteration 1775, loss = 0.000229041
I0621 07:17:40.638520   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228709 (* 1 = 0.000228709 loss)
I0621 07:17:40.638584   388 solver.cpp:473] Iteration 1775, lr = 0.01
I0621 07:17:52.935817   388 solver.cpp:213] Iteration 1776, loss = 0.00022901
I0621 07:17:52.935905   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00022907 (* 1 = 0.00022907 loss)
I0621 07:17:52.935928   388 solver.cpp:473] Iteration 1776, lr = 0.01
I0621 07:18:05.149237   388 solver.cpp:213] Iteration 1777, loss = 0.000228853
I0621 07:18:05.149322   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000229074 (* 1 = 0.000229074 loss)
I0621 07:18:05.149344   388 solver.cpp:473] Iteration 1777, lr = 0.01
I0621 07:18:17.439736   388 solver.cpp:213] Iteration 1778, loss = 0.000228814
I0621 07:18:17.440441   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228939 (* 1 = 0.000228939 loss)
I0621 07:18:17.440469   388 solver.cpp:473] Iteration 1778, lr = 0.01
I0621 07:18:29.730144   388 solver.cpp:213] Iteration 1779, loss = 0.000228713
I0621 07:18:29.730228   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228765 (* 1 = 0.000228765 loss)
I0621 07:18:29.730250   388 solver.cpp:473] Iteration 1779, lr = 0.01
I0621 07:18:42.005300   388 solver.cpp:213] Iteration 1780, loss = 0.000228538
I0621 07:18:42.005395   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228766 (* 1 = 0.000228766 loss)
I0621 07:18:42.005420   388 solver.cpp:473] Iteration 1780, lr = 0.01
I0621 07:18:54.379947   388 solver.cpp:213] Iteration 1781, loss = 0.000228585
I0621 07:18:54.380157   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228587 (* 1 = 0.000228587 loss)
I0621 07:18:54.380183   388 solver.cpp:473] Iteration 1781, lr = 0.01
I0621 07:19:06.589099   388 solver.cpp:213] Iteration 1782, loss = 0.000228452
I0621 07:19:06.589234   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228472 (* 1 = 0.000228472 loss)
I0621 07:19:06.589288   388 solver.cpp:473] Iteration 1782, lr = 0.01
I0621 07:19:18.923295   388 solver.cpp:213] Iteration 1783, loss = 0.000228253
I0621 07:19:18.923378   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228452 (* 1 = 0.000228452 loss)
I0621 07:19:18.923400   388 solver.cpp:473] Iteration 1783, lr = 0.01
I0621 07:19:31.235750   388 solver.cpp:213] Iteration 1784, loss = 0.000228121
I0621 07:19:31.235991   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227986 (* 1 = 0.000227986 loss)
I0621 07:19:31.236028   388 solver.cpp:473] Iteration 1784, lr = 0.01
I0621 07:19:43.599803   388 solver.cpp:213] Iteration 1785, loss = 0.000228114
I0621 07:19:43.599886   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000228459 (* 1 = 0.000228459 loss)
I0621 07:19:43.599907   388 solver.cpp:473] Iteration 1785, lr = 0.01
I0621 07:19:56.050914   388 solver.cpp:213] Iteration 1786, loss = 0.000227997
I0621 07:19:56.050997   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227993 (* 1 = 0.000227993 loss)
I0621 07:19:56.051020   388 solver.cpp:473] Iteration 1786, lr = 0.01
I0621 07:20:08.337926   388 solver.cpp:213] Iteration 1787, loss = 0.000227832
I0621 07:20:08.338176   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227616 (* 1 = 0.000227616 loss)
I0621 07:20:08.338224   388 solver.cpp:473] Iteration 1787, lr = 0.01
I0621 07:20:20.672529   388 solver.cpp:213] Iteration 1788, loss = 0.000227618
I0621 07:20:20.672610   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227509 (* 1 = 0.000227509 loss)
I0621 07:20:20.672633   388 solver.cpp:473] Iteration 1788, lr = 0.01
I0621 07:20:32.964118   388 solver.cpp:213] Iteration 1789, loss = 0.00022764
I0621 07:20:32.964205   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227944 (* 1 = 0.000227944 loss)
I0621 07:20:32.964228   388 solver.cpp:473] Iteration 1789, lr = 0.01
I0621 07:20:45.225201   388 solver.cpp:213] Iteration 1790, loss = 0.00022761
I0621 07:20:45.225447   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227696 (* 1 = 0.000227696 loss)
I0621 07:20:45.225493   388 solver.cpp:473] Iteration 1790, lr = 0.01
I0621 07:20:57.639405   388 solver.cpp:213] Iteration 1791, loss = 0.000227421
I0621 07:20:57.639487   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227501 (* 1 = 0.000227501 loss)
I0621 07:20:57.639509   388 solver.cpp:473] Iteration 1791, lr = 0.01
I0621 07:21:09.919955   388 solver.cpp:213] Iteration 1792, loss = 0.000227238
I0621 07:21:09.920037   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227055 (* 1 = 0.000227055 loss)
I0621 07:21:09.920059   388 solver.cpp:473] Iteration 1792, lr = 0.01
I0621 07:21:22.249560   388 solver.cpp:213] Iteration 1793, loss = 0.000227198
I0621 07:21:22.249871   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226929 (* 1 = 0.000226929 loss)
I0621 07:21:22.249897   388 solver.cpp:473] Iteration 1793, lr = 0.01
I0621 07:21:34.633163   388 solver.cpp:213] Iteration 1794, loss = 0.000227139
I0621 07:21:34.633249   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00022723 (* 1 = 0.00022723 loss)
I0621 07:21:34.633271   388 solver.cpp:473] Iteration 1794, lr = 0.01
I0621 07:21:46.876281   388 solver.cpp:213] Iteration 1795, loss = 0.000227046
I0621 07:21:46.876363   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226654 (* 1 = 0.000226654 loss)
I0621 07:21:46.876384   388 solver.cpp:473] Iteration 1795, lr = 0.01
I0621 07:21:59.138347   388 solver.cpp:213] Iteration 1796, loss = 0.00022694
I0621 07:21:59.138543   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000227158 (* 1 = 0.000227158 loss)
I0621 07:21:59.138569   388 solver.cpp:473] Iteration 1796, lr = 0.01
I0621 07:22:11.366406   388 solver.cpp:213] Iteration 1797, loss = 0.000226775
I0621 07:22:11.366492   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226924 (* 1 = 0.000226924 loss)
I0621 07:22:11.366515   388 solver.cpp:473] Iteration 1797, lr = 0.01
I0621 07:22:23.579661   388 solver.cpp:213] Iteration 1798, loss = 0.000226736
I0621 07:22:23.579743   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226748 (* 1 = 0.000226748 loss)
I0621 07:22:23.579766   388 solver.cpp:473] Iteration 1798, lr = 0.01
I0621 07:22:35.996112   388 solver.cpp:213] Iteration 1799, loss = 0.000226499
I0621 07:22:35.996299   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226624 (* 1 = 0.000226624 loss)
I0621 07:22:35.996325   388 solver.cpp:473] Iteration 1799, lr = 0.01
I0621 07:22:48.341241   388 solver.cpp:213] Iteration 1800, loss = 0.000226384
I0621 07:22:48.341327   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225895 (* 1 = 0.000225895 loss)
I0621 07:22:48.341352   388 solver.cpp:473] Iteration 1800, lr = 0.01
I0621 07:23:00.613872   388 solver.cpp:213] Iteration 1801, loss = 0.000226469
I0621 07:23:00.613955   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226773 (* 1 = 0.000226773 loss)
I0621 07:23:00.613977   388 solver.cpp:473] Iteration 1801, lr = 0.01
I0621 07:23:12.844205   388 solver.cpp:213] Iteration 1802, loss = 0.000226219
I0621 07:23:12.844383   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226425 (* 1 = 0.000226425 loss)
I0621 07:23:12.844408   388 solver.cpp:473] Iteration 1802, lr = 0.01
I0621 07:23:25.114648   388 solver.cpp:213] Iteration 1803, loss = 0.000226231
I0621 07:23:25.114734   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226229 (* 1 = 0.000226229 loss)
I0621 07:23:25.114758   388 solver.cpp:473] Iteration 1803, lr = 0.01
I0621 07:23:37.335178   388 solver.cpp:213] Iteration 1804, loss = 0.000226061
I0621 07:23:37.335264   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225881 (* 1 = 0.000225881 loss)
I0621 07:23:37.335286   388 solver.cpp:473] Iteration 1804, lr = 0.01
I0621 07:23:49.592015   388 solver.cpp:213] Iteration 1805, loss = 0.000225991
I0621 07:23:49.598637   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000226168 (* 1 = 0.000226168 loss)
I0621 07:23:49.598664   388 solver.cpp:473] Iteration 1805, lr = 0.01
I0621 07:24:01.925946   388 solver.cpp:213] Iteration 1806, loss = 0.000225845
I0621 07:24:01.926039   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225748 (* 1 = 0.000225748 loss)
I0621 07:24:01.926062   388 solver.cpp:473] Iteration 1806, lr = 0.01
I0621 07:24:14.265408   388 solver.cpp:213] Iteration 1807, loss = 0.000225722
I0621 07:24:14.265487   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225646 (* 1 = 0.000225646 loss)
I0621 07:24:14.265511   388 solver.cpp:473] Iteration 1807, lr = 0.01
I0621 07:24:26.546815   388 solver.cpp:213] Iteration 1808, loss = 0.000225644
I0621 07:24:26.547003   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225404 (* 1 = 0.000225404 loss)
I0621 07:24:26.547031   388 solver.cpp:473] Iteration 1808, lr = 0.01
I0621 07:24:38.796891   388 solver.cpp:213] Iteration 1809, loss = 0.00022561
I0621 07:24:38.796974   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225504 (* 1 = 0.000225504 loss)
I0621 07:24:38.796998   388 solver.cpp:473] Iteration 1809, lr = 0.01
I0621 07:24:51.114555   388 solver.cpp:213] Iteration 1810, loss = 0.000225467
I0621 07:24:51.114640   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225398 (* 1 = 0.000225398 loss)
I0621 07:24:51.114663   388 solver.cpp:473] Iteration 1810, lr = 0.01
I0621 07:25:03.375527   388 solver.cpp:213] Iteration 1811, loss = 0.000225302
I0621 07:25:03.375741   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225086 (* 1 = 0.000225086 loss)
I0621 07:25:03.375767   388 solver.cpp:473] Iteration 1811, lr = 0.01
I0621 07:25:15.698451   388 solver.cpp:213] Iteration 1812, loss = 0.000225196
I0621 07:25:15.698541   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225211 (* 1 = 0.000225211 loss)
I0621 07:25:15.698564   388 solver.cpp:473] Iteration 1812, lr = 0.01
I0621 07:25:28.059960   388 solver.cpp:213] Iteration 1813, loss = 0.000225057
I0621 07:25:28.060044   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225468 (* 1 = 0.000225468 loss)
I0621 07:25:28.060065   388 solver.cpp:473] Iteration 1813, lr = 0.01
I0621 07:25:40.479676   388 solver.cpp:213] Iteration 1814, loss = 0.000224996
I0621 07:25:40.479919   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225076 (* 1 = 0.000225076 loss)
I0621 07:25:40.479954   388 solver.cpp:473] Iteration 1814, lr = 0.01
I0621 07:25:52.891602   388 solver.cpp:213] Iteration 1815, loss = 0.000224972
I0621 07:25:52.891686   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000225123 (* 1 = 0.000225123 loss)
I0621 07:25:52.891708   388 solver.cpp:473] Iteration 1815, lr = 0.01
I0621 07:26:05.149487   388 solver.cpp:213] Iteration 1816, loss = 0.000224851
I0621 07:26:05.149569   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224926 (* 1 = 0.000224926 loss)
I0621 07:26:05.149590   388 solver.cpp:473] Iteration 1816, lr = 0.01
I0621 07:26:17.494316   388 solver.cpp:213] Iteration 1817, loss = 0.000224559
I0621 07:26:17.494545   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224372 (* 1 = 0.000224372 loss)
I0621 07:26:17.494578   388 solver.cpp:473] Iteration 1817, lr = 0.01
I0621 07:26:29.827272   388 solver.cpp:213] Iteration 1818, loss = 0.000224657
I0621 07:26:29.827369   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224784 (* 1 = 0.000224784 loss)
I0621 07:26:29.827390   388 solver.cpp:473] Iteration 1818, lr = 0.01
I0621 07:26:42.202198   388 solver.cpp:213] Iteration 1819, loss = 0.000224423
I0621 07:26:42.202280   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224485 (* 1 = 0.000224485 loss)
I0621 07:26:42.202303   388 solver.cpp:473] Iteration 1819, lr = 0.01
I0621 07:26:54.457970   388 solver.cpp:213] Iteration 1820, loss = 0.000224404
I0621 07:26:54.458354   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224172 (* 1 = 0.000224172 loss)
I0621 07:26:54.458400   388 solver.cpp:473] Iteration 1820, lr = 0.01
I0621 07:27:06.797382   388 solver.cpp:213] Iteration 1821, loss = 0.000224288
I0621 07:27:06.797472   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224356 (* 1 = 0.000224356 loss)
I0621 07:27:06.797493   388 solver.cpp:473] Iteration 1821, lr = 0.01
I0621 07:27:19.067090   388 solver.cpp:213] Iteration 1822, loss = 0.000224143
I0621 07:27:19.067174   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224207 (* 1 = 0.000224207 loss)
I0621 07:27:19.067198   388 solver.cpp:473] Iteration 1822, lr = 0.01
I0621 07:27:31.300726   388 solver.cpp:213] Iteration 1823, loss = 0.000224044
I0621 07:27:31.300927   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223996 (* 1 = 0.000223996 loss)
I0621 07:27:31.300956   388 solver.cpp:473] Iteration 1823, lr = 0.01
I0621 07:27:43.606948   388 solver.cpp:213] Iteration 1824, loss = 0.000223935
I0621 07:27:43.607035   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223821 (* 1 = 0.000223821 loss)
I0621 07:27:43.607059   388 solver.cpp:473] Iteration 1824, lr = 0.01
I0621 07:27:55.909399   388 solver.cpp:213] Iteration 1825, loss = 0.000223961
I0621 07:27:55.909483   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224293 (* 1 = 0.000224293 loss)
I0621 07:27:55.909507   388 solver.cpp:473] Iteration 1825, lr = 0.01
I0621 07:28:08.212189   388 solver.cpp:213] Iteration 1826, loss = 0.000223782
I0621 07:28:08.212440   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223724 (* 1 = 0.000223724 loss)
I0621 07:28:08.212482   388 solver.cpp:473] Iteration 1826, lr = 0.01
I0621 07:28:20.649102   388 solver.cpp:213] Iteration 1827, loss = 0.000223724
I0621 07:28:20.649183   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000224168 (* 1 = 0.000224168 loss)
I0621 07:28:20.649205   388 solver.cpp:473] Iteration 1827, lr = 0.01
I0621 07:28:33.042991   388 solver.cpp:213] Iteration 1828, loss = 0.000223541
I0621 07:28:33.043081   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223679 (* 1 = 0.000223679 loss)
I0621 07:28:33.043104   388 solver.cpp:473] Iteration 1828, lr = 0.01
I0621 07:28:45.358983   388 solver.cpp:213] Iteration 1829, loss = 0.000223573
I0621 07:28:45.365964   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223517 (* 1 = 0.000223517 loss)
I0621 07:28:45.365990   388 solver.cpp:473] Iteration 1829, lr = 0.01
I0621 07:28:57.652329   388 solver.cpp:213] Iteration 1830, loss = 0.000223432
I0621 07:28:57.652416   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223226 (* 1 = 0.000223226 loss)
I0621 07:28:57.652437   388 solver.cpp:473] Iteration 1830, lr = 0.01
I0621 07:29:09.965960   388 solver.cpp:213] Iteration 1831, loss = 0.000223399
I0621 07:29:09.966043   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222993 (* 1 = 0.000222993 loss)
I0621 07:29:09.966066   388 solver.cpp:473] Iteration 1831, lr = 0.01
I0621 07:29:22.253644   388 solver.cpp:213] Iteration 1832, loss = 0.00022319
I0621 07:29:22.253873   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223071 (* 1 = 0.000223071 loss)
I0621 07:29:22.253906   388 solver.cpp:473] Iteration 1832, lr = 0.01
I0621 07:29:34.650163   388 solver.cpp:213] Iteration 1833, loss = 0.000223061
I0621 07:29:34.650248   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000223183 (* 1 = 0.000223183 loss)
I0621 07:29:34.650269   388 solver.cpp:473] Iteration 1833, lr = 0.01
I0621 07:29:46.949978   388 solver.cpp:213] Iteration 1834, loss = 0.00022299
I0621 07:29:46.950065   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222779 (* 1 = 0.000222779 loss)
I0621 07:29:46.950088   388 solver.cpp:473] Iteration 1834, lr = 0.01
I0621 07:29:59.201710   388 solver.cpp:213] Iteration 1835, loss = 0.000222881
I0621 07:29:59.203361   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222974 (* 1 = 0.000222974 loss)
I0621 07:29:59.203419   388 solver.cpp:473] Iteration 1835, lr = 0.01
I0621 07:30:11.446660   388 solver.cpp:213] Iteration 1836, loss = 0.000222774
I0621 07:30:11.446743   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222816 (* 1 = 0.000222816 loss)
I0621 07:30:11.446764   388 solver.cpp:473] Iteration 1836, lr = 0.01
I0621 07:30:23.748150   388 solver.cpp:213] Iteration 1837, loss = 0.000222626
I0621 07:30:23.748237   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222287 (* 1 = 0.000222287 loss)
I0621 07:30:23.748260   388 solver.cpp:473] Iteration 1837, lr = 0.01
I0621 07:30:35.993389   388 solver.cpp:213] Iteration 1838, loss = 0.000222575
I0621 07:30:35.993576   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222417 (* 1 = 0.000222417 loss)
I0621 07:30:35.993600   388 solver.cpp:473] Iteration 1838, lr = 0.01
I0621 07:30:48.230128   388 solver.cpp:213] Iteration 1839, loss = 0.000222455
I0621 07:30:48.230211   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222767 (* 1 = 0.000222767 loss)
I0621 07:30:48.230233   388 solver.cpp:473] Iteration 1839, lr = 0.01
I0621 07:31:00.481802   388 solver.cpp:213] Iteration 1840, loss = 0.000222306
I0621 07:31:00.481885   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222486 (* 1 = 0.000222486 loss)
I0621 07:31:00.481907   388 solver.cpp:473] Iteration 1840, lr = 0.01
I0621 07:31:12.710085   388 solver.cpp:213] Iteration 1841, loss = 0.000222231
I0621 07:31:12.710273   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222458 (* 1 = 0.000222458 loss)
I0621 07:31:12.710297   388 solver.cpp:473] Iteration 1841, lr = 0.01
I0621 07:31:24.964417   388 solver.cpp:213] Iteration 1842, loss = 0.000222075
I0621 07:31:24.964499   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222064 (* 1 = 0.000222064 loss)
I0621 07:31:24.964522   388 solver.cpp:473] Iteration 1842, lr = 0.01
I0621 07:31:37.296630   388 solver.cpp:213] Iteration 1843, loss = 0.000222046
I0621 07:31:37.296716   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000222069 (* 1 = 0.000222069 loss)
I0621 07:31:37.296738   388 solver.cpp:473] Iteration 1843, lr = 0.01
I0621 07:31:49.578542   388 solver.cpp:213] Iteration 1844, loss = 0.000221893
I0621 07:31:49.578727   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221837 (* 1 = 0.000221837 loss)
I0621 07:31:49.578752   388 solver.cpp:473] Iteration 1844, lr = 0.01
I0621 07:32:01.863955   388 solver.cpp:213] Iteration 1845, loss = 0.000221827
I0621 07:32:01.864037   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221592 (* 1 = 0.000221592 loss)
I0621 07:32:01.864058   388 solver.cpp:473] Iteration 1845, lr = 0.01
I0621 07:32:14.135139   388 solver.cpp:213] Iteration 1846, loss = 0.00022179
I0621 07:32:14.135222   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221997 (* 1 = 0.000221997 loss)
I0621 07:32:14.135246   388 solver.cpp:473] Iteration 1846, lr = 0.01
I0621 07:32:26.516635   388 solver.cpp:213] Iteration 1847, loss = 0.000221662
I0621 07:32:26.517102   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221714 (* 1 = 0.000221714 loss)
I0621 07:32:26.517132   388 solver.cpp:473] Iteration 1847, lr = 0.01
I0621 07:32:38.834446   388 solver.cpp:213] Iteration 1848, loss = 0.000221486
I0621 07:32:38.834542   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221189 (* 1 = 0.000221189 loss)
I0621 07:32:38.834568   388 solver.cpp:473] Iteration 1848, lr = 0.01
I0621 07:32:51.148491   388 solver.cpp:213] Iteration 1849, loss = 0.000221456
I0621 07:32:51.148572   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221626 (* 1 = 0.000221626 loss)
I0621 07:32:51.148597   388 solver.cpp:473] Iteration 1849, lr = 0.01
I0621 07:33:03.402590   388 solver.cpp:213] Iteration 1850, loss = 0.000221425
I0621 07:33:03.402804   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221619 (* 1 = 0.000221619 loss)
I0621 07:33:03.402833   388 solver.cpp:473] Iteration 1850, lr = 0.01
I0621 07:33:15.695482   388 solver.cpp:213] Iteration 1851, loss = 0.000221154
I0621 07:33:15.695565   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221031 (* 1 = 0.000221031 loss)
I0621 07:33:15.695587   388 solver.cpp:473] Iteration 1851, lr = 0.01
I0621 07:33:28.011690   388 solver.cpp:213] Iteration 1852, loss = 0.000221221
I0621 07:33:28.011776   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000221341 (* 1 = 0.000221341 loss)
I0621 07:33:28.011800   388 solver.cpp:473] Iteration 1852, lr = 0.01
I0621 07:33:40.309417   388 solver.cpp:213] Iteration 1853, loss = 0.000220985
I0621 07:33:40.309595   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220432 (* 1 = 0.000220432 loss)
I0621 07:33:40.309620   388 solver.cpp:473] Iteration 1853, lr = 0.01
I0621 07:33:52.765159   388 solver.cpp:213] Iteration 1854, loss = 0.000220953
I0621 07:33:52.765242   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220887 (* 1 = 0.000220887 loss)
I0621 07:33:52.765265   388 solver.cpp:473] Iteration 1854, lr = 0.01
I0621 07:34:05.030895   388 solver.cpp:213] Iteration 1855, loss = 0.000220837
I0621 07:34:05.030978   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220705 (* 1 = 0.000220705 loss)
I0621 07:34:05.031000   388 solver.cpp:473] Iteration 1855, lr = 0.01
I0621 07:34:17.328039   388 solver.cpp:213] Iteration 1856, loss = 0.000220758
I0621 07:34:17.328276   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220928 (* 1 = 0.000220928 loss)
I0621 07:34:17.328305   388 solver.cpp:473] Iteration 1856, lr = 0.01
I0621 07:34:29.619856   388 solver.cpp:213] Iteration 1857, loss = 0.000220658
I0621 07:34:29.619956   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220723 (* 1 = 0.000220723 loss)
I0621 07:34:29.619981   388 solver.cpp:473] Iteration 1857, lr = 0.01
I0621 07:34:41.878517   388 solver.cpp:213] Iteration 1858, loss = 0.000220527
I0621 07:34:41.878599   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220401 (* 1 = 0.000220401 loss)
I0621 07:34:41.878621   388 solver.cpp:473] Iteration 1858, lr = 0.01
I0621 07:34:54.293395   388 solver.cpp:213] Iteration 1859, loss = 0.000220496
I0621 07:34:54.293637   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220626 (* 1 = 0.000220626 loss)
I0621 07:34:54.293687   388 solver.cpp:473] Iteration 1859, lr = 0.01
I0621 07:35:06.576665   388 solver.cpp:213] Iteration 1860, loss = 0.000220434
I0621 07:35:06.576750   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220514 (* 1 = 0.000220514 loss)
I0621 07:35:06.576771   388 solver.cpp:473] Iteration 1860, lr = 0.01
I0621 07:35:18.916299   388 solver.cpp:213] Iteration 1861, loss = 0.000220269
I0621 07:35:18.916394   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220496 (* 1 = 0.000220496 loss)
I0621 07:35:18.916419   388 solver.cpp:473] Iteration 1861, lr = 0.01
I0621 07:35:31.208777   388 solver.cpp:213] Iteration 1862, loss = 0.000220142
I0621 07:35:31.208967   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021973 (* 1 = 0.00021973 loss)
I0621 07:35:31.208992   388 solver.cpp:473] Iteration 1862, lr = 0.01
I0621 07:35:43.470734   388 solver.cpp:213] Iteration 1863, loss = 0.000220051
I0621 07:35:43.470819   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219909 (* 1 = 0.000219909 loss)
I0621 07:35:43.470842   388 solver.cpp:473] Iteration 1863, lr = 0.01
I0621 07:35:55.698489   388 solver.cpp:213] Iteration 1864, loss = 0.000219936
I0621 07:35:55.698577   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000220036 (* 1 = 0.000220036 loss)
I0621 07:35:55.698602   388 solver.cpp:473] Iteration 1864, lr = 0.01
I0621 07:36:07.941092   388 solver.cpp:213] Iteration 1865, loss = 0.000219779
I0621 07:36:07.947134   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219895 (* 1 = 0.000219895 loss)
I0621 07:36:07.947159   388 solver.cpp:473] Iteration 1865, lr = 0.01
I0621 07:36:20.223335   388 solver.cpp:213] Iteration 1866, loss = 0.000219701
I0621 07:36:20.223429   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219929 (* 1 = 0.000219929 loss)
I0621 07:36:20.223454   388 solver.cpp:473] Iteration 1866, lr = 0.01
I0621 07:36:32.508641   388 solver.cpp:213] Iteration 1867, loss = 0.000219688
I0621 07:36:32.508725   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219313 (* 1 = 0.000219313 loss)
I0621 07:36:32.508749   388 solver.cpp:473] Iteration 1867, lr = 0.01
I0621 07:36:44.856279   388 solver.cpp:213] Iteration 1868, loss = 0.000219566
I0621 07:36:44.863010   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219606 (* 1 = 0.000219606 loss)
I0621 07:36:44.863054   388 solver.cpp:473] Iteration 1868, lr = 0.01
I0621 07:36:57.194947   388 solver.cpp:213] Iteration 1869, loss = 0.000219524
I0621 07:36:57.195027   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219841 (* 1 = 0.000219841 loss)
I0621 07:36:57.195050   388 solver.cpp:473] Iteration 1869, lr = 0.01
I0621 07:37:09.578699   388 solver.cpp:213] Iteration 1870, loss = 0.000219376
I0621 07:37:09.578784   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219073 (* 1 = 0.000219073 loss)
I0621 07:37:09.578807   388 solver.cpp:473] Iteration 1870, lr = 0.01
I0621 07:37:21.971516   388 solver.cpp:213] Iteration 1871, loss = 0.000219272
I0621 07:37:21.971762   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002192 (* 1 = 0.0002192 loss)
I0621 07:37:21.971797   388 solver.cpp:473] Iteration 1871, lr = 0.01
I0621 07:37:34.432806   388 solver.cpp:213] Iteration 1872, loss = 0.000219179
I0621 07:37:34.432945   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219429 (* 1 = 0.000219429 loss)
I0621 07:37:34.432986   388 solver.cpp:473] Iteration 1872, lr = 0.01
I0621 07:37:46.812432   388 solver.cpp:213] Iteration 1873, loss = 0.000219133
I0621 07:37:46.812513   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021889 (* 1 = 0.00021889 loss)
I0621 07:37:46.812536   388 solver.cpp:473] Iteration 1873, lr = 0.01
I0621 07:37:59.241061   388 solver.cpp:213] Iteration 1874, loss = 0.000218921
I0621 07:37:59.241328   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219147 (* 1 = 0.000219147 loss)
I0621 07:37:59.241385   388 solver.cpp:473] Iteration 1874, lr = 0.01
I0621 07:38:11.581583   388 solver.cpp:213] Iteration 1875, loss = 0.00021899
I0621 07:38:11.581684   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000218824 (* 1 = 0.000218824 loss)
I0621 07:38:11.581715   388 solver.cpp:473] Iteration 1875, lr = 0.01
I0621 07:38:23.892446   388 solver.cpp:213] Iteration 1876, loss = 0.000218809
I0621 07:38:23.892531   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000219295 (* 1 = 0.000219295 loss)
I0621 07:38:23.892554   388 solver.cpp:473] Iteration 1876, lr = 0.01
I0621 07:38:36.142277   388 solver.cpp:213] Iteration 1877, loss = 0.000218634
I0621 07:38:36.144902   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021839 (* 1 = 0.00021839 loss)
I0621 07:38:36.144928   388 solver.cpp:473] Iteration 1877, lr = 0.01
I0621 07:38:48.491138   388 solver.cpp:213] Iteration 1878, loss = 0.000218578
I0621 07:38:48.491217   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000218397 (* 1 = 0.000218397 loss)
I0621 07:38:48.491238   388 solver.cpp:473] Iteration 1878, lr = 0.01
I0621 07:39:00.876034   388 solver.cpp:213] Iteration 1879, loss = 0.000218664
I0621 07:39:00.876104   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000218761 (* 1 = 0.000218761 loss)
I0621 07:39:00.876123   388 solver.cpp:473] Iteration 1879, lr = 0.01
I0621 07:39:13.314693   388 solver.cpp:213] Iteration 1880, loss = 0.000218306
I0621 07:39:13.315784   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000218425 (* 1 = 0.000218425 loss)
I0621 07:39:13.315810   388 solver.cpp:473] Iteration 1880, lr = 0.01
I0621 07:39:25.613482   388 solver.cpp:213] Iteration 1881, loss = 0.000218245
I0621 07:39:25.613564   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000218594 (* 1 = 0.000218594 loss)
I0621 07:39:25.613585   388 solver.cpp:473] Iteration 1881, lr = 0.01
I0621 07:39:38.064633   388 solver.cpp:213] Iteration 1882, loss = 0.000218068
I0621 07:39:38.064712   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000218202 (* 1 = 0.000218202 loss)
I0621 07:39:38.064734   388 solver.cpp:473] Iteration 1882, lr = 0.01
I0621 07:39:50.424805   388 solver.cpp:213] Iteration 1883, loss = 0.000218004
I0621 07:39:50.424999   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217947 (* 1 = 0.000217947 loss)
I0621 07:39:50.425025   388 solver.cpp:473] Iteration 1883, lr = 0.01
I0621 07:40:02.804265   388 solver.cpp:213] Iteration 1884, loss = 0.000218036
I0621 07:40:02.804350   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000218006 (* 1 = 0.000218006 loss)
I0621 07:40:02.804374   388 solver.cpp:473] Iteration 1884, lr = 0.01
I0621 07:40:15.192533   388 solver.cpp:213] Iteration 1885, loss = 0.000217855
I0621 07:40:15.192611   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217837 (* 1 = 0.000217837 loss)
I0621 07:40:15.192636   388 solver.cpp:473] Iteration 1885, lr = 0.01
I0621 07:40:27.601083   388 solver.cpp:213] Iteration 1886, loss = 0.000217673
I0621 07:40:27.601297   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217536 (* 1 = 0.000217536 loss)
I0621 07:40:27.601331   388 solver.cpp:473] Iteration 1886, lr = 0.01
I0621 07:40:40.042891   388 solver.cpp:213] Iteration 1887, loss = 0.000217768
I0621 07:40:40.042979   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217767 (* 1 = 0.000217767 loss)
I0621 07:40:40.042999   388 solver.cpp:473] Iteration 1887, lr = 0.01
I0621 07:40:52.360462   388 solver.cpp:213] Iteration 1888, loss = 0.000217597
I0621 07:40:52.360546   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217758 (* 1 = 0.000217758 loss)
I0621 07:40:52.360569   388 solver.cpp:473] Iteration 1888, lr = 0.01
I0621 07:41:04.606885   388 solver.cpp:213] Iteration 1889, loss = 0.000217407
I0621 07:41:04.607156   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217313 (* 1 = 0.000217313 loss)
I0621 07:41:04.607251   388 solver.cpp:473] Iteration 1889, lr = 0.01
I0621 07:41:17.050318   388 solver.cpp:213] Iteration 1890, loss = 0.000217456
I0621 07:41:17.050405   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217204 (* 1 = 0.000217204 loss)
I0621 07:41:17.050428   388 solver.cpp:473] Iteration 1890, lr = 0.01
I0621 07:41:29.377640   388 solver.cpp:213] Iteration 1891, loss = 0.000217307
I0621 07:41:29.377718   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217356 (* 1 = 0.000217356 loss)
I0621 07:41:29.377742   388 solver.cpp:473] Iteration 1891, lr = 0.01
I0621 07:41:41.649418   388 solver.cpp:213] Iteration 1892, loss = 0.000217208
I0621 07:41:41.649613   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217544 (* 1 = 0.000217544 loss)
I0621 07:41:41.649639   388 solver.cpp:473] Iteration 1892, lr = 0.01
I0621 07:41:53.957329   388 solver.cpp:213] Iteration 1893, loss = 0.000217119
I0621 07:41:53.957415   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216676 (* 1 = 0.000216676 loss)
I0621 07:41:53.957438   388 solver.cpp:473] Iteration 1893, lr = 0.01
I0621 07:42:06.332737   388 solver.cpp:213] Iteration 1894, loss = 0.000217146
I0621 07:42:06.332823   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216826 (* 1 = 0.000216826 loss)
I0621 07:42:06.332845   388 solver.cpp:473] Iteration 1894, lr = 0.01
I0621 07:42:18.665948   388 solver.cpp:213] Iteration 1895, loss = 0.000217015
I0621 07:42:18.666124   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000217196 (* 1 = 0.000217196 loss)
I0621 07:42:18.666148   388 solver.cpp:473] Iteration 1895, lr = 0.01
I0621 07:42:30.893084   388 solver.cpp:213] Iteration 1896, loss = 0.000216849
I0621 07:42:30.893169   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021706 (* 1 = 0.00021706 loss)
I0621 07:42:30.893192   388 solver.cpp:473] Iteration 1896, lr = 0.01
I0621 07:42:43.201511   388 solver.cpp:213] Iteration 1897, loss = 0.000216684
I0621 07:42:43.201637   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216768 (* 1 = 0.000216768 loss)
I0621 07:42:43.201676   388 solver.cpp:473] Iteration 1897, lr = 0.01
I0621 07:42:55.519086   388 solver.cpp:213] Iteration 1898, loss = 0.000216594
I0621 07:42:55.519273   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216595 (* 1 = 0.000216595 loss)
I0621 07:42:55.519299   388 solver.cpp:473] Iteration 1898, lr = 0.01
I0621 07:43:07.834595   388 solver.cpp:213] Iteration 1899, loss = 0.0002166
I0621 07:43:07.834681   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216336 (* 1 = 0.000216336 loss)
I0621 07:43:07.834702   388 solver.cpp:473] Iteration 1899, lr = 0.01
I0621 07:43:20.180435   388 solver.cpp:213] Iteration 1900, loss = 0.000216399
I0621 07:43:20.180524   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216664 (* 1 = 0.000216664 loss)
I0621 07:43:20.180547   388 solver.cpp:473] Iteration 1900, lr = 0.01
I0621 07:43:32.485806   388 solver.cpp:213] Iteration 1901, loss = 0.000216241
I0621 07:43:32.486008   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216119 (* 1 = 0.000216119 loss)
I0621 07:43:32.486034   388 solver.cpp:473] Iteration 1901, lr = 0.01
I0621 07:43:44.732969   388 solver.cpp:213] Iteration 1902, loss = 0.000216304
I0621 07:43:44.733050   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216649 (* 1 = 0.000216649 loss)
I0621 07:43:44.733074   388 solver.cpp:473] Iteration 1902, lr = 0.01
I0621 07:43:56.993343   388 solver.cpp:213] Iteration 1903, loss = 0.000216154
I0621 07:43:56.993427   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000216253 (* 1 = 0.000216253 loss)
I0621 07:43:56.993448   388 solver.cpp:473] Iteration 1903, lr = 0.01
I0621 07:44:09.343919   388 solver.cpp:213] Iteration 1904, loss = 0.000216011
I0621 07:44:09.344177   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002158 (* 1 = 0.0002158 loss)
I0621 07:44:09.344208   388 solver.cpp:473] Iteration 1904, lr = 0.01
I0621 07:44:21.643138   388 solver.cpp:213] Iteration 1905, loss = 0.000215926
I0621 07:44:21.643220   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215914 (* 1 = 0.000215914 loss)
I0621 07:44:21.643244   388 solver.cpp:473] Iteration 1905, lr = 0.01
I0621 07:44:33.889974   388 solver.cpp:213] Iteration 1906, loss = 0.000215895
I0621 07:44:33.890061   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215481 (* 1 = 0.000215481 loss)
I0621 07:44:33.890084   388 solver.cpp:473] Iteration 1906, lr = 0.01
I0621 07:44:46.148685   388 solver.cpp:213] Iteration 1907, loss = 0.000215827
I0621 07:44:46.148866   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215855 (* 1 = 0.000215855 loss)
I0621 07:44:46.148890   388 solver.cpp:473] Iteration 1907, lr = 0.01
I0621 07:44:58.370249   388 solver.cpp:213] Iteration 1908, loss = 0.000215737
I0621 07:44:58.370337   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215608 (* 1 = 0.000215608 loss)
I0621 07:44:58.370360   388 solver.cpp:473] Iteration 1908, lr = 0.01
I0621 07:45:10.609290   388 solver.cpp:213] Iteration 1909, loss = 0.000215678
I0621 07:45:10.609376   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215869 (* 1 = 0.000215869 loss)
I0621 07:45:10.609400   388 solver.cpp:473] Iteration 1909, lr = 0.01
I0621 07:45:22.906235   388 solver.cpp:213] Iteration 1910, loss = 0.000215518
I0621 07:45:22.907171   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215147 (* 1 = 0.000215147 loss)
I0621 07:45:22.907196   388 solver.cpp:473] Iteration 1910, lr = 0.01
I0621 07:45:35.237663   388 solver.cpp:213] Iteration 1911, loss = 0.000215394
I0621 07:45:35.237746   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215477 (* 1 = 0.000215477 loss)
I0621 07:45:35.237769   388 solver.cpp:473] Iteration 1911, lr = 0.01
I0621 07:45:47.681980   388 solver.cpp:213] Iteration 1912, loss = 0.000215269
I0621 07:45:47.682062   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021556 (* 1 = 0.00021556 loss)
I0621 07:45:47.682085   388 solver.cpp:473] Iteration 1912, lr = 0.01
I0621 07:45:59.953853   388 solver.cpp:213] Iteration 1913, loss = 0.000215289
I0621 07:45:59.954030   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215064 (* 1 = 0.000215064 loss)
I0621 07:45:59.954054   388 solver.cpp:473] Iteration 1913, lr = 0.01
I0621 07:46:12.171041   388 solver.cpp:213] Iteration 1914, loss = 0.000215144
I0621 07:46:12.171134   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215067 (* 1 = 0.000215067 loss)
I0621 07:46:12.171156   388 solver.cpp:473] Iteration 1914, lr = 0.01
I0621 07:46:24.462522   388 solver.cpp:213] Iteration 1915, loss = 0.000215057
I0621 07:46:24.462606   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215216 (* 1 = 0.000215216 loss)
I0621 07:46:24.462630   388 solver.cpp:473] Iteration 1915, lr = 0.01
I0621 07:46:36.723448   388 solver.cpp:213] Iteration 1916, loss = 0.00021497
I0621 07:46:36.723692   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215009 (* 1 = 0.000215009 loss)
I0621 07:46:36.723719   388 solver.cpp:473] Iteration 1916, lr = 0.01
I0621 07:46:49.058486   388 solver.cpp:213] Iteration 1917, loss = 0.000214882
I0621 07:46:49.058568   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000215025 (* 1 = 0.000215025 loss)
I0621 07:46:49.058590   388 solver.cpp:473] Iteration 1917, lr = 0.01
I0621 07:47:01.304040   388 solver.cpp:213] Iteration 1918, loss = 0.000214789
I0621 07:47:01.304124   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021486 (* 1 = 0.00021486 loss)
I0621 07:47:01.304147   388 solver.cpp:473] Iteration 1918, lr = 0.01
I0621 07:47:13.613643   388 solver.cpp:213] Iteration 1919, loss = 0.000214569
I0621 07:47:13.613917   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000214114 (* 1 = 0.000214114 loss)
I0621 07:47:13.613955   388 solver.cpp:473] Iteration 1919, lr = 0.01
I0621 07:47:25.936740   388 solver.cpp:213] Iteration 1920, loss = 0.000214537
I0621 07:47:25.936830   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021483 (* 1 = 0.00021483 loss)
I0621 07:47:25.936853   388 solver.cpp:473] Iteration 1920, lr = 0.01
I0621 07:47:38.441529   388 solver.cpp:213] Iteration 1921, loss = 0.000214528
I0621 07:47:38.441612   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000214858 (* 1 = 0.000214858 loss)
I0621 07:47:38.441634   388 solver.cpp:473] Iteration 1921, lr = 0.01
I0621 07:47:50.857023   388 solver.cpp:213] Iteration 1922, loss = 0.000214378
I0621 07:47:50.857213   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000214359 (* 1 = 0.000214359 loss)
I0621 07:47:50.857237   388 solver.cpp:473] Iteration 1922, lr = 0.01
I0621 07:48:03.102565   388 solver.cpp:213] Iteration 1923, loss = 0.000214302
I0621 07:48:03.102648   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000214414 (* 1 = 0.000214414 loss)
I0621 07:48:03.102669   388 solver.cpp:473] Iteration 1923, lr = 0.01
I0621 07:48:15.436880   388 solver.cpp:213] Iteration 1924, loss = 0.000214203
I0621 07:48:15.436964   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000214123 (* 1 = 0.000214123 loss)
I0621 07:48:15.436986   388 solver.cpp:473] Iteration 1924, lr = 0.01
I0621 07:48:27.768095   388 solver.cpp:213] Iteration 1925, loss = 0.000214114
I0621 07:48:27.768328   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000214383 (* 1 = 0.000214383 loss)
I0621 07:48:27.768389   388 solver.cpp:473] Iteration 1925, lr = 0.01
I0621 07:48:40.025995   388 solver.cpp:213] Iteration 1926, loss = 0.000214087
I0621 07:48:40.026082   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000214195 (* 1 = 0.000214195 loss)
I0621 07:48:40.026106   388 solver.cpp:473] Iteration 1926, lr = 0.01
I0621 07:48:52.485539   388 solver.cpp:213] Iteration 1927, loss = 0.00021397
I0621 07:48:52.485626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213909 (* 1 = 0.000213909 loss)
I0621 07:48:52.485648   388 solver.cpp:473] Iteration 1927, lr = 0.01
I0621 07:49:04.893061   388 solver.cpp:213] Iteration 1928, loss = 0.000213928
I0621 07:49:04.893319   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213525 (* 1 = 0.000213525 loss)
I0621 07:49:04.893362   388 solver.cpp:473] Iteration 1928, lr = 0.01
I0621 07:49:17.176241   388 solver.cpp:213] Iteration 1929, loss = 0.000213685
I0621 07:49:17.176321   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213439 (* 1 = 0.000213439 loss)
I0621 07:49:17.176343   388 solver.cpp:473] Iteration 1929, lr = 0.01
I0621 07:49:29.591523   388 solver.cpp:213] Iteration 1930, loss = 0.000213576
I0621 07:49:29.591617   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213072 (* 1 = 0.000213072 loss)
I0621 07:49:29.591641   388 solver.cpp:473] Iteration 1930, lr = 0.01
I0621 07:49:41.910008   388 solver.cpp:213] Iteration 1931, loss = 0.000213529
I0621 07:49:41.910234   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213528 (* 1 = 0.000213528 loss)
I0621 07:49:41.910272   388 solver.cpp:473] Iteration 1931, lr = 0.01
I0621 07:49:54.181686   388 solver.cpp:213] Iteration 1932, loss = 0.000213529
I0621 07:49:54.181768   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213577 (* 1 = 0.000213577 loss)
I0621 07:49:54.181792   388 solver.cpp:473] Iteration 1932, lr = 0.01
I0621 07:50:06.498201   388 solver.cpp:213] Iteration 1933, loss = 0.000213423
I0621 07:50:06.498286   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213124 (* 1 = 0.000213124 loss)
I0621 07:50:06.498308   388 solver.cpp:473] Iteration 1933, lr = 0.01
I0621 07:50:18.799924   388 solver.cpp:213] Iteration 1934, loss = 0.000213319
I0621 07:50:18.800112   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213313 (* 1 = 0.000213313 loss)
I0621 07:50:18.800137   388 solver.cpp:473] Iteration 1934, lr = 0.01
I0621 07:50:31.057047   388 solver.cpp:213] Iteration 1935, loss = 0.000213174
I0621 07:50:31.057134   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000213133 (* 1 = 0.000213133 loss)
I0621 07:50:31.057157   388 solver.cpp:473] Iteration 1935, lr = 0.01
I0621 07:50:43.277771   388 solver.cpp:213] Iteration 1936, loss = 0.000213022
I0621 07:50:43.277854   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212749 (* 1 = 0.000212749 loss)
I0621 07:50:43.277879   388 solver.cpp:473] Iteration 1936, lr = 0.01
I0621 07:50:55.582427   388 solver.cpp:213] Iteration 1937, loss = 0.000213054
I0621 07:50:55.582648   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212874 (* 1 = 0.000212874 loss)
I0621 07:50:55.582679   388 solver.cpp:473] Iteration 1937, lr = 0.01
I0621 07:51:07.899150   388 solver.cpp:213] Iteration 1938, loss = 0.000212939
I0621 07:51:07.899236   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212898 (* 1 = 0.000212898 loss)
I0621 07:51:07.899260   388 solver.cpp:473] Iteration 1938, lr = 0.01
I0621 07:51:20.137567   388 solver.cpp:213] Iteration 1939, loss = 0.000212769
I0621 07:51:20.137652   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212634 (* 1 = 0.000212634 loss)
I0621 07:51:20.137676   388 solver.cpp:473] Iteration 1939, lr = 0.01
I0621 07:51:32.370226   388 solver.cpp:213] Iteration 1940, loss = 0.000212746
I0621 07:51:32.370415   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212516 (* 1 = 0.000212516 loss)
I0621 07:51:32.370441   388 solver.cpp:473] Iteration 1940, lr = 0.01
I0621 07:51:44.617296   388 solver.cpp:213] Iteration 1941, loss = 0.000212566
I0621 07:51:44.617377   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212423 (* 1 = 0.000212423 loss)
I0621 07:51:44.617399   388 solver.cpp:473] Iteration 1941, lr = 0.01
I0621 07:51:56.835006   388 solver.cpp:213] Iteration 1942, loss = 0.000212482
I0621 07:51:56.835093   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212105 (* 1 = 0.000212105 loss)
I0621 07:51:56.835114   388 solver.cpp:473] Iteration 1942, lr = 0.01
I0621 07:52:09.042052   388 solver.cpp:213] Iteration 1943, loss = 0.000212383
I0621 07:52:09.042215   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021209 (* 1 = 0.00021209 loss)
I0621 07:52:09.042239   388 solver.cpp:473] Iteration 1943, lr = 0.01
I0621 07:52:21.252537   388 solver.cpp:213] Iteration 1944, loss = 0.00021243
I0621 07:52:21.252624   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021209 (* 1 = 0.00021209 loss)
I0621 07:52:21.252645   388 solver.cpp:473] Iteration 1944, lr = 0.01
I0621 07:52:33.462559   388 solver.cpp:213] Iteration 1945, loss = 0.000212276
I0621 07:52:33.462643   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212515 (* 1 = 0.000212515 loss)
I0621 07:52:33.462666   388 solver.cpp:473] Iteration 1945, lr = 0.01
I0621 07:52:45.684917   388 solver.cpp:213] Iteration 1946, loss = 0.000212128
I0621 07:52:45.685112   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212136 (* 1 = 0.000212136 loss)
I0621 07:52:45.685139   388 solver.cpp:473] Iteration 1946, lr = 0.01
I0621 07:52:57.989042   388 solver.cpp:213] Iteration 1947, loss = 0.000212125
I0621 07:52:57.989135   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000212038 (* 1 = 0.000212038 loss)
I0621 07:52:57.989159   388 solver.cpp:473] Iteration 1947, lr = 0.01
I0621 07:53:10.290822   388 solver.cpp:213] Iteration 1948, loss = 0.000212003
I0621 07:53:10.290912   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211927 (* 1 = 0.000211927 loss)
I0621 07:53:10.290936   388 solver.cpp:473] Iteration 1948, lr = 0.01
I0621 07:53:22.739652   388 solver.cpp:213] Iteration 1949, loss = 0.000211894
I0621 07:53:22.740094   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211729 (* 1 = 0.000211729 loss)
I0621 07:53:22.740120   388 solver.cpp:473] Iteration 1949, lr = 0.01
I0621 07:53:35.089332   388 solver.cpp:213] Iteration 1950, loss = 0.000211738
I0621 07:53:35.089418   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211763 (* 1 = 0.000211763 loss)
I0621 07:53:35.089440   388 solver.cpp:473] Iteration 1950, lr = 0.01
I0621 07:53:47.384924   388 solver.cpp:213] Iteration 1951, loss = 0.000211687
I0621 07:53:47.385004   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211634 (* 1 = 0.000211634 loss)
I0621 07:53:47.385027   388 solver.cpp:473] Iteration 1951, lr = 0.01
I0621 07:53:59.767757   388 solver.cpp:213] Iteration 1952, loss = 0.000211621
I0621 07:53:59.767946   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211635 (* 1 = 0.000211635 loss)
I0621 07:53:59.767971   388 solver.cpp:473] Iteration 1952, lr = 0.01
I0621 07:54:12.136714   388 solver.cpp:213] Iteration 1953, loss = 0.00021156
I0621 07:54:12.136828   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021149 (* 1 = 0.00021149 loss)
I0621 07:54:12.136863   388 solver.cpp:473] Iteration 1953, lr = 0.01
I0621 07:54:24.518964   388 solver.cpp:213] Iteration 1954, loss = 0.000211402
I0621 07:54:24.519043   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211314 (* 1 = 0.000211314 loss)
I0621 07:54:24.519073   388 solver.cpp:473] Iteration 1954, lr = 0.01
I0621 07:54:36.870476   388 solver.cpp:213] Iteration 1955, loss = 0.000211412
I0621 07:54:36.870658   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211523 (* 1 = 0.000211523 loss)
I0621 07:54:36.870684   388 solver.cpp:473] Iteration 1955, lr = 0.01
I0621 07:54:49.184819   388 solver.cpp:213] Iteration 1956, loss = 0.000211275
I0621 07:54:49.184902   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210953 (* 1 = 0.000210953 loss)
I0621 07:54:49.184923   388 solver.cpp:473] Iteration 1956, lr = 0.01
I0621 07:55:01.454555   388 solver.cpp:213] Iteration 1957, loss = 0.000211212
I0621 07:55:01.454635   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211189 (* 1 = 0.000211189 loss)
I0621 07:55:01.454658   388 solver.cpp:473] Iteration 1957, lr = 0.01
I0621 07:55:13.813541   388 solver.cpp:213] Iteration 1958, loss = 0.000211007
I0621 07:55:13.813726   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211158 (* 1 = 0.000211158 loss)
I0621 07:55:13.813751   388 solver.cpp:473] Iteration 1958, lr = 0.01
I0621 07:55:26.137308   388 solver.cpp:213] Iteration 1959, loss = 0.000210976
I0621 07:55:26.137394   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000211015 (* 1 = 0.000211015 loss)
I0621 07:55:26.137418   388 solver.cpp:473] Iteration 1959, lr = 0.01
I0621 07:55:38.466596   388 solver.cpp:213] Iteration 1960, loss = 0.000210906
I0621 07:55:38.466678   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210949 (* 1 = 0.000210949 loss)
I0621 07:55:38.466701   388 solver.cpp:473] Iteration 1960, lr = 0.01
I0621 07:55:50.696310   388 solver.cpp:213] Iteration 1961, loss = 0.000210805
I0621 07:55:50.700881   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210982 (* 1 = 0.000210982 loss)
I0621 07:55:50.701009   388 solver.cpp:473] Iteration 1961, lr = 0.01
I0621 07:56:02.969472   388 solver.cpp:213] Iteration 1962, loss = 0.000210653
I0621 07:56:02.969555   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210858 (* 1 = 0.000210858 loss)
I0621 07:56:02.969578   388 solver.cpp:473] Iteration 1962, lr = 0.01
I0621 07:56:15.461349   388 solver.cpp:213] Iteration 1963, loss = 0.000210679
I0621 07:56:15.461449   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021087 (* 1 = 0.00021087 loss)
I0621 07:56:15.461480   388 solver.cpp:473] Iteration 1963, lr = 0.01
I0621 07:56:27.767948   388 solver.cpp:213] Iteration 1964, loss = 0.000210523
I0621 07:56:27.768192   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210044 (* 1 = 0.000210044 loss)
I0621 07:56:27.768242   388 solver.cpp:473] Iteration 1964, lr = 0.01
I0621 07:56:40.089088   388 solver.cpp:213] Iteration 1965, loss = 0.000210432
I0621 07:56:40.089170   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210046 (* 1 = 0.000210046 loss)
I0621 07:56:40.089193   388 solver.cpp:473] Iteration 1965, lr = 0.01
I0621 07:56:52.398725   388 solver.cpp:213] Iteration 1966, loss = 0.000210456
I0621 07:56:52.398807   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210375 (* 1 = 0.000210375 loss)
I0621 07:56:52.398849   388 solver.cpp:473] Iteration 1966, lr = 0.01
I0621 07:57:04.743165   388 solver.cpp:213] Iteration 1967, loss = 0.000210316
I0621 07:57:04.745378   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210484 (* 1 = 0.000210484 loss)
I0621 07:57:04.745426   388 solver.cpp:473] Iteration 1967, lr = 0.01
I0621 07:57:17.008147   388 solver.cpp:213] Iteration 1968, loss = 0.000210204
I0621 07:57:17.008234   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210422 (* 1 = 0.000210422 loss)
I0621 07:57:17.008256   388 solver.cpp:473] Iteration 1968, lr = 0.01
I0621 07:57:29.282568   388 solver.cpp:213] Iteration 1969, loss = 0.000210156
I0621 07:57:29.282649   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000210411 (* 1 = 0.000210411 loss)
I0621 07:57:29.282671   388 solver.cpp:473] Iteration 1969, lr = 0.01
I0621 07:57:41.519186   388 solver.cpp:213] Iteration 1970, loss = 0.000209999
I0621 07:57:41.519412   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00021004 (* 1 = 0.00021004 loss)
I0621 07:57:41.519451   388 solver.cpp:473] Iteration 1970, lr = 0.01
I0621 07:57:53.896714   388 solver.cpp:213] Iteration 1971, loss = 0.000209973
I0621 07:57:53.896800   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209809 (* 1 = 0.000209809 loss)
I0621 07:57:53.896822   388 solver.cpp:473] Iteration 1971, lr = 0.01
I0621 07:58:06.176959   388 solver.cpp:213] Iteration 1972, loss = 0.000209725
I0621 07:58:06.177039   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209657 (* 1 = 0.000209657 loss)
I0621 07:58:06.177062   388 solver.cpp:473] Iteration 1972, lr = 0.01
I0621 07:58:18.392333   388 solver.cpp:213] Iteration 1973, loss = 0.000209745
I0621 07:58:18.392520   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209846 (* 1 = 0.000209846 loss)
I0621 07:58:18.392545   388 solver.cpp:473] Iteration 1973, lr = 0.01
I0621 07:58:30.705474   388 solver.cpp:213] Iteration 1974, loss = 0.000209713
I0621 07:58:30.705559   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209316 (* 1 = 0.000209316 loss)
I0621 07:58:30.705581   388 solver.cpp:473] Iteration 1974, lr = 0.01
I0621 07:58:42.955770   388 solver.cpp:213] Iteration 1975, loss = 0.000209615
I0621 07:58:42.955857   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020975 (* 1 = 0.00020975 loss)
I0621 07:58:42.955878   388 solver.cpp:473] Iteration 1975, lr = 0.01
I0621 07:58:55.429378   388 solver.cpp:213] Iteration 1976, loss = 0.000209464
I0621 07:58:55.429641   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209207 (* 1 = 0.000209207 loss)
I0621 07:58:55.429698   388 solver.cpp:473] Iteration 1976, lr = 0.01
I0621 07:59:07.801015   388 solver.cpp:213] Iteration 1977, loss = 0.000209444
I0621 07:59:07.801100   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209436 (* 1 = 0.000209436 loss)
I0621 07:59:07.801120   388 solver.cpp:473] Iteration 1977, lr = 0.01
I0621 07:59:20.041319   388 solver.cpp:213] Iteration 1978, loss = 0.000209348
I0621 07:59:20.041406   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209317 (* 1 = 0.000209317 loss)
I0621 07:59:20.041429   388 solver.cpp:473] Iteration 1978, lr = 0.01
I0621 07:59:32.331940   388 solver.cpp:213] Iteration 1979, loss = 0.00020926
I0621 07:59:32.332190   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208857 (* 1 = 0.000208857 loss)
I0621 07:59:32.332305   388 solver.cpp:473] Iteration 1979, lr = 0.01
I0621 07:59:44.615627   388 solver.cpp:213] Iteration 1980, loss = 0.000209097
I0621 07:59:44.615710   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002088 (* 1 = 0.0002088 loss)
I0621 07:59:44.615731   388 solver.cpp:473] Iteration 1980, lr = 0.01
I0621 07:59:56.869544   388 solver.cpp:213] Iteration 1981, loss = 0.00020903
I0621 07:59:56.869626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020936 (* 1 = 0.00020936 loss)
I0621 07:59:56.869648   388 solver.cpp:473] Iteration 1981, lr = 0.01
I0621 08:00:09.086076   388 solver.cpp:213] Iteration 1982, loss = 0.000208973
I0621 08:00:09.086252   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000209143 (* 1 = 0.000209143 loss)
I0621 08:00:09.086278   388 solver.cpp:473] Iteration 1982, lr = 0.01
I0621 08:00:21.303441   388 solver.cpp:213] Iteration 1983, loss = 0.000208923
I0621 08:00:21.303555   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208829 (* 1 = 0.000208829 loss)
I0621 08:00:21.303591   388 solver.cpp:473] Iteration 1983, lr = 0.01
I0621 08:00:33.595523   388 solver.cpp:213] Iteration 1984, loss = 0.00020876
I0621 08:00:33.595605   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020851 (* 1 = 0.00020851 loss)
I0621 08:00:33.595628   388 solver.cpp:473] Iteration 1984, lr = 0.01
I0621 08:00:45.837640   388 solver.cpp:213] Iteration 1985, loss = 0.000208659
I0621 08:00:45.837846   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208991 (* 1 = 0.000208991 loss)
I0621 08:00:45.837889   388 solver.cpp:473] Iteration 1985, lr = 0.01
I0621 08:00:58.144243   388 solver.cpp:213] Iteration 1986, loss = 0.000208567
I0621 08:00:58.144325   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208674 (* 1 = 0.000208674 loss)
I0621 08:00:58.144347   388 solver.cpp:473] Iteration 1986, lr = 0.01
I0621 08:01:10.403195   388 solver.cpp:213] Iteration 1987, loss = 0.000208482
I0621 08:01:10.403275   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208952 (* 1 = 0.000208952 loss)
I0621 08:01:10.403297   388 solver.cpp:473] Iteration 1987, lr = 0.01
I0621 08:01:22.718631   388 solver.cpp:213] Iteration 1988, loss = 0.000208363
I0621 08:01:22.718858   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020837 (* 1 = 0.00020837 loss)
I0621 08:01:22.718895   388 solver.cpp:473] Iteration 1988, lr = 0.01
I0621 08:01:35.027988   388 solver.cpp:213] Iteration 1989, loss = 0.000208412
I0621 08:01:35.028074   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208376 (* 1 = 0.000208376 loss)
I0621 08:01:35.028096   388 solver.cpp:473] Iteration 1989, lr = 0.01
I0621 08:01:47.331646   388 solver.cpp:213] Iteration 1990, loss = 0.000208205
I0621 08:01:47.331729   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208078 (* 1 = 0.000208078 loss)
I0621 08:01:47.331753   388 solver.cpp:473] Iteration 1990, lr = 0.01
I0621 08:01:59.762704   388 solver.cpp:213] Iteration 1991, loss = 0.000208184
I0621 08:01:59.762982   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208107 (* 1 = 0.000208107 loss)
I0621 08:01:59.763036   388 solver.cpp:473] Iteration 1991, lr = 0.01
I0621 08:02:12.227315   388 solver.cpp:213] Iteration 1992, loss = 0.000208006
I0621 08:02:12.227398   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207984 (* 1 = 0.000207984 loss)
I0621 08:02:12.227419   388 solver.cpp:473] Iteration 1992, lr = 0.01
I0621 08:02:24.585564   388 solver.cpp:213] Iteration 1993, loss = 0.000207946
I0621 08:02:24.585644   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000208195 (* 1 = 0.000208195 loss)
I0621 08:02:24.585665   388 solver.cpp:473] Iteration 1993, lr = 0.01
I0621 08:02:36.863936   388 solver.cpp:213] Iteration 1994, loss = 0.000207892
I0621 08:02:36.864120   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207915 (* 1 = 0.000207915 loss)
I0621 08:02:36.864145   388 solver.cpp:473] Iteration 1994, lr = 0.01
I0621 08:02:49.227154   388 solver.cpp:213] Iteration 1995, loss = 0.000207684
I0621 08:02:49.227236   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207451 (* 1 = 0.000207451 loss)
I0621 08:02:49.227258   388 solver.cpp:473] Iteration 1995, lr = 0.01
I0621 08:03:01.475210   388 solver.cpp:213] Iteration 1996, loss = 0.000207647
I0621 08:03:01.475291   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207919 (* 1 = 0.000207919 loss)
I0621 08:03:01.475313   388 solver.cpp:473] Iteration 1996, lr = 0.01
I0621 08:03:13.763156   388 solver.cpp:213] Iteration 1997, loss = 0.000207658
I0621 08:03:13.763397   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207303 (* 1 = 0.000207303 loss)
I0621 08:03:13.763443   388 solver.cpp:473] Iteration 1997, lr = 0.01
I0621 08:03:26.107437   388 solver.cpp:213] Iteration 1998, loss = 0.000207509
I0621 08:03:26.107522   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207297 (* 1 = 0.000207297 loss)
I0621 08:03:26.107547   388 solver.cpp:473] Iteration 1998, lr = 0.01
I0621 08:03:38.430075   388 solver.cpp:213] Iteration 1999, loss = 0.000207462
I0621 08:03:38.430161   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207563 (* 1 = 0.000207563 loss)
I0621 08:03:38.430184   388 solver.cpp:473] Iteration 1999, lr = 0.01
I0621 08:03:41.181541   388 solver.cpp:362] Snapshotting to ./snapshot/latefusion-_iter_2000.caffemodel
I0621 08:04:02.310130   388 solver.cpp:370] Snapshotting solver state to ./snapshot/latefusion-_iter_2000.solverstate
I0621 08:04:05.870118   388 solver.cpp:291] Iteration 2000, Testing net (#0)
I0621 08:07:52.203627   388 solver.cpp:342]     Test net output #0: seg-accuracy = 1
I0621 08:07:52.203822   388 solver.cpp:342]     Test net output #1: seg-loss = 0.000207344 (* 1 = 0.000207344 loss)
I0621 08:08:03.982787   388 solver.cpp:213] Iteration 2000, loss = 0.000207355
I0621 08:08:03.982867   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207329 (* 1 = 0.000207329 loss)
I0621 08:08:03.982892   388 solver.cpp:473] Iteration 2000, lr = 0.01
I0621 08:08:16.356889   388 solver.cpp:213] Iteration 2001, loss = 0.000207261
I0621 08:08:16.356972   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207283 (* 1 = 0.000207283 loss)
I0621 08:08:16.356994   388 solver.cpp:473] Iteration 2001, lr = 0.01
I0621 08:08:28.615077   388 solver.cpp:213] Iteration 2002, loss = 0.000207272
I0621 08:08:28.615283   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207493 (* 1 = 0.000207493 loss)
I0621 08:08:28.615310   388 solver.cpp:473] Iteration 2002, lr = 0.01
I0621 08:08:40.932451   388 solver.cpp:213] Iteration 2003, loss = 0.000207127
I0621 08:08:40.932538   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207412 (* 1 = 0.000207412 loss)
I0621 08:08:40.932560   388 solver.cpp:473] Iteration 2003, lr = 0.01
I0621 08:08:53.229851   388 solver.cpp:213] Iteration 2004, loss = 0.000207045
I0621 08:08:53.229946   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206786 (* 1 = 0.000206786 loss)
I0621 08:08:53.229970   388 solver.cpp:473] Iteration 2004, lr = 0.01
I0621 08:09:05.520593   388 solver.cpp:213] Iteration 2005, loss = 0.000206891
I0621 08:09:05.520795   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000207285 (* 1 = 0.000207285 loss)
I0621 08:09:05.520823   388 solver.cpp:473] Iteration 2005, lr = 0.01
I0621 08:09:17.957670   388 solver.cpp:213] Iteration 2006, loss = 0.000206834
I0621 08:09:17.957758   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206869 (* 1 = 0.000206869 loss)
I0621 08:09:17.957780   388 solver.cpp:473] Iteration 2006, lr = 0.01
I0621 08:09:30.459379   388 solver.cpp:213] Iteration 2007, loss = 0.000206797
I0621 08:09:30.459458   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206771 (* 1 = 0.000206771 loss)
I0621 08:09:30.459481   388 solver.cpp:473] Iteration 2007, lr = 0.01
I0621 08:09:42.688626   388 solver.cpp:213] Iteration 2008, loss = 0.000206607
I0621 08:09:42.688835   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206811 (* 1 = 0.000206811 loss)
I0621 08:09:42.688863   388 solver.cpp:473] Iteration 2008, lr = 0.01
I0621 08:09:54.944283   388 solver.cpp:213] Iteration 2009, loss = 0.000206627
I0621 08:09:54.944365   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206689 (* 1 = 0.000206689 loss)
I0621 08:09:54.944387   388 solver.cpp:473] Iteration 2009, lr = 0.01
I0621 08:10:07.212647   388 solver.cpp:213] Iteration 2010, loss = 0.00020655
I0621 08:10:07.212730   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206363 (* 1 = 0.000206363 loss)
I0621 08:10:07.212754   388 solver.cpp:473] Iteration 2010, lr = 0.01
I0621 08:10:19.510782   388 solver.cpp:213] Iteration 2011, loss = 0.000206487
I0621 08:10:19.511030   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206432 (* 1 = 0.000206432 loss)
I0621 08:10:19.511112   388 solver.cpp:473] Iteration 2011, lr = 0.01
I0621 08:10:31.747025   388 solver.cpp:213] Iteration 2012, loss = 0.000206344
I0621 08:10:31.747113   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206247 (* 1 = 0.000206247 loss)
I0621 08:10:31.747135   388 solver.cpp:473] Iteration 2012, lr = 0.01
I0621 08:10:44.052114   388 solver.cpp:213] Iteration 2013, loss = 0.000206172
I0621 08:10:44.052196   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000206067 (* 1 = 0.000206067 loss)
I0621 08:10:44.052219   388 solver.cpp:473] Iteration 2013, lr = 0.01
I0621 08:10:56.275485   388 solver.cpp:213] Iteration 2014, loss = 0.000206135
I0621 08:10:56.275670   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020595 (* 1 = 0.00020595 loss)
I0621 08:10:56.275694   388 solver.cpp:473] Iteration 2014, lr = 0.01
I0621 08:11:08.499816   388 solver.cpp:213] Iteration 2015, loss = 0.000205958
I0621 08:11:08.499900   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0002058 (* 1 = 0.0002058 loss)
I0621 08:11:08.499924   388 solver.cpp:473] Iteration 2015, lr = 0.01
I0621 08:11:20.728268   388 solver.cpp:213] Iteration 2016, loss = 0.000205959
I0621 08:11:20.728355   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205844 (* 1 = 0.000205844 loss)
I0621 08:11:20.728379   388 solver.cpp:473] Iteration 2016, lr = 0.01
I0621 08:11:32.959098   388 solver.cpp:213] Iteration 2017, loss = 0.000205919
I0621 08:11:32.959270   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205789 (* 1 = 0.000205789 loss)
I0621 08:11:32.959295   388 solver.cpp:473] Iteration 2017, lr = 0.01
I0621 08:11:45.166167   388 solver.cpp:213] Iteration 2018, loss = 0.000205714
I0621 08:11:45.166252   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020578 (* 1 = 0.00020578 loss)
I0621 08:11:45.166275   388 solver.cpp:473] Iteration 2018, lr = 0.01
I0621 08:11:57.545460   388 solver.cpp:213] Iteration 2019, loss = 0.000205689
I0621 08:11:57.545541   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205689 (* 1 = 0.000205689 loss)
I0621 08:11:57.545563   388 solver.cpp:473] Iteration 2019, lr = 0.01
I0621 08:12:09.873699   388 solver.cpp:213] Iteration 2020, loss = 0.000205632
I0621 08:12:09.873894   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205586 (* 1 = 0.000205586 loss)
I0621 08:12:09.873929   388 solver.cpp:473] Iteration 2020, lr = 0.01
I0621 08:12:22.124923   388 solver.cpp:213] Iteration 2021, loss = 0.000205553
I0621 08:12:22.125005   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205537 (* 1 = 0.000205537 loss)
I0621 08:12:22.125028   388 solver.cpp:473] Iteration 2021, lr = 0.01
I0621 08:12:34.402725   388 solver.cpp:213] Iteration 2022, loss = 0.000205397
I0621 08:12:34.402822   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205521 (* 1 = 0.000205521 loss)
I0621 08:12:34.402849   388 solver.cpp:473] Iteration 2022, lr = 0.01
I0621 08:12:46.731233   388 solver.cpp:213] Iteration 2023, loss = 0.000205437
I0621 08:12:46.732722   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020542 (* 1 = 0.00020542 loss)
I0621 08:12:46.732748   388 solver.cpp:473] Iteration 2023, lr = 0.01
I0621 08:12:59.026283   388 solver.cpp:213] Iteration 2024, loss = 0.000205282
I0621 08:12:59.026371   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205197 (* 1 = 0.000205197 loss)
I0621 08:12:59.026392   388 solver.cpp:473] Iteration 2024, lr = 0.01
I0621 08:13:11.259084   388 solver.cpp:213] Iteration 2025, loss = 0.000205203
I0621 08:13:11.259166   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204789 (* 1 = 0.000204789 loss)
I0621 08:13:11.259192   388 solver.cpp:473] Iteration 2025, lr = 0.01
I0621 08:13:23.555694   388 solver.cpp:213] Iteration 2026, loss = 0.000205089
I0621 08:13:23.555960   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205388 (* 1 = 0.000205388 loss)
I0621 08:13:23.555987   388 solver.cpp:473] Iteration 2026, lr = 0.01
I0621 08:13:35.819828   388 solver.cpp:213] Iteration 2027, loss = 0.000205071
I0621 08:13:35.819914   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204797 (* 1 = 0.000204797 loss)
I0621 08:13:35.819937   388 solver.cpp:473] Iteration 2027, lr = 0.01
I0621 08:13:48.064769   388 solver.cpp:213] Iteration 2028, loss = 0.000204923
I0621 08:13:48.064846   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204931 (* 1 = 0.000204931 loss)
I0621 08:13:48.064870   388 solver.cpp:473] Iteration 2028, lr = 0.01
I0621 08:14:00.367274   388 solver.cpp:213] Iteration 2029, loss = 0.00020498
I0621 08:14:00.367514   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204972 (* 1 = 0.000204972 loss)
I0621 08:14:00.367591   388 solver.cpp:473] Iteration 2029, lr = 0.01
I0621 08:14:12.742372   388 solver.cpp:213] Iteration 2030, loss = 0.000204813
I0621 08:14:12.742454   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000205039 (* 1 = 0.000205039 loss)
I0621 08:14:12.742475   388 solver.cpp:473] Iteration 2030, lr = 0.01
I0621 08:14:25.130993   388 solver.cpp:213] Iteration 2031, loss = 0.00020469
I0621 08:14:25.131089   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204416 (* 1 = 0.000204416 loss)
I0621 08:14:25.131114   388 solver.cpp:473] Iteration 2031, lr = 0.01
I0621 08:14:37.452759   388 solver.cpp:213] Iteration 2032, loss = 0.000204629
I0621 08:14:37.453007   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020483 (* 1 = 0.00020483 loss)
I0621 08:14:37.453052   388 solver.cpp:473] Iteration 2032, lr = 0.01
I0621 08:14:49.855358   388 solver.cpp:213] Iteration 2033, loss = 0.000204589
I0621 08:14:49.855443   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204467 (* 1 = 0.000204467 loss)
I0621 08:14:49.855464   388 solver.cpp:473] Iteration 2033, lr = 0.01
I0621 08:15:02.150962   388 solver.cpp:213] Iteration 2034, loss = 0.000204469
I0621 08:15:02.151049   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204757 (* 1 = 0.000204757 loss)
I0621 08:15:02.151077   388 solver.cpp:473] Iteration 2034, lr = 0.01
I0621 08:15:14.444572   388 solver.cpp:213] Iteration 2035, loss = 0.00020441
I0621 08:15:14.444793   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204407 (* 1 = 0.000204407 loss)
I0621 08:15:14.444819   388 solver.cpp:473] Iteration 2035, lr = 0.01
I0621 08:15:26.734197   388 solver.cpp:213] Iteration 2036, loss = 0.000204229
I0621 08:15:26.734282   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204935 (* 1 = 0.000204935 loss)
I0621 08:15:26.734304   388 solver.cpp:473] Iteration 2036, lr = 0.01
I0621 08:15:39.152576   388 solver.cpp:213] Iteration 2037, loss = 0.000204108
I0621 08:15:39.152662   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204059 (* 1 = 0.000204059 loss)
I0621 08:15:39.152685   388 solver.cpp:473] Iteration 2037, lr = 0.01
I0621 08:15:51.468274   388 solver.cpp:213] Iteration 2038, loss = 0.00020415
I0621 08:15:51.468466   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204058 (* 1 = 0.000204058 loss)
I0621 08:15:51.468492   388 solver.cpp:473] Iteration 2038, lr = 0.01
I0621 08:16:03.911301   388 solver.cpp:213] Iteration 2039, loss = 0.000204043
I0621 08:16:03.911384   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204206 (* 1 = 0.000204206 loss)
I0621 08:16:03.911409   388 solver.cpp:473] Iteration 2039, lr = 0.01
I0621 08:16:16.240005   388 solver.cpp:213] Iteration 2040, loss = 0.000203949
I0621 08:16:16.240089   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204015 (* 1 = 0.000204015 loss)
I0621 08:16:16.240111   388 solver.cpp:473] Iteration 2040, lr = 0.01
I0621 08:16:28.481289   388 solver.cpp:213] Iteration 2041, loss = 0.000203884
I0621 08:16:28.481468   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204133 (* 1 = 0.000204133 loss)
I0621 08:16:28.481492   388 solver.cpp:473] Iteration 2041, lr = 0.01
I0621 08:16:40.729837   388 solver.cpp:213] Iteration 2042, loss = 0.000203663
I0621 08:16:40.729923   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000204104 (* 1 = 0.000204104 loss)
I0621 08:16:40.729944   388 solver.cpp:473] Iteration 2042, lr = 0.01
I0621 08:16:53.004642   388 solver.cpp:213] Iteration 2043, loss = 0.000203679
I0621 08:16:53.004726   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203712 (* 1 = 0.000203712 loss)
I0621 08:16:53.004748   388 solver.cpp:473] Iteration 2043, lr = 0.01
I0621 08:17:05.289894   388 solver.cpp:213] Iteration 2044, loss = 0.000203661
I0621 08:17:05.290081   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203854 (* 1 = 0.000203854 loss)
I0621 08:17:05.290107   388 solver.cpp:473] Iteration 2044, lr = 0.01
I0621 08:17:17.565839   388 solver.cpp:213] Iteration 2045, loss = 0.000203536
I0621 08:17:17.565933   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203599 (* 1 = 0.000203599 loss)
I0621 08:17:17.565955   388 solver.cpp:473] Iteration 2045, lr = 0.01
I0621 08:17:30.001947   388 solver.cpp:213] Iteration 2046, loss = 0.000203456
I0621 08:17:30.002033   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203433 (* 1 = 0.000203433 loss)
I0621 08:17:30.002056   388 solver.cpp:473] Iteration 2046, lr = 0.01
I0621 08:17:42.221865   388 solver.cpp:213] Iteration 2047, loss = 0.000203339
I0621 08:17:42.222054   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203322 (* 1 = 0.000203322 loss)
I0621 08:17:42.222079   388 solver.cpp:473] Iteration 2047, lr = 0.01
I0621 08:17:54.580411   388 solver.cpp:213] Iteration 2048, loss = 0.000203307
I0621 08:17:54.580492   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203662 (* 1 = 0.000203662 loss)
I0621 08:17:54.580513   388 solver.cpp:473] Iteration 2048, lr = 0.01
I0621 08:18:06.935559   388 solver.cpp:213] Iteration 2049, loss = 0.000203284
I0621 08:18:06.935648   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202918 (* 1 = 0.000202918 loss)
I0621 08:18:06.935672   388 solver.cpp:473] Iteration 2049, lr = 0.01
I0621 08:18:19.277994   388 solver.cpp:213] Iteration 2050, loss = 0.000203018
I0621 08:18:19.278204   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203182 (* 1 = 0.000203182 loss)
I0621 08:18:19.278247   388 solver.cpp:473] Iteration 2050, lr = 0.01
I0621 08:18:31.609745   388 solver.cpp:213] Iteration 2051, loss = 0.000203057
I0621 08:18:31.609829   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203161 (* 1 = 0.000203161 loss)
I0621 08:18:31.609851   388 solver.cpp:473] Iteration 2051, lr = 0.01
I0621 08:18:43.969660   388 solver.cpp:213] Iteration 2052, loss = 0.0002028
I0621 08:18:43.969744   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202708 (* 1 = 0.000202708 loss)
I0621 08:18:43.969766   388 solver.cpp:473] Iteration 2052, lr = 0.01
I0621 08:18:56.247002   388 solver.cpp:213] Iteration 2053, loss = 0.000202855
I0621 08:18:56.247264   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000203118 (* 1 = 0.000203118 loss)
I0621 08:18:56.247309   388 solver.cpp:473] Iteration 2053, lr = 0.01
I0621 08:19:08.560853   388 solver.cpp:213] Iteration 2054, loss = 0.00020279
I0621 08:19:08.560936   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202366 (* 1 = 0.000202366 loss)
I0621 08:19:08.560958   388 solver.cpp:473] Iteration 2054, lr = 0.01
I0621 08:19:20.922986   388 solver.cpp:213] Iteration 2055, loss = 0.000202736
I0621 08:19:20.923084   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202416 (* 1 = 0.000202416 loss)
I0621 08:19:20.923110   388 solver.cpp:473] Iteration 2055, lr = 0.01
I0621 08:19:33.254003   388 solver.cpp:213] Iteration 2056, loss = 0.000202653
I0621 08:19:33.254289   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202698 (* 1 = 0.000202698 loss)
I0621 08:19:33.254323   388 solver.cpp:473] Iteration 2056, lr = 0.01
I0621 08:19:45.604617   388 solver.cpp:213] Iteration 2057, loss = 0.000202436
I0621 08:19:45.604714   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202332 (* 1 = 0.000202332 loss)
I0621 08:19:45.604738   388 solver.cpp:473] Iteration 2057, lr = 0.01
I0621 08:19:57.973130   388 solver.cpp:213] Iteration 2058, loss = 0.000202409
I0621 08:19:57.973213   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202324 (* 1 = 0.000202324 loss)
I0621 08:19:57.973237   388 solver.cpp:473] Iteration 2058, lr = 0.01
I0621 08:20:10.259287   388 solver.cpp:213] Iteration 2059, loss = 0.000202385
I0621 08:20:10.259531   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202163 (* 1 = 0.000202163 loss)
I0621 08:20:10.259567   388 solver.cpp:473] Iteration 2059, lr = 0.01
I0621 08:20:22.563021   388 solver.cpp:213] Iteration 2060, loss = 0.000202276
I0621 08:20:22.563108   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020226 (* 1 = 0.00020226 loss)
I0621 08:20:22.563133   388 solver.cpp:473] Iteration 2060, lr = 0.01
I0621 08:20:34.846834   388 solver.cpp:213] Iteration 2061, loss = 0.000202154
I0621 08:20:34.846920   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202175 (* 1 = 0.000202175 loss)
I0621 08:20:34.846942   388 solver.cpp:473] Iteration 2061, lr = 0.01
I0621 08:20:47.102511   388 solver.cpp:213] Iteration 2062, loss = 0.000202229
I0621 08:20:47.102733   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201925 (* 1 = 0.000201925 loss)
I0621 08:20:47.102763   388 solver.cpp:473] Iteration 2062, lr = 0.01
I0621 08:20:59.432425   388 solver.cpp:213] Iteration 2063, loss = 0.000202029
I0621 08:20:59.432513   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202095 (* 1 = 0.000202095 loss)
I0621 08:20:59.432538   388 solver.cpp:473] Iteration 2063, lr = 0.01
I0621 08:21:11.797225   388 solver.cpp:213] Iteration 2064, loss = 0.000202015
I0621 08:21:11.797310   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201775 (* 1 = 0.000201775 loss)
I0621 08:21:11.797333   388 solver.cpp:473] Iteration 2064, lr = 0.01
I0621 08:21:24.136023   388 solver.cpp:213] Iteration 2065, loss = 0.000201841
I0621 08:21:24.136296   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000202012 (* 1 = 0.000202012 loss)
I0621 08:21:24.136360   388 solver.cpp:473] Iteration 2065, lr = 0.01
I0621 08:21:36.555181   388 solver.cpp:213] Iteration 2066, loss = 0.000201783
I0621 08:21:36.555280   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201844 (* 1 = 0.000201844 loss)
I0621 08:21:36.555305   388 solver.cpp:473] Iteration 2066, lr = 0.01
I0621 08:21:48.906069   388 solver.cpp:213] Iteration 2067, loss = 0.000201709
I0621 08:21:48.906162   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201549 (* 1 = 0.000201549 loss)
I0621 08:21:48.906188   388 solver.cpp:473] Iteration 2067, lr = 0.01
I0621 08:22:01.405499   388 solver.cpp:213] Iteration 2068, loss = 0.000201582
I0621 08:22:01.405725   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201709 (* 1 = 0.000201709 loss)
I0621 08:22:01.405769   388 solver.cpp:473] Iteration 2068, lr = 0.01
I0621 08:22:13.669543   388 solver.cpp:213] Iteration 2069, loss = 0.000201519
I0621 08:22:13.669626   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201399 (* 1 = 0.000201399 loss)
I0621 08:22:13.669649   388 solver.cpp:473] Iteration 2069, lr = 0.01
I0621 08:22:25.906740   388 solver.cpp:213] Iteration 2070, loss = 0.000201445
I0621 08:22:25.906826   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201672 (* 1 = 0.000201672 loss)
I0621 08:22:25.906850   388 solver.cpp:473] Iteration 2070, lr = 0.01
I0621 08:22:38.142884   388 solver.cpp:213] Iteration 2071, loss = 0.000201441
I0621 08:22:38.143136   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201542 (* 1 = 0.000201542 loss)
I0621 08:22:38.143195   388 solver.cpp:473] Iteration 2071, lr = 0.01
I0621 08:22:50.459306   388 solver.cpp:213] Iteration 2072, loss = 0.000201212
I0621 08:22:50.459393   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201398 (* 1 = 0.000201398 loss)
I0621 08:22:50.459416   388 solver.cpp:473] Iteration 2072, lr = 0.01
I0621 08:23:02.736680   388 solver.cpp:213] Iteration 2073, loss = 0.000201223
I0621 08:23:02.736764   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201422 (* 1 = 0.000201422 loss)
I0621 08:23:02.736786   388 solver.cpp:473] Iteration 2073, lr = 0.01
I0621 08:23:14.993458   388 solver.cpp:213] Iteration 2074, loss = 0.000201114
I0621 08:23:14.993661   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201189 (* 1 = 0.000201189 loss)
I0621 08:23:14.993686   388 solver.cpp:473] Iteration 2074, lr = 0.01
I0621 08:23:27.340131   388 solver.cpp:213] Iteration 2075, loss = 0.000201021
I0621 08:23:27.340215   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201198 (* 1 = 0.000201198 loss)
I0621 08:23:27.340239   388 solver.cpp:473] Iteration 2075, lr = 0.01
I0621 08:23:39.659363   388 solver.cpp:213] Iteration 2076, loss = 0.00020104
I0621 08:23:39.659447   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00020118 (* 1 = 0.00020118 loss)
I0621 08:23:39.659474   388 solver.cpp:473] Iteration 2076, lr = 0.01
I0621 08:23:51.926340   388 solver.cpp:213] Iteration 2077, loss = 0.000200825
I0621 08:23:51.926661   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000201141 (* 1 = 0.000201141 loss)
I0621 08:23:51.926731   388 solver.cpp:473] Iteration 2077, lr = 0.01
I0621 08:24:04.203053   388 solver.cpp:213] Iteration 2078, loss = 0.000200871
I0621 08:24:04.203147   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200791 (* 1 = 0.000200791 loss)
I0621 08:24:04.203171   388 solver.cpp:473] Iteration 2078, lr = 0.01
I0621 08:24:16.519948   388 solver.cpp:213] Iteration 2079, loss = 0.000200602
I0621 08:24:16.520033   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200777 (* 1 = 0.000200777 loss)
I0621 08:24:16.520056   388 solver.cpp:473] Iteration 2079, lr = 0.01
I0621 08:24:28.862952   388 solver.cpp:213] Iteration 2080, loss = 0.000200575
I0621 08:24:28.863186   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200885 (* 1 = 0.000200885 loss)
I0621 08:24:28.863209   388 solver.cpp:473] Iteration 2080, lr = 0.01
I0621 08:24:41.213848   388 solver.cpp:213] Iteration 2081, loss = 0.000200524
I0621 08:24:41.213935   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200309 (* 1 = 0.000200309 loss)
I0621 08:24:41.213958   388 solver.cpp:473] Iteration 2081, lr = 0.01
I0621 08:24:53.541532   388 solver.cpp:213] Iteration 2082, loss = 0.000200513
I0621 08:24:53.541601   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200428 (* 1 = 0.000200428 loss)
I0621 08:24:53.541620   388 solver.cpp:473] Iteration 2082, lr = 0.01
I0621 08:25:05.806710   388 solver.cpp:213] Iteration 2083, loss = 0.000200344
I0621 08:25:05.806921   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200569 (* 1 = 0.000200569 loss)
I0621 08:25:05.806953   388 solver.cpp:473] Iteration 2083, lr = 0.01
I0621 08:25:18.075546   388 solver.cpp:213] Iteration 2084, loss = 0.00020042
I0621 08:25:18.075633   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200322 (* 1 = 0.000200322 loss)
I0621 08:25:18.075654   388 solver.cpp:473] Iteration 2084, lr = 0.01
I0621 08:25:30.344085   388 solver.cpp:213] Iteration 2085, loss = 0.000200207
I0621 08:25:30.344171   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199944 (* 1 = 0.000199944 loss)
I0621 08:25:30.344194   388 solver.cpp:473] Iteration 2085, lr = 0.01
I0621 08:25:42.645361   388 solver.cpp:213] Iteration 2086, loss = 0.000200174
I0621 08:25:42.645627   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019998 (* 1 = 0.00019998 loss)
I0621 08:25:42.645671   388 solver.cpp:473] Iteration 2086, lr = 0.01
I0621 08:25:55.087607   388 solver.cpp:213] Iteration 2087, loss = 0.000200145
I0621 08:25:55.087728   388 solver.cpp:228]     Train net output #0: seg-loss = 0.0001998 (* 1 = 0.0001998 loss)
I0621 08:25:55.087765   388 solver.cpp:473] Iteration 2087, lr = 0.01
I0621 08:26:07.363998   388 solver.cpp:213] Iteration 2088, loss = 0.000199979
I0621 08:26:07.364086   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199792 (* 1 = 0.000199792 loss)
I0621 08:26:07.364109   388 solver.cpp:473] Iteration 2088, lr = 0.01
I0621 08:26:19.592851   388 solver.cpp:213] Iteration 2089, loss = 0.000199967
I0621 08:26:19.593042   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000200032 (* 1 = 0.000200032 loss)
I0621 08:26:19.593067   388 solver.cpp:473] Iteration 2089, lr = 0.01
I0621 08:26:31.809172   388 solver.cpp:213] Iteration 2090, loss = 0.000199881
I0621 08:26:31.809258   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199949 (* 1 = 0.000199949 loss)
I0621 08:26:31.809280   388 solver.cpp:473] Iteration 2090, lr = 0.01
I0621 08:26:44.039654   388 solver.cpp:213] Iteration 2091, loss = 0.000199838
I0621 08:26:44.039741   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199823 (* 1 = 0.000199823 loss)
I0621 08:26:44.039762   388 solver.cpp:473] Iteration 2091, lr = 0.01
I0621 08:26:56.271828   388 solver.cpp:213] Iteration 2092, loss = 0.000199741
I0621 08:26:56.271999   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199684 (* 1 = 0.000199684 loss)
I0621 08:26:56.272024   388 solver.cpp:473] Iteration 2092, lr = 0.01
I0621 08:27:08.547722   388 solver.cpp:213] Iteration 2093, loss = 0.00019955
I0621 08:27:08.547804   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199285 (* 1 = 0.000199285 loss)
I0621 08:27:08.547827   388 solver.cpp:473] Iteration 2093, lr = 0.01
I0621 08:27:20.758121   388 solver.cpp:213] Iteration 2094, loss = 0.000199545
I0621 08:27:20.758200   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199769 (* 1 = 0.000199769 loss)
I0621 08:27:20.758224   388 solver.cpp:473] Iteration 2094, lr = 0.01
I0621 08:27:32.971680   388 solver.cpp:213] Iteration 2095, loss = 0.000199437
I0621 08:27:32.971865   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199525 (* 1 = 0.000199525 loss)
I0621 08:27:32.971889   388 solver.cpp:473] Iteration 2095, lr = 0.01
I0621 08:27:45.216809   388 solver.cpp:213] Iteration 2096, loss = 0.00019937
I0621 08:27:45.216895   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019945 (* 1 = 0.00019945 loss)
I0621 08:27:45.216917   388 solver.cpp:473] Iteration 2096, lr = 0.01
I0621 08:27:57.441921   388 solver.cpp:213] Iteration 2097, loss = 0.000199385
I0621 08:27:57.441994   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199443 (* 1 = 0.000199443 loss)
I0621 08:27:57.442014   388 solver.cpp:473] Iteration 2097, lr = 0.01
I0621 08:28:09.710660   388 solver.cpp:213] Iteration 2098, loss = 0.000199185
I0621 08:28:09.710872   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199119 (* 1 = 0.000199119 loss)
I0621 08:28:09.710902   388 solver.cpp:473] Iteration 2098, lr = 0.01
I0621 08:28:22.107595   388 solver.cpp:213] Iteration 2099, loss = 0.00019916
I0621 08:28:22.107676   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198947 (* 1 = 0.000198947 loss)
I0621 08:28:22.107699   388 solver.cpp:473] Iteration 2099, lr = 0.01
I0621 08:28:34.454396   388 solver.cpp:213] Iteration 2100, loss = 0.000199099
I0621 08:28:34.454483   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199459 (* 1 = 0.000199459 loss)
I0621 08:28:34.454506   388 solver.cpp:473] Iteration 2100, lr = 0.01
I0621 08:28:46.692770   388 solver.cpp:213] Iteration 2101, loss = 0.00019897
I0621 08:28:46.692992   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198722 (* 1 = 0.000198722 loss)
I0621 08:28:46.693029   388 solver.cpp:473] Iteration 2101, lr = 0.01
I0621 08:28:58.949383   388 solver.cpp:213] Iteration 2102, loss = 0.000198885
I0621 08:28:58.949465   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198662 (* 1 = 0.000198662 loss)
I0621 08:28:58.949488   388 solver.cpp:473] Iteration 2102, lr = 0.01
I0621 08:29:11.200155   388 solver.cpp:213] Iteration 2103, loss = 0.000198746
I0621 08:29:11.205519   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198676 (* 1 = 0.000198676 loss)
I0621 08:29:11.205576   388 solver.cpp:473] Iteration 2103, lr = 0.01
I0621 08:29:23.508939   388 solver.cpp:213] Iteration 2104, loss = 0.00019867
I0621 08:29:23.514856   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000199074 (* 1 = 0.000199074 loss)
I0621 08:29:23.514883   388 solver.cpp:473] Iteration 2104, lr = 0.01
I0621 08:29:35.897702   388 solver.cpp:213] Iteration 2105, loss = 0.000198654
I0621 08:29:35.897785   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198597 (* 1 = 0.000198597 loss)
I0621 08:29:35.897806   388 solver.cpp:473] Iteration 2105, lr = 0.01
I0621 08:29:48.168731   388 solver.cpp:213] Iteration 2106, loss = 0.000198673
I0621 08:29:48.168812   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019877 (* 1 = 0.00019877 loss)
I0621 08:29:48.168834   388 solver.cpp:473] Iteration 2106, lr = 0.01
I0621 08:30:00.436231   388 solver.cpp:213] Iteration 2107, loss = 0.000198504
I0621 08:30:00.436405   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019855 (* 1 = 0.00019855 loss)
I0621 08:30:00.436430   388 solver.cpp:473] Iteration 2107, lr = 0.01
I0621 08:30:12.809499   388 solver.cpp:213] Iteration 2108, loss = 0.000198299
I0621 08:30:12.809581   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198027 (* 1 = 0.000198027 loss)
I0621 08:30:12.809607   388 solver.cpp:473] Iteration 2108, lr = 0.01
I0621 08:30:25.062101   388 solver.cpp:213] Iteration 2109, loss = 0.000198378
I0621 08:30:25.062188   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198031 (* 1 = 0.000198031 loss)
I0621 08:30:25.062211   388 solver.cpp:473] Iteration 2109, lr = 0.01
I0621 08:30:37.314122   388 solver.cpp:213] Iteration 2110, loss = 0.000198219
I0621 08:30:37.314329   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019833 (* 1 = 0.00019833 loss)
I0621 08:30:37.314363   388 solver.cpp:473] Iteration 2110, lr = 0.01
I0621 08:30:49.766760   388 solver.cpp:213] Iteration 2111, loss = 0.00019815
I0621 08:30:49.766849   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000198277 (* 1 = 0.000198277 loss)
I0621 08:30:49.766871   388 solver.cpp:473] Iteration 2111, lr = 0.01
I0621 08:31:02.123641   388 solver.cpp:213] Iteration 2112, loss = 0.00019813
I0621 08:31:02.123728   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019783 (* 1 = 0.00019783 loss)
I0621 08:31:02.123751   388 solver.cpp:473] Iteration 2112, lr = 0.01
I0621 08:31:14.442950   388 solver.cpp:213] Iteration 2113, loss = 0.000198037
I0621 08:31:14.443145   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197875 (* 1 = 0.000197875 loss)
I0621 08:31:14.443171   388 solver.cpp:473] Iteration 2113, lr = 0.01
I0621 08:31:26.701058   388 solver.cpp:213] Iteration 2114, loss = 0.000197852
I0621 08:31:26.701148   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197797 (* 1 = 0.000197797 loss)
I0621 08:31:26.701170   388 solver.cpp:473] Iteration 2114, lr = 0.01
I0621 08:31:39.038019   388 solver.cpp:213] Iteration 2115, loss = 0.000197866
I0621 08:31:39.038105   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019768 (* 1 = 0.00019768 loss)
I0621 08:31:39.038128   388 solver.cpp:473] Iteration 2115, lr = 0.01
I0621 08:31:51.464102   388 solver.cpp:213] Iteration 2116, loss = 0.000197779
I0621 08:31:51.464337   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197916 (* 1 = 0.000197916 loss)
I0621 08:31:51.464391   388 solver.cpp:473] Iteration 2116, lr = 0.01
I0621 08:32:03.801477   388 solver.cpp:213] Iteration 2117, loss = 0.000197659
I0621 08:32:03.801558   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197824 (* 1 = 0.000197824 loss)
I0621 08:32:03.801580   388 solver.cpp:473] Iteration 2117, lr = 0.01
I0621 08:32:16.091692   388 solver.cpp:213] Iteration 2118, loss = 0.000197599
I0621 08:32:16.091773   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197112 (* 1 = 0.000197112 loss)
I0621 08:32:16.091796   388 solver.cpp:473] Iteration 2118, lr = 0.01
I0621 08:32:28.425864   388 solver.cpp:213] Iteration 2119, loss = 0.000197426
I0621 08:32:28.426136   388 solver.cpp:228]     Train net output #0: seg-loss = 0.00019738 (* 1 = 0.00019738 loss)
I0621 08:32:28.426167   388 solver.cpp:473] Iteration 2119, lr = 0.01
I0621 08:32:40.736074   388 solver.cpp:213] Iteration 2120, loss = 0.000197521
I0621 08:32:40.736152   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197258 (* 1 = 0.000197258 loss)
I0621 08:32:40.736173   388 solver.cpp:473] Iteration 2120, lr = 0.01
I0621 08:32:52.966835   388 solver.cpp:213] Iteration 2121, loss = 0.000197269
I0621 08:32:52.966922   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196965 (* 1 = 0.000196965 loss)
I0621 08:32:52.966944   388 solver.cpp:473] Iteration 2121, lr = 0.01
I0621 08:33:05.230583   388 solver.cpp:213] Iteration 2122, loss = 0.00019733
I0621 08:33:05.230815   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197675 (* 1 = 0.000197675 loss)
I0621 08:33:05.230870   388 solver.cpp:473] Iteration 2122, lr = 0.01
I0621 08:33:17.595443   388 solver.cpp:213] Iteration 2123, loss = 0.000197181
I0621 08:33:17.595528   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196954 (* 1 = 0.000196954 loss)
I0621 08:33:17.595549   388 solver.cpp:473] Iteration 2123, lr = 0.01
I0621 08:33:29.928844   388 solver.cpp:213] Iteration 2124, loss = 0.00019717
I0621 08:33:29.928935   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197443 (* 1 = 0.000197443 loss)
I0621 08:33:29.928957   388 solver.cpp:473] Iteration 2124, lr = 0.01
I0621 08:33:42.201953   388 solver.cpp:213] Iteration 2125, loss = 0.00019703
I0621 08:33:42.202183   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196843 (* 1 = 0.000196843 loss)
I0621 08:33:42.202216   388 solver.cpp:473] Iteration 2125, lr = 0.01
I0621 08:33:54.556742   388 solver.cpp:213] Iteration 2126, loss = 0.000197021
I0621 08:33:54.556828   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196862 (* 1 = 0.000196862 loss)
I0621 08:33:54.556850   388 solver.cpp:473] Iteration 2126, lr = 0.01
I0621 08:34:06.825788   388 solver.cpp:213] Iteration 2127, loss = 0.000196954
I0621 08:34:06.825875   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000197049 (* 1 = 0.000197049 loss)
I0621 08:34:06.825897   388 solver.cpp:473] Iteration 2127, lr = 0.01
I0621 08:34:19.057454   388 solver.cpp:213] Iteration 2128, loss = 0.0001969
I0621 08:34:19.057641   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196944 (* 1 = 0.000196944 loss)
I0621 08:34:19.057665   388 solver.cpp:473] Iteration 2128, lr = 0.01
I0621 08:34:31.485680   388 solver.cpp:213] Iteration 2129, loss = 0.000196758
I0621 08:34:31.485761   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196768 (* 1 = 0.000196768 loss)
I0621 08:34:31.485785   388 solver.cpp:473] Iteration 2129, lr = 0.01
I0621 08:34:43.830844   388 solver.cpp:213] Iteration 2130, loss = 0.000196575
I0621 08:34:43.830932   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196516 (* 1 = 0.000196516 loss)
I0621 08:34:43.830955   388 solver.cpp:473] Iteration 2130, lr = 0.01
I0621 08:34:56.103215   388 solver.cpp:213] Iteration 2131, loss = 0.000196602
I0621 08:34:56.103392   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196191 (* 1 = 0.000196191 loss)
I0621 08:34:56.103418   388 solver.cpp:473] Iteration 2131, lr = 0.01
I0621 08:35:08.416074   388 solver.cpp:213] Iteration 2132, loss = 0.000196495
I0621 08:35:08.416167   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196365 (* 1 = 0.000196365 loss)
I0621 08:35:08.416191   388 solver.cpp:473] Iteration 2132, lr = 0.01
I0621 08:35:20.662935   388 solver.cpp:213] Iteration 2133, loss = 0.000196479
I0621 08:35:20.663017   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196445 (* 1 = 0.000196445 loss)
I0621 08:35:20.663039   388 solver.cpp:473] Iteration 2133, lr = 0.01
I0621 08:35:32.895570   388 solver.cpp:213] Iteration 2134, loss = 0.00019637
I0621 08:35:32.895807   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196459 (* 1 = 0.000196459 loss)
I0621 08:35:32.895840   388 solver.cpp:473] Iteration 2134, lr = 0.01
I0621 08:35:45.194900   388 solver.cpp:213] Iteration 2135, loss = 0.000196308
I0621 08:35:45.194983   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196524 (* 1 = 0.000196524 loss)
I0621 08:35:45.195006   388 solver.cpp:473] Iteration 2135, lr = 0.01
I0621 08:35:57.419922   388 solver.cpp:213] Iteration 2136, loss = 0.000196242
I0621 08:35:57.420008   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196118 (* 1 = 0.000196118 loss)
I0621 08:35:57.420032   388 solver.cpp:473] Iteration 2136, lr = 0.01
I0621 08:36:09.701344   388 solver.cpp:213] Iteration 2137, loss = 0.000196126
I0621 08:36:09.701601   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196015 (* 1 = 0.000196015 loss)
I0621 08:36:09.701648   388 solver.cpp:473] Iteration 2137, lr = 0.01
I0621 08:36:22.034313   388 solver.cpp:213] Iteration 2138, loss = 0.000196058
I0621 08:36:22.034402   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196028 (* 1 = 0.000196028 loss)
I0621 08:36:22.034426   388 solver.cpp:473] Iteration 2138, lr = 0.01
I0621 08:36:34.307898   388 solver.cpp:213] Iteration 2139, loss = 0.000196054
I0621 08:36:34.307998   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000195865 (* 1 = 0.000195865 loss)
I0621 08:36:34.308022   388 solver.cpp:473] Iteration 2139, lr = 0.01
I0621 08:36:46.717857   388 solver.cpp:213] Iteration 2140, loss = 0.000195854
I0621 08:36:46.718041   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000195713 (* 1 = 0.000195713 loss)
I0621 08:36:46.718067   388 solver.cpp:473] Iteration 2140, lr = 0.01
I0621 08:36:59.083597   388 solver.cpp:213] Iteration 2141, loss = 0.000195808
I0621 08:36:59.083710   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000195638 (* 1 = 0.000195638 loss)
I0621 08:36:59.083757   388 solver.cpp:473] Iteration 2141, lr = 0.01
I0621 08:37:11.521929   388 solver.cpp:213] Iteration 2142, loss = 0.000195821
I0621 08:37:11.522013   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000196138 (* 1 = 0.000196138 loss)
I0621 08:37:11.522037   388 solver.cpp:473] Iteration 2142, lr = 0.01
I0621 08:37:23.837950   388 solver.cpp:213] Iteration 2143, loss = 0.000195687
I0621 08:37:23.838171   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000195956 (* 1 = 0.000195956 loss)
I0621 08:37:23.838204   388 solver.cpp:473] Iteration 2143, lr = 0.01
I0621 08:37:36.091753   388 solver.cpp:213] Iteration 2144, loss = 0.000195654
I0621 08:37:36.091843   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000195674 (* 1 = 0.000195674 loss)
I0621 08:37:36.091866   388 solver.cpp:473] Iteration 2144, lr = 0.01
I0621 08:37:48.428300   388 solver.cpp:213] Iteration 2145, loss = 0.000195567
I0621 08:37:48.428387   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000195834 (* 1 = 0.000195834 loss)
I0621 08:37:48.428409   388 solver.cpp:473] Iteration 2145, lr = 0.01
I0621 08:38:00.738204   388 solver.cpp:213] Iteration 2146, loss = 0.000195445
I0621 08:38:00.738389   388 solver.cpp:228]     Train net output #0: seg-loss = 0.000195667 (* 1 = 0.000195667 